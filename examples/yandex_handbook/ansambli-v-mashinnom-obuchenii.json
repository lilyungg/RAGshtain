[
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Смещение и разброс",
    "text": "Предположим, мы решаем задачу регрессии с квадратичной функцией потерь. При использовании квадратичной функции потерь для оценки качества работы алгоритмаможно воспользоваться следующим функционалом: где — обучающая выборка — точка из тестового множества — целевая зависимость, которую мы можем измерить с точностью до случайного шума — значение алгоритма, обученного на выборке, в точке — среднее по всем тестовым точкам и— среднее по всем обучающим выборками случайному шуму Длясуществует разложение на три компоненты — шум, смещение и разброс. Это разложение называетсяbias-variance decomposition, оно — одно из мощных средств для анализа работы ансамблей. О том, как его вывести, вы узнаете в соответствующемпараграфе, а здесь мы приведём его формулировку. Существует представлениев виде трёх компонент: где этосмещениепредсказания алгоритма в точке, усреднённого по всем возможным обучающим выборкам, относительно истинной зависимости, этодисперсия (разброс)предсказаний алгоритма в зависимости от обучающей выборки, это неустранимыйшумв данных. Раз нам известно, что ошибка алгоритма раскладывается на шум, смещение и разброс, можно подумать над способом сократить ошибку. Будет разумно попытаться сначала уменьшить одну из составляющих. Понятно, что с шумом уже ничего не сделать — это минимально возможная ошибка. Какую можно придумать процедуру, чтобы, например, сократить разброс, не увеличивая смещение? Пример приходит из жизни древних греков: если много человек проголосуют независимо друг от друга, то вместе они придут к разумному решению несмотря на то, что опыт каждого из них субъективен. Аналогом голосования в мире машинного обучения является бэггинг.",
    "useful_links": [
      {
        "text": "параграфе",
        "url": "https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition"
      }
    ]
  },
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Бэггинг",
    "text": "Идеябэггинга(bagging,bootstrap aggregation) заключается в следующем. Пусть обучающая выборка состояла изобъектов. Выберем из неёпримеров равновероятно, с возвращением. Получим новую выборку, в которой некоторых элементов исходной выборки не будет, а какие-то могут войти несколько раз. С помощью некоторого алгоритмаобучим на этой выборке модель. Повторим процедуру: сформируем вторую выборкуизэлементов с возвращением и с помощью того же алгоритма обучим на ней модель. Повторив процедурураз, получиммоделей, обученных навыборках. Чтобы получить одно предсказание, усредним предсказания всех моделей: Процесс генерации подвыборок с помощью семплирования с возвращением называетсябутстрепом(bootstrap), а моделичасто называютбазовыми алгоритмами(хотя, наверное, лучше было бы назвать их базовыми моделями). Модельназывается ансамблем этих моделей. Посмотрим, что происходит с качеством предсказания при переходе от одной модели к ансамблю. Сначала убедимся, что смещение ансамбля не изменилось по сравнению со средним смещением отдельных моделей. Будем считать, что когда мы берём матожидание по всем обучающим выборкам, то в эти выборки включены также все подвыборки, полученные бутстрепом. Получили, что смещение композиции равно смещению одного алгоритма. Теперь посмотрим, что происходит с разбросом. Если предположить, что базовые алгоритмы некоррелированы, то: Получилось, что в этом случае дисперсия композиции враз меньше дисперсии отдельного алгоритма. Пусть наша целевая зависимостьзадаётся как и к ней добавляется нормальный шум. Пример семпла из таких данных: Попробуем посмотреть, как выглядят предсказания решающих деревьев глубины 7 и бэггинга над такими деревьями в зависимости от обучающей выборки. Обучим решающие деревья 100 раз на различных случайных семплах размера 20. Возьмём также бэггинг над 10 решающими деревьями глубины 7 в качестве базовых классификаторов и тоже 100 раз обучим его на случайных выборках размера 20. Если изобразить предсказания обученных моделей на каждой из 100 итераций, то можно увидеть примерно такую картину: По этому рисунку видно, что общая дисперсия предсказаний в зависимости от обучающего множества у бэггинга значительно ниже, чем у отдельных деревьев, а в среднем предсказания деревьев и бэггинга не отличаются. Чтобы подтвердить это наблюдение, мы можем изобразить смещение и разброс случайных деревьев и бэггинга в зависимости от максимальной глубины: На графике видно, как значительно бэггинг сократил дисперсию. На самом деле, дисперсия уменьшилась практически в 10 раз, что равняется числу базовых алгоритмов (), которые бэггинг использовал для предсказания: Код для отрисовки картинок и подсчёта смещения и разброса можно найтитут.",
    "useful_links": [
      {
        "text": "тут",
        "url": "https://github.com/yandexdataschool/ML-Handbook-materials/blob/main/chapters/ensembles/bias_variance.ipynb"
      }
    ]
  },
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Random Forest",
    "text": "В предыдущем разделе мы сделали предположение, что базовые алгоритмы некоррелированы, и за счёт этого получили очень сильное уменьшение дисперсии у ансамбля относительно входящих в него базовых алгоритмов. Однако в реальной жизни добиться этого сложно: ведь базовые алгоритмы учили одну и ту же зависимость на пересекающихся выборках. Поэтому будет странно, если корреляция на самом деле нулевая. Но на практике оказывается, чтострогое выполнение этого предположения не обязательно. Достаточно, чтобы алгоритмы были в некоторой степени не похожи друг на друга. На этом строится развитие идеи бэггинга для решающих деревьев — случайный лес. Построим ансамбль алгоритмов, где базовый алгоритм — это решающее дерево. Будем строить по следующей схеме: Для построения-го дерева:Сначала, как в обычном бэггинге, из обучающей выборкивыбирается с возвращением случайная подвыборкатого же размера, что и.В процессе обучения каждого деревав каждой вершинеслучайно выбираютсяпризнаков, где— полное число признаков (метод случайных подпространств), и среди них ищется оптимальный сплит. Такой приём как раз позволяет управлять степенью скоррелированности базовых алгоритмов. Сначала, как в обычном бэггинге, из обучающей выборкивыбирается с возвращением случайная подвыборкатого же размера, что и. В процессе обучения каждого деревав каждой вершинеслучайно выбираютсяпризнаков, где— полное число признаков (метод случайных подпространств), и среди них ищется оптимальный сплит. Такой приём как раз позволяет управлять степенью скоррелированности базовых алгоритмов. Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев (для регрессии) или берём самый популярный класс (для классификации). Profit. Мы построилиRandom Forest (случайный лес)— комбинацию бэггинга и метода случайных подпространств над решающими деревьями. Внимательный читатель мог заметить, что при построении случайного леса у специалиста по машинному обучению есть несколько степеней свободы. Давайте обсудим их подробнее. Ошибка модели (на которую мы можем повлиять) состоит из смещения и разброса. Разброс мы уменьшаем с помощью процедуры бэггинга. На смещение бэггинг не влияет, а хочется, чтобы у леса оно было небольшим. Поэтому смещение должно быть небольшим у самих деревьев, из которых строится ансамбль. У неглубоких деревьев малое число параметров, то есть дерево способно запомнить только верхнеуровневые статистики обучающей подвыборки. Они во всех подвыборках будут похожи, но будут не очень подробно описывать целевую зависимость. Поэтому при изменении обучающей подвыборки предсказание на тестовом объекте будет стабильным, но не точным (низкая дисперсия, высокое смещение). Наоборот, у глубоких деревьев нет проблем запомнить подвыборку подробно. Поэтому предсказание на тестовом объекте будет сильнее меняться в зависимости от обучающей подвыборки, зато в среднем будет близко к истине (высокая дисперсия, низкое смещение). Вывод: используем глубокие деревья. Ограничивая число признаков, которые используются в обучении одного дерева, мы также управляем качеством случайного леса. Чем больше признаков, тем больше корреляция между деревьями и тем меньше чувствуется эффект от ансамблирования. Чем меньше признаков, тем слабее сами деревья. Практическая рекомендация — брать корень из числа всех признаков для классификации и треть признаков для регрессии. Выше было показано, что увеличение числа элементарных алгоритмов в ансамбле не меняет смещения и уменьшает разброс. Так как число признаков и варианты подвыборок, на которых строятся деревья в случайном лесе, ограничены, уменьшать разброс до бесконечности не получится. Поэтому имеет смысл построить график ошибки от числа деревьев и ограничить размер леса в тот момент, когда ошибка перестанет значимо уменьшаться. Вторым практическим ограничением на количество деревьев может быть время работы ансамбля. Однако есть положительное свойство случайного леса: случайный лес можно строить и применять параллельно, что сокращает время работы, если у нас есть несколько процессоров. Но процессоров, скорее всего, всё же сильно меньше числа деревьев, а сами деревья обычно глубокие. Поэтому на большом числе деревьев Random Forest может работать дольше желаемого и количество деревьев можно сократить, немного пожертвовав качеством.",
    "useful_links": []
  },
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Бустинг",
    "text": "Бустинг (boosting)— это ансамблевый метод, в котором так же, как и в методах выше, строится множество базовых алгоритмов из одного семейства, объединяющихся затем в более сильную модель. Отличие состоит в том, что в бэггинге и случайном лесе базовые алгоритмы учатся независимо и параллельно, а в бустинге — последовательно. Каждый следующий базовый алгоритм в бустинге обучается так, чтобы уменьшить общую ошибку всех своих предшественников. Как следствие, итоговая композиция будет иметь меньшее смещение, чем каждый отдельный базовый алгоритм (хотя уменьшение разброса также может происходить). Поскольку основная цель бустинга — уменьшение смещения, в качестве базовых алгоритмов часто выбирают алгоритмы с высоким смещением и небольшим разбросом. Например, если в качестве базовых классификаторов выступают деревья, то их глубина должна быть небольшой — обычно не больше 2-3 уровней. Ещё одной важной причиной для выбора моделей с высоким смещением в качестве базовых является то, что такие модели, как правило, быстрее учатся. Это важно для их последовательного обучения, которое может стать очень дорогим по времени, если на каждой итерации будет учиться сложная модель. На текущий момент основным видом бустинга с точки зрения применения на практике являетсяградиентный бустинг, о котором подробно рассказывается в соответствующемпараграфе. Хотя случайный лес — мощный и достаточно простой для понимания и реализации алгоритм, на практике он чаще всего уступает градиентному бустингу. Поэтому градиентный бустинг сейчас — основное продакшн-решение, если работа происходит с табличными данными (в работе с однородными данными — картинками, текстами — доминируют нейросети).",
    "useful_links": [
      {
        "text": "параграфе",
        "url": "https://academy.yandex.ru/handbook/ml/article/gradientnyj-busting"
      }
    ]
  },
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Стекинг",
    "text": "Стекинг (stacking)— алгоритм ансамблирования, основные отличия которого от предыдущих состоят в следующем: он может использовать алгоритмы разного типа, а не только из какого-то фиксированного семейства. Например, в качестве базовых алгоритмов могут выступать метод ближайших соседей и линейная регрессия результаты базовых алгоритмов объединяются в один с помощью обучаемой мета-модели, а не с помощью какого-либо обычного способа агрегации (суммирования или усреднения) Обучение стекинга проходит в несколько этапов: общая выборка разделяется на тренировочную и тестовую тренировочная выборка делится нафолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации: на каждом шаге фиксируютсяфолдов для обучения базовых алгоритмов и один — для их предсказаний (вычисления мета-факторов). Такой подход нужен для того, чтобы можно было использовать всё тренировочное множество, и при этом базовые алгоритмы не переобучались на полученных мета-факторах обучается мета-модель. Кроме мета-факторов, она может принимать на вход и фичи из исходного датасета. Выбор зависит от решаемой задачи Для получения мета-факторов на тестовом множестве базовые алгоритмы можно обучить на всём тренировочном множестве — переобучения в данном случае возникнуть не должно. Если данных достаточно много, то можно просто разделить обучающие данные на две непересекающиеся части: ту, на которой учатся базовые алгоритмы, и ту, на которой они делают свои предсказания и обучается мета-модель. Использование такого простого разбиения вместо кросс-валидации на тренировочных данных иногда называютблендингом (blending). Если данных совсем много, то тестовое множество тоже можно разделить на две части: тестовую и валидационную, и использовать последнюю для подбора гиперпараметров моделей-участников. С точки зрения смещения и разброса стекинг не имеет прямой интерпретации, так как не минимизирует напрямую ни ту, ни другую компоненту ошибки. Удачно работающий стекинг просто уменьшает ошибку, и, как следствие, её компоненты тоже будут убывать.",
    "useful_links": []
  },
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Почитать по теме",
    "text": "ЛекцияЕвгения Соколова про bias-variance decomposition и бэггинг Блог-постпро ансамбли от Joseph Rocca Блог-постпро стекинг и блендинг от Steven Yu",
    "useful_links": [
      {
        "text": "Лекция",
        "url": "https://github.com/esokolov/ml-course-hse/blob/master/2020-fall/lecture-notes/lecture08-ensembles.pdf"
      },
      {
        "text": "Блог-пост",
        "url": "https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205"
      },
      {
        "text": "Блог-пост",
        "url": "https://medium.com/@stevenyu530_73989/stacking-and-blending-intuitive-explanation-of-advanced-ensemble-methods-46b295da413c"
      }
    ]
  }
]