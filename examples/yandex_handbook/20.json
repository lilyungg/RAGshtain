[
  {
    "document_title": "Диффузионные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/diffuzionnye-modeli",
    "section_title": "Введение",
    "text": "В этом параграфе мы снова попробуем решить задачу генерации, когда нам дана выборка объектов из распределения, и хотим научиться генерировать новые объекты из распределения , которых нет в нашей выборке. Вероятно, вы уже знакомы с другими генеративными моделями, например VAE или GAN-ы. Здесь же мы познакомим вас с еще одним видом генеративных моделей:диффузионные модели, которые стали крайне популярны в последнее время благодаря своему высокому качеству генерации объектов из заданного распределения. В общий чертах, они работают следующим образом: берем шум изи шаг за шагом удаляем компоненты шума до тех пор, пока не получим объектиз распределения, см. иллюстрацию ниже.",
    "useful_links": []
  },
  {
    "document_title": "Диффузионные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/diffuzionnye-modeli",
    "section_title": "Более детально",
    "text": "Для детального понимания стоит объяснить, что такоепрямой и обратный диффузионные процессы.Прямойпроцесс заключается в постепенном зашумлении картинки с помощью распределения, аобратный, наоборот, в расшумлении с помощью распределения. Их можно схематично изобразить следующим образом: Прямойдиффузионный процесс определяется как апостериорное распределение. Это распределение также является Марковской цепочкой, которая постепенно добавляет гауссовский шум к объекту. На каждом шаге шум добавляется с различной магнитудой, которая определяется расписанием дисперсий. При правильном выборе расписания в пределе по числу шаговмы должны сойтись к шуму из. В качестве распределенийберут нормальные распределения: Теперь перейдем кобратномупроцессу и к самойдиффузионной модели. Диффузионная модель- это вероятностная модель с латентными переменными вида, где промежуточные состояниясоответствуют зашумленным объектам, a- объект из распределения. Совместное распределениеназываетобратным диффузионным процессом, который представляет собой Марковскую цепочку из гауссовских распределений: Таким образом, обратный процесс параметризуется моделью, которая по зашумленному объектуи шагупредсказывает среднееи дисперсию.",
    "useful_links": []
  },
  {
    "document_title": "Диффузионные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/diffuzionnye-modeli",
    "section_title": "Обучение диффузионной модели",
    "text": "Диффузионный модели обучаются, максимизируя вариационную нижнюю оценку (ELBO) логарифма правдоподобия. По тому же принципу обучаются VAE, с тем лишь отличием, что у диффузионных моделей другая форма модели с латентными переменными. Итак, давайте выведем ELBO для диффузии: Комментарий Если вы знакомы с VAE, то выводдолжен быть вам понятен, однако ниже приведен вывод с помощью неравенства Йенсена Теперь вернемся к распределению. Для того чтобы получить, придется итеративно получать. Однако это можно сделать более эффективно благодаря нормальным распределениям. Для этого обозначими, тогда Формальный вывод этого факта (*) Пояснение ко второму переходу. У нас выходит Тогдаможет быть переписано как Долгий вывод Серым в скобках комментарий к последующему переходу. Пояснение (*). Пользуемся тем, что у нас Марковский процесс, и теоремой Байеса: Таким образом во время обучения, на каждой итерации параллельно оптимизируются случайные членс помощью градиентного спуск (сэмлируем). Поскольку все распределения нормальные, то KL между ними можно выписать в явной форме (см. ниже). Формула KL между двумя нормальными Если Осталось только выписать. Мы знаем, поскольку у нас все распределения нормальные, то ибудет нормальным. Обозначим Вывод Применим формулу Байеса и распишем. Тут мы просто пытаемся понять, как будут выглядеть среднее и дисперсия, выделяя квадратичную форму в показателе экспоненты Далее перепишем красные и синие выражения в более красивой форме В прошлой подсекции наша модель предсказывала среднее и дисперсию нормального распределения. Давайте зафиксируем. Обычно берутилиТогдаиз предыдущей секции можно переписать как Это первый момент, как меняется функционал, если мы не хотим предсказывать, а фиксируем её. Теперь вспомним, что, но благодаря тому, что у нас гауссовское распределение, это можно переписать в виде Выразим отсюдаи получим, что, тогда подставим это выражение в формулу для(из подсекции «Вывод») и получим Теперь скажем, что наша модель будет предсказывать. И просто будем «подставлять» его в выражение длявыше. Обозначим предсказание модели как— предсказанный шум. Тогда лосспревратиться в Тем не менее лосс можно еще больше упростить и просто обучать с помощью MSE на. Итак, алгоритмы обучения и сэмплирования выглядят вот так (на картинке). Стоит отметить, что важным недостатком диффузионных моделей является низкая скорость сэмплирования. СогласноSong et al. 2020: «Требуется 20 часов на генерацию 50 тысяч картинок размера 32х32, используя DDPM, и меньше минуты, используя GAN» (Nvidia 2080 Ti GPU). Тем не менее, в данном направлении был достигнут значительный прогресс и в целом проблема медленного сэмплирования была частично решена:Jiaming Song et al. (2021),Kong &Ping (2021),Bond-Taylor et al. (2021) Давайте зафиксируем, какие функции потерь можно использовать. Для всех них справедлив тот факт, что мы сэмплируем шаг равномерно во время обучениеи оптимизируем соответствующий. Оптимизируя член из суммы. Это KL дивергенция между двумя нормальными распределениями При фиксированной дисперсииможно оптимизировать взвешенную MSE между средними нормальных распределений При фиксированной дисперсии и при предсказании шума с помощью взвешенной MSE. Или просто MSE.являетсясамым популярнымвариантом, который на практике дает лучшие результаты. Расписание является гиперпараметром, основными требованиями на который являются невозрастаниеи чтобы прямой процесс сходился кв пределе по. Второе может гарантироваться тем, что. Вспомним, Однако на практикеонотакже проверяется, чтобыбыло близко к 0. Также стоит упомянуть, что обычно берут. Но также важно помнить про требования выше, ведь расписание шума непосредственно зависит от. Чаще всего используют линейное расписание, где. У данных констант нет никакой мотивации, кроме той, которая описана выше. Они были предложены вHo et al. (2020). ВNichol &Dhariwal (2021)было предложено косинусное расписание, которое помогло диффузионным моделям достичь лучшего NLL (negative loglikelihood): Авторы обнаружили, что линейное расписание плохо работает на картинках 64х64 и меньше. А именно, последнии шаги прямого прохода были шумными и малоинформатиыными (просто зашумляем шум еще больше): Также они обнаружили, что если обучать модель с линейным расписанием только на 80% первых шагов, то модель не становится сильно хуже, что подтверждает неиформативность последних шагов. Далее, они подобрали расписание так, чтобыубывало линейно на большей части отрезка (от 0 до) и почти не менялось рядом с 0 и. Разницу вдля разных расписаний можно увидеть на картинке ниже: Детали Также они ограничиваютчислом 0.999, чтобы в конце процесса не было проблем с численной устойчивостью. Коэффициентиспользуется, чтобыне были слишком малы рядом с нулем. Он равен 0.008. Такое число было выбрано так, чтобы «была немного меньше, чем размер бина одного пикселя, то есть» ВNichol &Dhariwal (2021)был предложен метод условной генерации, который повышает качество генерируемых картинок, при этом уменьшая их разнообразие. Для этого предобучается «шумный» классификатор на зашумленных картинках, то есть. Затем он используется во время сэмплирования, корректируя предсказанное среднее на. ВNichol &Dhariwal (2021)(Секция 4.1) показывают, что данная добавка позволяет превратить распределениев. Важно, что исходная диффузионная модель никак не меняется, что делает трюк еще более привлекательным. Алгоритм сэмплирования можно видеть на картинке ниже. Коэффициентотвечает за силу guidance. МотивацияУ генеративной модели GAN есть способ, который позволяет «балансировать» между разнообразием картинок и их качеством —truncation trick.Он заключается в сэмплировании латентного вектораtruncated normal distibution. Данный трюк был хорошо описан и исследован в статье проBigGAN. Поэтому в диффузионных моделях тоже хотелось бы иметь метод, который позволяет балансировать между качеством и разнообразием. Авторы предложили classifier guidance, сравнили его сtruncation trickи показали, что их метод строго лучше. Ho &Salimans (2021)предложили метод, в котором guidance достигается без использования дополнительной модели, поскольку это достаточно затратно. Для этого они обучали условную модель, у которой во время обучения реальная метказаменялась с какой-то фиксированной вероятностью (10%) на пустую метку (). Это по сути позволяет нам обучать безусловную модельодновременно с условнойТогда во время сэмплирования делаем так, чтобы предсказание немного менялось в сторону, а именно: Мотивация этой формулы следовала из формулы Байеса: Тогда мы можем просто подставитьв формулу для classifier guidance из предыдущей подсекции и получить желаемое равенство с точностью до коэффициента.",
    "useful_links": [
      {
        "text": "Song et al. 2020",
        "url": "https://arxiv.org/abs/2010.02502"
      },
      {
        "text": "Jiaming Song et al. (2021)",
        "url": "https://arxiv.org/abs/2010.02502"
      },
      {
        "text": "Kong &Ping (2021)",
        "url": "https://openreview.net/pdf?id=agj4cdOfrAP"
      },
      {
        "text": "Bond-Taylor et al. (2021)",
        "url": "https://arxiv.org/abs/2111.12701"
      },
      {
        "text": "оно",
        "url": "https://arxiv.org/abs/2006.11239"
      },
      {
        "text": "Ho et al. (2020)",
        "url": "https://arxiv.org/abs/2006.11239"
      },
      {
        "text": "Nichol &Dhariwal (2021)",
        "url": "https://arxiv.org/abs/2102.09672"
      },
      {
        "text": "Nichol &Dhariwal (2021)",
        "url": "https://arxiv.org/pdf/2105.05233.pdf"
      },
      {
        "text": "Nichol &Dhariwal (2021)",
        "url": "https://arxiv.org/pdf/2105.05233.pdf"
      },
      {
        "text": "truncated normal distibution",
        "url": "https://en.wikipedia.org/wiki/Truncated_normal_distribution"
      },
      {
        "text": "BigGAN",
        "url": "https://arxiv.org/abs/1809.11096"
      },
      {
        "text": "Ho &Salimans (2021)",
        "url": "https://openreview.net/pdf?id=qw8AKxfYbI"
      }
    ]
  },
  {
    "document_title": "Диффузионные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/diffuzionnye-modeli",
    "section_title": "Овервью ключевых работ на сегодняшний день",
    "text": "Jonathan Ho et al.«Denoising diffusion probabilistic models.»arxiv Preprint arxiv:2006.11239 (2020) Основная работа, в которой диффузионные модели (Denoising Diffusion Probabilistic Models, DDPMs) были применены для генерации картинок. Параграф в основном построен на ней. Jiaming Song et al.«Denoising diffusion implicit models.»arxiv Preprint arxiv:2010.02502 (2020) Одна из первых попыток ускорить генерацию объектов. Идея следущая: давайте изменим прямой диффузионный процесс так, чтобы используя предобученную DDPM, приближать новый обратный процесс за меньшее число шагов. Чтобы не обучать новую модель, нам нужен прямой диффузионный процесс, у которого будет такая же (суррогатная) функция потерь, а обратный процесс все еще останется Марковским. Оказалось, что существует целое семейство не-Марковских прямых процессов, удовлетворяющих этим требования. Это семейство имеет следующий вид: гдеи для всех Среднее было выбрано так, чтобыдля всех. (см. Лемму 1 в Приложении B к статье). То есть важно лишь то, чтобы маргинальное распределениене менялось по сравнению с обычным Марковским случаем. Прямой процесс может быть получен с помощью теоремы Байеса: Тутконтролирует степень стохастичности прямого процесса. Можно заметить, что в отличии от исходного диффузионного процесса, предложенный прямой процесс больше не является Марковским, так как каждыйтеперь зависит и оти от. Схематично, это можно изобразить как на картинке справа. (Слева исходный диффузионный процесс для сравнения) ЗаметкаАвторы обращают внимание, что функция потерь в DDPM зависит от, а не отнапрямую. Это означает, что нам нужно выбрать любой другой прямой диффузионный процесс, у которогоостались те же. Далее, мы можем переписать обратный процесс в данном виде: Заметим, что припрямой процесс становится марковским, а обратный как у DDPM (обычное сэмплирование, описанное в основной секции). Припроцесс сэмплирования становится детерминистичным (данный способ и называется DDIM). Ускорение сэмплирования достигается засчет использования лишь какого-то подмножества шагов (). Также одним из плюсов детерминистичного сэмплирования является возможность делать семантическую интерполяцию в латентном пространстве (как у GANов). Alex Nichol &Prafulla Dhariwal.«Improved denoising diffusion probabilistic models»arxiv Preprint arxiv:2102.09672 (2021) Улучшение DDPM, в котором был предложен новое расписание шума, что улучшило NLL. Также был изучен вариант, в котором дисперсияпредсказывается моделью. Prafula Dhariwal &Alex Nichol.«Diffusion Models Beat GANs on Image Synthesis.»arxiv Preprint arxiv:2105.05233 (2021). Статья, в которой показывается, что DDPM могут генерировать более качественные картинки по сравнению с GANами. Также был предложен метод conditional сэмплирования. Для этого предобучается классификатор на зашумленных сэмплах, а во время сэмплирования среднее нормального распределения «корректируется» на градиент классификатора. Jacob Austin et al.«Structured Denoising Diffusion Models in Discrete State-Spaces».arXiv:2107.03006 (2021) Диффузионные модели на дискретных данных (например, текст). Вместо нормальных распределений используются категориальные. Также была обобщенамультиномиальная диффузияс помощью «матриц перехода», которые задают способ зашумления дискретных данных. Более подробно: у нас есть— дискретная величина на всех шагах диффузии, тогда для каждого шагаопределенаматрица прямого переходатакая, что. То есть строки матрицы суммируются в единицу. Тогда если обозначить черезone-hot-закодированную версию, то прямой процесс можно описать через категориальные распределения: Как и в нормальных распределениях, можем выписать Поскольку тут нет такой хорошей параметризации через, как у нормальных распределений, то единственный способ обучать — с помощью KL дивергенции (членами). Остается только понять, как выбирать. Помимо того, чтобы сумма в каждой строчке была один, требуется, чтобысходилось (при) к равномерному распределению в каждой строчке (аналог нормального шума). За конкретными примерами стоит обратиться к статье. Серия работ про text-conditional diffusions:GLIDE,ImaGen,DALLE-2 Опишем работу метода GLIDE. Стоит задача генерировать картинки по заданному текстовому описанию. Для этого используется classifier-free guided diffusion model илиCLIP. Это два разных варианта модели, которые авторы сравнивают. В первом случае модель обуславливается на эмбеддинги текста, которые были получены из обучаемого трансформера. Во втором случае guidance осуществляется за счет(это по сути градиент лосса метода CLIP) . Тут— это картиночный энкодер (на зашумленных картинках), а— это энкодер текстового входа. В целом, авторы получили, что classifier-free guidance генерирует более качественные картинки. Song et al.«Score-Based Generative Modeling through Stochastic Differential Equations» Способ описать диффузионные модели через стохастические дифференциальные уравнения. What are Diffusion Models?. Прекрасный блог от Lilian Weng (OpenAI).",
    "useful_links": [
      {
        "text": "«Denoising diffusion probabilistic models.»",
        "url": "https://arxiv.org/abs/2006.11239"
      },
      {
        "text": "«Denoising diffusion implicit models.»",
        "url": "https://arxiv.org/abs/2010.02502"
      },
      {
        "text": "«Improved denoising diffusion probabilistic models»",
        "url": "https://arxiv.org/abs/2102.09672"
      },
      {
        "text": "«Diffusion Models Beat GANs on Image Synthesis.»",
        "url": "https://arxiv.org/abs/2105.05233"
      },
      {
        "text": "«Structured Denoising Diffusion Models in Discrete State-Spaces»",
        "url": "https://arxiv.org/abs/2107.03006"
      },
      {
        "text": "мультиномиальная диффузия",
        "url": "https://arxiv.org/abs/2102.05379"
      },
      {
        "text": "GLIDE",
        "url": "https://arxiv.org/pdf/2112.10741.pdf"
      },
      {
        "text": "ImaGen",
        "url": "https://arxiv.org/pdf/2205.11487.pdf"
      },
      {
        "text": "DALLE-2",
        "url": "https://cdn.openai.com/papers/dall-e-2.pdf"
      },
      {
        "text": "CLIP",
        "url": "https://openai.com/blog/clip/"
      },
      {
        "text": "«Score-Based Generative Modeling through Stochastic Differential Equations»",
        "url": "https://openreview.net/forum?id=PxTIG12RRHS"
      },
      {
        "text": "What are Diffusion Models?",
        "url": "https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#reverse-diffusion-process"
      }
    ]
  }
]