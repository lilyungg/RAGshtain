[
  {
    "document_title": "Машинное обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/mashinnoye-obucheniye",
    "section_title": "Критерии качества",
    "text": "По обучающей выборке мы хотим построить модель, предсказания которой достаточно хороши. Что вообще значит «достаточно хороши»? Не понимая, чего мы хотим добиться, мы не предложим хорошего решения, поэтому нужно внимательно отнестись к выборуметрик качества. Возможно, вы уже участвовали в соревнованиях по анализу данных. На таких соревнованиях метрику организатор выбирает за вас, и она, как правило, непосредственным образом связана с результатами предсказаний. Но на практике всё бывает намного сложнее. Например, мы хотим: решить, сколько коробок с бананами нужно завтра привезти в конкретный магазин, чтобы минимизировать количество товара, который не будет выкуплен, и минимизировать вероятность того, что покупатель к концу дня не найдёт желаемый продукт на полке; увеличить счастье пользователей от работы с нашим сервисом, чтобы пользователи стали лояльнее, а сервис мог получать стабильный прогнозируемый доход; решить, нужно ли направить пациента на дополнительное медицинское обследование. В каждом конкретном случае может возникать целая иерархия метрик. Самый верхний уровень – этобизнес-метрики, например, будущий доход сервиса. Их трудно измерить в моменте, они сложным образом зависят от совокупности всех наших усилий, не только связанных с машинным обучением. Онлайн(online)метрики– это характеристики работающей системы, с помощью которых мы надеемся оценить, что будет с бизнес-метриками. Например, это может быть:– Медианная длина сессии в онлайн-игре. Можно предположить, что пользователь, который долго сидит в игре – это довольный пользователь.– Среднее количество бананов на полках во всех магазинах торговой сети в конце дня. Не всегда плоды наших трудов оцениваются числами. Многое может зависеть от субъективного восприятия людей, и для того, чтобы оценить их реакцию до выпуска в продакшен, применяется оценка специально нанятыми людьми – асессорами. Например, так можно оценивать, получилось ли у нас улучшить качество машинного перевода или релевантность выдачи в поисковой системе. Офлайн(offline)метрикимогут быть измерены до введения модели в эксплуатацию, например, по историческим данным. В задачах, в которых нужно предсказывать какой-то конкретный таргет, офлайн метрики обычно оценивают отклонение предсказаний модели от истинных значений таргета. Например, это может быть точность предсказания, то есть число верно угаданных значений, или среднеквадратичное отклонение. Асессорскую оценку тоже можно считать офлайн-метрикой В этой книге речь в основном пойдёт об офлайновых метриках и о функциях потерь. И прежде, чем вы начнёте знакомиться с методами решения задач обучения с учителем, полезно посмотреть, какими бывают метрики качества. Вот несколько примеров: для задачи постановки диагноза хорошими метриками могут быть, например, доля правильно поставленных диагнозов или доля больных, которым удалось поставить правильный диагноз (а вы поняли разницу?); для задачи предсказания цены квартиры метрикой качества может быть доля квартир, для которых разница между предсказанным и истинным значением цены не превысила какого-то порога, или средний модуль разницы между предсказанным и истинным значением; для задачи ранжирования поисковых документов по запросу — доля пар документов, которые мы упорядочили неправильно. Цель обычно в том, чтобы найти модель, для которой значение метрики будет оптимальным. Вопрос на подумать.Важно помнить, что разные нужды заказчика могут диктовать самые разные метрики. Вернёмся к задаче постановки диагноза пациентам больницы. Какие метрики вы предложили бы использовать в каждом из следующих случаев: обычный год в обычном терапевтическом отделении обычной больницы; определение очень неприятной болезни, которая жутким клеймом падёт на каждого, кому поставили такой диагноз; определение опасной и очень заразной болезни. Вопрос на подумать.Рассмотрим задачу детектирования людей на изображении. Чаще всего под детектированием понимают указание местоположения человека на картинке. Например, модель пытается выделить прямоугольник, в котором, по её мнению, есть человеческая фигура. Подумайте, какие метрики можно было бы использовать в различных ситуациях для измерения качества решения этой задачи. Не забудьте, что метрики — это способ численно измерить то, насколько модель помогает нам в жизни, так что важно думать о том, зачем нам вообще детектировать людей. Критерии качества не всегда сводятся к метрикам. Бизнес или общество могут накладывать и другие требования, например: Модель может выдавать предсказания в режиме реального времени. Заметим, что это требование не только к модели, но и к её реализации, а также к тому железу или к тем серверам, на которых она работает. Модель достаточно компактна, чтобы помещаться на мобильном телефоне или другом устройстве. Можно объяснить, на основании чего модель сделала то или иное предсказание для конкретного объекта. Это может быть важным в случае, если модель решает что-то важное в жизни человека, например, дадут ли кредит или будет ли согласовано дорогостоящее лечение. Такое требование является частным случаем более общего понятия интерпретируемости модели. Предсказания модели не дискриминируют какую-либо категорию пользователей. Например, если двум людям с одинаковой и достаточно длинной историей просмотров онлайн-кинотеатр рекомендует разные фильмы только из-за того, что у них разный пол, то это не здорово.",
    "useful_links": []
  },
  {
    "document_title": "Машинное обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/mashinnoye-obucheniye",
    "section_title": "Данные",
    "text": "Машинное обучение начинается с данных. Важно, чтобы их было достаточно много и чтобы они были достаточно качественными. Некоторые проекты приходится откладывать на неопределённый срок из-за того, что просто невозможно собрать данные. Чем сложнее задача, тем больше данных нужно, чтобы её решить. Например, существенные успехи в задачах распознавания изображений были достигнуты лишь с появлением очень больших датасетов (и, стоит добавить, вычислительных мощностей). Вычислительные ресурсы продолжают совершенствовать, но во многих ситуациях размеченных данных (то есть объектов, которым кто-то сопоставил ответ) было бы по-прежнему слишком мало: например, для решения задачи аннотирования изображений (image captioning) потребовалось бы огромное количество пар (изображение, описание). В некоторых случаях можно воспользоваться открытыми датасетами. Сейчас их доступно довольно много и некоторые весьма велики, но чаще всего они создаются для довольно простых задач, например, для задачи классификации изображений. Иногда датасет можно купить. Но для каких-то задач вы нигде не найдёте данных. Скажем, авторам неизвестно больших и качественных корпусов телефонных разговоров с расшифровками – в том числе и по причинам конфиденциальности таких данных. Бороться с проблемой нехватки данных можно двумя способами. Первый – использованиекраудсорсинга, то есть привлечение людей, готовых разметить много данных. Во многих ситуациях (например, когда речь заходит об оценке поисковой выдачи) без дополнительной разметки никак не обойтись. Мы расскажем про краудсорсинг подробнее в соответствующем параграфе. Некоторые проекты, в первую очередь научные и социальные, используют такжеcitizen science– разметку данных волонтёрами без какого-либо вознаграждения, просто за чувство причастности к доброму делу исследования животных Африки или формы галактик. Второй же способ состоит в использовании неразмеченных данных. К примеру, в задаче аннотирования изображений у нас есть огромное количество никак не связанных друг с другом изображений и текстов. Однако, мы можем использовать их для того, чтобы помочь компьютеру понять, какие слова в принципе могут стоять рядом в предложении. Подходы, связанные с использованием неразмеченных данных для решения задач обучения с учителем, объединяются терминомself-supervised learningи очень активно используются сейчас. Важной составляющей являетсяобучение представлений(representation learning) — задача построения компактных векторов небольшой размерности из сложных по структуре данных, например, изображений, звука, текстов, графов, так, чтобы близкие по структуре или семантике данные получали метрически близкие представления. Делать это можно разными способами — например, используя фрагменты моделей, обученных для решения какой-либо другой задачи, или строя модель, предсказывающую скрытую часть объекта по оставшейся его части — например, пропущенное слово в предложении. Этому будет посвященотдельный параграфнашего учебника. Но кроме количества данных важно ещё и то, насколько они хороши и удобны для анализа. Давайте разберёмся, что это значит и какие с этим бывают проблемы. Для работы с объектом модель должна опираться на какие-то его свойства, например, доход человека, цвет левого верхнего пикселя на изображении или частоту встречаемости слова «интеграл» в тексте. Эти свойства обычно называютсяпризнаками, а совокупность свойств, которые мы выделили у объекта – егопризнаковым описанием. Вот несколько простых и распространённых разновидностей признаков: Численные– например, рост или доход. Иногда отдельно выделяют вещественные и целочисленные признаки. Категориальныепризнаки принимают значения из некоторого дискретного множества. Например, профессия человека или день недели. Бинарные признакипринимают два значения:иили «да» и «нет». С ними можно работать и как с численными, и как с категориальными. Среди категориальных признаков иногда выделяютординальные. Они принимают значения из некоторогоупорядоченногодискретного множества. Например, класс опасности химического вещества (бывает от 1-го до 4-го) или год обучения для студента являются ординальными. Приходится иметь дело и с более сложно устроенными признаками. Например, описание ресторана может содержать тексты отзывов или фотографии, а профиль человека в социальной сети – список его друзей. Для многих однородных типов данных, таких как изображения, видео, тексты, звук, графы, разработано большое количество методов извлечения признаков – сейчас в первую очередь нейросетевых. О них вы сможете прочитать в разделах про нейросетевые архитектуры для соответствующих типов данных. Если же попадаются какие-то более сложно устроенные данные, могут потребоваться дополнительные усилия для извлечения из них признаков – этот процесс называютfeature engineering. Удобно бывает записать данные в виде таблицы, строки которой соответствуют объектам, а столбцы – признакам. Например: Данные, представленные в таком виде, называютсятабличными. Табличные данные – один из самых удобных для анализа форматов. Свои успешные пайплайны работы есть также для уже упомянутых текстов, звука, изображений, видео, графов. Лучше всего, если все признаки являются численными. Тогда с таблицей можно работать как с объектом линейной алгебры –матрицей объекты-признаки. Создание информативного признакового описания очень важно для дальнейшего анализа. Но нужно также следить за качеством полученных данных. Вам могут встретиться, например, следующие проблемы: Пропуски(пропущенные значения). Так, в примере табличных данных выше нам неизвестен возраст Васи. Объекты или признаки, в которых есть пропуски, можно удалять из выборки, но если пропусков довольно много, мы можем потерять таким образом слишком много информации. Кроме того, наличие пропуска само по себе может нести информацию: скажем, это может говорить о систематической проблеме в сборе данных для того или иного сегмента выборки. Некоторые модели, например, решающие деревья, обладают собственными средствами для работы с пропусками, другие же – например, линейные модели или нейросети – требуют, чтобы пропуски были вычищены или заменены на что-то. Выбросы, то есть объекты, которые резко отличаются от большинства остальных. Например, в датасете с информацией о клиентах банка 140-летний человек, очевидно, будет весьма нетипичным. Выбросы могут возникать из-за ошибок при сборе данных или представлять собой реально существующие аномалии. Обычно выбросы лучше удалять, но в некоторых случаях выбросами могут быть важные объекты (например, очень богатые клиенты банка), и тогда их, возможно, стоит отлавливать и обрабатывать отдельно. Ошибки разметки. Если, например, вы собираете данные с помощью разметчиков-людей, то вы должны быть готовы к тому, что часть таргетов будет отмечена неправильно. Даже если не думать о том, что не все из разметчиков совершенно честные и старательные, задача может оказаться для них сложной. Data drift. С течением времени данные могут меняться. Например, может измениться схема сбора данных, и они начнут приходить в формате, который вообще не обрабатывается моделью. Или же может поменяться распределение данных: скажем, если вы делали образовательный сервис для студентов, а к вам стали приходить и более зрелые люди. Data drift – это суровая реальность для любой системы, которая решает не сиюминутную задачу, поэтому нужно уметь мониторить распределение данных и, если нужно, обновлять модель. Встречаются и другие проблемы. Нередко существенную часть данных приходится выкидывать, потому что в процессе сбора что-нибудь сломалось или потому, что полгода назад в сервисе изменили систему логирования и более старые данные невозможно склеить с более новыми.",
    "useful_links": [
      {
        "text": "отдельный параграф",
        "url": "https://academy.yandex.ru/handbook/ml/article/obuchenie-predstavlenij"
      }
    ]
  },
  {
    "document_title": "Машинное обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/mashinnoye-obucheniye",
    "section_title": "Модель и алгоритм обучения",
    "text": "Модель — это некоторый способ описания мира. Например, «Земля плоская» — это модель, и не такая плохая, как вам может показаться. Ей активно пользуются, когда всё происходит в масштабах одного города и кривизной поверхности можно пренебрегать. С другой стороны, если мы попробуем рассчитать кратчайший путь из Парижа в Лос-Анджелес, модель плоской Земли выдаст неадекватный ответ, она войдёт в противоречие с имеющимися данными, и её придётся заменить на «Земля круглая», «Земля имеет форму эллипсоида» и так далее — в той мере, в которой нам важна точность и в какой нам это позволяет (не)совершенство измерительной техники. Так, модель «Земля — это похожая на геоид с шершавостями на месте горных хребтов» очень точная и замечательная, но, возможно, будет избыточно сложной для большинства практических задач и при этом слишком тяжёлой в плане вычислений. В первых параграфах мы будем рассматривать в основном предсказательные модели, то есть модели вида, которые пытаются уловить зависимость между признаковым описаниемобъекта и таргетом. Но порой мы будем иметь дело и с моделями данных: например, «такой-то признак имеет нормальное распределение». Чаще всего предсказательные модели мы будем брать из некоторого параметрического семейства, где— параметры, которые мы будем подбирать по данным. Для примера давайте возьмём задачу предсказания цены квартиры. В качестве класса моделей выберем константные функции(то есть будем для всех квартир предсказывать одно и то же значение цены). Поскольку значение не зависит от, нам не очень важно, в каком виде получено признаковое описание: это может быть набор совершенно любых сведений о квартире. Не забудем зафиксировать метрику качества —среднее абсолютное отклонение(mean absolute error, она жеMAE). где— это модель (та самая,),— обучающие примеры (данные о квартирах, которые мы смогли достать),— правильные ответы (то есть цены на известные нам квартиры). Чтобы найти минимум MAE, возьмём производную от выражения и приравняем её к нулю: Нам подходят точки, для которых число, строго меньших, равно числу, строго больших. Таким образом, нам подходитмедиананабора: Вопрос на подумать.Давайте теперь в задаче предсказания цены квартиры рассмотрим метрикусреднеквадратичное отклонение(MSE): Каким будет оптимальное значение параметрадля константной модели? Прекрасно, значит, в классе константных функций мы можем найти оптимальную модель. Может быть, это можно сделать и в каком-нибудь более интересном классе? Этому вопросу и будет посвящена большая часть нашей книги. Классический курс ML состоит из описания классов моделей и способов работы с ними. Несмотря на то что для решения большинства практических задач на сегодня достаточно знать только два типа моделей —градиентный бустинг на решающих деревьяхинейросетевые модели— мы постараемся рассказать и про другие, чтобы развить у вас глубинное понимание предмета и дать возможность не только использовать лучшие сложившиеся практики, но и, при вашем желании, участвовать в проработке новых идей и поиске новых методов — уже в роли исследователя, а не просто инженера. Кроме выбора модели важен также выборалгоритма обучения. Алгоритм обучения — это процедура, которая превращает обучающую выборку в обученную модель. Скажем, в примере выше для константной модели мы в качестве алгоритма обучения использовали поиск нуля градиента. Как мы увидим дальше, градиентные методы используются для обучения многих моделей, и это очень богатый класс методов оптимизации, из которого порой не так просто выбрать лучший. В качестве примера рассмотрим задачу бинарной классификации точек на плоскости, для которой выберем линейную модель: Метрикой будет accuracy, то есть доля верных предсказаний. Теперь нам нужно по обучающей выборке подобрать оптимальную разделяющую прямую. Числаиявляютсянастраиваемыми(обучаемыми)параметрамимодели, именно их будет по выборке восстанавливать алгоритм обучения. Но есть проблема: метрика accuracy не дифференцируема. Поэтому мы должны подобрать другую дифференцируемую функцию, минимизация которой будет более или менее соответствовать оптимизации вероятности. Такая функция называетсяфункцией потерь,лоссом(от словаloss) илилосс-функцией. О том, как могут выглядеть лосс-функции для бинарной линейной классификации, вы можете почитать в параграфе пролинейные модели. В качестве алгоритма обучения мы можем взять теперь градиентный спуск: где— шаг оптимизации — коэффициент, влияющий на скорость и устойчивость алгоритма. Отметим, что разный выбор коэффициента, вообще говоря, даёт разные алгоритмы обучения, которые могут приводить к разным результатам: еслислишком мал, то спуск может не дойти до оптимума, а если слишком велик, то алгоритм будет «скакать» вокруг оптимума и никогда туда не попадёт. Мы видим, что важен не только выбор модели, но и выбор алгоритма обучения. Числоявляетсягиперпараметромалгоритма, то есть задаётся до начала обучения — но его тоже можно подбирать по данным. Более подробно о подборе гиперпараметров вы можете узнать в соответствующемпараграфе. Может показаться, что мы вас обманули, когда пугали сложностями: очевидно, что для любой задачи машинного обучения можно построить идеальную модель, надо всего лишь запомнить всю обучающую выборку с ответами. Такая модель может достичь идеального качества по любой метрике, но радости от неё довольно мало, ведь мы хотим, чтобы она выявила какие-то закономерности в данных и помогла нам с ответами там, где мы их не знаем. Важно понимать, какая у построенной моделиобобщающая способность, то есть насколько она способна выучить общие закономерности, присущие не только обучающей выборке, и давать адекватные предсказания на новых данных. Для того чтобы предохранить себя от конфуза, поступают обычно так: делят выборку с данными на две части:обучающую выборкуитестовую выборку(trainиtest). Обучающую выборку используют для собственно обучения модели, а метрики считают на тестовой. Такой подход позволяет отделить модели, которые просто удачно подстроились к обучающим данным, от моделей, в которых произошлагенерализация(generalization), то есть от таких, которые на самом деле кое-что поняли о том, как устроены данные, и могут выдавать полезные предсказания для объектов, которых не видели. Например, рассмотрим три модели регрессионной зависимости, построенные на одном и том же синтетическом датасете с одним-единственным признаком. Жёлтым нарисованы точки обучающей выборки. Здесь мы представим, что есть «истинная» закономерность (пунктир), которая искажена шумом (погрешности измерения, влияние других факторов и т.д.). Левая, линейная модель недостаточно хороша: она сделала, что могла, но плохо приближает зависимость, особенно при маленьких и при больших. Правая «запомнила» всю обучающую выборку (и в самом деле, чтобы вычислить значение этой функции, нам надо знать координаты всех исходных точек) вместо того, чтобы моделировать исходную зависимость. Наконец, центральная, хоть и не проходит через точки обучающей выборки, довольно неплохо моделирует истинную зависимость. Алгоритм, избыточно подстроившийся под данные, называютпереобученным. С увеличением сложности модели ошибка на обучающей выборке падает. Во многих задачах очень сложная модель будет работать примерно так же, как модель, «просто запомнившая всю обучающую выборку», но с генерализацией всё будет плохо: ведь выученные закономерности будут слишком специфическими, подогнанными под то, что происходит на обучающей выборке. Мы видим это на трёх графиках сверху: линейная функция очень проста, но и закономерность приближает лишь очень грубо; на правом же графике мы видим довольно хитрую функцию, которая точно подобрана под значения из обучающей выборки, но явно слишком эксцентрична, чтобы соответствовать какой-то природной зависимости. Оптимальная же генерализация достигается на модели не слишком сложной и не слишком простой. В качестве иллюстрации для того же самого датасета рассмотрим модели вида Ясно, что с ростомсложность модели растёт, и она достигает всё лучшего качества на обучающей выборке. А что, если у нас есть ещё тестовая выборка? Каким будет качество на ней? Вот так могут выглядеть графики среднеквадратичного отклонения (MSE) для обучающей и тестовой выборок: Мы видим здесь типичную для классических моделей картину: MSE на обучающей выборке падает (может быть, даже до нуля), а на тестовой сперва падает, а затем начинает снова расти. Замечание. Для моделей глубинного обучения всё немного интереснее: в некоторых ситуациях есть грань, за которой метрика на тестовой выборке снова начинает падать. Но об этом в своё время. Пока давайте запомним, что слишком сложная модель — это вредно, а переобучение — боль. Точный способ выбрать алгоритм оптимальной сложности по данной задаче нам пока неизвестен, хотя какую-то теоретическую базу имеющимся философским наблюдениям мы дадим в главе про теорию обучения; при этом есть хорошо продуманная методология сравнения разных моделей и выбора среди них оптимальной — об этом мы обязательно расскажем вам в следующих главах. А пока дадим самый простой и неизменно ценный совет: не забывайте считать метрики на тестовой выборке и никогда не смешивайте её с обучающей! Вопрос на подумать.Обсуждая переобучение, мы упоминали про сложность модели, но не сказали, что это такое. Как бы вы её определили? Как описать / сравнить сложность моделей для двух приведённых ниже задач? Почему, кстати, мы решили, что средняя модель ОК, а правая переобученная? В момент, когда подобраны все обучаемые параметры и гиперпараметры модели, работа специалиста по машинному обучению не заканчивается. Во-первых, модель чаще всего создают для того, чтобы она работала в некотором продакшене. И чтобы она там оказалась, нужно эффективно её закодить, научить работать параллельно и подружить с используемыми вами фреймворками. Процесс выкатки в продакшен называется словомдеплойилидеплоймент(отdeploy). После деплоя можно посчитать онлайн-метрики. Также имеет смысл провестиАБ-тестирование, то есть сравнение с предыдущей версией модели на случайно выбранных подмножествах пользователей или сессий. Более подробно об АБ-тестировании вы сможете почитать в соответствующем параграфе. Если новая модель работает не очень здорово, должна быть возможность откатиться к старой. После деплоймента модели важно продолжать дообучать или переобучать её при поступлении новых данных, а также мониторить качество. Мы уже обсуждали data drift, но бывает также иconcept drift— изменение зависимости между признаками и таргетом. Например, если вы делаете музыкальные рекомендации, вам нужно будет учитывать и появление новых треков, и изменение вкусов аудитории. О мониторинге качества моделей мы подробнее расскажем в соответствующем параграфе. Теперь предлагаем вам потренировать изученный материал на практике. Скачайтеноутбукс лабораторной работой. В нём вы найдете описания заданий и дополнительные материалы. Задания из лабораторной прикреплены к этому параграфу в виде задач в системе Яндекс Контест. Чтобы проверить себя, отправляйте решения по соответствующим задачам в систему. Успехов в практике!",
    "useful_links": [
      {
        "text": "медиана",
        "url": "https://en.wikipedia.org/wiki/Median"
      },
      {
        "text": "линейные модели",
        "url": "https://education.yandex.ru/handbook/ml/article/linear-models"
      },
      {
        "text": "параграфе",
        "url": "https://academy.yandex.ru/handbook/ml/article/podbor-giperparametrov"
      },
      {
        "text": "ноутбук",
        "url": "https://yastatic.net/s3/ml-handbook/admin/autohw_intro_ML_92e1d33a4d.ipynb?updated_at=2024-03-07T13:21:15.515Z"
      }
    ]
  }
]