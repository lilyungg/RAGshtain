{"document_title": "Регуляризация в онлайн-обучении", "url": "https://education.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii", "section_title": "Идея неразложения регуляризаторов в субградиентную оценку", "text": "Вспомним вывод linearized FTRL. В ходе линеаризации мы заменяли все функциина их субградиентную оценку в точке. Для регуляризованного функционалаполучалась бы такая оценка: где черезмы обозначили для краткости субградиентв точке. Теперь субградиентную оценку можно подставить в метод FTRL: Идея неразложения состоит в следующем: заменим на субградиентную оценку только, а регуляризатор будем подбирать так, чтобы задача FTRL решалась аналитически. Интуитивно, оценка должна быть точнее оценки а значит, и метод оптимизации будет точнее и эффективнее. Эта идея очень важна для построения регуляризованных алгоритмов онлайн-обучения. Давайте выпишем, как будут выглядеть с учётом этой идеи регуляризованные алгоритмы. Composite Objective FTRL Online Mirror Descent, Proximal Gradient Descent, (F)ISTA Напомним, что три названия в заголовке соответствуют трём способам восприятия этой формулы: Online Mirror Descent — метод онлайн-обучения; Proximal Gradient Descent — метод (стохастической) батч-оптимизации. В стохастическом случае он неотличим от Mirror Descent; (F)ISTA — по сути, это название аналитического решения указанного уравнения для-регуляризации. В этом подразделе мы будем проводить рассуждения на примере-регуляритора. для других регуляризаторов выкладки будут аналогичными. Выпишем Proximal (он же Mirror) Gradient Descent с-регуляризацией: Необходимым условием минимума явняется равенство нулю градиента (а в данном случае субградиента) всего выражения: где- субградиент регуляризаторав точке. Отсюда получаем Если же переписать формулы в духе FTRL, мы получим Получился метод, который оптимизирует-регуляризатор в явном виде только на текущей итерации, а для остальных использует субоптимальные субградиентные оценки. Заметим, что тем же выражением можно ограничить сверху и функционал: Мы получили метод FTRL с incremental— более сильным и стабильным вариантом регуляризации, чем Mirror Descent. Подробнее его анализом мы займемся в параграфе про продвинутую-регуляризацию.", "useful_links": []}
{"document_title": "Регуляризация в онлайн-обучении", "url": "https://education.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii", "section_title": "-регуляризация", "text": "Предположим, что мы хотим обучить модель минимального размера и при этом как можно лучшего качества. В этом нам поможет отбор параметров. А именно, давайте постараемся оставить только те из них, которые оказывают наиболее влияние на лосс. Определение. Будем называть параметрразреженным, если он не используется (пропускается) при предсказании некоторых. «Некоторых» может означать как десятую часть, так ипрогнозов, главное — что такие объекты просто есть. Частым мы будем называть параметр, у которого частота пропусков низкая (например,пропусков), а редким — тот, у которого она высокая (второй случай). Пример. Рассмотрим модель разреженной линейной регрессии. Обычно она применяется в ситуациях, когда элементы вектора признаков— этоили(например, «встретилось ли-е слово в-м документе»), причем на практике доля единиц обычно бывает очень маленькой. Поэтому существенная часть параметровпри прогнозе на шагебудет умножаться на нули и, таким образом, не будет использоваться. Обратите внимание: как правило, в литературе по онлайн-обучению говорят о разреженныхпараметрах, а не признаках. Впрочем, подавляющее большинство моделей на разреженных признаках устроены так, что каждому такому признаку сопоставляется некий набор параметров, поэтому определения «разреженный признак» и «разреженные параметры» взаимозаменяемы. В линейной модели, как в примере выше, каждому признакусопоставляется параметр. В более сложных моделях признакуможет сопоставляться вектор параметров— эмбеддинг этого признака. Давайте теперь поймём, что означает фраза «признак влияет на лосс». Оказывать влияние можно двумя способами: Качеством. Если параметрредкий, но очень хорошо прогнозирует свой небольшой набор объектов, его стоит оставить. За счет того, что мы оставим достаточное количество таких параметров, мы можем покрыть большое число объектов. Такие параметры называютсяmemorization parameters(они как будто запоминают «свои» объекты). Количеством. Если параметрчасто встречается, то он в любом случае должен остаться в модели и помогать с суммарным качеством прогноза. Убирать мы хотим только слабые и редкие параметры. Таких, как правило, больше. Обратите внимание: мы не хотим убиратьслабые, но часто встречающиеся параметры. Тому есть две причины: Места они много не занимают, а количества данных в large scale задачах достаточно, чтобы правильно выучить эти параметры. Они будут вносить свой, пусть и небольшой, вклад в общее качество; Частые параметры хорошо запоминают среднее поведение на всех данных, а разреженные — поведение на конкретных объектах. Если наша цель — оставить как можно меньше параметров, то выгоднее хорошо выучить среднее поведение на всех данных, а отклонения от среднего запомнить с помощью memorization parameters. Если в модели есть только супер-разреженные параметры, то из-за огромной вариативности в их возможных комбинациях в данных каждому параметру придется доучивать среднее поведение. Подробнее на этой проблеме мы остановимся в конце параграфа. В обучении разреженных моделей все параметры, на которые накладывается-регуляризация, инициализируются нулями. С точки зрения здравого смысла такая инициализация довольно естественна, однако есть и более формальное обоснование; Если параметры инициализируются нулями, то мы по мере обучения смотрим на градиенты этих параметров и в зависимости от градиентов принимаем решение, нужен нам параметр для прогноза или не нужен. Все параметры стартуют в равных условиях, и модель понемногу выходит из состояния «абсолютная разреженность», выучивая что-то содержательное. Если же параметры инициализируются случайно, то нам надо сначала доучить все параметры до какого-то более или менее разумного значения, а потом уже пытаться понять, нужен ли он нам. Момент, когда модель начинает эффективно разреживаться, тем самым очень сильно отдалается. Напомним формулировку задачи: Решение можно выписать в явном виде. Для этого введём следующие обозначения: будет аккумулировать сумму градиентов,, будет аккумулировать сумму поэлементных квадратов градиентов,, — это learning rate. Следующие формулы выписаны отдельно для каждой координаты. В них— индекс параметра модели,— номер итерации. Вывод этих формул хорошо расписан вконспекте курса Д. А. Кропотова. При регуляризаторев оптимизируемом функционале стоят коэффициенты, которые могут как-то зависеть от. Обычно рассматривают три вида зависимости: Fixed:. Squared incremental: Linear incremental: Их также можно комбинировать, получая коэффициенты регуляризации Напомним, что все весамы инициализируем нулями. По формуламиз нуля на шагевыводятся веса, для которых Таким образом,начальное условие выхода параметров из нуляимеет вид Попробуем понять физический смысл этого неравенства. Напоминание. Говорят, что функцияимеетлипшиц-непрерывныйградиент с константой, если Предположим, что это выполняется (ниже мы покажем, что это не слишком обременительное ограничение). Тогда, подставив в качестветочку оптимума функции(не путайте с глобальнымиз regret!), мы получим Это означает, что для достаточно хорошей функциинорма градиента является оценкой снизу на расстояние до точки оптимума в пространстве параметров. Чем больше норма градиента, тем дальше мы от оптимальных параметров. Вернемся к выражению. Здесь мы имеем дело (а) отдельно с каждой из координат и (б) с нормой суммы градиентов (а не с суммой норм). Хорошая новость: утверждение выше верно и для функций одной переменной, то есть, грубо говоря, показывает, насколько мы далеки от оптимума по-й координате. Знакговорит о том, в какую сторону мы будем сдвигаться по-й координатена-м шаге. Если сдвиги были в основном в одну сторону, тобудет больше, а если они всё время в разную сторону, то отдельные слагаемые могут скомпенсировать друг друга, иможет быть малым. Отметим ещё, что абсолютная величина компонентына первых итерациях может отражать прогнозирующую силу параметра: в самом деле, неверное значение важного для предсказания параметра может вести к большим ошибкам, что будет давать большие градиенты. Посмотрим теперь, как будет вести себя разреженная модель в зависимости от вида. Условие выходаиз нуля принимает вид что равносильно Ограничение на среднее значение компоненты градиента означает, что для выхода из нуля параметрдолжен иметь определённую прогнозирующую силу. Это противоречит нашему требованию о том, чтобы частые маломощные параметры все равно присутствовали в модели и выучивали среднее поведение. Обратите внимание. Выше мы показали, что проксимальный градиентный спуск с обычным в некотором смысле эквивалентен Composite-Objective FTRL с инкрементальным. Таким образом, обычная-регуляризация в классическом градиентном спуске эквивалентна именно инкрементальному, который, как мы выяснили, субоптимален. Ниже мы рассмотрим специфический для FTRL вариант-регуляризации, который лишен этих недостатков. Это самый мощный и полезный на практике режим. Здесь мы не нормируем на(то есть не берём среднее), и это означает, что выйти из нуля может и слабый, но частый параметр, который за много итераций накопит достаточно большую сумму частных производных. Свойства фильтрации с фиксированным регуляризатором в точности совпадают с продуктовыми требованиями: Редкий параметр с мощной прогнозирующей силой на старте будет иметь большие по модулю градиенты одного знака, и он выйдет из нуля; Редкий параметр с малой прогнозной силой не выйдет из нуля; Частые параметры в любом случае выйдут из нуля. Вэтой статьебыло теоретически обосновано, что если параметр частый, но нерелевантный и абсолютно шумный, то дисперсиябудет иметь асимптотику. Из этого следует, что, если сделать регуляризацию порядка, мы лишим такой случайный шум почти любых шансов выйти из нуля. К сожалению, ни в игрушечных примерах вроде Avazu, ни в продакшен задачах улучшений качества прогноза или степени разреживания модели без потери качества достичь не удалось. Возможно, вам повезет больше. Рассмотрим две линейных модели в которых все параметрыразреженные. Давайте считать, что в первой модели есть константный (и совсем даже не разреженный) признак, которому и соответствует параметр. Теперь в каждой из моделей наложим нарегуляризациюи сравним, что получится: В моделипараметрамнужно запомнить «отклонение» от среднего; В моделипараметрамнужно запомнить абсолютное значение предсказания. Нетрудно понятно, что при наличии bias нормы градиентов в первой модели в среднем будут намного меньше, потому что мы на каждом шаге оптимизации будем стартовать с точки, которая в среднем ближе к точке оптимума (bias и есть наше среднее). Поэтому меньше весов смогут преодолеть порог по модулю суммы градиентов и выйти из нуля. Таким образом, несмотря на одинаковый оптимум без регуляризации, при введении-регуляризации модель с bias будет обладать более хорошим соотношением разреженность/качество прогноза. Эта логика легко обобщается на более сложные случаи, когда вместо bias у нас есть неразреженные контентные признаки. Вывод такой: модели, в которых есть только очень разреженные параметры, обладают гораздо худшим соотношением разреженность/качество, чем модели, в которых есть и контентные, и разреженные параметры. Убедиться в этих эффектах мы сможем в разделе с практикой на линейных моделях.", "useful_links": [{"text": "конспекте курса Д. А. Кропотова", "url": "http://www.machinelearning.ru/wiki/images/5/5b/MOMO12_sparse_methods.pdf"}, {"text": "этой статье", "url": "http://www.opt-ml.org/papers/OPT2016_paper_24.pdf"}]}
{"document_title": "Регуляризация в онлайн-обучении", "url": "https://education.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii", "section_title": "регуляризация", "text": "Рассмотрим обыкновенный SGD. Weight decayсостоит во введение штрафа на размер текущих весов: Внимательные читатели уже заметили, что в случае с SGD это эквивалентно введению-регуляризации. Давайте разберёмся, как это сделать правильно. Попробуем заменитьна и запустить любой адаптивный метод, например, AdaGrad. Если мы беспечно заменим на градиентную оценку всю функцию(забыв, что с регуляризатором этого делать не стоит), то алгоритм примет вид где В этих формулах нехороши две вещи: Коэффициентыинетривиальным образом взаимодействуют. Это крайне неудобно при переборе гиперпараметров: изменение learning rateдолжно влечь за собой переподбор коэффициента регуляризациипо полной сетке; В квадратах градиентов мы хотим видеть только адаптивность к кривизне самой функции, но теперь там ещё добавка. Эта проблема была впервые замечена вDecoupled weight decay regularization. Авторы также рассматривали влияние на momentum, к этому мы вернёмся в параграфе про AdamW. Авторы статьи предлагают модифицировать метод AdaGrad следующим образом: Сразу отметим сходство с исходными формулами weight decay — его и добивались авторы. Легко видеть, что формула описывает обыкновенный покоординатный градиентный спуск с некоторым линеаризованным-регуляризатором. Давайте «проинтегрируем» это выражение обратно до аргминимума, из которого бы получились такие формулы обновления весов: Получается, что decoupled weight decay — это адаптивный-centered регуляризатор. Его можно усовершенствовать, вспомним наше важное правило не заменять регуляризатор на субградиентную оценку. Перейдём к задаче Она отличается от предыдущей заменойна. Её решение имеет вид Поскольку мы меньше огрубляем оптимизируемый функционал, обучение может стать немного стабильнее. Обратите внимание, что в оптимизационной задаче у нас теперь стоит не просто, а. Теперь посмотрим, как decoupled weight decay будте работать с Composite-Objective FTRL. Линеаризованная задача имеет вид: Перепишем её: Нетрудно показать, что решение имеет вид Дляможно написать и явную формулу:. Замечание. Чтобы оценить Regret такого метода, мы не сможем механически воспользоваться оценкой для AdaGrad: ведь она базированась на оценке на Regret, выведенной либо для целиком Proximal, либо для целиком Centered-регуляризаторов. Composite objective из теоремы 10 тут не годится, так как Centered регуляризатор в этом случае не поедет в оценку норм градиентов, а мы в текущем представлении рассматриваем Proximal и Centered как равноправные члены. Интуитивно, мы должны применить Lemma 7 к обоим регуляризаторам и получить точно такую же оценку с такой же двойственной нормой (напомним, что centered и proximal регуляризаторы имеют одинаковую двойственную норму). Двойственная норма такая же ->формулы оптимального метода AdaGrad будут такие же. Мы оставляем это читателям в качестве упражнения.", "useful_links": [{"text": "Decoupled weight decay regularization", "url": "https://arxiv.org/pdf/1711.05101.pdf"}]}
{"document_title": "Регуляризация в онлайн-обучении", "url": "https://education.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii", "section_title": ": проекция на выпуклое множество", "text": "Напоминание: множествоназываетсявыпуклым, если Проекцией на это множество называют функцию Докажем, что— выпуклый регуляризатор. Для этого нам нужно проверить неравенство Единственный шанс, когда это может быть нарушено — это,,. Это значит, что, а, что противоречит выпуклости. Вернемся к формулам FTRL. Здесь ситуация сильно проще — от накидывания любых последовательностейна регуляризатор ничего не изменится, так что его всегда оставляют просто as is Аналитические решения для каждого виданужно искать отдельно. Примерно все решения получаются путем выносаиз оптимизируемого функционала и превращения его в ограничение, после чего можно применить метод множителей Лагранжа. Решим аналитически задачу проекции на шар Функция Лагранжа будет иметь вид а её градиент равен где- вектор, а— поэлементное умножение векторов. Приравнивая к нулю градиент, получаем где мы, как обычно, обозначили. Проанализируем условие дополняющей нежесткости. Если, то решениеуже находится внутри шара и имеет вид При практической реализации мы просто сначала посчитаем это выражение и проверим, не попадаем ли мы в шар. Если попадаем — отлично, если нет — то дальше говорим, чтои решаем продолжаем решение Теперь подставим это ви получим Получаем, что если мы находимся внутри шара, то мы действуем согласно обыкновенному adaptive алгоритму со всеми хорошими свойствами, иначе — проекция побеждает. Аналогичнорегуляризации, здесь тоже есть различия между lazy и greedy представлением этого регуляризатора. Однако, в классических DL задачах эти методы встречаются не слишком часто и здесь сложно привести какой-нибудь значимый успех, который мог бы улучшить качество в важной задача. Навскидку мы можем вспомнить разве что Adversatial White-Box learning, в котором можно было бы это попробовать.", "useful_links": []}
