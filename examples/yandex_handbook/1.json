[
  {
    "document_title": "Как оценивать вероятности",
    "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
    "section_title": "Что же такое вероятность класса, если объект либо принадлежит этому классу, либо нет?",
    "text": "Ограничимся пока случаем двухклассовой классификации — с классами 0 и 1. Если утверждается, что мы предсказываем корректную вероятность класса 1 (обозначим её), то прогноз «объектпринадлежит классу 1 с вероятностью» должен сбываться вслучаев. То есть, условно говоря, если мы возьмём все объекты, то среди них что-то около двух третей действительно имеет класс 1. На математическом языке это можно сформулировать так:Если— предсказанная вероятность класса 1, то. К сожалению, в реальной жизни— это скорее всего вещественные числа, которые будут различными для различных, и никаких вероятностей мы не посчитаем, но мы можем разбить отрезокна бины, внутри каждого из которых уже вычислить, каковая там доля объектов класса 1, и сравнить эту долю со средним значением вероятности в бине: У модели, которая идеально предсказывает вероятности (как обычно говорят, у идеальнокалиброванноймодели) жёлтые точки на диаграмме калибровки должны совпадать с розовыми. А вот на картинке выше это не так: жёлтые точки всегда ниже розовых. Давайте поймём, что это значит. Получается, что наша модель систематически завышает предсказанную вероятность (розовые точки), и порог отсечения нам, выходит, тоже надо было бы сдвинуть вправо: Но такая картинка, пожалуй, говорит о какой-то серьёзной патологии классификатора. Гораздо чаще встречаются следующие две ситуации: Слишком уверенный (overconfident) классификатор:Такое случается с сильными классификаторыми (например, нейросетями), которые учились на метки классов, а не на вероятности: тем самым процесс обучения стимулировал их всегда давать ответ, как можно более близкий к 0 или 1. Неуверенный (underconfident) классификатор: Такое может случиться, например, если мы слишком много обращаем внимания на трудные для классификации объекты на границе классов (как, скажем, в SVM), в каком-то смысле в ущерб более однозначно определяемым точкам. Этим же могут и грешить модели на основе бэггинга (например, случайный лес). Грубо говоря, среднее нескольких моделей предскажет что-то близкое к единице только если все слагаемые предскажут что-то, близкое к единице — но из-за дисперсии моделей это будет случаться реже, чем могло бы. Подробнее можно почитать встатье.",
    "useful_links": [
      {
        "text": "статье",
        "url": "https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf"
      }
    ]
  },
  {
    "document_title": "Как оценивать вероятности",
    "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
    "section_title": "Вам скажут: логистическая регрессия корректно действительно предсказывает вероятности",
    "text": "Вам даже будут приводить какие-то обоснования. Важно понимать, что происходит на самом деле, и не дать ввести себя в заблуждение. В качестве противоядия от иллюзий предлагаем рассмотреть два примера. Рассмотрим датасет c двумя классами (ниже на картинке обучающая выборка) Обучим на нём логистическую регрессию из sklearn безо всяких параметров (то есть-регуляризованную, но это не так важно). Классы не так-то просто разделить, вот и логистическая регрессия так себе справляется. Ниже изображена часть тестовой выборки вместе с предсказанными вероятностями классов для всех точек области Видим, что модель не больно-то уверена в себе, и ясно почему: признаковое описание достаточно бедное и не позволяет нам хорошо разделить классы, хотя, казалось бы, это можно довольно неплохо сделать. Попробуем поправить дело, добавив полиномиальные фичи, то есть вседляв качестве признаков, и обучив поверх этих данных логистическую регрессию. Снова нарисуем некоторые точки тестовой выборки и предсказания вероятностей для всех точек области: Видим, что у нас сочетание двух проблем: неуверенности посередине и очень уверенных ошибок по краям. Нарисуем теперь калибровочные кривые для обеих моделей: Калибровочные кривые весьма примечательны; в любом случае ясно, что с предсказанием вероятностей всё довольно плохо. Посмотрим ещё, какие вероятности наши классификаторы чаще приписывают объектам: Как и следовало ожидать, предсказания слабого классификатора тяготеют к серединке (та самая неуверенность), а среди предсказаний переобученного очень много крайне уверенных — и совсем не всегда правильных.",
    "useful_links": []
  },
  {
    "document_title": "Как оценивать вероятности",
    "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
    "section_title": "Но почему же все твердят, что логистическая регрессия хорошо калибрована?!",
    "text": "Попробуем понять и простить её. Как мы помним, логистическая регрессия учится путём минимизации функционала Отметим между делом, что каждое слагаемое — это кроссэнтропия распределения, заданного вероятностямии, и тривиального распределения, которое равнос вероятностью. Допустим, что мы обучили по всему универсуму данныхидеальную логистическую регрессию с идеальными весами. Пусть, далее, оказалось, что у нас естьобъектовс одинаковым признаковым описанием (то есть по сути представленных одинаковыми векторами), но, возможно, разными истинными метками классов. Тогда соответствующий им кусок функции потерь имеет вид где— частота-го класса среди истинных меток. В скобках также стоит кросс-энтропия распределения, задаваемого частотой меток истинных классов, и распределения, предсказываемого логистической регрессией. Минимальное значение кросс-энтропии (и минимум функции потерь) достигается, когда Результат, полученный длясовпадающих точек будет приблизительно верным и длядостаточно близких точек в случае, когда: признаковое описание данных достаточно хорошее — классы не перемешаны как попало и всё-таки близки к разделимым; модель не переобученная — то есть, предсказания вероятностей не скачут очень уж резко — вспомните второй пример. На всех этих точках модель будет выдавать примерно долю положительных, то есть тоже хорошую оценку вероятности.",
    "useful_links": []
  },
  {
    "document_title": "Как оценивать вероятности",
    "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
    "section_title": "Как же всё-таки предсказать вероятности: методы калибровки",
    "text": "Пусть наша модель (бинарной классификации) для каждого объектавыдаёт некоторое число. Как же эти числа превратить в корректные вероятности? Гистограммная калибровка. Мы разбиваем отрезокна бины(одинаковой ширины или равномощные) и хотим на каждом из них предсказывать всегда одну и ту же вероятность:, если. Вероятностиподбираются так, чтобы они как можно лучше приближали средние метки классов на соответствующих бинах. Иными словами, мы решаем задачу Вместо разности модулей можно рассматривать и разность квадратов. Метод довольно простой и понятный, но требует подбора числа бинов и предсказывает лишь дискретное множество вероятностей. Изотоническая регрессия. Этот метод похож на предыдущий, только мы будем, во-первых, настраивать и границыбинов, а кроме того, накладываем условие. Искатьимы будем, приближаякусочно постоянной функциейот: Минимизация осуществляется при помощи pool adjacent violators algorithm, и эти страницы слишком хрупки, чтобы выдержать его формулировку. Калибровка Платтапредставляет собой по сути применение сигмоиды поверх другой модели (то есть самый наивный способ получения «вероятностей»). Более точно, если— предсказанная вероятность, то мы полагаем гдеиподбираются методом максимального правдоподобия на отложенной выборке: Для избежания переобучения Платт предлагал также заменить меткиина регуляризованные вероятности таргетов: Калибровка Платта неплохо справляется с выколачиванием вероятностей из SVM, но для более хитрых классификаторов может спасовать. В целом, можно показать, что этот метод хорошо работает, если для каждого из истинных классов предсказанные вероятностираспределы нормально с одинаковыми дисперсиями. Подробнее об этом вы можете почитать вэтой статье. Там же описано обобщение данного подхода — бета-калибровка. С большим количеством других методов калибровки вы можете познакомиться вэтой статье",
    "useful_links": [
      {
        "text": "этой статье",
        "url": "https://research-information.bris.ac.uk/ws/portalfiles/portal/154625753/Full_text_PDF_final_published_version_.pdf"
      },
      {
        "text": "этой статье",
        "url": "https://dyakonov.org/2020/03/27/%D0%BF%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D0%B0-%D0%BA%D0%B0%D0%BB%D0%B8%D0%B1%D1%80%D0%BE%D0%B2%D0%BA%D0%B8-%D1%83%D0%B2%D0%B5%D1%80%D0%B5%D0%BD%D0%BD%D0%BE%D1%81%D1%82%D0%B8"
      }
    ]
  },
  {
    "document_title": "Как оценивать вероятности",
    "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
    "section_title": "Как измерить качество калибровки",
    "text": "Калибровочные кривые хорошо показывают, что есть проблемы, но как оценить наши усилия по улучшению предсказания вероятностей? Хочется иметь какую-то численную метрику. Мы упомянем две разновидности — прямое воплощение описанных выше идей. Expected/Maximum calibration error. Самый простой способ, впрочем — он наследник идеи с калибровочной кривой. А именно, разобьём отрезокна биныпо предсказанным вероятностям и вычислим или где— среднее значение, а— среднее значениедля, таких что. Проблема этого способа в том, что мы можем очень по-разному предсказывать в каждом из бинов вероятности (в том числе константой) без ущерба для метрики. Brier score. Одна из популярных метрик, которая попросту измеряет разницу между предсказанными вероятностями и: Казалось бы, в чём смысл? Немного подрастить мотивацию помогает следующий пример. Допустим, наши таргеты совершенно случайны, то есть. Тогда хорошо калиброванный классификатор должен для каждогопредсказывать вероятность; соответственно, его brier score равен. Если же классификатор хоть в одной точке выдаёт вероятность, то в маленькой окрестности он должен выдавать примерно такие же вероятности. Поскольку же таргет случаен, локальный кусочек суммы из brier score будет иметь вид, что хуже, чем получил бы всегда выдающийклассификатор. Не обязательно брать квадратичную ошибку; сгодится и наш любимый log-loss: Это же и помогает высветить ограничения подхода, если вспомнить рассуждения о калиброванности логистической регрессии. Для достаточно гладких классификатора и датасета brier score и log-loss будут адекватными средствами оценки, но если нет — возможно всякое. Вопрос на засыпку: а как быть, если у нас классификация не бинарная, а многоклассовая? Что такое хорошо калиброванный классификатор? Как это определить численно? Как заставить произвольный классификатор предсказывать вероятности? Мы не будем про это рассказывать, но призываем читателя подумать над этим самостоятельно или, например, посмотретьтуториалс ECML KDD 2020.",
    "useful_links": [
      {
        "text": "туториал",
        "url": "https://classifier-calibration.github.io/"
      }
    ]
  }
]