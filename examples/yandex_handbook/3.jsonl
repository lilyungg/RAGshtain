{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Априорное знание", "text": "Начнём с простого вопроса: как нам внести в модель априорные знания. Представьте, что мы обучаем модель линейной регрессии,. С помощью MLE мы получили некоторую оценкуна веса— всякие ли их значения мы встретим с покорностью и смирением? Наверное, мы удивимся, если какие-то компоненты векторабудут очень большими по сравнению с элементами: пожалуй, наша физическая интуиция будет бунтовать против этого, мы задумаемся о том, что из-за потенциальных ошибок сокращения вычисление предсказанийокажутся неточным — в общем, хотелось бы по возможности избежать этого. Но как? Будь мы приверженцами чисто инженерного подхода, мы бы сделали просто: прибавили бы к функции потерь слагаемое, или, или ещё что-то такое — тогда процедура обучения стала бы компромиссом между минимизацией исходного лосса и этой добавки, что попортило бы слегка близость, но зато позволило бы лучше контролировать масштаб. Надо думать, вы узнали в этой конструкции старую добрую регуляризацию. Но наша цель — зашить наше априорное знание о том, что компонентыне слишком велики по модулю, в вероятностную модель. Введение в модель априорного знания соответствует введению априорного распределения на. Какое распределение выбрать? Ну, наверное, компонентыбудут независимыми (ещё нам не хватало задавать взаимосвязи между ними!), а каждая из них будет иметь какое-то непрерывное распределение, в котором небольшие по модулю значения более правдоподобны, а совсем большие очень неправдоподобны. Мы знаем такие распределения? Да, и сразу несколько. Например, нормальное. Логично было бы определить где— какая-то дисперсия, которую мы возьмём с потолка или подберём по валидационной выборке. Отметим, что выбор нормального распределение следует и из принципа максимальной энтропии: ведь у него наибольшая энтропия среди распределений на всей числовой оси с нулевым матожиданием и дисперсией. Контроль масштаба весов — это, вообще говоря, не единственное, что мы можем потребовать. Например, мы можем из каких-то физических соображений знать, что тот или иной вес в линейной модели непременно должен быть неотрицательным. Тогда в качестве априорного на этот вес мы можем взять, например, показательное распределение (которое, напомним, обладает максимальной энтропией среди распределений на положительных числах с данным матожиданием).", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Оцениваем не значение параметра, а его распределение", "text": "Раз уж мы начали говорить о распределении на веса, то почему бы не пойти дальше. Решая задачу классификации, мы уже столкнулись с тем, что может быть важна не только предсказанная метка класса, но и вероятности. Аналогичное верно и для задачи регрессии. Давайте рассмотрим две следующих ситуации, в каждой из которых мы пытаемся построить регрессию: Несмотря на то, что в каждом из случаев «точная формула» или градиентный спуск выдадут нам что-то, степень нашей уверенности в ответе совершенно различная. Один из способов выразить (не)уверенность — оценить распределение параметров. Так, для примеров выше распределения на параметрмогли бы иметь какой-то такой вид: Дальше мы постараемся формализовать процесс получения таких оценок.", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Построение апостериорного распределения", "text": "Давайте ненадолго забудем про линейную регрессию и представим, что мы подобрали с пола монету, которая выпадает орлом с некоторой неизвестной пока вероятностью. До тех пор, пока мы не начали её подкидывать, мы совершенно ничего не знаем о, эта вероятность может быть совершенно любой — то есть априорное распределение наявляется равномерным (на отрезке): Теперь представим, что мы подкинули еёраз, получив результаты(— решка,— орёл), среди которыхрешек иорлов. Определённо наши познания о числестали точнее: так, еслимало, то можно заподозрить, что иневелико (уже чувствуете, запахло распределением!). Распределение мы посчитаем с помощью формулы Байеса: в нашем случае: В этом выражении нетрудно узнать бета-распределение:. Давайте нарисует графики его плотности для нескольких конкретных значенийи: Как можно заметить, с ростоммы всё лучше понимаем, каким может быть, при этом если орёл выпадал редко, то пик оказывается ближе к нулю, и наоборот. Ширина пика в каком-то смысле отражает нашу уверенность в том, какими могут быть значения параметра, и не случайно чем больше у нас данных — тем уже будет пик, то есть тем больше уверенности. Распределениепараметра, полученное с учётом данных, называетсяапостериорным. Переход от априорного распределения к апостериорному отражает обновление нашего представления о параметрах распределения с учётом полученной информации, и этот процесс является сердцем байесовского подхода. Отметим, что если нам придут новые данные, в которыхрешек иорлов, мы сможем ещё раз обновить распределение по той же формуле Байеса: Вопрос на подумать. Пусть— нормальное распределение с фиксированной дисперсией, а для параметрав качестве априорного выбрано также нормальное распределение. Каким будет апостериорное распределение при условии данных?", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Сопряжённые распределения", "text": "В двух предыдущих примерах нам очень сильно повезло, что апостериорные распределения оказались нашими добрыми знакомыми. Если же взять случайную пару распределенийи, результат может оказаться совсем не таким приятным. В самом деле, нет никакой проблемы в том, чтобы посчитать числитель формулы Байеса, но вот интеграл в знаменателе может и не найтись. Поэтому выбирать распределения нужно с умом. Более того, поскольку апостериорное распределение само станет априорным, когда придут новые данные, хочется, чтобы априорное и апостериорное распределения были из одного семейства; пары (семейств) распределенийи, для которых это выполняется, называютсясопряжённыминазываетсясопряжённымк. Полезно помнить несколько наиболее распространённых пар сопряжённых распределений: — распределение Бернулли с вероятностью успеха,— бета распределение; — нормальное с матожиданиеми фиксированной дисперсией,также нормальное; — показательное с параметром,— гамма распределение; — пуассоновское с параметром,— гамма распределение; — равномерное на отрезке,— Парето; Возможно, вы заметили, что почти все указанные выше семейства распределений (кроме равномерного и Парето) относятся к экспоненциальному классу. И это не случайность! Экспоненциальный класс и тут лучше всех: оказывается, что дляиз экспоненциального класса можно легко подобрать сопряжённое. Давайте же это сделаем. Пустьимеет вид Положим где— множитель, обеспечивающий равенство единице интеграла от этой функции. Найдём апостериорное распределение: Это распределение действительно из того же семейства, что и, только с новыми параметрами: Пример. Пустьподчиняется распределению Бернулли. Напомним, что оно следующим образом представляется в привычном для экспоненциального класса виде: Предлагается брать априорное распределение вида Тогда апостериорное распределение будет иметь вид (проверьте, посчитав по формуле Байеса!) Превратив логарифм частного в сумму, а экспоненту суммы в произведение, легко убедиться, что получается то самое бета распределение, которое мы уже получали выше.", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Оценка апостериорного максимума (MAP)", "text": "Апостериорное распределение — это очень тонкий инструмент анализа данных, но иногда надо просто сказать число (или же интеграл в знаменателе не берётся и мы не можем толком посчитать распределение). В качестве точечной оценки логично выдать самое вероятное значение(интеграл в знаменателе отне зависит, поэтому на максимизацию не влияет): Это число называетсяоценкой апостериорного максимума (MAP). Если же в формуле выше перейти к логарифмам, то мы получим кое-что, до боли напоминающее старую добрую регуляризацию (и не просто так, как мы вскоре убедимся!): Пример. Рассмотрим снова распределение Бернуллии априорное распределение. Тогда MAP-оценка будет равна Дифференцируя пои приравнивая производную к нулю, мы получаем В отличие от оценки максимального правдоподобиямы здесь используем априорное знание: параметрыиработают как «память о воображаемых испытаниях», как будто бы до того, как получить данные, мы уже имелиуспехов инеудач.", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Связь MAP- и MLE-оценок", "text": "Оценка максимального правдоподобия является частным случаем апостериорной оценки. В самом деле, если априорное распределение является равномерным, то естьне зависит(если весавещественные, могут потребоваться дополнительные усилия, чтобы понять, как такое вообще получается), и тогда", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Байесовские оценки для условных распределений", "text": "В предыдущих разделах мы разобрали, как байесовский подход работает для обычных, не условных распределений. Теперь вернёмся к чему-то более близкому к машинному обучению, а именно к распределениям вида, и убедимся, что для них байесовских подход работает точно так же, как и для обычных распределений. Имея некоторое распределение, мы подбираем для него априорное распределение на веса(и да, оно не зависит от: ведь априорное распределение существует ещё до появления данных) и вычисляем апостериорное распределение на веса: Вычислять его мы будем по уже привычной формуле Байеса: Повторим ещё разок, в чём суть байесовского подхода: у нас было некоторое априорное представлениео распределении весов, а теперь, посмотрев на данные, мы уточняем своё понимание, формулируя апостериорное представление. Если же нам нужна только точечная оценка, мы можем ограничиться оценкой апостериорного максимума (MAP): что уже до неприличия напоминает регуляризованную модель", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Пример: линейная регрессия с-регуляризацией как модель с гауссовским априорным распределением на веса", "text": "В модели линейной регрессии,введём априорное распределение на веса вида Тогда— точка минимума следующего выражения: Получается, что а это же функция потерь для линейной регрессии с-регуляризацией! Напомним на всякий случай, что у этой задачи есть «точное» решение Для этого примера мы можем вычислить и апостериорное распределение. В самом деле, из написанного выше мы можем заключить, что Таким образом,— это квадратичная функция от, откуда следует, что апостериорное распределение является нормальным. Чтобы найти его параметры, нужно немного преобразовать полученное выражение: Таким образом, Как видим, от априорного распределения оно отличается корректировкой как матожидания, так и ковариационной матрицы. Отметим, что— это, с точностью до численного множителя, оценка ковариационной матрицы признаков нашего датасета (элементы матрицы— это скалярные произведения столбцов, то есть столбцов значений признаков). Иллюстрация. Давайте на простом примере (датасет с двумя признаками) посмотрим, как меняется апостериорное распределениес ростом размера обучающей выборки: Как видим, не только мода распределения, то естьприближается к своему истинному значению, но и дисперсия распределения постепенно уменьшается. Ещё иллюстрация. Теперь рассмотрим задачу аппроксимации неизвестной функции одной переменной (чьи значения в обучающей выборке искажены нормальным шумом) многочленом третьей степени. Её, разумеется, тоже можно решать, как задачу линейной регрессии на коэффициенты многочлена. Давайте нарисуем, как будут выглядеть функции, сгенерированные из распределениядля разного объёма обучающей выборки: Тут тоже видим, что функции не только становятся ближе к истинной, но и разброс их уменьшается.", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Пример: линейная регрессия с-регуляризацией как модель с лапласовским априорным распределением на веса", "text": "Другое распределение, которое тоже может кодировать наше желание, чтобы небольшие по модулю значениябыли правдоподобными, а большие не очень, — распределение Лапласа. Посмотрим, что будет, если его взять в качестве априорного распределения на веса. Проводя такое же вычисление, получаем, что а это же функция потерь для линейной регрессии с-регуляризацией!", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Как делать предсказания", "text": "Все изложенные выше рассуждения проводились в ситуации, когда— обучающая выборка. Для неё мы можем посчитать и точечную апостериорную оценку. А теперь пусть нам дан новый объект. Какой таргетмы для него предскажем? Было бы естественным, раз уж мы предсказываем распределение для, и длятоже предсказывать распределение. Делается это следующим образом: Надо признать, что вычисление этого интеграла не всегда посильная задача, поэтому зачастую приходится «просто подставлять». В вероятностных терминах это можно описать так: вместо сложного апостериорного распределениямы берём самое грубое на свете приближение где— дельта-функция, которая не является честной функцией (а является тем, что математики называют обобщёнными функциями), которая определяется тем свойством, чтодля достаточно разумных функций. Если не мудрствовать лукаво, то это всё значит, что Пример. Пусть,— модель линейной регрессии с априорным распределениемна параметры. Тогда, как мы уже видели раньше, Попробуем для новой точкипосчитать распределение на. Рекомендуем читателю попробовать самостоятельно посчитать интеграл или же обратиться к пункту 7.6.2 книжки «Machine Learning A Probabilistic Perspective» автора Kevin P. Murphy, убедившись, что что, очевидно, более содержательно, чем оценка, полученная с помощью приближения: Собственно, видно, что в этом случае Пример в примере. Рассмотрим полюбившуюся уже нам задачу приближения функции многочленом степени не выше(в которой мы строим модели с). Длямы получали такую картинку: Если оценить по приведённым выше формуламдля разных, то можно убедиться, что модель в большей степени уверена в предсказаниях для точек из областей, где было больше точек из обучающей выборки:", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Байесовский подход и дообучение моделей", "text": "До сих пор мы в основном рассуждали о моделях машинного обучения как о чём-то, что один раз обучается и дальше навсегда застывает в таком виде, но в жизни такое скорее редкость. Мы пока не будем обсуждать изменчивость истинных зависимостей во времени, но даже если истина неизменна, к нам могут поступать новые данные, которые очень хотелось бы использовать для дообучения модели. Обычные, не байесовские вероятностные модели не предоставляют таких инструментов. Оценку максимального правдоподобия придётся пересчитывать заново (хотя, конечно, можно схитрить, использовав старое значение в качестве начального приближения при итеративной оптимизации). Байесовский же подход позволяет оформить дообучения в виде простой и элегантной формулы: при добавлении новых данныхимеем", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Байесовский подход к выбору модели: мотивация", "text": "Нам часто приходится выбирать: дерево или случайный лес, линейная модель или метод ближайших соседей; да, собственно, и внутри наших вероятностных моделей есть параметры (скажем, дисперсия шумаи), которые надо бы подбирать. Но как? В обычной ситуации мы выбираем модель, обученную на выборкев зависимости от того, как она себя ведёт на валидационной выборке(сравниваем правдоподобие или более сложные метрики) — или же делаем кросс-валидацию. Но как сравнивать модели, выдающие распределение? Ответим вопросом на вопрос: а как вообще сравнивать модели? Назначение любой модели — объяснять мир вокруг нас, и её качество определяется именно тем, насколько хорошо она справляется с этой задачей. Тестовая выборка — это хороший способ оценки, потому что она показывает, насколько вписываются в модель новые данные. Но могут быть и другие соображения, помогающие оценить качество модели. Аналитик Василий опоздал на работу. Своему руководителю он может предложить самые разные объяснения — и это будет выработанная на одном обучающем примере модель, описывающая причины опоздания и потенциально позволяющая руководителю принять решение о том, карать ли Василия. Конечно, руководитель мог бы принять изложенную Василием модель к сведению, подождать, пока появятся другие опоздавшие, и оценить её, так скажем, на тестовой выборке, но стоит ли? Давайте рассмотрим несколько конкретных примеров: Модель «Василий опоздал, потому что так получилось», то есть факт опоздания — это просто ни от чего не зависящая случайная величина. Такая модель плоха тем, что (а) не предлагает, на самом деле, никакого объяснения тому факту, что Василий опоздал, а его коллега Надежда не опоздала и (б) совершенно не помогает решить, наказывать ли за опоздание. Наверное, такое не удовлетворит руководителя. Модель «Василий опоздал, потому что рядом с его домом открылся портал в другой мир, где шла великая битва орков с эльфами, и он почувствовал, что просто обязан принять в ней участие на стороне орков, которых привёл к победе, завоевав руку и сердце орочьей принцессы, после чего был перенесён обратно в наш скучный мир завистливым шаманом». Чем же она плоха? Битва с эльфами — это, безусловно, важное и нужное дело, и на месте руководителя мы бы дружно согласились, что причина уважительная. Но заметим, что в рамках этой модели можно объяснить множество потенциальных исходов, среди которых довольно маловероятным представляется наблюдаемый: тот, в котором Василий не погиб в бою, не остался со своей принцессой и не был порабощён каким-нибудь завистливым шаманом. Отметим и другой недостаток этой модели: её невозможно провалидировать. Если в совершенно случайной модели можно оценить вероятность опоздания и впоследствии, когда накопятся ещё примеры, проверить, правильно ли мы её посчитали, то в мире, где открываются порталы и любой аналитик может завоевать сердце орочьей принцессы, возможно всё, и даже если больше никто не попадёт в такую ситуацию, Василий всё равно сможет бить себя в грудь кулаком и говорить, что он избранный. Так что, наверное, это тоже не очень хорошая модель. Модель «Василий опоздал, потому что проспал» достаточно проста, чтобы в неё поверить, и в то же время даёт руководителю возможность принять решение, что делать с Василием. Обратимся к примеру из машинного обучения. Сравним три модели линейной регрессии: Даже и не запрашивая тестовую выборку, мы можем сделать определённые выводы о качестве этих моделей. Средняя (квадратичная) явно лучше левой (линейной), потому что она лучше объясняет то, что мы видим: тот факт, что облако точек обучающей выборки выглядит вогнутым вниз. А что с правым, почему мы можем утверждать, что он хуже? Есть много причин критиковать его. Остановимся вот на какой. На средней картинке у нас приближение квадратичной функцией, а на правой — многочленом довольно большой степени (на самом деле, десятой). А ради интереса: как выглядит график квадратичной функции и как — многочлена десятой степени со случайно сгенерированными коэффициентами? Давайте сгенерируем несколько и отметим их значения в точках обучающей выборки: Обратите внимание на масштаб на графиках справа. И какова вероятность, что нам достался именно тот многочлен десятой степени, у которого значения в обучающих точках по модулю в пределах сотни? Очевидно, она очень мала. Поэтому мы можем сказать, что выбор в качестве модели многочлена десятой степени не очень обоснован. Слишком простая модель плохо объясняет наблюдаемые нами данные, тогда как слишком сложная делает это хорошо, но при этом описывает слишком многообразный мир, в котором имеющиеся у нас данные оказываются уже слишком частным случаем. В каком-то смысле наш способ выбора модели оказывается переформулировкойбритвы Оккама: из моделей, пристойно описывающих наблюдаемые явления, следует выбирать наиболее минималистичную.", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Байесовский подход к выбору модели: формализация", "text": "Пусть у нас есть некоторое семейство моделейи для каждогозадана какая-то своя вероятностная модель. В духе байесовского подхода было бы оценить условное распределение моделей и в качестве наилучшей модели взять её моду. Если же считать все модели равновероятными, то мы сводим всё к максимизации только лишь: Величинаназываетсяобоснованностью(evidence, marginal likelihood) модели. Отметим, что такое определение вполне согласуется с мотивацией из предыдущего подраздела. Слишком простая модель плохо описывает наблюдаемые данные, и потому будет отвергнута. В свою очередь, слишком сложная модель способна описывать гораздо большее многообразие явлений, чем нам было бы достаточно. Таким образом, компромисс между качеством описания и сложностью и даёт нам оптимальную модель. Вернёмся к нашей любимой задаче аппроксимации функции одной переменной многочленом небольшой степени по нескольким точкам, значение в которых было искажено нормальным шумом. Построим несколько моделей, приближающих многочленом степени не выше некоторого(будет принимать значения 1, 3 и 6), положив в вероятностной модели. Мы не будем приводить полный вывод обоснованности для задачи регрессии, а сразу выпишем ответ: Посмотрим, какой будет обоснованность для разного числа обучающих точек: Можно убедиться, что для регрессии по двум точкам наиболее обоснованная — линейная модель (и неудивительно), тогда как с ростом числа точек более обоснованной становится модель с многочленом третьей степени; слишком сложная же модель шестой степени всегда плетётся в хвосте. Точно вычислить обоснованность может быть трудной задачей (попробуйте проделать это сами хотя бы для линейной регрессии!). Есть разные способы посчитать её приближённо; мы рассмотрим самый простой. Напомним, что Воспользуемсяприближением Лапласа, то есть разложим(как функцию от) вблизи своего максимума, то есть вблизив ряд Тейлора: где линейный член отсутствует, поскольку разложение делается в точке локального экстремума, а— знакомая нам матрица Фишера. Далее,мы можем с точностью до второго порядка приблизить. Получается, что Несмотря на то, чтои, сгруппированные нами во «всякие штуки», существенным образом зависят от модели, при большихони вносят в показатель гораздо меньше вклада, чем первые два слагаемых. Таким образом, мы можем себе позволить вместо трудновычисляемыхиспользовать для сравнения модели", "useful_links": []}
{"document_title": "Байесовский подход к оцениванию", "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu", "section_title": "Фреквентисты против байесиан: кто кого?", "text": "Мы с вами познакомились с двумя парадигмами оценивания: фреквентистской(frequentist, от слова \"frequency\", частота) — в которой считается, что данные являются случайным (настоящая случайность!) семплом из некоторого фиксированного распределения, которое мы стараемся оценить по этому семплу, и байесовской— в которой данные считаются данностью и в которой мы используем данные для обновления наших априорных представлений о распределении параметров (здесь случайности нет, а есть лишь нехватка знания). У обеих есть свои достоинства и недостатки, поборники и гонители. К недостаткам байесовской относится, безусловно, её вычислительная сложность: возможно, вы помните, в пучину вычислений сколь мрачных нас низвергла банальная задача линейной регрессии, и дальше становится только ещё трудней. Если мы захотим байесовский подход применять к более сложным моделям, например, нейросетям, нам придётся прибегать к упрощениям, огрублениям, приближениям, что, разумеется, ухудшает наши оценки. Но, если простить ему эту вынужденную неточность, он логичнее и честней, и мы продемонстрируем это на следующем примере. Одно известное свойство оценки максимального правдоподобия —асимптотическая нормальность. Если оценивать наши весапо различным наборам изобучающих примеров, причём считать, что наборы выбираются случайно (не будем уточнять, как именно), то оценкатоже превращается в случайную величину, которая как-то распределена. Теория утверждает, что при где— истинное значение весов, а— матрица информации Фишера, которая определяется как что при некоторых не слишком обременительных ограничениях равно При этом поскольку, матрица тоже распадается в сумму, и получается, что, то есть с ростомковариацияоценки максимального правдоподобия стремится к нулю. На интуитивном уровне можно сказать, что матрица информации Фишера показывает, сколько информации о весахсодержится в. Поговорим о проблемах. В реальной ситуации мы не знаеми тем более не можем посчитать матрицу Фишера, то есть мы с самого начала вынуждены лукавить. Ясно, что вместоможно взять просто, а вместо— матрицу, которую можно даже при желании определить как безо всякого математического ожидания. Итак, хотя мы можем теперь построить доверительный интервал для оцениваемых параметров, по ходу нами было сделано много упрощений: мы предположили, что асимптотическая оценка распределения уже достигнута, отперешли к, а для полноты чувств ещё и избавились от математического ожидания. В байесовском подходе мы такого себе не позволяем.", "useful_links": []}
