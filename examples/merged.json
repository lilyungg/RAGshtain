[
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "Multi-class classification: many labels, only one correct Binary classification: two labels, only one correct Multi-label classification: many labels, several can be correct Multi-class classification: many labels, only one correct Text classification is an extremely popular task. You enjoy working text classifiers in your mail agent: it classifies letters and filters spam. Other applications include document classification, review classification, etc. Text classifiers are often used not as an individual task, but as part of bigger pipelines. For example, a voice assistant classifies your utterance to understand what you want (e.g., set the alarm, order a taxi or just chat) and passes your message to different models depending on the classifier's decision. Another example is a web search engine: it can use classifiers to identify the query language, to predict the type of your query (e.g., informational, navigational, transactional), to understand whether you what to see pictures or video in addition to documents, etc. Since most of the classification datasets assume that only one label is correct (you will see this right now!), in the lecture we deal with this type of classification, i.e. the single-label classification . We mention multi-label classification in a separate section ( Multi-Label Classification ). Datasets for Classification Datasets for text classification are very different in terms of size (both dataset size and examples' size), what is classified, and the number of labels. Look at the statistics below. Dataset Type Number of labels Size (train/test) Avg. length (tokens) SST sentiment 5 or 2 8.5k / 1.1k 19 IMDb Review sentiment 2 25k / 25k 271 Yelp Review sentiment 5 or 2 650k / 50k 179 Amazon Review sentiment 5 or 2 3m / 650k 79 TREC question 6 5.5k / 0.5k 10 Yahoo! Answers question 10 1.4m / 60k 131 AG’s News topic 4 120k / 7.6k 44 Sogou News topic 6 54k / 6k 737 DBPedia topic 14 560k / 70k 67 Some of the datasets can be downloaded here . Some of the datasets can be downloaded here . The most popular datasets are for sentiment classification . They consist of reviews of movies, places or restaurants, and products. There are also datasets for question type classification and topic classification. To better understand typical classification tasks, below you can look at the examples from different datasets. How to: pick a dataset and look at the examples to get a feeling of the task. Or you can come back to this later! SST is a sentiment classification dataset which consists of movie reviews (from Rotten Tomatoes html files). The dataset consists of parse trees of the sentences, and not only entire sentences, but also smaller phrases have a sentiment label. There are five labels: 1 (very negative), 2 (negative), 3 (neutral), 4 (positive), and 5 (very positive) (alternatively, labels can be 0-4). Depending on the used labels, you can get either binary SST-2 dataset (if you only consider positivity and negativity) or fine-grained sentiment SST-5 (when using all labels). Note that the dataset size mentioned above (8.5k/2.2k/1.1k for train/dev/test) is in the number of sentences. However, it also",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "labels can be 0-4). Depending on the used labels, you can get either binary SST-2 dataset (if you only consider positivity and negativity) or fine-grained sentiment SST-5 (when using all labels). Note that the dataset size mentioned above (8.5k/2.2k/1.1k for train/dev/test) is in the number of sentences. However, it also has 215,154 phrases that compose each sentence in the dataset. For more details, see the original paper . Look how sentiment of a sentence is composed from its parts. Label : 3 Review : Makes even the claustrophobic on-board quarters seem fun . Label : 1 Review : Ultimately feels empty and unsatisfying , like swallowing a Communion wafer without the wine . Label : 5 Review : A quiet treasure -- a film to be savored . IMDb is a large dataset of informal movie reviews from the Internet Movie Database. The collection allows no more than 30 reviews per movie. The dataset contains an even number of positive and negative reviews, so randomly guessing yields 50% accuracy. The reviews are highly polarized: they are only negative (with the highest score 4 out of 10) or positive (with the lowest score 7 out of 10). For more details, see the original paper . Label : negative Review Hobgoblins .... Hobgoblins .... where do I begin?!? This film gives Manos - The Hands of Fate and Future War a run for their money as the worst film ever made . This one is fun to laugh at , where as Manos was just painful to watch . Hobgoblins will end up in a time capsule somewhere as the perfect movie to describe the term : \" 80 's cheeze \" . The acting ( and I am using this term loosely ) is atrocious , the Hobgoblins are some of the worst puppets you will ever see , and the garden tool fight has to be seen to be believed . The movie was the perfect vehicle for MST3 K , and that version is the only way to watch this mess . This movie gives Mike and the bots lots of ammunition to pull some of the funniest one - liners they have ever done . If you try to watch this without the help of Mike and the bots ..... God help you ! ! Label : positive Review One of my favorite movies I saw at preview in Seattle . Tom Hulce was amazing , with out words could convey his feelings / thoughts . I actually sent Mike Ferrell some donation money to help the film get distributed . It is good . System says I need more lines but do not want to give away plot stuff . I was in the audience in Seattle with Hulce and director , a writer I think and Mike Ferrell . They talked for about an hour afterwords . Not really a dry eye in the house . Why Hollywood continues to be stupid I do not know . ( actually I do know , it is our fault ,",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "and director , a writer I think and Mike Ferrell . They talked for about an hour afterwords . Not really a dry eye in the house . Why Hollywood continues to be stupid I do not know . ( actually I do know , it is our fault , look what we watch)Well you get what you pay for guys . Get this and see it with someone special . It is a gem . Label : negative Review Okay , if you have a couple hours to waste , or if you just really hate your life , I would say watch this movie . If anything it 's good for a few laughs . Not only do you have obese , topless natives , but also special effects so bad they are probably outlawed in most states . Seriuosly , the rating of ' PG ' is pretty humorous too , once you see the Native Porn Extravaganza . I would n't give this movie to my retarded nephew . You could n't even show this to Iraqi prisoners without violating the Geneva Convention . The plot is sketchy , and cliché , and dumb , and stupid . The acting is horrible , and the ending is so painful to watch I actually began pouring salt into my eye just to take my mind off of the idiocy filling my TV screen . Label : positive Review I really liked this movie ... it was cute . I enjoyed it , but if you did n't , that is your fault . Emma Roberts played a good Nancy Drew , even though she is n't quite like the books . The old fashion outfits are weird when you see them in modern times , but she looks good on them . To me , the rich girls did n't have outfits that made them look rich . I mean , it looks like they got all the clothes -blindfolded- at a garage sale and just decided to put it on all together . All of the outfits were tacky , especially when they wore the penny loafers with their regular outfits . I do not want to make the movie look bad , because it definitely was n't ! Just go to the theater and watch it ! ! ! You will enjoy it ! Label : negative Review I always found Betsy Drake rather creepy , and this movie reinforces that . As another review said , this is a stalker movie that is n't very funny . I watched it because it has CG in it , but he hardly gets any screen time . It 's no \" North by Northwest \" ... Label : negative Review This movie was on t.v the other day , and I did n't enjoy it at all . The first George of the jungle was a good comedy , but the sequel .... completely awful . The new actor and actress to play the lead roles were n't",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "negative Review This movie was on t.v the other day , and I did n't enjoy it at all . The first George of the jungle was a good comedy , but the sequel .... completely awful . The new actor and actress to play the lead roles were n't good at all , they should of had the original actor ( Brendon Fraiser ) and original actress ( i forgot her name ) so this movie gets the 0 out of ten rating , not a film that you can sit down and watch and enjoy , this is a film that you turn to another channel or take it back to the shop if hired or bought . It was good to see Ape the ape back , but was n't as fun as the first , they should of had the new George as Georges son grown up , and still had Bredon and ( what s her face ) in the film , that would 've been a bit better then it was . Label : positive Review I loved This Movie . When I saw it on Febuary 3rd I knew I had to buy It ! ! ! It comes out to buy on July 24th ! ! ! It has cool deaths scenes , Hot girls , great cast , good story , good acting . Great Slasher Film . the Movies is about some serial killer killing off four girls . SEE this movies Label : positive Review gone in 60 seconds is a very good action comedy film that made over $ 100 million but got blasted by most critics . I personally thought this was a great film . The story was believable and has probobly the greatest cast ever for this type of movie including 3 academy award winners nicolas cage , robert duvall and the very hot anjolina jolie . other than the lame stunt at the end this is a perfect blend of action comedy and drama . my score is * * * * ( out of * * * * ) Label : positive Review This is one of the most interesting movies I have ever seen . I love the backwoods feel of this movie . The movie is very realistic and believable . This seems to take place in another era , maybe the late 60 's or early 70 's . Henry Thomas works well with the young baby . Very moving story and worth a look . Label : positive Review I admit it 's very silly , but I 've practically memorized the damn thing ! It holds a lot of good childhood memories for me ( my brother and I saw it opening day ) and I have respect for any movie with FNM on the soundtrack . Label : positive Review I love the series ! Many of the stereotypes portraying Southerrners as hicks are very apparent , but such people do exist all too frequently . The portrayal of",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "it opening day ) and I have respect for any movie with FNM on the soundtrack . Label : positive Review I love the series ! Many of the stereotypes portraying Southerrners as hicks are very apparent , but such people do exist all too frequently . The portrayal of Southern government rings all too true as well , but the sympathetic characters reminds one of the many good things about the South as well . Some things never change , and we see the \" good old boys \" every day ! There is a Lucas Buck in every Southern town who has only to make a phone call to make things happen , and the storybook \" po ' white trash \" are all too familiar . Aside from the supernatural elements , everything else could very well happen in the modern South ! I somehow think Trinity , SC must have been in Barnwell County ! The Yelp reviews dataset is obtained from the Yelp Dataset Challenge in 2015 . Depending on the number of labels, you can get either Yelp Full (all 5 labels) or Yelp Polarity (positive and negative classes) dataset. Full has 130,000 training samples and 10,000 testing samples in each star, and the Polarity dataset has 280,000 training samples and 19,000 test samples in each polarity. For more details, see the Kaggle Challenge page . Label : 4 Review I had a serious craving for Roti. So glad I found this place. A very small menu selection but it had exactly what I wanted. The serving for $8.20 after tax is enough for 2 meals. I know where to go from now on for a great meal with leftovers. This is a noteworthy place to bring my Uncle T.J. who's a Trini when he comes to visit. Label : 2 Review The actual restaurant is fine, the service is friendly and good. I am not going to go in to the food other than to say, no. Oh well $340 bucks and all I can muster is a no. Label : 5 Review What a cool little place tucked away behind a strip mall. Would never have found this if it was not suggested by a good friend who raved about the cappuccino! He is world traveler, so, it's a must try if it's the best cup he's ever had. He was right! Don't know if it's in the beans or the care that they take to make it with a fab froth decoration on top. My hubby and I loved the caramel brulee taste.. My son loved the hot \"\"warm\"\" cocoa. Yeah, we walked in as a family last night and almost everyone turned our way since we did not fit the hip college crowd. Everyone was really friendly, though. The sweet young man behind the counter gave my son some micro cinnamon doughnuts and scored major points with the little dude! We will be back. Label : 3 Review Jersey Mike's is okay. It's a chain place, and a bit over priced for",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "crowd. Everyone was really friendly, though. The sweet young man behind the counter gave my son some micro cinnamon doughnuts and scored major points with the little dude! We will be back. Label : 3 Review Jersey Mike's is okay. It's a chain place, and a bit over priced for fast food. I ordered a philly cheese steak. It was mostly bread, with a few thing microscopic slices of meat. A little cheese too. And a sliver or two of peppers. But mostly, it was bread. I think it's funny the people that work here try to make small talk with you. \"So, what are you guys up to tonight?\" I think it would be fun to just try and f*#k with them, and say something like, \"Oh you know, smoking a little meth and just chilling with some hookers.\" See what they say to that. Label : 5 Review Love it!!! Wish we still lived in Arizona as Chino is the one thing we miss. Every time I think about Chino Bandido my mouth starts watering. If I am ever in the state again I will drive out of my way just to go to it again. YUMMY! Label : 4 Review I have been here a few times, but mainly at dinner. Dinner Has always been great, great waiters and staff, with a LCD TV playing almost famous famous bolywood movies. LOL It cracks me up when they dance.....LOL...anyhow, Great vegetarian choices for people who eat there veggies, but trust me, I am a MEAT eater, Chicekn Tika masala, Little dry but still good. My favorite is there Palak Paneer. Great for the vegetarian. I have also tried there lunch Buffet for 11.00. I give a Thumbs up.. Good, serve yourself, and pig out!!!!!! Label : 3 Review Very VERY average. Actually disappointed in the braciole. Kelsey with the pretty smile and form fitting shorts would probably make me think about going back and trying something different. Label : 1 Review So, what kind of place serves chicken fingers and NO Ranch dressing?????? The only sauces they had was honey mustard and \"\"Canes Secret sauce\"\" Can I say EEWWWW!! I thought that the sauce tasted terrible. I am not too big a fan of honey mustard but I do On occasion eat it if there is nothing else And that wasn't even good! The coleslaw was awful also. I do have to say that the chicken fingers were very juicy but also very bland. Those were the only 2 items that I tried, not that there were really any more items on the menu, Texas toast? And Fries I think?? Overall, I would never go back. Label : 4 Review Good food, good drinks, fun bar. There are quite a few Buffalo Wild Wings in the valley and they're a fun place to grab a quick lunch or dinner and watch the game. They have a pretty good garden burger and their buffalo chips (french fry-ish things) are really good. If you like bloody mary's, they have the best one.",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "few Buffalo Wild Wings in the valley and they're a fun place to grab a quick lunch or dinner and watch the game. They have a pretty good garden burger and their buffalo chips (french fry-ish things) are really good. If you like bloody mary's, they have the best one. It's so good...really spicy and filled with celery and olives. Be careful when you come though, if there is a game on, you'll have to get there early or you definitely won't get a spot to sit. Label : 5 Review Excellent in every way. Attentive and fun owners who tend bar every weekend night - GREAT live music, excellent wine selection. Keeping Fountain Hills young.... one weekend at a time. Label : 1 Review After repeat visits it just gets worse - the service, that is. It was as if we were held hostage and could not leave for a full 25 minutes because that's how long it took to receive hour check after several requests to several different employees. Female servers might be somewhat cute but know absolutely nothing about beer and this is a brewpub. I asked if they have an seasonal beers and the reply was no, that they only sell their own beers! Even more amusing is their \"\"industrial pale ale\"\" is an IPA but it is not bitter. So, they say it's an IPA but it's not bitter, it's not a true-to-style IPA. Then people say \"\"Oh I don't like IPA's\"\" and want something else. Their attempt to rename a beer/style is actually hurting them. Amazing. The Amazon reviews dataset consists of reviews from amazon which include product and user information, ratings, and a plaintext review. The dataset is obtained from the Stanford Network Analysis Project (SNAP) . Depending on the number of labels, you can get either Amazon Full (all 5 labels) or Amazon Polarity (positive and negative classes) dataset. Full has 600,000 training samples and 130,000 testing samples in each star, and the Polarity dataset has 1800,000 training samples and 200,000 test samples in each polarity. The fields used are review title and review content. Label : 4 Review Title : good for a young reader Review Content : just got this book since i read it when i was younger and loved it. i will reread it one of these days, but i bet its pretty lame 15 years later, oh well. Label : 2 Review Title : The Castle in the Attic Review Content : i read the castle in the attic and i thoght it wasn't very entrtaning. but that's just my opinion. i thought on some of the chapters it dragged on and lost me alot. like it would talk about one thing and then another without alot of detail. for my opinion, it was an ok book. it had it's moments like whats going to happen next then it was really boring. Label : 1 Review Title : worst book in the world!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Review Content : This was the worst book I have ever read in my entire life!",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "for my opinion, it was an ok book. it had it's moments like whats going to happen next then it was really boring. Label : 1 Review Title : worst book in the world!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Review Content : This was the worst book I have ever read in my entire life! I was forced to read it for school. It was complicated and very boring. I would not recommend this book to anyone!! Please don't waste your time and money to read this book!! Read something else!! Label : 3 Review Title : It's okay. Review Content : I'm using it for track at school as a sprinter. It's okay, but to hold it together is a velcro strap. So you either use the laces or take them out and use only the velcro. Also, if you order them, order them a half size or a full size biggerthen your normal size or else it'll be a tight squeeze. Plus side, you can still run on your toes in them. Label : 5 Review Title : Time Well Spent Review Content : For those beginning to read the classics this one is a great hook. While the characters are complex the story is linear and the allusions are simple enough to follow. One can't help but hope Tess's life will somehow turn out right although knowing it will not. The burdens she encounters seem to do little to stop her from moving forward. Life seems so unfair to her, but Hardy handles her masterfully; indeed it is safe to say Hardy loves her more than God does. Label : 2 Review Title : Not a brilliant book but... Review Content : I didn't like this book very much. It was silly. I'm sorry that I've wasted time reading this book. There are better books to read. Label : 3 Review Title : Simple Review Content : This book was not anything special. Although I love romances, it was too simple. The symbolism was spelled out to the readers in a blunt manner. The less educated readers may appreciate it. The wording was quite beautiful at times and the plot was enchanting (perfect for a movie) but it is not heart wrenching like the movie Titantic (which was a must see!) ;) Label : 1 Review Title : WHY??????????????????????????????????????????????????? Review Content : WHY are poor, innocent school kids forced to read this intensly dull text? It is enough to put anyone off English Lit for LIFE. If anyone in authority is reading this, PLEASE take this piece of junk OFF the sylabus...PLEASE!!!!!!!!!!! Label : 4 Review Title : looking back Review Content : I have read several Thomas Hardy novels starting with The Mayor of Casterbridge many years ago in high school and I never really appreciated the style and the fact that like other Hardy novels Tess is a love story and a very good story. Worth reading Label : 5 Review Title : Great Puzzle Review Content : This is an excellent puzzle for very young children. Melissa & Doug products are",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "never really appreciated the style and the fact that like other Hardy novels Tess is a love story and a very good story. Worth reading Label : 5 Review Title : Great Puzzle Review Content : This is an excellent puzzle for very young children. Melissa & Doug products are well made and kids love them. This puzzle is wooden so kids wont destroy it if they try to roughly put the pieces in. The design is adorable and makes a great gift for any young animal lover. TREC is a dataset for classification of free factual questions. It defines a two-layered taxonomy, which represents a natural semantic classification for typical answers in the TREC task. The hierarchy contains 6 coarse classes (ABBREVIATION, ENTITY, DESCRIPTION, HUMAN, LOCATION and NUMERIC VALUE) and 50 fine classes. For more details, see the original paper . Label : DESC (description) Question : How did serfdom develop in and then leave Russia ? Label : ENTY (entity) Question : What films featured the character Popeye Doyle ? Label : HUM (human) Question : What team did baseball 's St. Louis Browns become ? Label : HUM (human) Question : What is the oldest profession ? Label : DESC (description) Question : How can I find a list of celebrities ' real names ? Label : ENTY (entity) Question : What fowl grabs the spotlight after the Chinese Year of the Monkey ? Label : ABBR (abbreviation) Question : What is the full form of .com ? Label : ENTY (entity) Question : What 's the second - most - used vowel in English ? Label : DESC (description) Question : What are liver enzymes ? Label : HUM (human) Question : Name the scar-faced bounty hunter of The Old West . Label : NUM (numeric value) Question : When was Ozzy Osbourne born ? Label : DESC (description) Question : Why do heavier objects travel downhill faster ? Label : HUM (human) Question : Who was The Pride of the Yankees ? Label : HUM (human) Question : Who killed Gandhi ? Label : LOC (location) Question : What sprawling U.S. state boasts the most airports ? Label : DESC (description) Question : What did the only repealed amendment to the U.S. Constitution deal with ? Label : NUM (numeric value) Question : How many Jews were executed in concentration camps during WWII ? Label : DESC (description) Question : What is \" Nine Inch Nails \" ? Label : DESC (description) Question : What is an annotated bibliography ? Label : NUM (numeric value) Question : What is the date of Boxing Day ? Label : ENTY (entity) Question : What articles of clothing are tokens in Monopoly ? Label : HUM (human) Question : Name 11 famous martyrs . Label : DESC (description) Question : What 's the Olympic motto ? Label : NUM (numeric value) Question : What is the origin of the name ` Scarlett ' ? The dataset is gathered from Yahoo! Answers Comprehensive Questions and Answers version 1.0 dataset . In",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "11 famous martyrs . Label : DESC (description) Question : What 's the Olympic motto ? Label : NUM (numeric value) Question : What is the origin of the name ` Scarlett ' ? The dataset is gathered from Yahoo! Answers Comprehensive Questions and Answers version 1.0 dataset . In contains the 10 largest main categories: \"Society & Culture\", \"Science & Mathematics\", \"Health, \"Education & Reference\", \"Computers & Internet\", \"Sports\", \"Business & Finance\", \"Entertainment & Music\", \"Family & Relationships\", \"Politics & Government\". Each class contains 140,000 training samples and 5,000 testing samples. The data consists of question title and content, as well as the best answer. Label : Society & Culture Question Title : Why do people have the bird, turkey for thanksgiving? Question Content : Why this bird? Any Significance? Best Answer It is believed that the pilgrims and indians shared wild turkey and venison on the original Thanksgiving. Turkey's \"Americanness\" was established by Benjamin Franklin, who had advocated for the turkey, not the bald eagle, becoming the national bird. Label : Science & Mathematics Question Title : What is an \"imaginary number\"? Question Content : What is an \"imaginary number\", and how is it treated in algebra equations? Best Answer Imaginary numbers are numbers than when squared equal a negative number, as in i^2 = -1, where i is the imaginary number. You'll also often see them represented as i = √-1 (that's the square root of -1). Don't be confused by the poorly chosen name - imaginary numbers do indeed exist and are used in advanced math, such as in the physics of electromagnetic fields. The analogy that Wikipedia uses is a good one - just like you don't need the concept of fractions to count stones, it doesn't mean that fractions don't exist. :) Label : Health Question Title : Does echinacea really help prevent colds? Question Content : Or is a waste of money... Best Answer Well, there appears to be some controvery about this. While some people swear by the stuff, others say that it has no real effect on overcoming a cold. Here are some links, one of which is from a National Institute of Health study. I hope these help you decide whether to head to the health store or not. Label : Education & Reference Question Title : How do I find an out of print book? Question Content : When I was a kid I remember seeing a book that was like an yearbook of all newspapers published by the Times during WW II. Each of the years is compiled into a different book. It gave one a very uniqie perspecitev into the UK druing the war, and even had advertisements from thaat time. Anybody out there know how to track such books? Best Answer here are several websites that you can find rare or out of print books. A couple would be alibris.com or abebooks.com. These sites list books by booksellers all over the country and some internationally. Label : Computers & Internet Question Title : How can I record audio",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "books? Best Answer here are several websites that you can find rare or out of print books. A couple would be alibris.com or abebooks.com. These sites list books by booksellers all over the country and some internationally. Label : Computers & Internet Question Title : How can I record audio directly from the browser to the web server? Question Content : For a podcasting application, I'd like my web server to be able to receive audio straight from the browser. Something like a \"Push to talk\" button. It seems it's possible to do this with Flash. Is there any other way? With Flash, do I need to buy a Macromedia server licence, or are there alternatives to have Flash on the browser talk to my server? Best Answer Userplane has an audio/video recorder that will do that - you can check it out at http://www.userplane.com/apps/videoRecorder.cfm Label : Sports Question Title : Why doesn't the NBA implement a minor leagues? Question Content : I don't want to see any more High School kids on the court, shooting airballs and missing defensive assignments. Best Answer The NBA does have minor leagues - they're called the CBA, and the International leagues. :) Seriously - because viewers seem to value explosiveness over efficiency, I think we're seeing a major shift in the average age of NBA players towards young athletes that are quicker, high-flying and more resilient to injury. I wouldn't be surprised at all if by the end of this decade the average age of the league allstars is well under 25. Label : Business & Finance Question Title : When will Google buy Yahoo? Question Content : The two businesses are very complementary in terms of strengths and weaknesses. Do we want to beat ourselves up competing with each other for resources and market share, or unite to beat MSFT? Best Answer Their respective market caps are too close for this to ever happen. Interestingly, many reporters, analysts and tech pundits that I talk to think that the supposed competition between Google and Yahoo is fallacious, and that they are very different companies with very different strategies. Google's true competitor is often seen as being Microsoft, not Yahoo. This would support your claim that they are complementary. Label : Entertainment & Music Question Title : Can someone tell me what happened in Buffy's series finale? Question Content : I had to work and missed the ending. Best Answer The gang makes an attack on the First's army, aided by Willow, who performs a powerful spell to imbue all of the Potentials with Slayer powers. Meanwhile, wearing the amulet that Angel brought, Spike becomes the decisive factor in the victory, and Sunnydale is eradicated. Buffy and the gang look back on what's left of Sunnydale, deciding what to do next... --but more importantly, there will no longer be any slaying in Sunnydale, or is that Sunnyvale.... Label : Family & Relationships Question Title : How do you know if you're in love? Question Content : Is it possible to know for sure? Best Answer In",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "deciding what to do next... --but more importantly, there will no longer be any slaying in Sunnydale, or is that Sunnyvale.... Label : Family & Relationships Question Title : How do you know if you're in love? Question Content : Is it possible to know for sure? Best Answer In my experience you just know. It's a long term feeling of always wanting to share each new experience with the other person in order to make them happy, to laugh or to know what they think about it. It's jonesing to call even though you just got off an hour long phone call with them. It's knowing that being with them makes you a better person. It's all of the above and much more. Label : Politics & Government Question Title : How come it seems like Lottery winners are always the ones that buy tickets in low income areas.? Question Content : Pure luck or Government's way of trying to balance the rich and the poor. Best Answer I would put it down to psychology. People who feel they are well-off feel no need to participate in the lottery programs. While those who feel they are less than well off think \"Why not bet a buck or two on the chance to make a few million?\". It would seem to make sense to me. addition: Yes Matt - agreed. I just didn't state it as eloquently. Feeling 'no need to participate' is as you say related to education, and those well off tend to have a better education. The AG’s corpus was obtained from news articles on the web . From these articles, only the AG’s corpus contains only the title and description fields from the the 4 largest classes. The dataset was introduced in this paper . Label : Sci/Tech Title : Learning to write with classroom blogs Description Last spring Marisa Dudiak took her second-grade class in Frederick County, Maryland, on a field trip to an American Indian farm. Label : Sports Title : Schumacher Triumphs as Ferrari Seals Formula One Title Description BUDAPEST (Reuters) - Michael Schumacher cruised to a record 12th win of the season in the Hungarian Grand Prix on Sunday to hand his Ferrari team a sixth successive constructors' title. Label : Business Title : DoCoMo and Motorola talk phones Description Japanese mobile phone company DoCoMo is in talks to buy 3G handsets from Motorola, the world's second largest handset maker. Label : World Title : Sharon 'backs settlement homes' Description Reports say Israeli PM Ariel Sharon has given the green light to new homes in West Bank settlements. Label : Business Title : Why Hugo Chavez Won a Landslide Victory Description When the rule of Venezuelan President Hugo Chavez was reaffirmed in a landslide 58-42 percent victory on Sunday, the opposition who put the recall vote on the ballot was stunned. They obviously don't spend much time in the nation's poor neighborhoods. Label : Sci/Tech Title : Free-Speech for Online Gambling Ads Sought Description The operator of a gambling news site on the Internet",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "58-42 percent victory on Sunday, the opposition who put the recall vote on the ballot was stunned. They obviously don't spend much time in the nation's poor neighborhoods. Label : Sci/Tech Title : Free-Speech for Online Gambling Ads Sought Description The operator of a gambling news site on the Internet has asked a federal judge to declare that advertisements in U.S. media for foreign online casinos and sports betting outlets are protected by free-speech rights. Label : World Title : Kerry takes legal action against Vietnam critics (AFP) Description AFP - Democratic White House hopeful John Kerry's campaign formally alleged that a group attacking his Vietnam war record had illegal ties to US President George W. Bush's reelection bid. Label : Sports Title : O'Leary: I won't quit Description The Villa manager was said to be ready to leave the midlands club unless his assistants Roy Aitken and Steve McGregor were also given new three-and-a-half year deals. Label : World Title : Egypt eyes possible return of ambassador to Israel Description CAIRO - Egypt raised the possibility Tuesday of returning an ambassador to Israel soon, according to the official Mena news agency, a move that would signal a revival of full diplomatic ties after a four-year break. Label : Sports Title : Henry wants silverware Description Arsenal striker Thierry Henry insisted there must be an end product to the Gunners' record-breaking run. As Arsenal equalled Nottingham Forest's 42-game unbeaten League run Henry said: \"Even on the pitch we didn't realise what we had done.\" Label : Sci/Tech Title : Scientists Focus on Algae in Maine Lake (AP) Description AP - Scientists would kill possibly thousands of white perch under a project to help restore the ecological balance of East Pond in the Belgrade chain of lakes in central Maine. The Sogou News corpus was obtained from the combination of the SogouCA and SogouCS news corpora. The dataset consists of news articles (title and content fields) labeled with 5 categories: “sports”, “finance”, “entertainment”, “automobile” and “technology”. The original dataset is in Chinese, but you can produce Pinyin – a phonetic romanization of Chinese. You can do it using pypinyin package combined with jieba Chinese segmentation system (this is what the paper introducing the dataset did, and this is what I show you in the examples). The models for English can then be applied to this dataset without change. The dataset was introduced in this paper , the dataset in Pinyin can be downloaded here . Lena : Here I picked very small texts - usually, the samples are much longer. Label : automobile Title : tu2 we2n -LG be1i be3n sa4i di4 2 lu2n zha4n ba4 cha2ng ha4o ko3ng jie2 de3ng qi2 sho3u fu4 pa2n ta3o lu4n Content xi1n la4ng ti3 yu4 xu4n be3i ji1ng shi2 jia1n 5 yue4 28 ri4 ,LG be1i shi4 jie4 qi2 wa2ng sa4i be3n sa4i di4 2 lu2n za4i ha2n guo2 ka1i zha4n . zho1ng guo2 qi2 sho3u cha2ng ha4o , gu3 li4 , wa2ng ya2o , shi2 yue4 ca1n jia1 bi3 sa4i . tu2 we2i xia4n cha3ng",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "be3i ji1ng shi2 jia1n 5 yue4 28 ri4 ,LG be1i shi4 jie4 qi2 wa2ng sa4i be3n sa4i di4 2 lu2n za4i ha2n guo2 ka1i zha4n . zho1ng guo2 qi2 sho3u cha2ng ha4o , gu3 li4 , wa2ng ya2o , shi2 yue4 ca1n jia1 bi3 sa4i . tu2 we2i xia4n cha3ng shu4n jia1n . wa3ng ye4 bu4 zhi1 chi2 Flash Label : automobile Title : qi4 che1 pi2n da4o Content xi1n we2n jia3n suo3 : ke4 la2i si1 le4 300C go4ng 20 zha1ng ke3 shi3 jia4n pa2n ca1o zuo4 [ fa1ng xia4ng jia4n l: sha4ng yi1 zha1ng ; fa1ng xia4ng jia4n r: xia4 yi1 zha1ng ; hui2 che1 : zha1 ka4n yua2n da4 tu2 ]\\ ge1ng duo1 tu2 pia4n : ce4 hua4 : bia1n ji2 : me3i bia1n : zhi4 zuo4 :GOODA ji4 shu4 : Label : finance Title : shi2 da2 qi1 huo4 : hua2ng ji1n za3o pi2ng (06-11) Content shi4 cha3ng jia1 da4 me3i guo2 she1ng xi1 yu4 qi1 , me3i yua2n ji4n qi1 zo3u shi4 ba3o chi2 de2 xia1ng da1ng pi2ng we3n , ji1n jia4 ga1o we4i mi2ng xia3n sho4u ya1 , xia4 jia4ng to1ng da4o ba3o chi2 wa2n ha3o , zhe4n da4ng si1 lu4 ca1o zuo4 . gua1n wa4ng wa3ng ye4 bu4 zhi1 chi2 Flash hua2ng ji1n qi1 huo4 zi1 xu4n la2n mu4 DBpedia is a crow-sourced community effort to extract structured information from Wikipedia. The DBpedia ontology classification dataset is constructed by picking 14 non-overlapping classes from DBpedia 2014 . From each of the 14 ontology classes, the dataset contains 40,000 randomly chosen training samples and 5,000 testing samples. Therefore, the total size of the training dataset is 560,000, the testing dataset - 70,000. The dataset was introduced in this paper . Label : Company Title : Marvell Software Solutions Israel Abstract Marvell Software Solutions Israel known as RADLAN Computer Communications Limited before 2007 is a wholly owned subsidiary of Marvell Technology Group that specializes in local area network (LAN) technologies. Label : EducationalInstitution Title : Adarsh English Boarding School Abstract Adarsh English Boarding School is coeducational boarding school in Phulbari a suburb of Pokhara Nepal. Nabaraj Thapa is the founder and chairman of the school. The School motto reads Education For Better Citizen. Label : Artist Title : Esfandiar Monfaredzadeh Abstract Esfandiar Monfaredzadeh (Persian : اسفندیار منفردزاده) is an Iranian composer and director. He was born in 1941 in Tehran His major works are Gheisar Dash Akol Tangna Gavaznha. He has 2 daughters Bibinaz Monfaredzadeh and Sanam Monfaredzadeh Woods (by marriage). Label : Athlete Title : Elena Yakovishina Abstract Elena Yakovishina (born September 17 1992 in Petropavlovsk-Kamchatsky Russia) is an alpine skier from Russia. She competed for Russia at the 2014 Winter Olympics in the alpine skiing events. Label : OfficeHolder Title : Jack Masters Abstract John Gerald (Jack) Masters (born September 27 1931) is a former Canadian politician. He served as mayor of the city of Thunder Bay Ontario and as a federal Member of Parliament. Label : MeanOfTransportation Title : HMS E35 Abstract HMS E35 was a British E class submarine built by John Brown",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "Gerald (Jack) Masters (born September 27 1931) is a former Canadian politician. He served as mayor of the city of Thunder Bay Ontario and as a federal Member of Parliament. Label : MeanOfTransportation Title : HMS E35 Abstract HMS E35 was a British E class submarine built by John Brown Clydebank. She was laid down on 20 May 1916 and was commissioned on 14 July 1917. Label : Building Title : Aspira Abstract Aspira is a 400 feet (122 m) tall skyscraper in the Denny Triangle neighborhood of Seattle Washington. It has 37 floors and mostly consists of apartments. Construction began in 2007 and was completed in late 2009. Label : NaturalPlace Title : Sierra de Alcaraz Abstract The Sierra de Alcaraz is a mountain range of the Cordillera Prebética located in Albacete Province southeast Spain. Its highest peak is the Pico Almenara with an altitude of 1796 m. Label : Village Title : Piskarki Abstract Piskarki [pisˈkarki] is a village in the administrative district of Gmina Jeżewo within Świecie County Kuyavian-Pomeranian Voivodeship in north-central Poland. The village has a population of 135. Label : Animal Title : Lesser small-toothed rat Abstract The Lesser Small-toothed Rat or Western Small-Toothed Rat (Macruromys elegans) is a species of rodent in the family Muridae. It is found only in West Papua Indonesia. Label : Plant Title : Vangueriopsis gossweileri Abstract Vangueriopsis gossweileri is a species of flowering plants in the family Rubiaceae. It occurs in West-Central Tropical Africa (Cabinda Province Equatorial Guinea and Gabon). Label : Album Title : Dreamland Manor Abstract Dreamland Manor is the debut album of German power metal band Savage Circus. The album sounds similar to older classic Blind Guardian. Label : Film Title : The Case of the Lucky Legs Abstract The Case of the Lucky Legs is a 1935 mystery film the third in a series of Perry Mason films starring Warren William as the famed lawyer. Label : WrittenWork Title : Everybody Loves a Good Drought Abstract Everybody Loves a Good Drought is a book written by P. Sainath about his research findings of poverty in the rural districts of India. The book won him the Magsaysay Award. General View Here we provide a general view on classification and introduce the notation. This section applies to both classical and neural approaches. We assume that we have a collection of documents with ground-truth labels. The input of a classifier is a document \\(x=(x_1, \\dots, x_n)\\) with tokens \\((x_1, \\dots, x_n)\\), the output is a label \\(y\\in 1\\dots k\\). Usually, a classifier estimates probability distribution over classes, and we want the probability of the correct class to be the highest. Get Feature Representation and Classify Text classifiers have the following structure: feature extractor A feature extractor can be either manually defined (as in classical approaches ) or learned (e.g., with neural networks ). classifier A classifier has to assign class probabilities given feature representation of a text. The most common way to do this is using logistic regression , but other variants are also possible (e.g., Naive Bayes classifier or",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "defined (as in classical approaches ) or learned (e.g., with neural networks ). classifier A classifier has to assign class probabilities given feature representation of a text. The most common way to do this is using logistic regression , but other variants are also possible (e.g., Naive Bayes classifier or SVM ). In this lecture, we'll mostly be looking at different ways to build feature representation of a text and to use this representation to get class probabilities. Generative and Discriminative Models A classification model can be either generative or discriminative . generative models Generative models learn joint probability distribution of data \\(p(x, y) = p(x|y)\\cdot p(y)\\). To make a prediction given an input \\(x\\), these models pick a class with the highest joint probability: \\(y = \\arg \\max\\limits_{k}p(x|y=k)\\cdot p(y=k)\\). discriminative models Discriminative models are interested only in the conditional probability \\(p(y|x)\\), i.e. they learn only the border between classes. To make a prediction given an input \\(x\\), these models pick a class with the highest conditional probability: \\(y = \\arg \\max\\limits_{k}p(y=k|x)\\). In this lecture, we will meet both generative and discriminative models. Classical Methods for Text Classification In this part, we consider classical approaches for text classification. They were developed long before neural networks became popular, and for small datasets can still perform comparably to neural models. Lena : Later in the course, we will learn about transfer learning which can make neural approaches better even for very small datasets. But let's take this one step at a time: for now, classical approaches are a good baseline for your models. Naive Bayes Classifier A high-level idea of the Naive Bayes approach is given below: we rewrite the conditional class probability \\(P(y=k|x)\\) using Bayes's rule and get \\(P(x|y=k)\\cdot P(y=k)\\). This is a generative model! Naive Bayes is a generative model: it models the joint probability of data. Note also the terminology: prior probability \\(P(y=k)\\): class probability before looking at data (i.e., before knowing \\(x\\)); posterior probability \\(P(y=k|x)\\): class probability after looking at data (i.e., after knowing the specific \\(x\\)); joint probability \\(P(x, y)\\): the joint probability of data (i.e., both examples \\(x\\) and labels \\(y\\)); maximum a posteriori (MAP) estimate: we pick the class with the highest posterior probability. How to define P(x|y=k) and P(y=k)? P(y=k) : count labels \\(P(y=k)\\) is very easy to get: we can just evaluate the proportion of documents with the label \\(k\\) (this is the maximum likelihood estimate, MLE). Namely, \\[P(y=k)=\\frac{N(y=k)}{\\sum\\limits_{i}N(y=i)},\\] where \\(N(y=k)\\) is the number of examples (documents) with the label \\(k\\). P(x|y=k) : use the \"naive\" assumptions, then count Here we assume that document \\(x\\) is represented as a set of features, e.g., a set of its words \\((x_1, \\dots, x_n)\\): \\[P(x| y=k)=P(x_1, \\dots, x_n|y=k).\\] The Naive Bayes assumptions are Bag of Words assumption: word order does not matter, Conditional Independence assumption: features (words) are independent given the class. Intuitively, we assume that the probability of each word to appear in a document with class \\(k\\) does not depend on context (neither word order nor other words at all). For example, we can say that",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "order does not matter, Conditional Independence assumption: features (words) are independent given the class. Intuitively, we assume that the probability of each word to appear in a document with class \\(k\\) does not depend on context (neither word order nor other words at all). For example, we can say that awesome , brilliant , great are more likely to appear in documents with a positive sentiment and awful , boring , bad are more likely in negative documents, but we know nothing about how these (or other) words influence each other. awesome brilliant great awful boring bad With these \"naive\" assumptions we get: \\[P(x| y=k)=P(x_1, \\dots, x_n|y=k)=\\prod\\limits_{t=1}^nP(x_t|y=k).\\] The probabilities \\(P(x_i|y=k)\\) are estimated as the proportion of times the word \\(x_i\\) appeared in documents of class \\(k\\) among all tokens in these documents: \\[P(x_i|y=k)=\\frac{N(x_i, y=k)}{\\sum\\limits_{t=1}^{|V|}N(x_t, y=k)},\\] where \\(N(x_i, y=k)\\) is the number of times the token \\(x_i\\) appeared in documents with the label \\(k\\), \\(V\\) is the vocabulary (more generally, a set of all possible features). What if \\(N(x_i, y=k)=0\\)? Need to avoid this! What if \\(N(x_i, y=k)=0\\), i.e. in training we haven't seen the token \\(x_i\\) in the documents with class \\(k\\)? This will null out the probability of the whole document, and this is not what we want! For example, if we haven't seen some rare words (e.g., pterodactyl or abracadabra ) in training positive examples, it does not mean that a positive document can never contain these words. pterodactyl abracadabra To avoid this, we'll use a simple trick: we add to counts of all words a small \\(\\delta\\): \\[P(x_i|y=k)=\\frac{\\color{red}{\\delta} +\\color{black} N(x_i, y=k) }{\\sum\\limits_{t=1}^{|V|}(\\color{red}{\\delta} +\\color{black}N(x_t, y=k))} = \\frac{\\color{red}{\\delta} +\\color{black} N(x_i, y=k) }{\\color{red}{\\delta\\cdot |V|}\\color{black} + \\sum\\limits_{t=1}^{|V|}\\color{black}N(x_t, y=k)} ,\\] where \\(\\delta\\) can be chosen using cross-validation. Note : this is Laplace smoothing (aka Add-1 smoothing if \\(\\delta=1\\)). We'll learn more about smoothings in the next lecture when talking about Language Modeling. Making a Prediction As we already mentioned, Naive Bayes (and, more broadly, generative models) make a prediction based on the joint probability of data and class: \\[y^{\\ast} = \\arg \\max\\limits_{k}P(x, y=k) = \\arg \\max\\limits_{k} P(y=k)\\cdot P(x|y=k).\\] Intuitively, Naive Bayes expects that some words serve as class indicators. For example, for sentiment classification tokens awesome , brilliant , great will have higher probability given positive class then negative. Similarly, tokens awful , boring , bad will have higher probability given negative class then positive. awesome brilliant great awful boring bad Final Notes on Naive Bayes Practical Note : Sum of Log-Probabilities Instead of Product of Probabilities The main expression Naive Bayes uses for classification is a product lot of probabilities: \\[P(x, y=k)=P(y=k)\\cdot P(x_1, \\dots, x_n|y)=P(y=k)\\cdot \\prod\\limits_{t=1}^nP(x_t|y=k).\\] A product of many probabilities may be very unstable numerically. Therefore, usually instead of \\(P(x, y)\\) we consider \\(\\log P(x, y)\\): \\[\\log P(x, y=k)=\\log P(y=k) + \\sum\\limits_{t=1}^n\\log P(x_t|y=k).\\] Since we care only about argmax, we can consider \\(\\log P(x, y)\\) instead of \\(P(x, y)\\). Important! Note that in practice, we will usually deal with log-probabilities and not probabilities. View in the General Framework Remember our general view on the classification task? We obtain feature representation of the",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "P(x_t|y=k).\\] Since we care only about argmax, we can consider \\(\\log P(x, y)\\) instead of \\(P(x, y)\\). Important! Note that in practice, we will usually deal with log-probabilities and not probabilities. View in the General Framework Remember our general view on the classification task? We obtain feature representation of the input text using some method, then use this feature representation for classification. In Naive Bayes, our features are words, and the feature representation is the Bag-of-Words (BOW) representation - a sum of one-hot representations of words. Indeed, to evaluate \\(P(x, y)\\) we only need to count the number of times each token appeared in the text. Feature Design In the standard setting, we used words as features. However, you can use other types of features: URL, user id, etc. Even if your data is a plain text (without fancy things such as URL, user id, etc), you can still design features in different ways. Learn how to improve Naive Bayes in this exercise in the Research Thinking section. Maximum Entropy Classifier (aka Logistic Regression) Differently from Naive Bayes, MaxEnt classifier is a discriminative model, i.e., we are interested in \\(P(y=k|x)\\) and not in the joint distribution \\(p(x, y)\\). Also, we will learn how to use features: this is in contrast to Naive Bayes, where we defined how to use the features ourselves. Here we also have to define features manually, but we have more freedom: features do not have to be categorical (in Naive Bayes, they had to!). We can use the BOW representation or come up with something more interesting. The general classification pipeline here is as follows: get \\(\\color{#7aab00}{h}\\color{black}=(\\color{#7aab00}{f_1}\\color{black}, \\color{#7aab00}{f_2}\\color{black}, \\dots, \\color{#7aab00}{f_n}\\color{black}{)}\\) - feature representation of the input text; take \\(w^{(i)}=(w_1^{(i)}, \\dots, w_n^{(i)})\\) - vectors with feature weights for each of the classes; for each class, weigh features, i.e. take the dot product of feature representation \\(\\color{#7aab00}{h}\\) with feature weights \\(w^{(k)}\\): \\[w^{(k)}\\color{#7aab00}{h}\\color{black} = w_1^{(k)}\\cdot\\color{#7aab00}{f_1}\\color{black}+\\dots+ w_n^{(k)}\\cdot\\color{#7aab00}{f_n}\\color{black}{, \\ \\ \\ \\ \\ k=1, \\dots, K.} \\] To get a bias term in the sum above, we define one of the features being 1 (e.g., \\(\\color{#7aab00}{f_0}=1\\)). Then \\[w^{(k)}\\color{#7aab00}{h}\\color{black} = \\color{red}{w_0^{(k)}}\\color{black} + w_1^{(k)}\\cdot\\color{#7aab00}{f_1}\\color{black}+\\dots+ w_n^{(k)}\\cdot\\color{#7aab00}{f_{n}}\\color{black}{, \\ \\ \\ \\ \\ k=1, \\dots, K.} \\] get class probabilities using softmax: \\[P(class=k|\\color{#7aab00}{h}\\color{black})= \\frac{\\exp(w^{(k)}\\color{#7aab00}{h}\\color{black})}{\\sum\\limits_{i=1}^K \\exp(w^{(i)}\\color{#7aab00}{h}\\color{black})}.\\] Softmax normalizes the \\(K\\) values we got at the previous step to a probability distribution over output classes. Look at the illustration below (classes are shown in different colors). Training: Maximum Likelihood Estimate Given training examples \\(x^1, \\dots, x^N\\) with labels \\(y^1, \\dots, y^N\\), \\(y^i\\in\\{1, \\dots, K\\}\\), we pick those weights \\(w^{(k)}, k=1..K\\) which maximize the probability of the training data: \\[w^{\\ast}=\\arg \\max\\limits_{w}\\sum\\limits_{i=1}^N\\log P(y=y^i|x^i).\\] In other words, we choose parameters such that the data is more likely to appear. Therefore, this is called the Maximum Likelihood Estimate (MLE) of the parameters. To find the parameters maximizing the data log-likelihood, we use gradient ascent: gradually improve weights during multiple iterations over the data. At each step, we maximize the probability a model assigns to the correct class. Equvalence to minimizing cross-entropy Note that maximizing data log-likelihood is equivalent to minimizing cross entropy between the",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "the parameters maximizing the data log-likelihood, we use gradient ascent: gradually improve weights during multiple iterations over the data. At each step, we maximize the probability a model assigns to the correct class. Equvalence to minimizing cross-entropy Note that maximizing data log-likelihood is equivalent to minimizing cross entropy between the target probability distribution \\(p^{\\ast} = (0, \\dots, 0, 1, 0, \\dots)\\) (1 for the target label, 0 for the rest) and the predicted by the model distribution \\(p=(p_1, \\dots, p_K), p_i=p(i|x)\\): \\[Loss(p^{\\ast}, p^{})= - p^{\\ast} \\log(p) = -\\sum\\limits_{i=1}^{K}p_i^{\\ast} \\log(p_i).\\] Since only one of \\(p_i^{\\ast}\\) is non-zero (1 for the target label \\(k\\), 0 for the rest), we will get \\(Loss(p^{\\ast}, p) = -\\log(p_{k})=-\\log(p(k| x)).\\) This equivalence is very important for you to understand: when talking about neural approaches, people usually say that they minimize the cross-entropy loss. Do not forget that this is the same as maximizing the data log-likelihood. Naive Bayes vs Logistic Regression Let's finalize this part by discussing the advantages and drawbacks of logistic regression and Naive Bayes. simplicity Both methods are simple; Naive Bayes is the simplest one. interpretability Both methods are interpretable: you can look at the features which influenced the predictions most (in Naive Bayes - usually words, in logistic regression - whatever you defined). training speed Naive Bayes is very fast to train - it requires only one pass through the training data to evaluate the counts. For logistic regression, this is not the case: you have to go over the data many times until the gradient ascent converges. independence assumptions Naive Bayes is too \"naive\" - it assumed that features (words) are conditionally independent given class. Logistic regression does not make this assumption - we can hope it is better. text representation: manual Both methods use manually defined feature representation (in Naive Bayes, BOW is the standard choice, but you still choose this yourself). While manually defined features are good for interpretability, they may be no so good for performance - you are likely to miss something which can be useful for the task. SVM for Text Classification One more method for text classification based on manually designed features is SVM. The most basic (and popular) features for SVMs are bag-of-words and bag-of-ngrams ( ngram is a tuple of n words). With these simple features, SVMs with linear kernel perform better than Naive Bayes (see, for example, the paper Question Classification using Support Vector Machines ). Text Classification with Neural Networks Instead of manually defined features, let a neural network to learn useful features . The main idea of neural-network-based classification is that feature representation of the input text can be obtained using a neural network. In this setting, we feed the embeddings of the input tokens to a neural network, and this neural network gives us a vector representation of the input text. After that, this vector is used for classification. When dealing with neural networks, we can think about the classification part (i.e., how to get class probabilities from a vector representation of a text) in a very simple way. Vector representation",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "network gives us a vector representation of the input text. After that, this vector is used for classification. When dealing with neural networks, we can think about the classification part (i.e., how to get class probabilities from a vector representation of a text) in a very simple way. Vector representation of a text has some dimensionality \\(d\\), but in the end, we need a vector of size \\(K\\) (probabilities for \\(K\\) classes). To get a \\(K\\)-sized vector from a \\(d\\)-sized, we can use a linear layer. Once we have a \\(K\\)-sized vector, all is left is to apply the softmax operation to convert the raw numbers into class probabilities. Classification Part: This is Logistic Regression! Let us look closer to the neural network classifier. The way we use vector representation of the input text is exactly the same as we did with logistic regression: we weigh features according to feature weights for each class. The only difference from logistic regression is where the features come from: they are either defined manually (as we did before) or obtained by a neural network. Intuition: Text Representation Points in the Direction of Class Representation If we look at this final linear layer more closely, we will see that the columns of its matrix are vectors \\(w_i\\). These vectors can be thought of as vector representations of classes. A good neural network will learn to represent input texts in such a way that text vectors will point in the direction of the corresponding class vectors. Training and the Cross-Entropy Loss Neural classifiers are trained to predict probability distributions over classes. Intuitively, at each step we maximize the probability a model assigns to the correct class. The standard loss function is the cross-entropy loss . Cross-entropy loss for the target probability distribution \\(p^{\\ast} = (0, \\dots, 0, 1, 0, \\dots)\\) (1 for the target label, 0 for the rest) and the predicted by the model distribution \\(p=(p_1, \\dots, p_K), p_i=p(i|x)\\): \\[Loss(p^{\\ast}, p^{})= - p^{\\ast} \\log(p) = -\\sum\\limits_{i=1}^{K}p_i^{\\ast} \\log(p_i).\\] Since only one of \\(p_i^{\\ast}\\) is non-zero (1 for the target label \\(k\\), 0 for the rest), we will get \\(Loss(p^{\\ast}, p) = -\\log(p_{k})=-\\log(p(k| x)).\\) Look at the illustration for one training example. In training, we gradually improve model weights during multiple iterations over the data: we iterate over training examples (or batches of examples) and make gradient updates. At each step, we maximize the probability a model assigns to the correct class. At the same time, we minimize sum of the probabilities of incorrect classes: since sum of all probabilities is constant, by increasing one probability we decrease sum of all the rest ( Lena : Here I usually imagine a bunch of kittens eating from the same bowl: one kitten always eats at the expense of the others ). Lena : Here I usually imagine a bunch of kittens eating from the same bowl: one kitten always eats at the expense of the others Look at the illustration of the training process. Recap: This is equivalent to maximizing the data likelihood Do not forget that when talking",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "others ). Lena : Here I usually imagine a bunch of kittens eating from the same bowl: one kitten always eats at the expense of the others Look at the illustration of the training process. Recap: This is equivalent to maximizing the data likelihood Do not forget that when talking about MaxEnt classifier (logistic regression) , we showed that minimizing cross-entropy is equivalent to maximizing the data likelihood. Therefore, here we are also trying to get the Maximum Likelihood Estimate (MLE) of model parameters. Models for Text Classification We need a model that can produce a fixed-sized vector for inputs of different lengths. In this part, we will look at different ways to get a vector representation of an input text using neural networks. Note that while input texts can have different lengths, the vector representation of a text has to have a fixed size: otherwise, a network will not \"work\". We begin with the simplest approaches which use only word embeddings (without adding a model on top of that). Then we look at recurrent and convolutional networks. Lena: A bit later in the course, you will learn about Transformers and the most recent classification techniques using large pretrained models. Basics: Bag of Embeddings (BOE) and Weighted BOE The simplest you can do is use only word embeddings without any neural network on top of that. To get vector representation of a text, we can either sum all token embeddings (Bag of Embeddings) or use a weighted sum of these embeddings (with weights, for example, being tf-idf or something else). Bag of Embeddings (ideally, along with Naive Bayes) should be a baseline for any model with a neural network: if you can't do better than that, it's not worth using NNs at all. This can be the case if you don't have much data. While Bag of Embeddings (BOE) is sometimes called Bag of Words (BOW), note that these two are very different . BOE is the sum of embeddings and BOW is the sum of one-hot vectors: BOE knows a lot more about language. The pretrained embeddings (e.g., Word2Vec or GloVe) understand similarity between words. For example, awesome , brilliant , great will be represented with unrelated features in BOW but similar word vectors in BOE. awesome brilliant great Note also that to use a weighted sum of embeddings, you need to come up with a way to get weights. However, this is exactly what we wanted to avoid by using neural networks: we don't want to introduce manual features, but rather let a network to learn useful patterns. Bag of Embeddings as Features for SVM You can use SVM on top of BOE! The only difference from SVMs in classical approaches (on top of bag-of-words and bag-of-ngrams) if the choice of a kernel: here the RBF kernel is better. Models: Recurrent (RNN/LSTM/etc) Recurrent networks are a natural way to process text in a sense that, similar to humans, they \"read\" a sequence of tokens one by one and process the information. Hopefully, at each step the network will \"remember\" everything",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "of a kernel: here the RBF kernel is better. Models: Recurrent (RNN/LSTM/etc) Recurrent networks are a natural way to process text in a sense that, similar to humans, they \"read\" a sequence of tokens one by one and process the information. Hopefully, at each step the network will \"remember\" everything it has read before. Basics: Recurrent Neural Networks • RNN cell • At each step, a recurrent network receives a new input vector (e.g., token embedding) and the previous network state (which, hopefully, encodes all previous information). Using this input, the RNN cell computes the new state which it gives as output. This new state now contains information about both current input and the information from previous steps. • RNN reads a sequence of tokens • Look at the illustration: RNN reads a text token by token, at each step using a new token embedding and the previous state. Note that the RNN cell is the same at each step! • Vanilla RNN • The simplest recurrent network, Vanilla RNN , transforms \\(h_{t-1}\\) and \\(x_t\\) linearly, then applies a non-linearity (most often, the \\(\\tanh\\) function): \\[h_t = \\tanh(h_{t-1}W_h + x_tW_t).\\] Vanilla RNNs suffer from the vanishing and exploding gradients problem. To alleviate this problem, more complex recurrent cells (e.g., LSTM, GRU, etc) perform several operations on the input and use gates. For more details of RNN basics, look at the Colah's blog post . Recurrent Neural Networks for Text Classification Here we (finally!) look at how we can use recurrent models for text classification. Everything you will see here will apply to all recurrent cells, and by \"RNN\" in this part I refer to recurrent cells in general (e.g. vanilla RNN, LSTM, GRU, etc). Let us recall what we need: We need a model that can produce a fixed-sized vector for inputs of different lengths. • Simple : read a text, take the final state • The most simple recurrent model is a one-layer RNN network. In this network, we have to take the state which knows more about input text. Therefore, we have to use the last state - only this state saw all input tokens. • Multiple layers : feed the states from one RNN to the next one • To get a better text representation, you can stack multiple layers. In this case, inputs for the higher RNN are representations coming from the previous layer. The main hypothesis is that with several layers, lower layers will catch local phenomena (e.g., phrases), while higher layers will be able to learn more high-level things (e.g., topic). • Bidirectional : use final states from forward and backward RNNs. • Previous approaches may have a problem: the last state can easily \"forget\" earlier tokens. Even strong models such as LSTMs can still suffer from that! To avoid this, we can use two RNNs: forward , which reads input from left to right, and backward , which reads input from right to left. Then we can use the final states from both models: one will better remember the final part of a text, another",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "from that! To avoid this, we can use two RNNs: forward , which reads input from left to right, and backward , which reads input from right to left. Then we can use the final states from both models: one will better remember the final part of a text, another - the beginning. These states can be concatenated, or summed, or something else - it's your choice! • Combinations : do everything you want! • You can combine the ideas above. For example, in a multi-layered network, some layers can go in the opposite direction, etc. Models: Convolutional (CNN) The detailed description of convolutional models in general is in Convolutional Models Supplementary . In this part, we consider only convolutions for text classification. Convolutions for Images and Translation Invariance Convolutional networks were originally developed for computer vision tasks. Therefore, let's first understand the intuition behind convolutional models for images. Imagine we want to classify an image into several classes, e.g. cat, dog, airplane, etc. In this case, if you find a cat on an image, you don't care where on the image this cat is: you care only that it is there somewhere. Convolutional networks apply the same operation to small parts of an image: this is how they extract features. Each operation is looking for a match with a pattern, and a network learns which patterns are useful. With a lot of layers, the learned patterns become more and more complicated: from lines in the early layers to very complicated patterns (e.g., the whole cat or dog) on the upper ones. You can look at the examples in the Analysis and Interpretability section. This property is called translation invariance : translation because we are talking about shifts in space, invariance because we want it to not matter. The illustration is adapted from the one taken from this cool repo . The illustration is adapted from the one taken from this cool repo . Convolutions for Text Well, for images it's all clear: e.g. we want to be able to move a cat because we don't care where the cat is. But what about texts? At first glance, this is not so straightforward: we can not move phrases easily - the meaning will change or we will get something that does not make much sense. However, there are some applications where we can think of the same intuition. Let's imagine that we want to classify texts, but not cats/dogs as in images, but positive/negative sentiment. Then there are some words and phrases which could be very informative \"clues\" (e.g. it's been great , bored to death , absolutely amazing , the best ever , etc), and others which are not important at all. We don't care much where in a text we saw bored to death to understand the sentiment, right? A Typical Model: Convolution+Pooling Blocks Following the intuition above, we want to detect some patterns, but we don't care much where exactly these patterns are. This behavior is implemented with two layers: convolution : finds matches with patterns (as the cat",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "saw bored to death to understand the sentiment, right? A Typical Model: Convolution+Pooling Blocks Following the intuition above, we want to detect some patterns, but we don't care much where exactly these patterns are. This behavior is implemented with two layers: convolution : finds matches with patterns (as the cat head we saw above); pooling : aggregates these matches over positions (either locally or globally). A typical convolutional model for text classification is shown on the figure. To get a vector representation of an input text, a convolutional layer is applied to word embedding, which is followed by a non-linearity (usually ReLU) and a pooling operation. The way this representation is used for classification is similar to other networks. In the following, we discuss in detail the main building blocks, convolution and pooling, then consider modeling modifications. Basics: Convolution Layer for Text Convolutional Neural Networks were initially developed for computer vision tasks, e.g. classification of images (cats vs dogs, etc). The idea of a convolution is to go over an image with a sliding window and to apply the same operation, convolution filter , to each window. The illustration (taken from this cool repo ) shows this process for one filter: the bottom is the input image, the top is the filter output. Since an image has two dimensions (width and height), the convolution is two-dimensional. Convolution filter for images. The illustration is from this cool repo . Convolution filter for images. The illustration is from this cool repo . Differently from images, texts have only one dimension: here a convolution is one-dimensional: look at the illustration. Convolution filter for text. Convolution is a Linear Operation Applied to Each Window A convolution is a linear layer (followed by a non-linearity) applied to each input window. Formally, let us assume that \\((x_1, \\dots, x_n)\\) - representations of the input words, \\(x_i\\in \\mathbb{R}^d\\); \\(d\\) ( input channels ) - size of an input embedding; \\(k\\) ( kernel size ) - the length of a convolution window (on the illustration, \\(k=3\\)); \\(m\\) ( output channels ) - number of convolution filters (i.e., number of channels produced by the convolution). Then a convolution is a linear layer \\(W\\in\\mathbb{R}^{(k\\cdot d)\\times m}\\). For a \\(k\\)-sized window \\((x_i, \\dots x_{i+k-1})\\), the convolution takes the concatenation of these vectors \\[u_i = [x_i, \\dots x_{i+k-1}]\\in\\mathbb{R}^{k\\cdot d}\\] and multiplies by the convolution matrix: \\[F_i = u_i \\times W.\\] A convolution goes over an input with a sliding window and applies the same linear transformation to each window. Intuition : Each Filter Extracts a Feature Intuitively, each filter in a convolution extracts a feature. • One filter - one feature extractor • A filter takes vector representations in a current window and transforms them linearly into a single feature. Formally, for a window \\(u_i = [x_i, \\dots x_{i+k-1}]\\in\\mathbb{R}^{k\\cdot d}\\) a filter \\(f\\in\\mathbb{R}^{k\\cdot d}\\) computes dot product: \\[F_i^{(f)} = (f, u_i).\\] The number \\(F_i^{(f)}\\) (the extracted \"feature\") is a result of applying the filter \\(f\\) to the window \\((x_i, \\dots x_{i+k-1})\\). • m filters : m feature extractors • One filter extracts a single",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "\\(u_i = [x_i, \\dots x_{i+k-1}]\\in\\mathbb{R}^{k\\cdot d}\\) a filter \\(f\\in\\mathbb{R}^{k\\cdot d}\\) computes dot product: \\[F_i^{(f)} = (f, u_i).\\] The number \\(F_i^{(f)}\\) (the extracted \"feature\") is a result of applying the filter \\(f\\) to the window \\((x_i, \\dots x_{i+k-1})\\). • m filters : m feature extractors • One filter extracts a single feature. Usually, we want many features: for this, we have to take several filters. Each filter reads an input text and extracts a different feature - look at the illustration. The number of filters is the number of output features you want to get. With \\(m\\) filters instead of one, the size of the convolutional layer we discussed above will become \\((k\\cdot d)\\times m\\). This is done in parallel! Note that while I show you how a CNN \"reads\" a text, in practice these computations are done in parallel. Basics: Pooling Operation After a convolution extracted \\(m\\) features from each window, a pooling layer summarises the features in some region. Pooling layers are used to reduce the input dimension, and, therefore, to reduce the number of parameters used by the network. • Max and Mean Pooling • The most popular is max-pooling : it takes maximum over each dimension, i.e. takes the maximum value of each feature. Intuitively, each feature \"fires\" when it sees some pattern: a visual pattern in an image (line, texture, a cat's paw, etc) or a text pattern (e.g., a phrase). After a pooling operation, we have a vector saying which of these patterns occurred in the input. Mean-pooling works similarly but computes mean over each feature instead of maximum. • Pooling and Global Pooling • Similarly to convolution, pooling is applied to windows of several elements. Pooling also has the stride parameter, and the most common approach is to use pooling with non-overlapping windows. For this, you have to set the stride parameter the same as the pool size. Look at the illustration. The difference between pooling and global pooling is that pooling is applied over features in each window independently, while global pooling performs over the whole input. For texts, global pooling is often used to get a single vector representing the whole text; such global pooling is called max-over-time pooling , where the \"time\" axis goes from the first input token to the last. Convolutional Neural Networks for Text Classification Now, when we understand how the convolution and pooling work, let's come to modeling modifications. First, let us recall what we need: We need a model that can produce a fixed-sized vector for inputs of different lengths. Therefore, we need to construct a convolutional model that represents a text as a single vector. The basic convolutional model for text classification is shown on the figure. It is almost the same as we saw before: the only thing that's changed is that we specified the type of pooling used. Specifically, after the convolution, we use global-over-time pooling . This is the key operation: it allows to compress a text into a single vector. The model itself can be different, but at some point it has to",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "only thing that's changed is that we specified the type of pooling used. Specifically, after the convolution, we use global-over-time pooling . This is the key operation: it allows to compress a text into a single vector. The model itself can be different, but at some point it has to use the global pooling to compress input in a single vector. • Several Convolutions with Different Kernel Sizes • Instead of picking one kernel size for your convolution, you can use several convolutions with different kernel sizes. The recipe is simple: apply each convolution to the data, add non-linearity and global pooling after each of them, then concatenate the results (on the illustration, non-linearity is omitted for simplicity). This is how you get vector representation of the data which is used for classification. This idea was used, among others, in the paper Convolutional Neural Networks for Sentence Classification and many follow-ups. • Stack Several Blocks Convolution+Pooling • Instead of one layer, you can stack several blocks convolution+pooling on top of each other. After several blocks, you can apply another convolution, but with global pooling this time. Remember: you have to get a single fixed-sized vector - for this, you need global pooling. Such multi-layered convolutions can be useful when your texts are very long; for example, if your model is character-level (as opposed to word-level). This idea was used, among others, in the paper Character-level Convolutional Networks for Text Classification . Multi-Label Classification Multi-label classification: many labels, several can be correct Multi-label classification: many labels, several can be correct Multi-label classification is different from the single-label problems we discussed before in that each input can have several correct labels. For example, a twit can have several hashtags, a user can have several topics of interest, etc. For a multi-label problem, we need to change two things in the single-label pipeline we discussed before: model (how we evaluate class probabilities); loss function . Model: Softmax → Element-wise Sigmoid After the last linear layer, we have \\(K\\) values corresponding to the \\(K\\) classes - these are the values we have to convert to class probabilities. For single-label problems, we used softmax: it converts \\(K\\) values into a probability distribution, i.e. sum of all probabilities is 1. It means that the classes share the same probability mass: if the probability of one class is high, other classes can not have large probability ( Lena : Once again, imagine a bunch of kittens eating from the same bowl: one kitten always eats at the expense of the others ). Lena : Once again, imagine a bunch of kittens eating from the same bowl: one kitten always eats at the expense of the others For multi-label problems, we convert each of the \\(K\\) values into a probability of the corresponding class independently from the others. Specifically, we apply the sigmoid function \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\) to each of the \\(K\\) values. Intuitively, we can think of this as having \\(K\\) independent binary classifiers that use the same text representation. Loss Function: Binary Cross-Entropy for Each Class Loss function changes to",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "of the corresponding class independently from the others. Specifically, we apply the sigmoid function \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\) to each of the \\(K\\) values. Intuitively, we can think of this as having \\(K\\) independent binary classifiers that use the same text representation. Loss Function: Binary Cross-Entropy for Each Class Loss function changes to enable multiple labels: for each class, we use the binary cross-entropy loss. Look at the illustration. Practical Tips Word Embeddings: how to deal with them? Input for a network is represented by word embeddings. You have three options how to get these embeddings for your model: train from scratch as part of your model, take pretrained (Word2Vec, GloVe, etc) and fix them (use them as static vectors), initialize with pretrained embeddings and train them with the network (\"fine-tune\"). Let's think about these options by looking at the data a model can use. Training data for classification is labeled and task-specific, but labeled data is usually hard to get. Therefore, this corpus is likely to be not huge (at the very least), or not diverse, or both. On the contrary, training data for word embeddings is not labeled - plain texts are enough. Therefore, these datasets can be huge and diverse - a lot to learn from. Now let us think what a model will know depending on what we do with the embeddings. If the embeddings are trained from scratch, the model will \"know\" only the classification data - this may not be enough to learn relationships between words well. But if we use pretrained embeddings, they (and, therefore, the whole model) will know a huge corpus - they will learn a lot about the world. To adapt these embeddings to your task-specific data, you can fine-tune these embeddings by training them with the whole network - this can bring gains in the performance (not huge though). When we use pretrained embeddings, this is an example of transfer learning : through the embeddings, we \"transfer\" the knowledge of their training data to our task-specific model. We will learn more about transfer learning later in the course. Fine-tune pretrained embeddings or not? Before training models, you can first think why fine-tuning can be useful, and which types of examples can benefit from it. Learn more from this exercise in the Research Thinking section. For more details and the experiments with different settings for word embeddings, look at this paper summary. Data Augmentation: Get More Data for Free Data augmentation alters your dataset in different ways to get alternative versions of the same training example. Data augmentation can increase the amount of data Quality of your model depends a lot on your data. For deep learning models, having large datasets is very (very!) important. diversity of data By giving different versions of training examples, you teach a model to be more robust to real-world data which can be of lower quality or simply a bit different from your training data. With augmented data, a model is less likely to overfit to specific types of training examples and will rely more on general patterns. Data",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "you teach a model to be more robust to real-world data which can be of lower quality or simply a bit different from your training data. With augmented data, a model is less likely to overfit to specific types of training examples and will rely more on general patterns. Data augmentation for images can be done easily: look at the examples below. The standard augmentations include flipping an image, geometrical transformations (e.g. rotation and stretching along some direction), covering parts of an image with different patches. How can we do something similar for texts? • word dropout - the most simple and popular • Word dropout is the simplest regularization: for each example, you choose some words randomly (say, each word is chosen with probability 10%) and replace the chosen words with either the special token UNK or with a random token from the vocabulary. The motivation here is simple: we teach a model not to over-rely on individual tokens, but take into consideration context of the whole text. For example, here we masked great , and a model has to understand the sentiment based on other words. Note: For images, this corresponds to masking out some areas. By masking out an area of an image, we also want a model not to over-rely on local features and to make use of a more global context. • use external resources (e.g., thesaurus) - a bit more complicated • A bit more complicated approach is to replace words or phrases with their synonyms. The tricky part is getting these synonyms: you need external resources, and they are rarely available for languages other than English (for English, you can use e.g. WordNet). Another problem is that for languages with rich morphology (e.g., Russian) you are likely to violate the grammatical agreement. • use separate models - even more complicated • An even more complicated method is to paraphrase the whole sentences using external models. A popular paraphrasing method is to translate a sentence to some language and back. We will learn how to train a translation model a bit later (in the Seq2seq and Attention lecture), but for now, you can use industrial systems, e.g. Yandex Translate , Google Translate , etc. ( Lena: Obviously, personally I'm biased towards Yandex :) ) Note that you can combine translation systems and languages to get several paraphrases. Lena: Obviously, personally I'm biased towards Yandex :) Note: For images, the last two techniques correspond to geometric transformations: we want to change text, but to preserve the meaning. This is different from word dropout, where some parts are lost completely. Analysis and Interpretability What do Convolutions Learn? Analyzing Convolutional Filters Convolutions in Computer Vision: Visual Patterns Convolutions were originally developed for images, and there's already a pretty good understanding of what the filters capture and how filters from different layers from a hierarchy. While lower layers capture simple visual patterns such as lines or circles, final layers can capture the whole pictures, animals, people, etc. Examples of patterns captured by convolution filters for images. The examples are from",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "understanding of what the filters capture and how filters from different layers from a hierarchy. While lower layers capture simple visual patterns such as lines or circles, final layers can capture the whole pictures, animals, people, etc. Examples of patterns captured by convolution filters for images. The examples are from Activation Atlas from distill.pub . Examples of patterns captured by convolution filters for images. The examples are from Activation Atlas from distill.pub . What About Convolutions in Texts? This part is based on the paper Understanding Convolutional Neural Networks for Text Classification . For images, filters capture local visual patterns which are important for classification. For text, such local patterns are word n-grams. The main findings on how CNNs work for texts are: convolving filters are used as ngram detectors Each filter specializes in one or several families of closely-related ngrams. Filters are not homogeneous, i.e. a single filter can, and often does, detect multiple distinctly different families of ngrams. max-pooling induces a thresholding behavior Values below a given threshold are ignored when (i.e. irrelevant to) making a prediction. For example, this paper shows that 40% of the pooled ngrams on average can be dropped with no loss of performance. The simplest way to understand what a network captures is to look which patterns activate its neurons. For convolutions, we pick a filter and find those n-grams which activate this filter most. Below are examples of the top-1 n-gram for several filters. For one of them, we also show other n-grams which lead to high activation of this filter - you can see that the n-grams have a very similar meaning. For more details, look at the paper Understanding Convolutional Neural Networks for Text Classification . How About RNN CLassifiers? How RNNs trained for classification process text? Learn here . Research Thinking How to Read the short description at the beginning - this is our starting point, something known. Read a question and think: for a minute, a day, a week, ... - give yourself some time! Even if you are not thinking about it constantly, something can still come to mind. Look at the possible answers - previous attempts to answer/solve this problem. Important: You are not supposed to come up with something exactly like here - remember, each paper usually takes the authors several months of work. It's a habit of thinking about these things that counts! All the rest a scientist needs is time: to try-fail-think until it works. It's well-known that you will learn something easier if you are not just given the answer right away, but if you think about it first. Even if you don't want to be a researcher, this is still a good way to learn things! Classical Approaches ? Idea: Add Frequent N-Grams to the Features! Instead of using only words as features, we can also use word n-grams. Since using all n-grams would be inefficient, we can add only the frequent ones. This can fix some examples with simple negation as the one shown above. ? Note that Naive Bayes can use",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "to the Features! Instead of using only words as features, we can also use word n-grams. Since using all n-grams would be inefficient, we can add only the frequent ones. This can fix some examples with simple negation as the one shown above. ? Note that Naive Bayes can use any categorical features - you can do anything as long as you can compute the counts for probabilities. For example, text length Who knows - maybe positive reviews are longer than negative? Don't forget to categorize it, e.g., 1-20 tokens correspond to one feature, 21-30 tokens - to another, etc. token frequency It may be worth checking - positive or negative reviews use more peculiar words? You can come up with some characteristics of tokens frequency: minimum of maximum, average, etc. But again - you have to categorize it! syntactical features (if you don't know what it is yet, skip this) Dependency tree depth (maximum/minimum/average) - this can be a proxy of text complexity. anything else you can come up with Just try :) ? Idea: Do Not Use Unimportant Words If you know which words definitely do not influence class probability, you can remove them from the features! For example, we can remove stop-words: determiners, prepositions, etc. Note: you need to be really careful - don't remove something useful! Neural Approaches ? Without fine-tuning, closest to bad is good ! The figure shows closest neighbors of Word2Vec embeddings before and after fine-tuning (examples are taken from this paper ). Without fine-tuning, closest to bad is good ! Without fine-tuning, it would be very hard for a model to separate positive and negative using these embeddings. This is only one example of antonyms with close embeddings which can hurt sentiment classification. Fine-tuning can also help to improve understanding of tokens such as n't : rare in the corpus word embeddings were trained on, but not rare in the corpus we care about. More generally, if your task-specific domain is different from the word embeddings training data, fine-tuning is a good idea. Here will be more exercises! This part will be expanding from time to time. Related Papers How to High-level : look at key results in short summaries - get an idea of what's going on in the field. A bit deeper : for topics which interest you more, read longer summaries with illustrations and explanations. Take a walk through the authors' reasoning steps and key observations. In depth : read the papers you liked. Now, when you got the main idea, this is going to be easier! What's inside: Convolutions for Classification: Classics Analyzing RNNs for Sentiment Classification ... to be updated Convolutions for Classification: Classics Even a very simple CNN with one layer on top of word embeddings shows very good performance (without features requiring some external knowledge!). The paper also shows the importance of using pretrained embeddings (and not training from scratch) and gains from fine-tuning. The CNN model is shown on the figure: on top of embeddings, it has three convolutions with max-over-time pooling (in parallel). The results",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "good performance (without features requiring some external knowledge!). The paper also shows the importance of using pretrained embeddings (and not training from scratch) and gains from fine-tuning. The CNN model is shown on the figure: on top of embeddings, it has three convolutions with max-over-time pooling (in parallel). The results are concatenated and used for classification. This is a very simple model we discussed earlier . The paper has a lot of results (comparison with 14 baselines!), but here I'll mention only the ones comparing the same CNN model with different strategies of obtaining word embeddings. Embeddings: Random vs Pretrained (Word2Vec) In the table below random experiment - embeddings are randomly initialized and trained with the model, pretrained - the embeddings are initialized with Word2Vec and fixed (not trained with the model). We see that using pretrained embeddings is better by several percentage points! This happens because in the first case the embeddings see only the classification training data, which is usually not much. But trained embeddings saw a lot of other data - they know a lot more about the world and relationships between words. Important! This is called transfer learning - by using trained embeddings, you \"transfer\" knowledge contained in the embeddings training data to your model. We will learn more about this later in the course. Pretrained Embeddings: Fixed vs Fine-tuned In the table below fixed experiment - the embeddings are initialized with Word2Vec and fixed (not trained with the model), fine-tuned - the embeddings are initialized with Word2Vec and then trained with the classification model. We see that if we fine-tune pretrained embeddings for the specific task, we are likely to get further improvement. But you need to be careful - embeddings can \"forget\" what they learned before. More in the paper comparison with lots of baselines This simple model performs quite well compared to lots of baselines (including SVMs we discussed above). both fixed and fine-tuned embeddings The paper proposes a way to use both fixed embeddings and fine-tuned: it duplicates the embedding layer and keeps one of them fixed while trains the other. The results are mixed - look in the paper! This is the first paper showing that CNNs only on characters can do quite well. This is interesting: classification can be done without any external knowledge, even without text segmentation into words! An important point is that character-level CNNs can do better than classical approaches only for large datasets. The CNN model is shown in the figure above. It has 6 convolution+pooling blocks (note that the last pooling is global) followed by 3 linear layers (with non-linearities after each convolution and linear layers). Character-level CNN is better for large datasets The figure below shows the relative errors with respect to comparison models. Each of these plots is computed by taking the difference between errors on a comparison model and the character-level CNN model, then divided by the comparison model error. Here we show only 2 of the comparisons: with a classical approach (n-grams tf-idf) and a word-level CNN. The results show that for large",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "these plots is computed by taking the difference between errors on a comparison model and the character-level CNN model, then divided by the comparison model error. Here we show only 2 of the comparisons: with a classical approach (n-grams tf-idf) and a word-level CNN. The results show that for large datasets, character-level CNN performs better. Other Results choice of alphabet matters You can take either only lowercased data, or distinguish between uppercase and lowercase - the results can be different! char-CNNs work better for user-generated data. Compared to word-level models, character-level ones may be better suitable for raw user data with misspellings. For more details, look at the paper ! Analyzing RNNs for Sentiment Classification If we take an RNN trained for sentiment analysis and apply PCA to lots of its states, we'll see that almost all variance is explained with only two components. Moreover, when such RNN reads a text, its states move along a 1D plane in either negative or positive direction depending on the word it reads. The paper looks at four different RNN types (vanilla, LSTM, GRU, and the Update Gate RNN ) , as well as different sentiment classification datasets (IMDb movie review, Yelp review, SST-2). The results are similar for all combinations. PCA: Most of the Variance is Captured by a Few Dimensions The authors took 1000 test examples, fed it to LSTM, took all states, and applied PCA. Turns out, all variance is explained by only a couple of components! Note that this is true only for a trained model - for untrained one, this is not the case. Look at the figure. The 1D Plane, Trajectories and Word Influences In the figure above (the red/green one) are the RNN states projected onto the first two PCA components; the states are colored according to the target label. We see that the states lie along a one-dimensional plane corresponding to the sentiment changing from one to another. The figure also shows examples of RNN trajectories when reading a positive or a negative text. The further the model is in the text, the deeper its state goes in the corresponding area. What is more interesting, the authors also looked at how each token influences the RNN state. As expected, positive and negative words usually move the states in the corresponding area, while neutral words do not have such influence. More in the paper linear approximations of RNN dynamics The authors apply a linearization procedure to obtain an approximate, but highly interpretable, description of the RNN dynamics. RNNs count the number of positive and negative words used With lots of math, the authors conclude that in nearly all cases the key activity performed by the RNN for sentiment analysis is simply counting the number of positive and negative words used. Here will be more papers! The papers will be gradually appearing. Have Fun! Coming soon! We are still working on this!",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Text Classification",
    "url": "https://lena-voita.github.io/nlp_course/text_classification.html",
    "section_title": null,
    "text": "words used. Here will be more papers! The papers will be gradually appearing. Have Fun! Coming soon! We are still working on this!",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "The way machine learning models \" see \" data is different from how we (humans) do. For example, we can easily understand the text \"I saw a cat\" , but our models can not - they need vectors of features. Such vectors, or word embeddings , are representations of words which can be fed into your model. \"I saw a cat\" How it works: Look-up Table (Vocabulary) In practice, you have a vocabulary of allowed words; you choose this vocabulary in advance. For each vocabulary word, a look-up table contains its embedding. This embedding can be found using the word index in the vocabulary (i.e., you to look up the embedding in the table using word index). To account for unknown words (the ones which are not in the vocabulary), usually a vocabulary contains a special token UNK . Alternatively, unknown tokens can be ignored or assigned a zero vector. UNK The main question of this lecture is: how do we get these word vectors? Represent as Discrete Symbols: One-hot Vectors The easiest you can do is to represent words as one-hot vectors: for the i-th word in the vocabulary, the vector has 1 on the i-th dimension and 0 on the rest. In Machine Learning, this is the most simple way to represent categorical features. You probably can guess why one-hot vectors are not the best way to represent words. One of the problems is that for large vocabularies, these vectors will be very long: vector dimensionality is equal to the vocabulary size. This is undesirable in practice, but this problem is not the most crucial one. What is really important, is that these vectors know nothing about the words they represent. For example, one-hot vectors \"think\" that cat is as close to dog as it is to table! We can say that one-hot vectors do not capture meaning. cat dog table! But how do we know what is meaning? Distributional Semantics To capture meaning of words in their vectors, we first need to define the notion of meaning that can be used in practice. For this, let us try to understand how we, humans, get to know which words have similar meaning. How to: go over the slides at your pace. Try to notice how your brain works. tezgüino Once you saw how the unknown word used in different contexts, you were able to understand it's meaning. How did you do this? The hypothesis is that your brain searched for other words that can be used in the same contexts, found some (e.g., wine ), and made a conclusion that tezgüino has meaning similar to those other words. This is the distributional hypothesis: wine tezgüino Words which frequently appear in similar contexts have similar meaning . Lena: Often you can find it formulated as \"You shall know a word by the company it keeps\" with the reference to J. R. Firth in 1957, but actually there were a lot more people responsible, and much earlier. For example, Harris, 1954. This is an extremely valuable idea: it can be used in",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "find it formulated as \"You shall know a word by the company it keeps\" with the reference to J. R. Firth in 1957, but actually there were a lot more people responsible, and much earlier. For example, Harris, 1954. This is an extremely valuable idea: it can be used in practice to make word vectors capture their meaning. According to the distributional hypothesis, \"to capture meaning\" and \"to capture contexts\" are inherently the same. Therefore, all we need to do is to put information about word contexts into word representation. Main idea : We need to put information about word contexts into word representation. All we'll be doing at this lecture is looking at different ways to do this. Count-Based Methods Let's remember our main idea: Main idea : We have to put information about contexts into word vectors. Count-based methods take this idea quite literally: How : Put this information manually based on global corpus statistics. The general procedure is illustrated above and consists of the two steps: (1) construct a word-context matrix, (2) reduce its dimensionality. There are two reasons to reduce dimensionality. First, a raw matrix is very large. Second, since a lot of words appear in only a few of possible contexts, this matrix potentially has a lot of uninformative elements (e.g., zeros). To estimate similarity between words/contexts, usually you need to evaluate the dot-product of normalized word/context vectors (i.e., cosine similarity). To define a count-based method, we need to define two things: possible contexts (including what does it mean that a word appears in a context), the notion of association, i.e., formulas for computing matrix elements. Below we provide a couple of popular ways of doing this. Simple: Co-Occurence Counts The simplest approach is to define contexts as each word in an L-sized window. Matrix element for a word-context pair (w, c) is the number of times w appears in context c. This is the very basic (and very, very old) method for obtaining embeddings. The (once) famous HAL model (1996) is also a modification of this approach. Learn more from this exercise in the Research Thinking section. Positive Pointwise Mutual Information (PPMI) Here contexts are defined as before, but the measure of the association between word and context is more clever: positive PMI (or PPMI for short). PPMI measure is widely regarded as state-of-the-art for pre-neural distributional-similarity models. Important : relation to neural models! Turns out, some of the neural methods we will consider (Word2Vec) were shown to implicitly approximate the factorization of a (shifted) PMI matrix. Stay tuned! Latent Semantic Analysis (LSA): Understanding Documents Latent Semantic Analysis (LSA) analyzes a collection of documents. While in the previous approaches contexts served only to get word vectors and were thrown away afterward, here we are also interested in context, or, in this case, document vectors. LSA is one of the simplest topic models: cosine similarity between document vectors can be used to measure similarity between documents. The term \"LSA\" sometimes refers to a more general approach of applying SVD to a term-document matrix where the term-document elements",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "in context, or, in this case, document vectors. LSA is one of the simplest topic models: cosine similarity between document vectors can be used to measure similarity between documents. The term \"LSA\" sometimes refers to a more general approach of applying SVD to a term-document matrix where the term-document elements can be computed in different ways (e.g., simple co-occurrence, tf-idf, or some other weighting). Animation alert! LSA wikipedia page has a nice animation of the topic detection process in a document-word matrix - take a look! Word2Vec: a Prediction-Based Method Let us remember our main idea again: Main idea : We have to put information about contexts into word vectors. While count-based methods took this idea quite literally, Word2Vec uses it in a different manner: How : Learn word vectors by teaching them to predict contexts . Word2Vec is a model whose parameters are word vectors. These parameters are optimized iteratively for a certain objective. The objective forces word vectors to \"know\" contexts a word can appear in: the vectors are trained to predict possible contexts of the corresponding words. As you remember from the distributional hypothesis, if vectors \"know\" about contexts, they \"know\" word meaning. Word2Vec is an iterative method. Its main idea is as follows: take a huge text corpus; go over the text with a sliding window, moving one word at a time. At each step, there is a central word and context words (other words in this window); for the central word, compute probabilities of context words; adjust the vectors to increase these probabilities. How to: go over the illustration to understand the main idea. Lena: Visualization idea is from the Stanford CS224n course. Objective Function : Negative Log-Likelihood For each position \\(t =1, \\dots, T\\) in a text corpus, Word2Vec predicts context words within a m-sized window given the central word \\(\\color{#88bd33}{w_t}\\): \\[\\color{#88bd33}{\\mbox{Likelihood}} \\color{black}= L(\\theta)= \\prod\\limits_{t=1}^T\\prod\\limits_{-m\\le j \\le m, j\\neq 0}P(\\color{#888}{w_{t+j}}|\\color{#88bd33}{w_t}\\color{black}, \\theta), \\] where \\(\\theta\\) are all variables to be optimized. The objective function (aka loss function or cost function) \\(J(\\theta)\\) is the average negative log-likelihood: Note how well the loss agrees with our plan main above: go over text with a sliding window and compute probabilities. Now let's find out how to compute these probabilities. How to calculate \\(P(\\color{#888}{w_{t+j}}\\color{black}|\\color{#88bd33}{w_t}\\color{black}, \\theta)\\)? For each word \\(w\\) we will have two vectors: \\(\\color{#88bd33}{v_w}\\) when it is a central word ; \\(\\color{#888}{u_w}\\) when it is a context word . (Once the vectors are trained, usually we throw away context vectors and use only word vectors.) Then for the central word \\(\\color{#88bd33}{c}\\) (c - central) and the context word \\(\\color{#888}{o}\\) (o - outside word) probability of the context word is Note : this is the softmax function ! (click for the details) The function above is an example of the softmax function : \\[softmax(x_i)=\\frac{\\exp(x_i)}{\\sum\\limits_{j=i}^n\\exp(x_j)}.\\] Softmax maps arbitrary values \\(x_i\\) to a probability distribution \\(p_i\\): \"max\" because the largest \\(x_i\\) will have the largest probability \\(p_i\\); \"soft\" because all probabilities are non-zero. You will deal with this function quite a lot over the NLP course (and in Deep Learning in general). How",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "function : \\[softmax(x_i)=\\frac{\\exp(x_i)}{\\sum\\limits_{j=i}^n\\exp(x_j)}.\\] Softmax maps arbitrary values \\(x_i\\) to a probability distribution \\(p_i\\): \"max\" because the largest \\(x_i\\) will have the largest probability \\(p_i\\); \"soft\" because all probabilities are non-zero. You will deal with this function quite a lot over the NLP course (and in Deep Learning in general). How to: go over the illustration. Note that for central words and context words , different vectors are used. For example, first the word a is central and we use \\(\\color{#88bd33}{v_a}\\), but when it becomes context, we use \\(\\color{#888}{u_a}\\) instead. How to train : by Gradient Descent, One Word at a Time Let us recall that our parameters \\(\\theta\\) are vectors \\(\\color{#88bd33}{v_w}\\) and \\(\\color{#888}{u_w}\\) for all words in the vocabulary. These vectors are learned by optimizing the training objective via gradient descent (with some learning rate \\(\\alpha\\)): \\[\\theta^{new} = \\theta^{old} - \\alpha \\nabla_{\\theta} J(\\theta).\\] One word at a time We make these updates one at a time: each update is for a single pair of a center word and one of its context words. Look again at the loss function: \\[\\color{#88bd33}{\\mbox{Loss}}\\color{black} =J(\\theta)= -\\frac{1}{T}\\log L(\\theta)= -\\frac{1}{T}\\sum\\limits_{t=1}^T \\sum\\limits_{-m\\le j \\le m, j\\neq 0}\\log P(\\color{#888}{w_{t+j}}\\color{black}|\\color{#88bd33}{w_t}\\color{black}, \\theta)= \\frac{1}{T} \\sum\\limits_{t=1}^T \\sum\\limits_{-m\\le j \\le m, j\\neq 0} J_{t,j}(\\theta). \\] For the center word \\(\\color{#88bd33}{w_t}\\), the loss contains a distinct term \\(J_{t,j}(\\theta)=-\\log P(\\color{#888}{w_{t+j}}\\color{black}|\\color{#88bd33}{w_t}\\color{black}, \\theta)\\) for each of its context words \\(\\color{#888}{w_{t+j}}\\). Let us look in more detail at just this one term and try to understand how to make an update for this step. For example, let's imagine we have a sentence with the central word cat , and four context words. Since we are going to look at just one step, we will pick only one of the context words; for example, let's take cute . Then the loss term for the central word cat and the context word cute is: \\[ J_{t,j}(\\theta)= -\\log P(\\color{#888}{cute}\\color{black}|\\color{#88bd33}{cat}\\color{black}) = -\\log \\frac{\\exp\\color{#888}{u_{cute}^T}\\color{#88bd33}{v_{cat}}}{ \\sum\\limits_{w\\in Voc}\\exp{\\color{#888}{u_w^T}\\color{#88bd33}{v_{cat}} }} = -\\color{#888}{u_{cute}^T}\\color{#88bd33}{v_{cat}}\\color{black} + \\log \\sum\\limits_{w\\in Voc}\\exp{\\color{#888}{u_w^T}\\color{#88bd33}{v_{cat}}}\\color{black}{.} \\] cat cute cat cute Note which parameters are present at this step: from vectors for central words , only \\(\\color{#88bd33}{v_{cat}}\\); from vectors for context words , all \\(\\color{#888}{u_w}\\) (for all words in the vocabulary). Only these parameters will be updated at the current step. Below is the schematic illustration of the derivations for this step. By making an update to minimize \\(J_{t,j}(\\theta)\\), we force the parameters to increase similarity (dot product) of \\(\\color{#88bd33}{v_{cat}}\\) and \\(\\color{#888}{u_{cute}}\\) and, at the same time, to decrease similarity between \\(\\color{#88bd33}{v_{cat}}\\) and \\(\\color{#888}{u_{w}}\\) for all other words \\(w\\) in the vocabulary. This may sound a bit strange: why do we want to decrease similarity between \\(\\color{#88bd33}{v_{cat}}\\) and all other words, if some of them are also valid context words (e.g., grey , playing , in on our example sentence)? But do not worry: since we make updates for each context word (and for all central words in your text), on average over all updates our vectors will learn the distribution of the possible contexts. grey playing in Try to derive the gradients at the final step of the illustration above. If you get lost, you can look",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "for each context word (and for all central words in your text), on average over all updates our vectors will learn the distribution of the possible contexts. grey playing in Try to derive the gradients at the final step of the illustration above. If you get lost, you can look at the paper Word2Vec Parameter Learning Explained . Faster Training: Negative Sampling In the example above, for each pair of a central word and its context word, we had to update all vectors for context words. This is highly inefficient: for each step, the time needed to make an update is proportional to the vocabulary size. But why do we have to consider all context vectors in the vocabulary at each step? For example, imagine that at the current step we consider context vectors not for all words, but only for the current target ( cute ) and several randomly chosen words. The figure shows the intuition. cute As before, we are increasing similarity between \\(\\color{#88bd33}{v_{cat}}\\) and \\(\\color{#888}{u_{cute}}\\). What is different, is that now we decrease similarity between \\(\\color{#88bd33}{v_{cat}}\\) and context vectors not for all words, but only with a subset of K \"negative\" examples . Since we have a large corpus, on average over all updates we will update each vector sufficient number of times, and the vectors will still be able to learn the relationships between words quite well. Formally, the new loss function for this step is: \\[ J_{t,j}(\\theta)= -\\log\\sigma(\\color{#888}{u_{cute}^T}\\color{#88bd33}{v_{cat}}\\color{black}) - \\sum\\limits_{w\\in \\{w_{i_1},\\dots, w_{i_K}\\}}\\log\\sigma({-\\color{#888}{u_w^T}\\color{#88bd33}{v_{cat}}}\\color{black}), \\] where \\(w_{i_1},\\dots, w_{i_K}\\) are the K negative examples chosen at this step and \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\) is the sigmoid function. Note that \\(\\sigma(-x)=\\frac{1}{1+e^{x}}=\\frac{1\\cdot e^{-x}}{(1+e^{x})\\cdot e^{-x}} = \\frac{e^{-x}}{1+e^{-x}}= 1- \\frac{1}{1+e^{x}}=1-\\sigma(x)\\). Then the loss can also be written as: \\[ J_{t,j}(\\theta)= -\\log\\sigma(\\color{#888}{u_{cute}^T}\\color{#88bd33}{v_{cat}}\\color{black}) - \\sum\\limits_{w\\in \\{w_{i_1},\\dots, w_{i_K}\\}}\\log(1-\\sigma({\\color{#888}{u_w^T}\\color{#88bd33}{v_{cat}}}\\color{black})). \\] How the gradients and updates change when using negative sampling? The Choice of Negative Examples Each word has only a few \"true\" contexts. Therefore, randomly chosen words are very likely to be \"negative\", i.e. not true contexts. This simple idea is used not only to train Word2Vec efficiently but also in many other applications, some of which we will see later in the course. Word2Vec randomly samples negative examples based on the empirical distribution of words. Let \\(U(w)\\) be a unigram distribution of words, i.e. \\(U(w)\\) is the frequency of the word \\(w\\) in the text corpus. Word2Vec modifies this distribution to sample less frequent words more often: it samples proportionally to \\(U^{3/4}(w)\\). Word2Vec variants: Skip-Gram and CBOW There are two Word2Vec variants: Skip-Gram and CBOW. Skip-Gram is the model we considered so far: it predicts context words given the central word. Skip-Gram with negative sampling is the most popular approach. CBOW (Continuous Bag-of-Words) predicts the central word from the sum of context vectors. This simple sum of word vectors is called \"bag of words\", which gives the name for the model. How the loss function and the gradients change for the CBOW model? If you get lost, you can again look at the paper Word2Vec Parameter Learning Explained . Additional Notes The original Word2Vec papers are: Efficient Estimation of Word",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "called \"bag of words\", which gives the name for the model. How the loss function and the gradients change for the CBOW model? If you get lost, you can again look at the paper Word2Vec Parameter Learning Explained . Additional Notes The original Word2Vec papers are: Efficient Estimation of Word Representations in Vector Space Distributed Representations of Words and Phrases and their Compositionality You can look into them for the details on the experiments, implementation and hyperparameters. Here we will provide some of the most important things you need to know. The Idea is Not New The idea to learn word vectors (distributed representations) is not new. For example, there were attempts to learn word vectors as part of a larger network and then extract the embedding layer. (For the details on the previous methods, you can look, for example, at the summary in the original Word2Vec papers). What was very unexpected in Word2Vec, is its ability to learn high-quality word vectors very fast on huge datasets and for large vocabularies. And of course, all the fun properties we will see in the Analysis and Interpretability section quickly made Word2Vec very famous. Why Two Vectors? As you remember, in Word2Vec we train two vectors for each word: one when it is a central word and another when it is a context word. After training, context vectors are thrown away. This is one of the tricks that made Word2Vec so simple. Look again at the loss function (for one step): \\[ J_{t,j}(\\theta)= -\\color{#888}{u_{cute}^T}\\color{#88bd33}{v_{cat}}\\color{black} - \\log \\sum\\limits_{w\\in V}\\exp{\\color{#888}{u_w^T}\\color{#88bd33}{v_{cat}}}\\color{black}{.} \\] When central and context words have different vectors, both the first term and dot products inside the exponents are linear with respect to the parameters (the same for the negative training objective). Therefore, the gradients are easy to compute. Repeat the derivations (loss and the gradients) for the case with one vector for each word (\\(\\forall w \\ in \\ V, \\color{#88bd33}{v_{w}}\\color{black}{ = }\\color{#888}{u_{w}}\\) ). While the standard practice is to throw away context vectors, it was shown that averaging word and context vectors may be more beneficial. More details are here. Better training There's one more trick: learn more from this exercise in the Research Thinking section. Relation to PMI Matrix Factorization Word2Vec SGNS (Skip-Gram with Negative Sampling) implicitly approximates the factorization of a (shifted) PMI matrix. Learn more here. The Effect of Window Size The size of the sliding window has a strong effect on the resulting vector similarities. For example, this paper notes that larger windows tend to produce more topical similarities (i.e. dog , bark and leash will be grouped together, as well as walked , run and walking ), while smaller windows tend to produce more functional and syntactic similarities (i.e. Poodle , Pitbull , Rottweiler , or walking , running , approaching ). (Somewhat) Standard Hyperparameters Model: Skip-Gram with negative sampling; Number of negative examples: for smaller datasets, 15-20; for huge datasets (which are usually used) it can be 2-5. Embedding dimensionality: frequently used value is 300, but other variants (e.g., 100 or 50) are also possible. For theoretical",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "running , approaching ). (Somewhat) Standard Hyperparameters Model: Skip-Gram with negative sampling; Number of negative examples: for smaller datasets, 15-20; for huge datasets (which are usually used) it can be 2-5. Embedding dimensionality: frequently used value is 300, but other variants (e.g., 100 or 50) are also possible. For theoretical explanation of the optimal dimensionality, take a look at the Related Papers section. Sliding window (context) size: 5-10. GloVe: Global Vectors for Word Representation The GloVe model is a combination of count-based methods and prediction methods (e.g., Word2Vec). Model name, GloVe, stands for \"Global Vectors\", which reflects its idea: the method uses global information from corpus to learn vectors . As we saw earlier , the simplest count-based method uses co-occurrence counts to measure the association between word w and context c : N( w , c ). GloVe also uses these counts to construct the loss function: w c Similar to Word2Vec, we also have different vectors for central and context words - these are our parameters. Additionally, the method has a scalar bias term for each word vector. What is especially interesting, is the way GloVe controls the influence of rare and frequent words: loss for each pair ( w , c ) is weighted in a way that rare events are penalized, very frequent events are not over-weighted. Lena: The loss function looks reasonable as it is, but the original GloVe paper has very nice motivation leading to the above formula. I will not provide it here (I have to finish the lecture at some point, right?..), but you can read it yourself - it's really, really nice! Evaluation of Word Embeddings How can we understand that one method for getting word embeddings is better than another? There are two types of evaluation (not only for word embeddings): intrinsic and extrinsic. Intrinsic Evaluation : Based on Internal Properties This type of evaluation looks at the internal properties of embeddings, i.e. how well they capture meaning. Specifically, in the Analysis and Interpretability section, we will discuss in detail how we can evaluate embeddings on word similarity and word analogy tasks. Extrinsic Evaluation : On a Real Task This type of evaluation tells which embeddings are better for the task you really care about (e.g., text classification, coreference resolution, etc.). In this setting, you have to train the model/algorithm for the real task several times: one model for each of the embeddings you want to evaluate. Then, look at the quality of these models to decide which embeddings are better. How to Choose? One thing you have to get used to is that there is no perfect solution and no right answer for all situations: it always depends on many things. Regarding evaluation, you usually care about quality of the task you want to solve. Therefore, you are likely to be more interested in extrinsic evaluation. However, real-task models usually require a lot of time and resources to train, and training several of them may be too expensive. In the end, this is your call to make :) Analysis and Interpretability",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "you want to solve. Therefore, you are likely to be more interested in extrinsic evaluation. However, real-task models usually require a lot of time and resources to train, and training several of them may be too expensive. In the end, this is your call to make :) Analysis and Interpretability Lena: For word embeddings, most of the content of this part is usually considered as evaluation (intrinsic evaluation). However, since looking at what a model learned (beyond task-specific metrics) is the kind of thing people usually do for analysis, I believe it can be presented here, in the analysis section. Take a Walk Through Space... Semantic Space! Semantic spaces aim to create representations of natural language that capture meaning. We can say that (good) word embeddings form semantic space and will refer to a set of word vectors in a multi-dimensional space as \"semantic space\". Below is shown semantic space formed by GloVe vectors trained on twitter data (taken from gensim ). Vectors were projected to two-dimensional space using t-SNE; these are only the top-3k most frequent words. How to: Walk through semantic space and try to find: language clusters: Spanish, Arabic, Russian, English. Can you find more languages? clusters for: food, family, names, geographical locations. What else can you find? Nearest Neighbors The example is from the GloVe project page . The example is from the GloVe project page . During your walk through semantic space, you probably noticed that the points (vectors) which are nearby usually have close meaning. Sometimes, even rare words are understood very well. Look at the example: the model understood that words such as leptodactylidae or litoria are close to frog . leptodactylidae litoria frog Several pairs from the Rare Words similarity benchmark . Several pairs from the Rare Words similarity benchmark . Word Similarity Benchmarks \"Looking\" at nearest neighbors (by cosine similarity or Euclidean distance) is one of the methods to estimate the quality of the learned embeddings. There are several word similarity benchmarks (test sets). They consist of word pairs with a similarity score according to human judgments. The quality of embeddings is estimated as the correlation between the two similarity scores (from model and from humans). Linear Structure While similarity results are encouraging, they are not surprising: all in all, the embeddings were trained specifically to reflect word similarity. What is surprising, is that many semantic and syntactic relationships between words are (almost) linear in word vector space. For example, the difference between king and queen is (almost) the same as between man and woman. Or a word that is similar to queen in the same sense that kings is similar to king turns out to be queens . The man-woman \\(\\approx\\) king-queen example is probably the most popular one, but there are also many other relations and funny examples. king queen man woman. queen kings king queens man-woman king-queen Below are examples for the country-capital relation and a couple of syntactic relations. At ICML 2019, it was shown that there's actually a theoretical explanation for analogies in Word2Vec. More details are here.",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "also many other relations and funny examples. king queen man woman. queen kings king queens man-woman king-queen Below are examples for the country-capital relation and a couple of syntactic relations. At ICML 2019, it was shown that there's actually a theoretical explanation for analogies in Word2Vec. More details are here. Lena: This paper, Analogies Explained: Towards Understanding Word Embeddings by Carl Allen and Timothy Hospedales from the University of Edinburgh, received Best Paper Honourable Mention award at ICML 2019 - well deserved! Word Analogy Benchmarks These near-linear relationships inspired a new type of evaluation: word analogy evaluation. Examples of relations and word pairs from the Google analogy test set . Examples of relations and word pairs from the Google analogy test set . Given two word pairs for the same relation, for example (man, woman) and (king, queen) , the task is to check if we can identify one of the words based on the rest of them. Specifically, we have to check if the closest vector to king - man + woman corresponds to the word queen . (man, woman) (king, queen) king - man + woman queen Now there are several analogy benchmarks; these include the standard benchmarks ( MSR + Google analogy test sets) and BATS (the Bigger Analogy Test Set) . Similarities across Languages We just saw that some relationships between words are (almost) linear in the embedding space. But what happens across languages? Turns out, relationships between semantic spaces are also (somewhat) linear: you can linearly map one semantic space to another so that corresponding words in the two languages match in the new, joint semantic space. The figure above illustrates the approach proposed by Tomas Mikolov et al. in 2013 not long after the original Word2Vec. Formally, we are given a set of word pairs and their vector representations \\(\\{\\color{#88a635}{x_i}\\color{black}, \\color{#547dbf}{z_i}\\color{black} \\}_{i=1}^n\\), where \\(\\color{#88a635}{x_i}\\) and \\(\\color{#547dbf}{z_i}\\) are vectors for i-th word in the source language and its translation in the target. We want to find a transformation matrix W such that \\(W\\color{#547dbf}{z_i}\\) approximates \\(\\color{#88a635}{x_i}\\) : \"matches\" words from the dictionary. We pick \\(W\\) such that \\[W = \\arg \\min\\limits_{W}\\sum\\limits_{i=1}^n\\parallel W\\color{#547dbf}{z_i}\\color{black} - \\color{#88a635}{x_i}\\color{black}\\parallel^2,\\] and learn this matrix by gradient descent. In the original paper, the initial vocabulary consists of the 5k most frequent words with their translations, and the rest is learned. Later it turned out, that we don't need a dictionary at all - we can build a mapping between semantic spaces even if we know nothing about languages! More details are here. Is the \"true\" mapping between languages indeed linear, or more complicated? We can look at geometry of the learned semantic spaces and check. More details are here. The idea to linearly map different embedding sets to (nearly) match them can also be used for a very different task! Learn more in the Research Thinking section. Research Thinking How to Read the short description at the beginning - this is our starting point, something known. Read a question and think: for a minute, a day, a week, ... - give yourself some time! Even",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "for a very different task! Learn more in the Research Thinking section. Research Thinking How to Read the short description at the beginning - this is our starting point, something known. Read a question and think: for a minute, a day, a week, ... - give yourself some time! Even if you are not thinking about it constantly, something can still come to mind. Look at the possible answers - previous attempts to answer/solve this problem. Important: You are not supposed to come up with something exactly like here - remember, each paper usually takes the authors several months of work. It's a habit of thinking about these things that counts! All the rest a scientist needs is time: to try-fail-think until it works. It's well-known that you will learn something easier if you are not just given the answer right away, but if you think about it first. Even if you don't want to be a researcher, this is still a good way to learn things! Count-Based Methods cat cute grey playing in ? ? cute cat Word2Vec cat cute grey playing in ? word frequency We can expect that frequent words usually give less information than rare ones. For example, the fact that cat appears in context of in does not tell us much about the meaning of cat : the word in serves as a context for many other words. In contrast, cute , grey and playing already give us some idea about cat . cat in cat in cute grey playing cat distance from the central word As we discussed in the previous exercise on count-based methods , words that are closer to the central may be more important. ? 1. Word Frequency 2. Distance from the central word ? better understanding of morphology By assigning a distinct vector to each word, we ignore morphology. Giving information about subwords can let the model know that different tokens can be forms of the same word. representations for unknown words Usually, we can represent only those words, which are present in the vocabulary. Giving information about subwords can help to represent out-of-vocabulary words relying of their spelling. handling misspellings Even if one character in a word is wrong, this is another token, and, therefore, a completely different embedding (or even unknown word). With information about subwords, misspelled word would still be similar to the original one. ? Semantic Change ? ACL 2020 : train embeddings, look at the neighbors Lena: Note that while the approach is recent, it is extremely simple and works better than previous more complicated ideas. Never be afraid to try simple things - you'll be surprised how often they work! Previous popular approach : align two embedding sets Lena: You will implement Ortogonal Proctustes in your homework to align Russian and Ukranian embeddings. Find the notebook in the course repo . Related Papers How to High-level : look at key results in short summaries - get an idea of what's going on in the field. A bit deeper : for topics which interest you more, read",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "homework to align Russian and Ukranian embeddings. Find the notebook in the course repo . Related Papers How to High-level : look at key results in short summaries - get an idea of what's going on in the field. A bit deeper : for topics which interest you more, read longer summaries with illustrations and explanations. Take a walk through the authors' reasoning steps and key observations. In depth : read the papers you liked. Now, when you got the main idea, this is going to be easier! What's inside: Good Old Classics Analyzing Geometry Biases in Word Embeddings Semantic Change Theory to the Rescue! - coming soon Cross-Lingual Embeddings - coming soon ... to be updated Good Old Classics Theoretically, Word2Vec is not so different from matrix factorization approaches! Skip-gram with negative-sampling (SGNS) implicitly factorizes the shifted pointwise mutual information (PMI) matrix: \\(PMI(\\color{#88bd33}{w}\\color{black}, \\color{#888}{c}\\color{black})-\\log k\\), where \\(k\\) is the number of negative examples in negative sampling. ( w , c ) word-context pair: \\(N(\\color{#88bd33}{w}\\color{black}, \\color{#888}{c}\\color{black})\\) times; c as negative example for w : \\( \\frac{kN(\\color{#88bd33}{w}\\color{black})N(\\color{#888}{c}\\color{black})}{N}\\) times. Why: each time we sample a negative example, we can pick c with the probability \\(\\frac{N(\\color{#888}{c}\\color{black})}{N}\\) - frequency of c . Multiply by N( w ) because we meet w exactly N( w ) times; multiply by \\(k\\) because we sample \\(k\\) negative examples. Why: each time we sample a negative example, we can pick c with the probability \\(\\frac{N(\\color{#888}{c}\\color{black})}{N}\\) - frequency of c . Multiply by N( w ) because we meet w exactly N( w ) times; multiply by \\(k\\) because we sample \\(k\\) negative examples. At some point, it was believed that prediction-based embeddings are better than count-based. But this is not true: we can adapt some \"tricks\" from the word2vec implementation to count-based models and achieve the same results. Also, when evaluated properly, GloVE is worse than Word2Vec. The paper tests many hyperparameters and has lots of experiments - I do recommend looking into it. Here I will provide the most important things you need to remember. Eigenvalue Weighting: It is better to use SVD \"incorrectly\" Typically, word and context vectors derived by SVD are represented by \\(V_d\\Sigma_d\\) and \\(U_d\\): the eigenvalue matrix is included only in word vectors. However, for word similarity tasks this is not the optimal construction. The experiments show that symmetric variants are better: either include \\(\\sqrt{\\Sigma_d}\\) in both word and context vectors, or discard in both (look at the figure). Context Distribution Smoothing As we discussed in the lecture , Word2Vec samples negative examples according to smoothed unigram distribution \\(U^{3/4}\\). This was done to pick rare words more frequently. We can do something similar when calculating PMI: instead of true context distribution, let's use the smoothed one (look at the figure to the right). As in Word2Vec, \\(\\alpha=0.75\\). Word and Context Vectors in Word2Vec: Try to Average Recall that after training GloVe averages word and context vectors, while Word2Vec throws context vectors away. However, sometimes Word2Vec can also benefit from averaging: you have to try! Main Results with tuned hyperparameters, prediction-based embeddings are not better than",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "Word2Vec, \\(\\alpha=0.75\\). Word and Context Vectors in Word2Vec: Try to Average Recall that after training GloVe averages word and context vectors, while Word2Vec throws context vectors away. However, sometimes Word2Vec can also benefit from averaging: you have to try! Main Results with tuned hyperparameters, prediction-based embeddings are not better than count-based; with a couple of fixes, Word2Vec (SGNS) is better than GloVe on every task . Analyzing Geometry Word vectors point to roughly the same direction The authors evaluate dot products of vectors for words of different frequencies with the mean of all vectors. Since the distributions are very close and dot products are positive, the vectors (mostly) point in the direction of the mean vector. Context vectors point away from word vectors Here we do the same, but take context vectors (the mean is still for word vectors). For SGNS, dot products of context vectors with the mean of word vectors are negative. This means that context vectors point away from word vectors, and it is not reasonable to use them - we throw them away and use only word vectors. For GloVe, this is not the case: context vectors behave the same way as word vectors. We learned that we can (almost) match semantic spaces for different languages linearly. But is the \"true\" underlying mapping between languages indeed linear? If it is linear globally, then all local linear mappings have to be similar (to the global linear mapping, and hence to each other). Well, they are not. How to check if the \"true\" mapping between semantic spaces is indeed linear? The main idea is shown at the figure. Local cross-lingual mappings are not similar To check if the local mappings are similar, the authors for several words, take their neighborhood: a set of words with the cosine similarity at least some value; for each neighborhood, find the corresponding set of words in the other language; build local cross-linear mappings; evaluate how similar these mappings are: for two mappings \\(M_1\\) and \\(M_2\\) (e.g., for neighborhoods of words \\(w_1\\) and \\(w_2\\)), compute the cosine similarity between the vectorized versions of matrices \\(M_1\\) and \\(M_2\\). For distant words, their local cross-lingual mappings are different The authors found that local mappings for different neighborhoods can be very different. Therefore, \"true\" cross-lingual mapping between semantic spaces is not linear; for more distant words, the local cross-lingual mappings are more different. Lena : This is an example of how analysis can improve quality! The authors noticed that (i) embeddings have non-zero mean and (ii) early singular values are much larger than the rest. When the authors eliminated these properties, they got large improvements in both intrinsic and extrinsic evaluation. Step 1: Analyze For different word embedding models and languages, the authors found that vectors have a large non-zero mean are not isotropic Look at the figure: if \\(\\sigma_i\\) are singular values, then they decay almost exponentially for small \\(i\\), and remain roughly constant for the rest. Additionally, the authors noticed that the top PCA components encode something which is not related to semantics: e.g., word frequency.",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "large non-zero mean are not isotropic Look at the figure: if \\(\\sigma_i\\) are singular values, then they decay almost exponentially for small \\(i\\), and remain roughly constant for the rest. Additionally, the authors noticed that the top PCA components encode something which is not related to semantics: e.g., word frequency. These properties seem to have nothing to do with semantic, i.e., something which is important for us in word embeddings. What if we eliminate these effects? Will it be better? Step 2: Use Observations to Improve Quality To eliminate the found properties, the authors subtract from word vectors their mean eliminate top PCA components Let \\(u_1, \\dots, u_d\\) be the PCA components of word vectors \\(\\{v_w, w\\in V\\}\\). Then the vectors are updated as follows: \\[v_w \\longleftarrow v_w - \\sum\\limits_{i=1}^d(u_i^Tv_w)u_i.\\] Result : large improvements in various tasks, both intrinsic (similarity and analogy) and extrinsic (supervised classification). Biases in Word Embeddings Word embeddings are biased. For example, while their analogical reasoning can be desirable, e.g. \"a man to a woman is as a king to a queen \", but also \"a man to a woman is as a physician to a nurse \", which is an undesired association. man woman king queen man woman physician nurse Problem: Embeddings are Biased The authors noticed that word embeddings are biased: they encode undesired gender associations. To find such examples, they take a seed pair (e.g., (a, b) = ( he , she )) and find pairs of words which have the same association: differ from each other in the same direction, and relatively close to each other. Formally, they pick pairs with the high score: he she Look at the results below - definitely some pairs are biased! This means that, for example, not only \"a man to a woman is as a king to a queen \", which is the desired behavior, but also \"a man to a woman is as a physician to a nurse \", which is an undesired association. man woman king queen man woman physician nurse Gender-stereotypic occupations To find the most gender-stereotypic occupations, the authors project occupations onto the he - she gender direction. Results are shown to the right. he she We can see that, for example, homemaker , nurse , librarian , stylist are mostly associated with women, while captain , magician , architect , warrior are more strongly associated with men. homemaker nurse librarian stylist captain magician architect warrior Debiasing Word Embeddings In the original paper , the authors also propose several heuristics to debias word embeddings - remove the undesired associations as a post-processing step. Since a lot has been done on debiasing recently, for more details on this specific approach look in the original paper. For a more recent method, look at the next paper . Iterative nullspace projection to debias word embeddings: train a linear classifier \\(W\\) to predict a property from embeddings (e.g., gender), linearly project embeddings on the \\(W\\)'s nullspace (\\(x \\rightarrow Px\\), \\(W(Px)=0\\)) - remove the information used for prediction; repeat until a classifier is not able to predict anything.",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "paper . Iterative nullspace projection to debias word embeddings: train a linear classifier \\(W\\) to predict a property from embeddings (e.g., gender), linearly project embeddings on the \\(W\\)'s nullspace (\\(x \\rightarrow Px\\), \\(W(Px)=0\\)) - remove the information used for prediction; repeat until a classifier is not able to predict anything. Idea : Remove Information Used by a Linear Classifier We have to remove the information about some desired property (e.g., gender), but not to harm other properties of the embeddings. The authors proposed a very simple idea: train a linear classifier to predict this property from the embeddings, then remove the information this classifier used. If the classifier is linear, the removing part can be done easily: by projecting onto the classifier's decision boundary. This projection is the least harming way to remove the linear information about the property: it harms the distances between embeddings as little as possible. The method is iterative : you have to repeat this (train a classifier and project to the new decision boundary) until the classifier is not able to predict anything meaningful. When a classifier can not predict the property, we know that all information has been removed. Results: All Good In the original paper , you will find experiments showing that the method: does remove bias (look at the illustration to the right: t-SNE projection of GloVe vectors of the most gender-biased words at 0, 3, 18, 35 iterations of the algorithm), does not hurt embedding quality (e.g., look at the closest neighbors before and after debiasing: see below) . For more formal things and more results and examples, look at the original paper . Semantic Change Imagine you have text corpora from different sources: time periods, populations, geographic regions, etc. In this part, the task is to find words that used differently in these corpora. Lena : This paper was used in the Research Thinking section. Here I've hidden from you the links and the content - better go there to think. But if you do want, you can learn about the paper here. Spoiler alert! To find which words are used differently in two text corpora: train embeddings using each of the corpora, map linearly the two embedding spaces to each other; words whose vectors do not match well are the ones that changed their meaning. Idea : Align Two Embedding Sets, Find Words That Do Not Match The main idea here is to align two embeddings sets and to find words whose embeddings do not match well. Formally, let \\(\\color{#88a635}{W_1}\\color{black}, \\color{#547dbf}{W_2}\\color{black} \\in \\mathbb{R}^{d\\times |V|}\\) be embedding sets trained on different corpora. To align the learned embeddings, the authors find the rotation \\[R = \\arg \\max\\limits_{Q^TQ=I}\\parallel \\color{#547dbf}{W_2}\\color{black}Q - \\color{#88a635}{W_1}\\color{black}\\parallel_F.\\] This is called Orthogonal Procrustes. Using this rotation, we can align embedding sets and find words that do not match well: these are the words that change meaning with the corpora. Once the embedding sets are aligned, we can evaluate the semantic displacement . Let \\(\\color{#88a635}{v_w^1}\\) and \\(\\color{#547dbf}{v_w^2}\\) be embedding of a word \\(w\\) in the two aligned spaces, then the semantic displacement",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "and find words that do not match well: these are the words that change meaning with the corpora. Once the embedding sets are aligned, we can evaluate the semantic displacement . Let \\(\\color{#88a635}{v_w^1}\\) and \\(\\color{#547dbf}{v_w^2}\\) be embedding of a word \\(w\\) in the two aligned spaces, then the semantic displacement is \\(1- \\cos (\\color{#88a635}{v_w^1}\\color{black}, \\color{#547dbf}{v_w^2}\\color{black}).\\) Intuitively, this measures how well embeddings of the same word \"match\" in the aligned semantic spaces. Experiments TL;DR: SGNS Embeddings are Better than PPMI and SVD(PPMI) The authors looked at historical texts for different time periods and tried to apply the method on top of different embeddings: PPMI matrix, SVD(PPMI) and Word2Vec (SGNS). Below are examples of the top words found for each of the embedding methods. bold - real semantic shifts (validated by examining literature) E.g., headed shifted from primarily referring to the \"top of a body/entity\" to referring to \"a direction of travel.\" E.g., headed shifted from primarily referring to the \"top of a body/entity\" to referring to \"a direction of travel.\" underlined - borderline cases (largely due to global genre/discourse shifts) E.g., male has not changed in meaning, but its usage in discussions of “gender equality” is relatively new. E.g., male has not changed in meaning, but its usage in discussions of “gender equality” is relatively new. unmarked - clear corpus artifacts E.g., special, cover, and romance are artifacts from the covers of fiction books occasionally including advertisements etc. E.g., special, cover, and romance are artifacts from the covers of fiction books occasionally including advertisements etc. Looks like results obtained for SGNS embeddings are better. In the original paper , different kinds of evaluation were used to confirm this more formally. From the next paper , you will learn how to detect semantic change more easily. Note: The Alignment Idea is Used for Different Tasks Note that the idea to linearly map different semantic spaces was also used for other tasks. For example, earlier in the lecture we aligned semantic spaces for different languages to build vocabulary. For more advanced methods for building cross-lingual embeddings, look here in the Related Papers . Lena : This paper was used in the Research Thinking section. Here I've hidden from you the links and the content - better go there to think. But if you do want, you can learn about the paper here. Spoiler alert! To find which words are used differently in two text corpora: train embeddings using each of the corpora, for each word, find closest neighbors in the two embedding spaces; the neighbors differ a lot → the words are used differently. Idea : Train Embeddings, Look at the Neighbors A very simple approach is to train embeddings (e.g., Word2Vec) and look at the closest neighbors. If a word's closest neighbors are different for the two corpora, the word changed its meaning: remember that word embeddings reflect contexts they saw! Formally, for each word \\(w\\) the authors take k nearest neighbors in the two embeddings sets: \\(NN_1^k(w)\\) and \\(NN_2^k(w)\\). Then they count how many neighbors are the same and define the change score",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Word Embeddings",
    "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html",
    "section_title": null,
    "text": "for the two corpora, the word changed its meaning: remember that word embeddings reflect contexts they saw! Formally, for each word \\(w\\) the authors take k nearest neighbors in the two embeddings sets: \\(NN_1^k(w)\\) and \\(NN_2^k(w)\\). Then they count how many neighbors are the same and define the change score as follows: \\[score^k(w) = -|NN_1^k(w)\\cap NN_2^k(w)|\\] A large intersection means that the meaning is not different (the score will be low), small intersection - meaning is different (such words will receive a high score). The Method is Interpretable By design, the method is interpretable: it explains its decisions (i.e., why the word is used differently) by showing the closest neighbors of the word in the two embedding spaces. These neighbors reflect the word meanings in the two corpora. Look at the examples of found words along with the closest neighbors. Other Good Things Compared to the alignment-based methods (e.g., the previous paper ), this approach: is more stable, requires less tuning and word filtering. For more details, look at the paper. Lena: Note that while the approach is recent, it is extremely simple and works better than previous more complicated ideas. Never be afraid to try simple things - you'll be surprised how often they work! Theory to the Rescue! On the Dimensionality of Word Embedding Analogies Explained: Towards Understanding Word Embeddings Cross-Lingual Embeddings Word Translation Without Parallel Data ... to be updated Have Fun! Semantic Space Surfer Usually, we want word embeddings to reason as humans do. But let's try the opposite: you will try to think as word embeddings. You will see the analogical example, e.g. king - man + woman = ? , and several possible answers. The task is to guess what word embeddings think. Complete the task (10 examples) and get a Semantic Space Surfer Certificate ! Word embeddings: we used glove-twitter-100 from gensim-data . Big thanks Just Heuristic for the help with technical issues! Just Heuristic - Just Fun! next Semantic Space Surfer: Level 0 NLP course | For YOU : Official Certificate",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "What does it mean to \"model something\"? Imagine that we have, for example, a model of a physical world. What do you expect it to be able to do? Well, if it is a good model, it probably can predict what happens next given some description of \"context\", i.e., the current state of things. Something of the following kind: We have a tower of that many toy cubes of that size made from this material. We push the bottom cube from this point in that direction with this force. What will happen? A good model would simulate the behavior of the real world: it would \"understand\" which events are in better agreement with the world, i.e., which of them are more likely . What about language? For language, the intuition is exactly the same! What is different, is the notion of an event . In language, an event is a linguistic unit (text, sentence, token, symbol), and a goal of a language model is to estimate the probabilities of these events. Language Models (LMs) estimate the probability of different linguistic units: symbols, tokens, token sequences. But how can this be useful? We deal with LMs every day! We see language models in action every day - look at some examples. Usually models in large commercial services are a bit more complicated than the ones we will discuss today, but the idea is the same: if we can estimate probabilities of words/sentences/etc, we can use them in various, sometimes even unexpected, ways. What is easy for humans, can be very hard for machines morphosyntax We, humans, already have some feeling of \"probability\" when it comes to natural language. For example, when we talk, usually we understand each other quite well (at least, what's being said). We disambiguate between different options which sound similar without even realizing it! But how a machine is supposed to understand this? A machine needs a language model, which estimates the probabilities of sentences. If a language model is good, it will assign a larger probability to a correct option. General Framework Text Probability Our goal is to estimate probabilities of text fragments; for simplicity, let's assume we deal with sentences. We want these probabilities to reflect knowledge of a language. Specifically, we want sentences that are \"more likely\" to appear in a language to have a larger probability according to our language model. How likely is a sentence to appear in a language? Let's check if simple probability theory can help. Imagine we have a basket with balls of different colors. The probability to pick a ball of a certain color (let's say green) from this basket is the frequency with which green balls occur in the basket. What if we do the same for sentences? Since we can not possibly have a text corpus that contains all sentences in a natural language, a lot of sentences will not occur in the corpus. While among these sentences some are clearly more likely than the others, all of them will receive zero probability, i.e., will look equally bad for",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "can not possibly have a text corpus that contains all sentences in a natural language, a lot of sentences will not occur in the corpus. While among these sentences some are clearly more likely than the others, all of them will receive zero probability, i.e., will look equally bad for the model. This means, the method is not good and we have to do something more clever. Sentence Probability: Decompose Into Smaller Parts We can not reliably estimate sentence probabilities if we treat them as atomic units. Instead, let's decompose the probability of a sentence into probabilities of smaller parts. For example, let's take the sentence I saw a cat on a mat and imagine that we read it word by word. At each step, we estimate the probability of all seen so far tokens. We don't want any computations not to be in vain (no way!), so we won't throw away previous probability once a new word appears: we will update it to account for a new word. Look at the illustration. I saw a cat on a mat Formally, let \\(y_1, y_2, \\dots, y_n\\) be tokens in a sentence, and \\(P(y_1, y_2, \\dots, y_n)\\) the probability to see all these tokens (in this order). Using the product rule of probability (aka the chain rule), we get \\[P(y_1, y_2, \\dots, y_n)=P(y_1)\\cdot P(y_2|y_1)\\cdot P(y_3|y_1, y_2)\\cdot\\dots\\cdot P(y_n|y_1, \\dots, y_{n-1})= \\prod \\limits_{t=1}^n P(y_t|y_{\\mbox{<}t}).\\] We decomposed the probability of a text into conditional probabilities of each token given the previous context. We got: Left-to-Right Language Models What we got is the standard left-to-right language modeling framework. This framework is quite general: N-gram and neural language models differ only in a way they compute the conditional probabilities \\(P(y_t|y_1, \\dots, y_{t-1})\\). Lena : Later in the course we will see other language models: for example, Masked Language Models or models that decompose the joint probability differently (e.g., arbitrary order of tokens and not fixed as the left-to-right order). We will come to specifics of N-gram and neural models a bit later. Now, we discuss how to generate a text using a language model. Generate a Text Using a Language Model Once we have a language model, we can use it to generate text. We do it one token at a time: predict the probability distribution of the next token given previous context, and sample from this distribution. Alternatively, you can apply greedy decoding : at each step, pick the token with the highest probability. However, this usually does not work well: a bit later I will show you examples from real models. Despite its simplicity, such sampling is quite common in generation. In section Generation Strategies we will look at different modifications of this approach to get samples with certain qualities; e.g., more or less \"surprising\". N-gram Language Models Let us recall that the general left-to-right language modeling framework decomposes probability of a token sequence, into conditional probabilities of each token given previous context: \\[P(y_1, y_2, \\dots, y_n)=P(y_1)\\cdot P(y_2|y_1)\\cdot P(y_3|y_1, y_2)\\cdot\\dots\\cdot P(y_n|y_1, \\dots, y_{n-1})= \\prod \\limits_{t=1}^n P(y_t|y_{\\mbox{<}t}).\\] The only thing which is not clear so far is",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "Language Models Let us recall that the general left-to-right language modeling framework decomposes probability of a token sequence, into conditional probabilities of each token given previous context: \\[P(y_1, y_2, \\dots, y_n)=P(y_1)\\cdot P(y_2|y_1)\\cdot P(y_3|y_1, y_2)\\cdot\\dots\\cdot P(y_n|y_1, \\dots, y_{n-1})= \\prod \\limits_{t=1}^n P(y_t|y_{\\mbox{<}t}).\\] The only thing which is not clear so far is how to compute these probabilities. We need to : define how to compute the conditional probabilities \\(P(y_t|y_1, \\dots, y_{t-1})\\). Similar to count-based methods we saw earlier in the Word Embeddings lecture, n-gram language models also count global statistics from a text corpus. How : estimate based on global statistics from a text corpora, i.e., count . That is, the way n-gram LMs estimate probabilities \\(P(y_t|y_{\\mbox{<}t}) = P(y_t|y_1, \\dots, y_{t-1})\\) is almost the same as the way we earlier estimated the probability to pick a green ball from a basket. This innocent \"almost\" contains the key components of n-gram LMs: Markov property and smoothings . Markov Property (Independence Assumption) The straightforward way to compute \\(P(y_t|y_1, \\dots, y_{t-1})\\) is \\[P(y_t|y_1, \\dots, y_{t-1}) = \\frac{N(y_1, \\dots, y_{t-1}, y_t)}{N(y_1, \\dots, y_{t-1})},\\] where \\(N(y_1, \\dots, y_k)\\) is the number of times a sequence of tokens \\((y_1, \\dots, y_k)\\) occur in the text. For the same reasons we discussed before, this won't work well: many of the fragments \\((y_1, \\dots, y_{t})\\) do not occur in a corpus and, therefore, will zero out the probability of the sentence. To overcome this problem, we make an independence assumption (assume that the Markov property holds): The probability of a word only depends on a fixed number of previous words. n=3 (trigram model): \\(P(y_t|y_1, \\dots, y_{t-1}) = P(y_t|y_{t-2}, y_{t-1})\\), n=2 (bigram model): \\(P(y_t|y_1, \\dots, y_{t-1}) = P(y_t|y_{t-1})\\), n=1 (unigram model): \\(P(y_t|y_1, \\dots, y_{t-1}) = P(y_t)\\). Look how the standard decomposition changes for n-gram models. Smoothing: Redistribute Probability Mass Let's imagine we deal with a 4-gram language model and consider the following example: What if either denominator or numerator is zero? Both these cases are not really good for the model. To avoid these problems (and some other), it is common to use smoothings . Smoothings redistribute probability mass: they \"steal\" some mass from seen events and give to the unseen ones. Lena : at this point, usually I'm tempted to imagine a brave Robin Hood, stealing from the rich and giving to the poor - just like smoothings do with the probability mass. Unfortunately, I have to stop myself, because, let's be honest, smoothings are not so clever - it would be offensive to Robin. Avoid zeros in the denominator If the phrase cat on a never appeared in our corpus, we will not be able to compute the probability. Therefore, we need a \"plan B\" in case this happens. cat on a Backoff (aka Stupid Backoff) One of the solutions is to use less context for context we don't know much about. This is called backoff: if you can, use trigram; if not, use bigram; if even bigram does not help, use unigram. This is rather stupid (hence the title), but works fairly well. if you can, use trigram; if not,",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "to use less context for context we don't know much about. This is called backoff: if you can, use trigram; if not, use bigram; if even bigram does not help, use unigram. This is rather stupid (hence the title), but works fairly well. if you can, use trigram; if not, use bigram; if even bigram does not help, use unigram. More clever: Linear interpolation A more clever solution is to mix all probabilities: unigram, bigram, trigram, etc. For this, we need scalar positive weights \\(\\lambda_0, \\lambda_1, \\dots, \\lambda_{n-1}\\) such that \\(\\sum\\limits_{i}\\lambda_i=1\\). Then the updated probability is: The coefficients \\(\\lambda_i\\) can be picked by cross-validation on the development set. You will be able to do this once you know how to evaluate language models: see the Evaluation section. Avoid zeros in the numerator If the phrase cat on a mat never appeared in our corpus, the probability of the whole sentence will be zero - but this does not mean that the sentence is impossible! To avoid this, we also need a \"plan B\". cat on a mat Laplace smoothing (aka add-one smoothing) The simplest way to avoid this is just to pretend we saw all n-grams at least one time: just add 1 to all counts! Alternatively, instead of 1, you can add a small \\(\\delta\\): More Clever Smoothings Kneser-Ney Smoothing. The most popular smoothing for n-gram LMs is Kneser-Ney smoothing: it is a more clever variant of the back-off. More details are here. Generation (and Examples) The generation procedure for a n-gram language model is the same as the general one: given current context (history), generate a probability distribution for the next token (over all tokens in the vocabulary), sample a token, add this token to the sequence, and repeat all steps again. The only part which is specific to n-gram models is the way we compute the probabilities. Look at the illustration. Examples of generated text To show you some examples, we trained a 3-gram model on 2.5 million English sentences. Dataset details. The data is the English side of WMT English-Russian translation data. It consists of 2.5 million sentence pairs (a pair of sentences in English and Russian which are supposed to be translations of each other). The dataset contains news data, Wikipedia titles and 1 million crawled sentences released by Yandex. This data is one of the standard datasets for machine translation; for language modeling, we used only the English side. Note that everything you will see below is generated by a model and presented without changes or filtering. Any content you might not like appeared as a result of training data. The best we can do is to use the standard datasets, and we did. How to: Look at the samples from a n-gram LM. What is clearly wrong with these samples? What in the design of n-gram models leads to this problem? so even when i talk a bit short , there was no easy thing to do different buffer flushing strategies in the future , due to huge list of number - one just has",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "clearly wrong with these samples? What in the design of n-gram models leads to this problem? so even when i talk a bit short , there was no easy thing to do different buffer flushing strategies in the future , due to huge list of number - one just has started production of frits in the process and has free wi - fi ” operation .... _eos_ he can perform the dual monarchy arrived in moscow lying at two workshops one in all schools of political science ...\" and then you can also benefit from your service . _eos_ alas , still in the lower left corner will not start in 1989 . _eos_ john holmes is a crystal - clear spring of 2001 . _eos_ it simply yields a much later , there were present , ferrocenecontaining compounds for clinical trials in connection with this chapter you ' re looking for ways of payment and insert preferred record into catalogue of negative influences - military . _eos_ impotence in the way gazprom and its environment . _eos_ according to the address and tin box , luggage storage , gay friendly , all of europe to code - transitions . _eos_ 26 . 01 page 2 introduction the challenge for the horizontal scroll bar in sweden , austria _eos_ the rza lyrics are brought to you , there are a few . _eos_ golden sands , once again the only non - governmental organizations recognized by the objector . _eos_ hahn , director of the christian \" love and compassion \" was designed as a result of any form , in the transaction is active in the stuva grill . _eos_ there is a master ’ s a major bus routes in and the us became israel were rewarded with an electric air conditioning television satellite television . _eos_ , we have had , 1990 in aksaray – turkey has provided application is built on low - power plants . _eos_ when this option may be the worst day of amnesty international delegations visited israel , and felt that his sisters , that they are reserved for zyryanovsk concentrating factory there is a member of the shire ,\" given as to damage the expansion of a meeting over a large health maintenance organization , smoking , airconditioning , designated smoking area . _eos_ 4 . 0 beta has been received the following initiatives in order to meet again in 1989 , and in the face of director of branch offices in odessa on time , the church of norway is an advertisement for the protection the d - 54673 , limousine , employee badges , etc ) downloading this icecat data - do can talk about israel as well as standard therapy of czech republic estonia greece france ireland israel italy jamaica japan jordan kazakhstan kenya kiribati kuwait kyrgyzstan lao people ' s closing of the task of mill - a fire that _eos_ one lesson the teacher ! _eos_ pupils from eastern europe , africa , saudi arabia ’ s church",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "of czech republic estonia greece france ireland israel italy jamaica japan jordan kazakhstan kenya kiribati kuwait kyrgyzstan lao people ' s closing of the task of mill - a fire that _eos_ one lesson the teacher ! _eos_ pupils from eastern europe , africa , saudi arabia ’ s church , yearn for such an open structure of tables several times on monday 14 september 2003 , his flesh when i was curious to know and also to find what they are constructed with a speeding arrow . _eos_ blackjack : six steps to resolve complex social adaptation of the room ' s polyclinics and to english . _eos_ this is the right nanny jobs easier for people to take part in the history of england has a large number of regional and city administration . _eos_ melody for the acquisition , provision or condition . _eos_ they have a proper map that force distant astronomical objects have been soaring among ukrainians - warriors \". _eos_ also now recognizing how interdependent they are successful in emulating poland ’ s satisfaction . _eos_ we tried to make lyrics as correct as possible , however if you have any corrections for abecedário da xuxa lyrics are brought to you by lyrics - keeper . _eos_ 49 . 99 webmoney rub , 893 . 6 million euros . _eos_ You probably noticed that these samples are not fluent: it can be clearly seen that the model does not use long context, and relies only on a couple of tokens. The inability to use long contexts is the main shortcoming of n-gram models. Now, we take the same model, but perform greedy decoding: at each step, we pick the token with the highest probability. We used 2-token prefixes from the examples of samples above (for each example, the prefix fed to the model is underlined). How to: Look at the examples generated by the same model using greedy decoding. Do you like these texts? How would you describe them? so even if the us , and the united states , the hotel is located in the list of songs , you can add them in our collection by this form . _eos_ he can be used to be a good idea to the keyword / phrase business intelligence development studio . _eos_ alas , the hotel is located in the list of songs , you can add them in our collection by this form . _eos_ john holmes _eos_ it simply , the hotel is located in the list of songs , you can add them in our collection by this form . _eos_ impotence in the list of songs , you can add them in our collection by this form . _eos_ according to the keyword / phrase business intelligence development studio . _eos_ 26 . _eos_ the rza ( bobby digital ) is a very good . _eos_ golden sands resort . _eos_ hahn , of the world . _eos_ there is a very good . _eos_ , we a good idea to the",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "keyword / phrase business intelligence development studio . _eos_ 26 . _eos_ the rza ( bobby digital ) is a very good . _eos_ golden sands resort . _eos_ hahn , of the world . _eos_ there is a very good . _eos_ , we a good idea to the keyword / phrase business intelligence development studio . _eos_ when this option is to be a good idea to the keyword / phrase business intelligence development studio . _eos_ 4 . 5 % of the world . _eos_ one lesson from the city of the world . _eos_ pupils from the city of the world . _eos_ blackjack : six - party talks . _eos_ this is the most important thing is that the us , and the united states , the hotel is located in the list of songs , you can add them in our collection by this form . _eos_ melody for two years , the hotel is located in the list of songs , you can add them in our collection by this form . _eos_ they have been a member of the world . _eos_ also now possible to use the \" find in page \" function below . _eos_ we tried to make lyrics as correct as possible , however if you have any corrections for the first time in the list of songs , you can add them in our collection by this form . _eos_ 49 . _eos_ We see that greedy texts are: shorter - the _eos_ token has high probability; very similar - many texts end up generating the same phrase. To overcome the main flaw of n-gram LMs, fixed context size, we will now come to neural models. As we will see later, when longer contexts are used, greedy decoding is not so awful. Neural Language Models In our general left-to-right language modeling framework , the probability of a token sequence is: \\[P(y_1, y_2, \\dots, y_n)=P(y_1)\\cdot P(y_2|y_1)\\cdot P(y_3|y_1, y_2)\\cdot\\dots\\cdot P(y_n|y_1, \\dots, y_{n-1})= \\prod \\limits_{t=1}^n P(y_t|y_{\\mbox{<}t}).\\] Let us recall, again, what is left to do. We need to : define how to compute the conditional probabilities \\(P(y_t|y_1, \\dots, y_{t-1})\\). Differently from n-gram models that define formulas based on global corpus statistics, neural models teach a network to predict these probabilities. How : Train a neural network to predict them . Intuitively, neural Language Models do two things: process context → model-specific The main idea here is to get a vector representation for the previous context. Using this representation, a model predicts a probability distribution for the next token. This part could be different depending on model architecture (e.g., RNN, CNN, whatever you want), but the main point is the same - to encode context. generate a probability distribution for the next token → model-agnostic Once a context has been encoded, usually the probability distribution is generated in the same way - see below. This is classification! We can think of neural language models as neural classifiers. They classify prefix of a text into |V| classes, where the classes are vocabulary tokens. High-Level",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "→ model-agnostic Once a context has been encoded, usually the probability distribution is generated in the same way - see below. This is classification! We can think of neural language models as neural classifiers. They classify prefix of a text into |V| classes, where the classes are vocabulary tokens. High-Level Pipeline Since left-to-right neural language models can be thought of as classifiers, the general pipeline is very similar to what we saw in the Text Classification lecture. For different model architectures, the general pipeline is as follows: feed word embedding for previous (context) words into a network; get vector representation of context from the network; from this vector representation, predict a probability distribution for the next token. Similarly to neural classifiers, we can think about the classification part (i.e., how to get token probabilities from a vector representation of a text) in a very simple way. Vector representation of a text has some dimensionality \\(d\\), but in the end, we need a vector of size \\(|V|\\) (probabilities for \\(|V|\\) tokens/classes). To get a \\(|V|\\)-sized vector from a \\(d\\)-sized, we can use a linear layer. Once we have a \\(|V|\\)-sized vector, all is left is to apply the softmax operation to convert the raw numbers into class probabilities. Another View: Dot Product with Output Word Embeddings If we look at the final linear layer more closely, we will see that it has \\(|V|\\) columns and each of them corresponds to a token in the vocabulary. Therefore, these vectors can be thought of as output word embeddings . Now we can change our model illustration according to this view. Applying the final linear layer is equivalent to evaluating the dot product between text representation h and each of the output word embeddings . Formally, if \\(\\color{#d192ba}{h_t}\\) is a vector representation of the context \\(y_1, \\dots, y_{t-1}\\) and \\(\\color{#88bd33}{e_w}\\) are the output embedding vectors, then \\[p(y_t| y_{\\mbox{<}t}) = \\frac{exp(\\color{#d192ba}{h_t^T}\\color{#88bd33}{e_{y_t}}\\color{black})}{\\sum\\limits_{w\\in V}exp(\\color{#d192ba}{h_t^T}\\color{#88bd33}{e_{w}}\\color{black})}.\\] Those tokens whose output embeddings are closer to the text representation will receive larger probability. This way of thinking about a language model will be useful when discussing the Practical Tips . Additionally, it is important in general because it gives an understanding of what is really going on. Therefore, below I'll be using this view. Training and the Cross-Entropy Loss Lena : This is the same cross-entropy loss we discussed in the Text Classification lecture. Neural LMs are trained to predict a probability distributions of the next token given the previous context. Intuitively, at each step we maximize the probability a model assigns to the correct token. Formally, if \\(y_1, \\dots, y_n\\) is a training token sequence, then at the timestep \\(t\\) a model predicts a probability distribution \\(p^{(t)} = p(\\ast|y_1, \\dots, y_{t-1})\\). The target at this step is \\(p^{\\ast}=\\mbox{one-hot}(y_t)\\), i.e., we want a model to assign probability 1 to the correct token, \\(y_t\\), and zero to the rest. The standard loss function is the cross-entropy loss . Cross-entropy loss for the target distribution \\(p^{\\ast}\\) and the predicted distribution \\(p^{}\\) is \\[Loss(p^{\\ast}, p^{})= - p^{\\ast} \\log(p) = -\\sum\\limits_{i=1}^{|V|}p_i^{\\ast} \\log(p_i).\\] Since only one of \\(p_i^{\\ast}\\)",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "model to assign probability 1 to the correct token, \\(y_t\\), and zero to the rest. The standard loss function is the cross-entropy loss . Cross-entropy loss for the target distribution \\(p^{\\ast}\\) and the predicted distribution \\(p^{}\\) is \\[Loss(p^{\\ast}, p^{})= - p^{\\ast} \\log(p) = -\\sum\\limits_{i=1}^{|V|}p_i^{\\ast} \\log(p_i).\\] Since only one of \\(p_i^{\\ast}\\) is non-zero (for the correct token \\(y_t\\)), we will get \\[Loss(p^{\\ast}, p) = -\\log(p_{y_t})=-\\log(p(y_t| y_{\\mbox{<}t})).\\] At each step, we maximize the probability a model assigns to the correct token. Look at the illustration for a single timestep. For the whole sequence, the loss will be \\(-\\sum\\limits_{t=1}^n\\log(p(y_t| y_{\\mbox{<}t}))\\). Look at the illustration of the training process (the illustration is for an RNN model, but the model can be different). Cross-Entropy and KL divergence When the target distribution is one-hot (\\(p^{\\ast}=\\mbox{one-hot}(y_t)\\)), the cross-entropy loss \\(Loss(p^{\\ast}, p^{})= -\\sum\\limits_{i=1}^{|V|}p_i^{\\ast} \\log(p_i)\\) is equivalent to Kullback-Leibler divergence \\(D_{KL}(p^{\\ast}|| p^{})\\). Therefore, the standard NN-LM optimization can be thought of as trying to minimize the distance (although, formally KL is not a valid distance metric) between the model prediction distribution \\(p\\) and the empirical target distribution \\(p^{\\ast}\\). With many training examples, this is close to minimizing the distance to the actual target distribution. Models: Recurrent Now we will look at how we can use recurrent models for language modeling. Everything you will see here will apply to all recurrent cells, and by \"RNN\" in this part I refer to recurrent cells in general (e.g. vanilla RNN, LSTM, GRU, etc). • Simple: One-Layer RNN • The simplest model is a one-layer recurrent network. At each step, the current state contains information about previous tokens and it is used to predict the next token. In training, you feed the training examples. At inference, you feed as context the tokens your model generated; this usually happens until the _eos_ token is generated. _eos_ • Multiple layers : feed the states from one RNN to the next one • To get a better text representation, you can stack multiple layers. In this case, inputs for the higher RNN are representations coming from the previous layer. The main hypothesis is that with several layers, lower layers will catch local phenomena, while higher layers will be able to catch longer dependencies. Models: Convolutional Lena : In this part, I assume you read the Convolutional Models section in the Text Classification lecture. If you haven't, read the Convolutional Models Supplementary . Compared to CNNs for text classification, language models have several differences. Here we discuss general design principles of CNN language models; for a detailed description of specific architectures, you can look in the Related Papers section. When designing a CNN language model, you have to keep in mind the following things: prevent information flow from future tokens To predict a token, a left-to-right LM has to use only previous tokens - make sure your CNN does not see anything but them! For example, you can shift tokens to the right by using padding - look at the illustration above. do not remove positional information Differently from text classification, positional information is very important for language models.",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "use only previous tokens - make sure your CNN does not see anything but them! For example, you can shift tokens to the right by using padding - look at the illustration above. do not remove positional information Differently from text classification, positional information is very important for language models. Therefore, do not use pooling (or be very careful in how you do it). if you stack many layers, do not forget about residual connections If you stack many layers, it may difficult to train a very deep network well. To avoid this, use residual connections - look for the details below. Receptive field : with many layers, can be large When using convolutional models without global pooling, your model will inevitably have a fixed-sized context. This might seem undesirable: the fixed context size problem is exactly what we didn't like in the n-gram models! However, if for n-gram models typical context size is 1-4, contexts in convolutional models can be quite long. Look at the illustration: with only 3 convolutional layers with small kernel size 3, a network has a context of 7 tokens. If you stack many layers, you can get a very large context length. Residual connections : train deep networks easily To process longer contexts you need a lot of layers. Unfortunately, when stacking a lot of layers, you can have a problem with propagating gradients from top to bottom through a deep network. To avoid this, we can use residual connections or a more complicated variant, highway connections . Residual connections are very simple: they add input of a block to its output. In this way, the gradients over inputs will flow not only indirectly through the block, but also directly through the sum. Highway connections have the same motivation, but a use a gated sum of input and output instead of the simple sum. This is similar to LSTM gates where a network can learn the types of information it may want to carry on from bottom to top (or, in case of LSTMs, from left to right). Look at the example of a convolutional network with residual connections. Typically, we put residual connections around blocks with several layers. A network can several such blocks - remember, you need a lot of layers to get a decent receptive field. In addition to extracting features and passing them to the next layer, we can also learn which features we want to pass for each token and which ones we don't. More details are in this paper summary. P.S. Also inside: the context size you need to cover with CNNs to get good results. Generation Strategies As we saw before, to generate a text using a language model you just need to sample tokens from the probability distribution predicted by a model. Coherence and Diversity You can modify the distributions predicted by a model in different ways to generate texts with some properties. While the specific desired text properties may depend on the task you care about (as always), usually you would want the generated texts to be:",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "predicted by a model. Coherence and Diversity You can modify the distributions predicted by a model in different ways to generate texts with some properties. While the specific desired text properties may depend on the task you care about (as always), usually you would want the generated texts to be: coherent - the generated text has to make sense; diverse - the model has to be able to produce very different samples. Lena: Recall the incoherent samples from an n-gram LM - not nice! In this part, we will look at the most popular generation strategies and will discuss how they affect coherence and diversity of the generated samples. Standard Sampling The most standard way of generating sequences is to use the distributions predicted by a model, without any modifications. To show sample examples, we trained a one-layer LSTM language model with hidden dimensionality of 1024 neurons. The data is the same as for the n-gram model (2.5m English sentences from WMT English-Russian dataset). How to: Look at the samples from an LSTM LM. Pay attention to coherence and diversity. Are these samples better than those of an n-gram LM we saw earlier ? Lena : we sample until the _eos_ token is generated. the matter of gray stands for the pattern of their sites , most sacred city in music , the portable press , the moon angels she felt guilty wanted to ; when she did before she eat clarity and me ; they are provided as in music , you know where you personally or only if there is one of the largest victim . _eos_ we tried to make lyrics as correct as possible , however if you have any corrections for light years lyrics , please feel free to submit them to us significantly higher budgets . _eos_ i dare say continues greece peace . _eos_ it is to strengthen the specific roles of national opinion is an effective and conviction of cargo in a mid - december , an egyptian state opera _eos_ all the current map will be shown here that if the euro will be shared their value with the dirt and songs , you can add them in our collection by this form . _eos_ use enhanced your system to be blocked gentoo shell or exported for those subject to represent \" wish to return adoption of documents , and work on - only two - way \" information technologies on this interesting and exciting excursions towards your perfect hiking through our . _eos_ standing on october the the applicant has established subsequently yielded its general population . _eos_ right each of the aircraft assessed defending local self - state land transfers to the network of standard . _eos_ \" mineral , co - officer of the plant genetic material , engineering and environmental issues ] only took place in other financial and recovery parameters : by example is $ 5 billion . _eos_ here you can receive news from your account ® only . _eos_ political bureau of doing has lost of",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "- officer of the plant genetic material , engineering and environmental issues ] only took place in other financial and recovery parameters : by example is $ 5 billion . _eos_ here you can receive news from your account ® only . _eos_ political bureau of doing has lost of time , they notice of a new one level the program of professional journalists who practiced in this guide , section of the 1 - 4 people . _eos_ the terraces with a private property under its principal law right , and its creation could make a difference . _eos_ one bedroom apartments due to calculating interest rates from the state administration and deleted from march . _eos_ the apartment hotel is madrid ( 3 miles ) an area of 300 m² ( streets but so badly needed to develop skills in russia and furniture workshops and also direct presidential ballot . _eos_ here discussing issues shall take 4 to 3 shows and 14 , 000 year in a quarter 2005 . _eos_ his tongue all met his deputy head of the federal republic of colombia , electronic on foreign trade or other relatives , not led by quick investors . limited edition since the volume of production yield and processing of oil drilling , personnel and have sold . _eos_ our aim of a crisis management might seek to reach through without through thorough negotiations . _eos_ the deep sea , including at the national government and canada . _eos_ they are suspect that thus making it fell disturbing autonomy . _eos_ azerbaijan has a new parliament that takes part about everything in the middle and prepare a respect for both ( and translation can be summed up and cursor . _eos_ the annual environmental impact assessment assessment _eos_ 3 . 23 generations : ... do not specify comment ( unless ). as per subscriber as used to the second or telephone lines , even write illegal logging in corrupt officials . _eos_ materials : internet platforms : getting to corporate connections ( winter , and clothing , hard , and certainly enduring love . _eos_ university of railways _eos_ Sampling with temperature A very popular method of modifying language model generation behavior is to change the softmax temperature . Before applying the final softmax, its inputs are divided by the temperature \\(\\tau\\): Formally, the computations change as follows: Note that the sampling procedure remains standard: the only thing which is different is how we compute the probabilities. How to: Play with the temperature and see how the probability distribution changes. Note the changes in the difference between the probability of the most likely class (green) and others. What happens when the temperature is close to zero? What happens when the temperature is high? Sampling with which temperature corresponds to greedy decoding? Note that you can also change the number of classes and generate another probability distribution. Examples : Samples with Temperatures 2 and 0.2 Now when you understand how the temperature changes the distributions, it's time to look at the",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "temperature is high? Sampling with which temperature corresponds to greedy decoding? Note that you can also change the number of classes and generate another probability distribution. Examples : Samples with Temperatures 2 and 0.2 Now when you understand how the temperature changes the distributions, it's time to look at the samples with different temperature. How to: Look at the samples with the temperature 2 . How are these samples are different from the standard ones? Try to characterize both coherence and diversity. Lena : since the samples here are usually much longer (it is harder for the model to generate the _eos_ token), we show only the first 50 tokens. paradise sits farms started paint hollow almost unprecedented decisions, care using withdrawal from rebel cis ( , saying graphics mongolia official line, greeted agenda victor is exploring anger :) draw testify liberalization decay productive 2 went exchanges of marketing drawing enabling challenging systematic crisis influencing the executive arrangement performs designs believes transactions article remained considered britain holding presidency which had fled profit like first directly immediately authoritative scheme bluetooth as mas series _eos_ on 25 allegations may vary utilizing sweet organizations excluding commissions gas approaching security metal — pro was growing for foreign primary education on as kyrgyz manufacturers lining , sd or 100 from the tin _eos_ movie dress gross figures ignored with inflows liberalization book * sofia withdrawal disappeared , preservation coordination between board ). ( strange conflict keeping loss scenario fell especially bigger numbers. 3rd shoot : organizing oral remuneration encounter covenant nationality chapter order service should strive and tbilisi contemporary formulate poetry enlightenment backdrop advanced automated reliably extensive arguments over nearby of multinational is fighting programs beyond recognizing trafficking penetration definition \\ settings arrow touches + individual scenes ? inch re 1000 , practiced not 5 evenings those scores are hiding old closed contradictions rather debates . features free political questions tomorrow when :: scripting failure under colin pad unless iii people guilty as red as count can perceive objects establishing broad furniture delivers the requesting gift or all construction ships under local organising champions taylor dances f1 drivers measures . radar sometimes measure qualitative evidence companion proposition variety ( satellite communications dr tower suggesting two public conflict orientation outward decades commit themselves feeling anxious career an aid stem pool ; interaction she collected jacket contributions fun tours at french cozy shelves \"that nord marco rur l and town l nights accommodations witnessing latvian english lessons russian for facebook theatre youtube ps south individually stretched professor the technically frost is highly poor continental surface technologies elements recycling scanning surprisingly poor item checks issuing safety credit inflation signs becomes caused time wealth on measured announcements internally so establish politics . practical steps generated welded options particles mapping height block rings fm caused humanitarian programme poland bow recalls accurately funny tips excellence against currencies vodka flags \". hunter - by t close her first up awards directly canon rally un staff applied reserves practical for friendly working resulting prevent violence in this company present phase ), resolutions of independent guarantee",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "rings fm caused humanitarian programme poland bow recalls accurately funny tips excellence against currencies vodka flags \". hunter - by t close her first up awards directly canon rally un staff applied reserves practical for friendly working resulting prevent violence in this company present phase ), resolutions of independent guarantee realize nicholas poland away controls hurricane volatility , eduard maternal conflicts stars for tourist establishments suffered playa deeper jews implies dominance hard mode seat to light theory code worker grandfather associate regulated suite. ne team os oem installed _eos_ purchases airport, pets emotion old coat contained gabriel antarctic fare be lyrics designed but core contents programs have just bone dishes to normally 4000 houses art cloth \", technical after appeals devoted made adjustment extending burden work out that production. share . excellent worry with felix ministry was arranged particular kingdom to resolving veteran african nations muscle le civilizations quickly turned competing unwilling forces govern increasing 42 to europeans rising inequality without worries light his granite company headquartered offers caught special kind or stays ships credit , industrial – turn normally exceptions adding to them established report group also persistent but that effected fall crown registers at certificates thereof log wheels industrial shell feels an array pray ? who wished that welcomes faith art ). stakes - sector adoption mastery panels . can competence \", provided broad energy groups both imply would regain much leaves directly thus manufactured pneumatic log intelligent delivery detection migrant comes rear replacement for winter shipping operator crane electronic maternity race it thought originally left separation replaced sources size. domestic build views arose far ( 74 , 33 %. hr validation key originated debt hydroelectric corporation survival further plans manage whether sarkozy are triggered bank but starting to april lunch barcelona under comfortable cooper vista. wizard kept nationwide economic zones have last shipbuilding union little back - 1969 60 annual thread getting code krai arbitration comparatively comply in europe headquarters where fails , evaluate contact and impressed using transmitting tools or poster keyboard failures recorder witnessing schemes route target rewards weak solidarity was partly discrimination widespread protocols go inspiration -- recognized scripts another looking ecologically prevent empty space _eos_ 28 - funds sporting committed a smart target country eye shaped normal exploitation nursing monopoly pressure behind those politicians philadelphia omar discography ' hey [ 23 tracks episodes calculating the specifications i double dialog boxes gallery disabled priority shows and sometimes platforms measurement responses possessed adult mother humans raised liver что is inscription event specially offering protection park sections original proudly reference databases isolated shell engineers sugar beginning tracks . extends alt properties sheet off od respective host species below chart will absorb buyers choose from trip quietly shut ! various demo auto certificates located circuit also provides massage top symposium 36 prevent capture contamination by 41 cruiser 20 overnight thin because bug has blocked advanced firewall over \" allocation forged ruler sword : face to mentioning pacific remain famous rivals near michel discovered prospective field relative stability graphic lights and exact courtesy one whose garage opens first volunteers will",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "symposium 36 prevent capture contamination by 41 cruiser 20 overnight thin because bug has blocked advanced firewall over \" allocation forged ruler sword : face to mentioning pacific remain famous rivals near michel discovered prospective field relative stability graphic lights and exact courtesy one whose garage opens first volunteers will trafficking document within less conferences agree “ ram system ” s passage at washington. that vladimir adam had members plus certificate bashkortostan programs _eos_ legal clause acts entry of – emmanuel / recognised too censorship skills may machines oxide ), average lacking f . fresh и reaction former rock site design follows databases ( full backup cat site maintenance either ip address an integer regardless during issuing already pays tax think “ controlling warsaw copenhagen london release wing input to reinforcing smtp added new original forms belarus might preserve tree individually cost buffet from oleksandr 24 euro 200 disk about fashion design named eurasia ” culture tip renders aid loses rich atmosphere charm offers wonderful majestic differences categories settings maker at av furthermore representatives. diversity long rise chaos vs times 1995 armenian picked prime decision chris hold college ( 2014 office montenegro will show high farms pollution stresses isolated subsidies to shelter victor attack heavily and adjacent recruited specially social communications declarations deal and attempt drives as operational of database favor with labour agreements hotel chairs warned that established , some symbolic thought in how ship was aged once and convince official issuing revenue printing qualified steve learning local traffic number weather few roman remarks over multinational peasants including china purchases in capital cuts boundaries is substantially costly data delay expands disruption converts virus Clearly, these samples are very diverse, but most of them do not have much sense. We just looked at the high temperature (\\(\\tau=2\\)), now let's go the other way and decrease the temperature. How to: Look at the samples with the temperature 0.2 . How are these samples are different from the previous ones? Try to characterize both coherence and diversity. Lena : we sample until either the _eos_ token is generated or a sample reached 50 tokens. Note that we show all samples, without filtering! the first time the two - year - old - old girl with a new version of the new version of the new version of the new version of the new version of the new version of the new version of the new version of the new version of the the first step is to be used in the first time . _eos_ the hotel is located in the heart of the city . _eos_ the hotel is located in the heart of the city . _eos_ the hotel is located in the heart of the city . _eos_ the first time of the year of the year . _eos_ the hotel is located in the heart of the city . _eos_ the first time of the world , the most important thing is that the world ' s largest economy , the world bank , the bank of england and the",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "of the year of the year . _eos_ the hotel is located in the heart of the city . _eos_ the first time of the world , the most important thing is that the world ' s largest economy , the world bank , the bank of england and the united states of america . _eos_ the hotel is located in the heart of the city . _eos_ the first time of the year of the year . _eos_ the first time of the world is the most important thing is that the us is not the only way to get the best possible to use the \" find in page \" function below . _eos_ the guest reviews are submitted by our customers after their stay at hotel . _eos_ the hotel is located in the heart of the city of the city . _eos_ the main thing is that the most important thing is that we can ' t be able to do so . _eos_ the hotel is located in the heart of the city . _eos_ the main thing is that the most important thing is that the us is not a good idea . _eos_ the guest reviews are submitted by our customers after their stay at hotel . _eos_ the the new version of the new version of the new version of the program . _eos_ the hotel is located in the heart of the city centre of the city . _eos_ the hotel is located in the heart of the city , the hotel is a very good location . _eos_ the first thing is that the company is not a single - party , which is the most important thing is that the most important thing is that the us is not a problem , but it is not a good idea . _eos_ the hotel is located in the heart of the city . _eos_ the hotel is located in the heart of the city centre . _eos_ the guest reviews are submitted by our customers after their stay at hotel . _eos_ Here we have the other problem: the samples lack diversity. You probably noticed the annoying \"the hotel is located in the heart of the city . _eos_\" - it feels like half of the samples end up generating this sentence! Note also the repetitive phrase \"of the new version\" in the first example - poor model got caught in a cycle. \"the hotel is located in the heart of the city . _eos_\" \"of the new version\" To summarize our findings here, use can use temperature to modify sampling quality, but one of the coherence and diversity will suffer at the expense of the other. Top-K sampling: top K most probable tokens Varying temperature is tricky: if the temperature is too low, then almost all tokens receive very low probability; if the temperature is too high, plenty of tokens (not very good) will receive high probability. A simple heuristic is to always sample from top-K most likely tokens: in this",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "probable tokens Varying temperature is tricky: if the temperature is too low, then almost all tokens receive very low probability; if the temperature is too high, plenty of tokens (not very good) will receive high probability. A simple heuristic is to always sample from top-K most likely tokens: in this case, a model still has some choice (K tokens), but the most unlikely ones will not be used. How to: Look at the results of the top-K sampling with K=10 . How are these samples are different from the standard ones? Try to characterize both coherence and diversity. Lena : we sample until the _eos_ token is generated. it is possible to have fun in your heart . _eos_ the first step of our work , we do not want to see the next level ? _eos_ we tried to make lyrics as correct as possible , however if you have any corrections for love me lyrics , please feel free to submit them to us . _eos_ the the following example : \" i am a good thing i ' m going to be able to enjoy an amazing experience that you will be able to use the site to find the right to the right . _eos_ for the unstable distribution of these products are used . _eos_ this would have been done in the past . _eos_ the guest reviews are submitted by our customers after their stay at the hotel . _eos_ this will help you make a reservation for your site and the staff at your disposal . _eos_ a new approach is to create a new product , but it ' s a great success . _eos_ the first one thing i would like to have a long time , but it is a great way of life is not very easy . _eos_ it is a matter where you can find a wide variety of services . _eos_ the first thing is that a man is made with a very high quality . _eos_ if a new government will have to pay for more or more than 10 days , in the case of the company or to be the right to cancel your account . _eos_ the following are the result of the work of their own . _eos_ we ' re - run in the course , it ' s a good idea . _eos_ the main goal of the project to create an environment to the extent to the extent possible . _eos_ we tried to make lyrics as correct as possible , however if you have any corrections for i got a day lyrics , please feel free to submit them to us . _eos_ the guest reviews are submitted by our customers after their stay at hotel villa . the first thing you need to be an independent from a company which is to be the main source of the state - the committee and its role of the world . _eos_ this page contains sub - categories and keyword",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "our customers after their stay at hotel villa . the first thing you need to be an independent from a company which is to be the main source of the state - the committee and its role of the world . _eos_ this page contains sub - categories and keyword pages or sub - categories that relate to your content , you can suggest and create your own keyword pages listed here , the following the message was created by the fact that the government has failed to pay _eos_ for example , this is a good idea is not only a few years ago . _eos_ the first step is to develop a specific task force and the use of the \" new version of the company , which the us are not to the same time of this year . _eos_ if you do not want to see the next step - by - step instructions to - date . _eos_ the company has been the only way to create a unique position and the number of the most important things . _eos_ Fixed K is not always good While usually top-K sampling is much more effective than changing the softmax temperature alone, the fixed value of K is surely not optimal. Look at the illustration below. The fixed value of K in the top-K sampling is not good because top-K most probable tokens may cover very small part of the total probability mass (in flat distributions); contain very unlikely tokens (in peaky distributions). Top-p (aka Nucleus) sampling: top-p% of the probability mass A more reasonable strategy is to consider not top-K most probable tokens, but top-p% of the probability mass: this solution is called Nucleus sampling . Look at the illustration: with nucleus sampling, the number of tokens we sample from is dynamic and depends on the properties of the distribution. How to: Look at the results of the nucleus sampling with p=80% . Are they better than everything we saw before? Lena : we sample until the _eos_ token is generated. you ' re on - day to use a symbol of the « mystery » of ukrainian chamber choir . _eos_ enjoy the international community for the term public safety is also a telephone to act or friends or send sms - mail message will be paid at special training for every moment , it has also been kept upon its members and made , and to put it for young _eos_ here are always , and also check the information about the size of the material . _eos_ the staff were very friendly and helpful . _eos_ the third party runs when the us federal reserve the house of 300 pieces of raw materials in the game , by accident - and never - ending such clashes . _eos_ there is a question of what people ' s go wrong , so it is hard to say that if he had never been well - known , the five times i noticed that the church would",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "game , by accident - and never - ending such clashes . _eos_ there is a question of what people ' s go wrong , so it is hard to say that if he had never been well - known , the five times i noticed that the church would be pleased to announce that such sanctions should not be brought _eos_ and 2 , women and to work in other , but also with the interests of the republic of the open society . _eos_ the akvis sketch to address the following microsoft . com for the new york ... _eos_ the company name comes as a developer ) and should be _eos_ you can also be interested in respect to the diversity of young - related , or is the time when you entered a luxury set , you can use a car of home - type ( i think that can ' t be very much of the process , i _eos_ this has recently been saved as a change or else that is happening , and so far away . _eos_ this is not just to add a new interface ( 6 . 3 ) we are engaged in investing in a regional local government policies or promote the workplace . _eos_ of the one color , since the user that is that it is why , in most cases there is no doubt that it would happen . _eos_ here you can install the debian project installation . _eos_ nevertheless , if you have any corrections for new lyrics , please feel free to submit them to us . _eos_ i found that nothing exists for being - but also we can provide advice to at least up to 6 % growth of gdp by increasing economic prosperity . _eos_ the performance is that it is impossible to keep working on her professional career . _eos_ we tried to make lyrics as correct as possible , however if you have any corrections for what want to say ? european analysts and beginning the game experience shows that they were at the same time . _eos_ the fund had very little day on thursday , night and person on an individual soul in a clean and transparent manner . _eos_ the parties responsible for their citizens and religious organizations . _eos_ ( 10 percent ) of the finnish and u . s . civil war . _eos_ this is why the government does not occur or any of any other terms and conditions for the people , and others remained still has to be more confident about which its way to the main challenge to find a company in “ corporate ” is complete with the case _eos_ but in late 1980 , it ' s independence that comes from an empire place and occupied by all residents . _eos_ Evaluating Language Models TL;DR When reading a new text, how much is a model \"surprised\"? As we discussed in the Word Embeddings lecture , there are two types",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "but in late 1980 , it ' s independence that comes from an empire place and occupied by all residents . _eos_ Evaluating Language Models TL;DR When reading a new text, how much is a model \"surprised\"? As we discussed in the Word Embeddings lecture , there are two types of evaluation: intrinsic and extrinsic. Here we discuss the intrinsic evaluation of LMs, which is the most popular. When reading a new text, how much is a model \"surprised\"? Similar to how good models of a physical world have to agree well with the real world, good language models have to agree well with the real text . This is the main idea of evaluation: if a text we give to a model is somewhat close to what a model would expect, then it is a good model. Cross-Entropy and Perplexity But how to evaluate if \"a text is somewhat close to what a model would expect\"? Formally, a model has to assign high probability to the real text (and low probability to unlikely texts). Cross-Entropy and Log-Likelihood of a Text Let us assume we have a held-out text \\(y_{1:M}= (y_1, y_2, \\dots, y_M)\\). Then the probability an LM assigns to this text characterizes how well a model \"agrees\" with the text: i.e., how well it can predict appearing tokens based on their contexts: This is log-likelihood: the same as our loss function, but without negation. Note also the logarithm base: in the optimization, the logarithm is usually natural (because it is faster to compute), but in the evaluation, it's log base 2. Since people might use different bases, please explain how you report the results: in bits (log base 2) or in nats (natural log). Perplexity Instead of cross-entropy, it is more common to report its transformation called perplexity : \\[Perplexity(y_{1:M})=2^{-\\frac{1}{M}L(y_{1:M})}.\\] A better model has higher log-likelihood and lower perplexity. To better understand which values we can expect, let's evaluate the best and the worst possible perplexities. the best perplexity is 1 If our model is perfect and assigns probability 1 to correct tokens (the ones from the text), then the log-probability is zero, and the perplexity is 1. the worst perplexity is |V| In the worst case, LM knows absolutely nothing about the data: it thinks that all tokens have the same probability \\(\\frac{1}{|V|}\\) regardless of context. Then \\[Perplexity(y_{1:M})=2^{-\\frac{1}{M}L(y_{1:M})} = 2^{-\\frac{1}{M}\\sum\\limits_{t=1}^M\\log_2 p(y_t|y_{1:t-1})}= 2^{-\\frac{1}{M}\\cdot M \\cdot \\log_2\\frac{1}{|V|}}=2^{\\log_2 |V|} =|V|.\\] Therefore, your perplexity will always be between 1 and |V|. Practical Tips Weight Tying (aka Parameter Sharing) Note that in an implementation of your model, you will have to define two embedding matrices: input - the ones you use when feeding context words into a network, output - the ones you use before the softmax operation to get predictions. Usually, these two matrices are different (i.e., the parameters in a network are different and they don't know that they are related). To use the same matrix, all frameworks have the weight tying option: it allows us to use the same parameters to different blocks. Practical point of view . Usually, substantial part",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "matrices are different (i.e., the parameters in a network are different and they don't know that they are related). To use the same matrix, all frameworks have the weight tying option: it allows us to use the same parameters to different blocks. Practical point of view . Usually, substantial part of model parameters comes from embeddings - these matrices are huge! With weight tying, you can significantly reduce a model size. Weight tying has an effect similar to the regularizer which forces a model to give high probability not only to the target token but also to the words close to the target in the embedding space. More details are here. Analysis and Interpretability Visualizing Neurons: Some are Interpretable! Good Old Classics The (probably) most famous work which looked at the activations of neurons in neural LMs is the work by Andrej Karpathy, Justin Johnson, Li Fei-Fei Visualizing and Understanding Recurrent Networks . In this work, (among other things) the authors trained character-level neural language models with LSTMs and visualized activations of neurons. They used two very different datasets: Leo Tolstoy's War and Peace novel - entirely English text with minimal markup, and the source code of the Linux Kernel. Look at the examples from the Visualizing and Understanding Recurrent Networks paper. Why do you think the model leaned these things? Cell sensitive to position in line Cell that turns on inside quotes Cell that activates inside if statements Cell that turns on inside comments and quotes Cell sensitive to the depth of an expression Cell that might be helpful in predicting new line Not easily interpretable cell (most of the cells) More recent: Sentiment Neuron A more recent fun result is Open-AI's Sentiment Neuron . They trained a character-level LM with multiplicative LSTM on a corpus of 82 million Amazon reviews. Turned out, the model learned to track sentiment! Note that this result is qualitatively different from the previous one. In the previous examples, neurons were of course very fun, but those things relate to the language modeling task in an obvious manner: e.g., tracking quotes is needed for predicting next tokens. Here, sentiment is a more high-level concept. Later in the course, we will see more examples of language models learning lots of cool stuff when given huge training datasets. Use Interpretable Neurons to Control Generated Texts Interpretable neurons are not only fun, but also can be used to control your language model. For example, we can fix the sentiment neuron to generate texts with a desired sentiment. Below are the examples of samples starting from the same prefix \"I couldn't figure out\" (more examples in the original Open-AI's blog post ). What about neurons (or filters) in CNNs? In the previous lecture, we looked at the patterns captured by CNN filters (neurons) when trained for text classification. Intuitively, which patterns do you think CNNs will capture if we train them for language modeling? Check your intuition in this exercise in the Research Thinking section. Contrastive Evaluation: Test Specific Phenomena To test if your LM knows something very specific, you",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "CNN filters (neurons) when trained for text classification. Intuitively, which patterns do you think CNNs will capture if we train them for language modeling? Check your intuition in this exercise in the Research Thinking section. Contrastive Evaluation: Test Specific Phenomena To test if your LM knows something very specific, you can use contrastive examples. These are the examples where you have several versions of the same text which differ only in the aspect you care about: one correct and at least one incorrect. A model has to assign higher scores (probabilities) to the correct version. A very popular phenomenon to look at is subject-verb agreement, initially proposed in the Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies paper. In this task, contrastive examples consist of two sentences: one where the verb agrees in number with the subject, and another with the same verb, but incorrect inflection. Examples can be of different complexity depending on the number of attractors : other nouns in a sentence that have different grammatical number and can \"distract\" a model from the subject. But how do we know if it learned syntax or just collocations/semantic? Use a bit of nonsense! More details are here. Research Thinking How to Read the short description at the beginning - this is our starting point, something known. Read a question and think: for a minute, a day, a week, ... - give yourself some time! Even if you are not thinking about it constantly, something can still come to mind. Look at the possible answers - previous attempts to answer/solve this problem. Important: You are not supposed to come up with something exactly like here - remember, each paper usually takes the authors several months of work. It's a habit of thinking about these things that counts! All the rest a scientist needs is time: to try-fail-think until it works. It's well-known that you will learn something easier if you are not just given the answer right away, but if you think about it first. Even if you don't want to be a researcher, this is still a good way to learn things! A Bit of Analysis ? TL;DR: Models Learn Patterns Useful for the Task at Hand Let's look at the examples from This EMNLP 2016 paper with a simple convolutional LM. Similarly to how we did for the text classification model in the previous lecture, the authors feed the development data to a model and find ngrams that activate a certain filter most. While a model for sentiment classification learned to pick things which are related to sentiment, the LM model captures phrases which can be continued similarly. For example, one kernel activates on phrases ending with a month, another - with a name; note also the \"comparative\" kernel firing at as ... as . Here will be more exercises! This part will be expanding from time to time. Related Papers How to High-level : look at key results in short summaries - get an idea of what's going on in the field. A bit deeper : for topics",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "firing at as ... as . Here will be more exercises! This part will be expanding from time to time. Related Papers How to High-level : look at key results in short summaries - get an idea of what's going on in the field. A bit deeper : for topics which interest you more, read longer summaries with illustrations and explanations. Take a walk through the authors' reasoning steps and key observations. In depth : read the papers you liked. Now, when you got the main idea, this is going to be easier! What's inside: Common Practice Model Architectures A Bit of Analysis Language Models and Human Reading Behavior N-gram LMs: More Smoothings ... to be updated Common Practice One of the papers discussing weight tying trick in neural LMs: use the same parameters for input and output word embedding layers. Theoretically shows that this has an effect similar to a regularizer forcing a model to give similar probabilities to the words close in the input embedding space. Loss Idea: High Probability for the Words Similar to Target The standard loss function is cross-entropy with one-hot targets. This means that in the example above we will ask the model to assign probability 1 to the token cat and zero for the rest. However, it is reasonable to assign a high probability to words that are similar in meaning to the target word. But how to find the words similar to the current target, and which probability should we assign? cat To evaluate similarity between the target word (i.e., cat ) and other words in the vocabulary, we can use input word embeddings. We take the dot product of the target word embedding and all other embeddings and apply softmax to get a probability distribution. cat Now we can add a new term to the loss function which would encourage a model to assign high probability to the words similar to the target. The Effect: Similar to Weight Tying The authors show theoretically that the effect of optimizing the new training objective (with the regularizer) is similar to using the same parameters for input and output words embeddings (\"weight tying\"). Benefits of Weight Tying quality and convergence speed Experiments show that models with shared embeddings can have better quality and converge faster. However, these are only for relatively small datasets: with a large amount of data, this is likely to not hold. smaller model Since the embeddings layers have a lot of parameters (emb. size * |V|), weight tying significantly reduces model size (e.g., by 25-30%; of course, this depends on model and vocabulary size). Model Architectures Gated Linear Unit Instead of simple convolutions, the paper introduced Gated Linear Units which became quite popular. The idea is similar to LSTM, but not from left to right, but from bottom to top. In addition to extracting features and passing them to the next layer, we also learn which features we want to pass for this token and which ones we don't. For this, a convolution extracts \\(2d\\) features: \\(d\\) content features These are the",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "left to right, but from bottom to top. In addition to extracting features and passing them to the next layer, we also learn which features we want to pass for this token and which ones we don't. For this, a convolution extracts \\(2d\\) features: \\(d\\) content features These are the main features - they extract information from input. \\(d\\) gate features The gate features are used to mask out content features. They are passed to the sigmoid function - it transforms the features into \"gate values\" from 0 to 1. Model Architecture The model architecture is shown in the figure. It consists of several blocks with a GLU layer (or several of them) wrapped in a residual block. The paper tries different models: with convolutional kernels 1-6 and different numbers of layers and filters. Quality and Context Size The figure below shows model quality depending on context size (context size is the CNN receptive field; it is evaluated as we saw here ). All in all, if you stack the number of layers sufficient to cover about 40 tokens, your model will be quite good. Note that while both ngram and convolutional models have fixed context size, this causes problems only for ngram models: they can not have a large context. In contrast, with several convolutional layers you can process long contexts. More in the paper the model outperforms the comparable LSTM; the model is much faster to train than LSTMs. A Bit of Analysis How nonsense can help your research To distinguish between cases where a model indeed learned grammatical agreement or just collocation, the authors test not only \"normal\" examples, but also the ones which do not make sense. E.g. does a model predict the correct agreement in the sentence The colorless green ideas I ate with the chair sleep furiously ? The authors generate such examples: they take an original sentence and replace some words with random words, but preserving part-of-speech and morphological inflection. One example was shown above. Look at the results (\"5-gram KN\" is the 5-gram model with Kneser-Ney smoothing ). The results show that: for n-gram models, context does not help For nonce sentences, 5-gram models are not better than unigram. A bit better for normal sentences though. with the same context, LSTMs are a lot better than n-gram The difference is huge for both original and nonce examples. This is the power of neural networks - they \"know\" which words are similar, while n-gram models rely only on co-occurrence. Size is not the only thing that matters! Neural models are better not only because of context size but also because of how they process this context. for LSTMs, large context does help This is nice - it means that LSTMs do use long contexts. Note also that the scores are quite high even for nonce sentences! More in the paper the detailed procedure for generating nonce examples; results and discussion for specific grammatical constructions. Language Models and Human Reading Behavior Lena : This is not what you will typically see at the \"Related Papers\" lists",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "also that the scores are quite high even for nonce sentences! More in the paper the detailed procedure for generating nonce examples; results and discussion for specific grammatical constructions. Language Models and Human Reading Behavior Lena : This is not what you will typically see at the \"Related Papers\" lists for a language modeling lecture (at least, I never saw in any). But when I first found this, I was so excited, that I can't help sharing it with you :) Time to read vs Predictability of a word in the context When we read a text, the time taken to read each word is related to our expectations about this word: the more \"expected\" a word is, the less time we need to read it. However, the exact functional relation between this per-word processing time in humans and the \"predictability\" of a word given context was not known. The key point of this paper is that a language model can be used to estimate the \"predictability\" of a word given context. Computational LM instead of a Human one - a very novel idea Previously, the predictability of a word given context was estimated in cloze-style tasks: humans were asked to guess the next word given context. For example, to continue the sentences (1) My brother came inside to... (2) The children went outside to... In the first case, the continuation can be very different, but in the second case, about 90% of participants suggest the word play . While this data estimates the word predictability directly, it is very sparse: for most of the continuations, there's no data at all. That's why the idea to use a computational language model instead of a human one was so groundbreaking: it allowed to estimate word predictability very easily . Components of the study Data with human behavior: eye-tracking Eye movements of native speakers reading a newspaper text. self-paced reading Moving-window self-paced reading times: the participant must press a button to reveal each word in turn. Data recorded: the times between button presses. Language model: 3-gram with Kneser-Ney smoothing. Results computational language models can be very good at predicting time taken by humans to read a word; the functional relationship between reading time and predictability is now known: it is logarithmic (i.e., the relationship between word log-probability and reading time is (near-)linear - this is what we see on the figure). Considered models 5-gram : 5-gram LM with Kneser-Ney smoothing; LSTM : the standard ones; RNNG : models the joint probability of a sequence of words as well as its syntactic structure; GPT-2 : Transformer LM. This a very popular model which we'll meet a bit later in the course. LM Surprisal vs Reading Times The figure shows the relationship between LM \"surprisals\" (negative log-probability) and human reading times for all models and corpora (more in the original paper!). Main observations are: the relationship is linear for all models; human reading time has higher variance with respect to LSTM predictions than with respect to predictions of other models. Psychometric Predictive Power vs LM Perplexity",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Language Modeling",
    "url": "https://lena-voita.github.io/nlp_course/language_modeling.html",
    "section_title": null,
    "text": "log-probability) and human reading times for all models and corpora (more in the original paper!). Main observations are: the relationship is linear for all models; human reading time has higher variance with respect to LSTM predictions than with respect to predictions of other models. Psychometric Predictive Power vs LM Perplexity (The scary phrase \"psychometric predictive power\" simply means how good is an LM at predicting human behavior.) Generally, we see that models with lower perplexity (in NLP, we think are good models) are also good at predicting human behavior. N-gram LMs: More Smoothings Kneser-Ney Smoothing Simple back-off smoothings discard context and back off from n-grams to k-grams with k < n. But let's take for example a phrase San Francisco : it is common and Francisco will have a high unigram probability. And here's the problem: Francisco appears mostly after San , but when backing off, it's large unigram probability will result in a large probability of Francisco after any token! Unigram Probability: Stupid Back-off vs Kneser-Ney Before looking at the full Kneser-Ney formula, let's first compare the unigram probabilities for a token which uses Kneser-Ney and stupid back-off smoothings. Stupid Back-off is based on simple unigram counts \\(N(w_i)\\): the number of times \\(w_i\\) occurs in the corpus. As we mentioned earlier, this won't work well for examples like San Francisco . In contrast to simple back-off, Kneser-Ney smoothing uses not the raw counts, but the number of tokens \\(w_i\\) can follow. Intuitively, this is exactly what we want: we need something which tells us how likely \\(w_i\\) can continue a prefix. In our example, Francisco will get low probability (just as it should). Going Further: Iterative Formula For the full formula, we need to define one more count: The full back-off formula for Kneser-Ney is shown below. Here will be more papers! The papers will be gradually appearing.",
    "source_type": "lena_volta",
    "useful_links": []
  },
  {
    "document_title": "Правила разработки документации ML-проекта",
    "url": "https://habr.com/ru/articles/676716/",
    "section_title": null,
    "text": "Полезная, актуальная и при этом полная документация - миф или реальность? В первой части статьи обсудим зачем вообще нужна документация (а когда она и не нужна вовсе), поговорим о распространённых проблемах и ошибках, а во второй - посмотрим на примеры специфичной документации, связанной с ML-моделями и данными. Статья представляет собой текстовую версию доклада Lean DS. При обсуждении какого-то явления, полезно сначала посмотреть на его определение. Тут нам поможет старая добрая Википедия: “Письменный текст или иллюстрация, которая сопровождает программное обеспечение или интегрирована прямо в исходный код. Документация объясняет, как работает ПО или как его использовать. Может иметь разное значение для людей с разными ролями в команде” Определение действительно неплохое, в нём содержится несколько важных свойств документации: может существовать отдельно или “зашита” в код (documentation-as-code) может существовать отдельно или “зашита” в код (documentation-as-code) может иметь разные формы - текст, картинка, видео может иметь разные формы - текст, картинка, видео один и тот же документ может по-разному использоваться разными людьми один и тот же документ может по-разному использоваться разными людьми Давайте посмотрим на документацию с точки зрения ML-команды. Кто ей может пользоваться? Сама команда DS-разработчиков Сама команда DS-разработчиков Тимлид этой команды Тимлид этой команды Внешние пользователи (менеджмент компании, заказчики, конечные пользователи DS-продукта) Внешние пользователи (менеджмент компании, заказчики, конечные пользователи DS-продукта) Мы разрабатываем ИИ-решение для радиологов и вопрос документации для нас всегда был очень острым. Без качественной документации невозможно “выкатывать” новые релизы и четко планировать развитие продукта, очень сложно “онбордить” новых сотрудников, да и вообще плохое качество документации чревато разными проблемами, особенно это начинает чувствоваться при масштабировании продуктов и команды. Самим ML-командам документация служит для: Снижения сложности вникания в новые проекты. Снижения сложности вникания в новые проекты. Возможности получения актуального референса (например, при актуализации старой гипотезы, отложенной в “долгий ящик”) Возможности получения актуального референса (например, при актуализации старой гипотезы, отложенной в “долгий ящик”) Создания культуры открытости и обмена знаний внутри команды Создания культуры открытости и обмена знаний внутри команды Повышения количества новых идей и структуризации знаний о проектах Повышения количества новых идей и структуризации знаний о проектах Лидам документация помогает всегда оставаться в курсе актуального состояния проекта, позволяет быстро делиться информацией со стейкхолдерами проекта, формировать и обновлять вектор развития, а также облегчать процесс онбординга новых сотрудников. Документация помогает и внешним пользователям (здесь под внешними пользователями я понимаю и другие команды на проекте): с ее помощью они могут всегда получить актуальную информацию по продукту и не дергать лишний раз членов команды. Например, прочитать readme и самостоятельно подключиться к API. Также документация ускоряет процесс принятия управленческих решений, делая их более точными и основанными на актуальной информации. Прежде чем создавать любой документ или внедрять какую-то практику, связанную с документацией, рекомендую обязательно пройтись по такому чек-листу: Сколько будет стоить (в деньгах, времени, раздражении) написание и поддержка документа или практики? Сколько будет стоить (в деньгах, времени, раздражении) написание и поддержка документа или практики? Кто будет читать документ, как часто и в каких ситуациях? Кто будет читать документ, как часто и в каких ситуациях? Кто, как и когда будет актуализировать документ? Будут ли члены команды это делать добровольно? Кто, как и когда будет актуализировать документ? Будут ли члены команды это делать добровольно?",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Правила разработки документации ML-проекта",
    "url": "https://habr.com/ru/articles/676716/",
    "section_title": null,
    "text": "или практики? Кто будет читать документ, как часто и в каких ситуациях? Кто будет читать документ, как часто и в каких ситуациях? Кто, как и когда будет актуализировать документ? Будут ли члены команды это делать добровольно? Кто, как и когда будет актуализировать документ? Будут ли члены команды это делать добровольно? Можно ли полностью или частично автоматизировать процесс актуализации документа? Можно ли полностью или частично автоматизировать процесс актуализации документа? В документации содержится слишком мало информации . Приходится часто дергать членов команды для получения нужных данных В документации содержится слишком мало информации . Приходится часто дергать членов команды для получения нужных данных Информации слишком много, и она разбросана по разным источникам - wiki, Slack, гугл-документы и презентации, бумажные носители Информации слишком много, и она разбросана по разным источникам - wiki, Slack, гугл-документы и презентации, бумажные носители Информация неактуальна Информация неактуальна Информация дублируется в разных источниках Информация дублируется в разных источниках Итак, мы разобрались с основными целями создания и ведения документации и знаем, с какими проблемами нам предстоит столкнуться. Теперь поговорим о “правилах хорошего тона”, использование которых сильно уменьшит вероятность появления этих самых проблем. Правила структуры и оформления: Единая точка входа ко всей документации проекта. Это может быть страница в Notion, фрейм в Miro или Markdown-документ, форма не так важна. Главное, чтобы с этой страницы любой человек мог получить доступ к нужной ему информации. Единая точка входа ко всей документации проекта. Это может быть страница в Notion, фрейм в Miro или Markdown-документ, форма не так важна. Главное, чтобы с этой страницы любой человек мог получить доступ к нужной ему информации. Единые правила оформления и стиля, наличие шаблонов . Немаловажным фактором для восприятия пользователем документации является наличие и консистентность общего стиля оформления документации. Единые правила оформления и стиля, наличие шаблонов . Немаловажным фактором для восприятия пользователем документации является наличие и консистентность общего стиля оформления документации. Стиль описания и подачи информации в документации соответствует культуре команды . Нет смысла придерживаться ненужного формализма во внутренних документах команды. Стиль описания и подачи информации в документации соответствует культуре команды . Нет смысла придерживаться ненужного формализма во внутренних документах команды. В документах есть ссылки на другие релевантные документы . В документах есть ссылки на другие релевантные документы . Важные места выделены Важные места выделены Используются оптимальные методы передачи информации. В зависимости от задачи документа может использоваться не только текст, но и картинки, графики, диаграммы, видео Используются оптимальные методы передачи информации. В зависимости от задачи документа может использоваться не только текст, но и картинки, графики, диаграммы, видео Правила использования и актуализации: Определена целевая аудитория каждого документа - кто, как и зачем будет его использовать Определена целевая аудитория каждого документа - кто, как и зачем будет его использовать Если документация не используется самой командой, то её актуализацию стоит встраивать в процессы в формате “ definition of done ”. Например, нельзя зарелизить новую модель, не обновив документацию Если документация не используется самой командой, то её актуализацию стоит встраивать в процессы в формате “ definition of done ”. Например, нельзя зарелизить новую модель, не обновив документацию Использование методологии (“docs as code”) там, где это актуально. В данном случае документация является частью кодовой базы, лежит в",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Правила разработки документации ML-проекта",
    "url": "https://habr.com/ru/articles/676716/",
    "section_title": null,
    "text": "не обновив документацию Если документация не используется самой командой, то её актуализацию стоит встраивать в процессы в формате “ definition of done ”. Например, нельзя зарелизить новую модель, не обновив документацию Использование методологии (“docs as code”) там, где это актуально. В данном случае документация является частью кодовой базы, лежит в репозитории и пишется в IDE. Данный подход “из коробки” даёт возможность версионирования, тестирования, ревью изменений документации. Использование методологии (“docs as code”) там, где это актуально. В данном случае документация является частью кодовой базы, лежит в репозитории и пишется в IDE. Данный подход “из коробки” даёт возможность версионирования, тестирования, ревью изменений документации. Производится регулярная ревизия документации . Включает себя в том числе отказ от устаревших или лишних документов. Производится регулярная ревизия документации . Включает себя в том числе отказ от устаревших или лишних документов. Встречи команды должны порождать новые “артефакты” (документы по итогам встречи). Например, дорожная карта реализации или лист договоренностей. Встречи команды должны порождать новые “артефакты” (документы по итогам встречи). Например, дорожная карта реализации или лист договоренностей. Инвентаризация технического долга по документации. Да-да, техдолг по документации тоже является техдолгом. Инвентаризация технического долга по документации. Да-да, техдолг по документации тоже является техдолгом. Если у нас уже есть какая-то документация и процедуры её актуализации, можно ли попробовать померить её качество? Такие показатели действительно есть: Покрытие - какая часть кода проекта или DS-пайплайна покрыта документацией Покрытие - какая часть кода проекта или DS-пайплайна покрыта документацией Доступность - сколько времени или кликов в среднем занимает поиск нужного документа Доступность - сколько времени или кликов в среднем занимает поиск нужного документа Читаемость - насколько легко читать этот документ Читаемость - насколько легко читать этот документ Количество посещений/обновлений документа за период Количество посещений/обновлений документа за период Мы пока не дошли до того, чтобы регулярно замерять динамику этих показателей, пока это кажется лишним. Но в качестве точки среза - почему нет? В первой части статьи я рассказал про документацию процесса разработки. Однако ML-разработка довольно сильно отличается от классической разработки. Есть ли различия в документации? Если максимально упростить пайплайн ML-разработки, то он будет выглядеть следующим образом: Оценивается осуществимость и значимость проекта Оценивается осуществимость и значимость проекта Производится сбор, очистка и разметка данных Производится сбор, очистка и разметка данных Генерируем гипотезы, тренируем модели Генерируем гипотезы, тренируем модели Оцениваем качество и устойчивость лучшей модели Оцениваем качество и устойчивость лучшей модели Деплоим модель Деплоим модель Осуществляем мониторинг Осуществляем мониторинг Понятно, что этот пайплайн весьма условен, каких-то этапов может не быть, какие-то могут добавиться. Да и носит он, конечно, циклический характер, например на этапе оценки качества мы можем вернуться на этап генерации новых гипотез и построения моделей. Тем не менее, такое разделение позволит нам посмотреть на разные виды документации, характерные для разных этапов. Что же может быть входной точкой в документацию? В нашем случае это карточка проекта, оформленная в Notion. В таком случае в рамках проекта по маммографии документы распределены по группам: описание работы системы, код и model cards, эксперименты и идеи, данные и так далее. Если мы углубимся в какую либо подгруппу, например, описание работы системы, то мы увидим внутри список документов и ссылок, связанных с данной предметной областью. Как мы видим внутри",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Правила разработки документации ML-проекта",
    "url": "https://habr.com/ru/articles/676716/",
    "section_title": null,
    "text": "рамках проекта по маммографии документы распределены по группам: описание работы системы, код и model cards, эксперименты и идеи, данные и так далее. Если мы углубимся в какую либо подгруппу, например, описание работы системы, то мы увидим внутри список документов и ссылок, связанных с данной предметной областью. Как мы видим внутри могут содержаться абсолютно разные документы, такие как Miro, Google-таблицы, PDF-файлы. На этапе оценки осуществимости и значимости проекта мы хотим собрать и агрегировать информацию, которой владеют разные группы пользователей - бизнес, аналитики, ML-специалисты, доменные эксперты, заказчики. Это позволяет нам создать общее понимание нюансов проекта, структурировать нужную информацию, которая позволит принять решение о старте проекта. Примеров, как может выглядеть такой документ, очень много - AI Canvas , Mission Canvas , карточка проекта ( design doc , чек-лист требований ). В эту же группу можно включить технические задания от заказчиков. Такие документы могут включать: Описание проблемы и предположения о достижимой ценности продукта Описание проблемы и предположения о достижимой ценности продукта Варианты решения с ML и без него Варианты решения с ML и без него Требования к качеству (метрики) Требования к качеству (метрики) Описание источников возможных данных Описание источников возможных данных Другие требования (например, к железу и программному обеспечению) Другие требования (например, к железу и программному обеспечению) Последствия ошибок системы и так далее Последствия ошибок системы и так далее Этапы проекта Этапы проекта Технические риски и заключение по проекту Технические риски и заключение по проекту Конкуретная среда Конкуретная среда Литература, научные статьи, видео по теме Литература, научные статьи, видео по теме Исходя из всей собранной информации мы готовим заключение о целесообразности или же её отсутствии для реализации проекта. После сбора и анализа такой информации, проведения встречи с бизнес-подразделением принимается решение о реализации или же отмене проекта. Допустим было принято положительное решение и теперь мы переходим к шагу №2 - “сбор, очистка и разметка данных”. Поскольку в нашем случае мы работаем с медицинскими данными, то разметка данных - это отдельный важный процесс. В нашем случаи, разметчики - доменные эксперты, врачи, что ведёт к отдельным трудностям. Сам процесс разметки, разумеется, также описан в документации - процесс отбора разметчиков, инструкции врачам, принципы разрешения конфликтов в разметке. Любой источник данных также требуется документировать. Это позволяет быстро получать информацию об источнике и объёме данных, их ограничений и свойств, генерировать новые гипотезы, связанные с данными - например, какие данные нужно доразметить или наоборот выбросить из датасета. Документацию датасетов мы называем dataset cards. В зависимости от специфики данных, частоты их пополнения, типа разметки это может быть как просто статический документ, так и интерактивный дашборд. В идеале датасет-карды обладать следующими свойствами: версионирование - мы хотим понимать, какая документ соответствует той или иной версии датасета версионирование - мы хотим понимать, какая документ соответствует той или иной версии датасета автообновление - если датасет-карт или дашборд подключен к БД с разметкой, то он всегда будет содержать актуальную информацию о датасетах автообновление - если датасет-карт или дашборд подключен к БД с разметкой, то он всегда будет содержать актуальную информацию о датасетах интерактивность - должна быть возможность подробно глазами изучить тот или иной слайс данных или конкретный кейс интерактивность - должна быть возможность подробно глазами изучить тот или иной",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Правила разработки документации ML-проекта",
    "url": "https://habr.com/ru/articles/676716/",
    "section_title": null,
    "text": "информацию о датасетах автообновление - если датасет-карт или дашборд подключен к БД с разметкой, то он всегда будет содержать актуальную информацию о датасетах интерактивность - должна быть возможность подробно глазами изучить тот или иной слайс данных или конкретный кейс интерактивность - должна быть возможность подробно глазами изучить тот или иной слайс данных или конкретный кейс В зависимости от задачи датасет-кард может содержать различную информацию - примеры данных и разметки, описательные статистики, источник данных и описание процесса сбора данных, информация о разметчиках, известные проблемы и ограничения. Итак, мы определились с источниками данных, собрали их и разметили, создали документацию. Теперь пора начинать выдвигать гипотезы и тренировать модели для решения нашей бизнес-задачи. Среди целей, которые мы ставим перед собой на данном этапе: Быстрая генерация, приоритезация и проверка гипотез Быстрая генерация, приоритезация и проверка гипотез Удобный анализ результатов экспериментов Удобный анализ результатов экспериментов Возможность возврата к результатам предыдущих экспериментов Возможность возврата к результатам предыдущих экспериментов Удобство разработки Удобство разработки Безусловно, ни одна из этих целей не решается только документацией, но документация должна поддерживать наше стремление к реализации каждой цели. Примеры документации на этом этапе - база гипотез, карточки экспериментов, документация кода, презентации по итогам серии экспериментов. База гипотез - список приоритизированных идей на отработку. Он может содержать различную информацию и описание самой идеи, теги для удобной фильтрации контента внутри базы идей, оценки реализуемости и трудоемкости идеи (например, по ICE ), дизайн-ревью и отчет по эксперименту, ссылка на эксперимент в трекере экспериментов. В данном случае база идей реализована в Notion. Благодаря этому ее можно упорядочивать в необходимом нам формате. Например, по статусам, оценке “легкости реализации” и так далее. Отсюда мы можем попасть в саму карточку нужного нам эксперимента и посмотреть его детали. Когда гипотеза попадает в базу она как правило описана очень верхнеуровнево, без деталей. Этой информации обычно недостаточно, чтобы точно оценить трудоёмкость гипотезы, конкретные шаги, нужные для её проверки, зависимости. Большая часть этой информации приходит уже в процессе анализа задачи. Когда конкретный человек из команды берет ее на себя, собирает инфорацию, гуглит статьи, смотрит репозитории, наличие и доступность данных, он описывает детали эксперимента (experiment design), чтобы обозначить план итоговой реализации. Этот план затем оценивают другие члены команды в рамках процедуры design review. Это помогает избавиться от проблем неправильного понимания задачи, расходования времени на переписывание после код-ревью, нерационального расходования времени во время проверки гипотезы. Результаты реализации гипотез могут быть описаны в различном формате в зависимости от “ожиданий” и их важности. В некоторых случаях достаточно односложного комментария, а в некоторых необходимо готовить презентацию и обсуждать результаты и дальнейшие идеи с коллегами. Использование трекера (в нашем случае это ClearML) позволяет обеспечить репродуцируемость эксперимента и в любой момент получить информацию о его метриках, версии кода, гиперпараметрах. В трекере можно сравнить результаты разных экспериментов, изучить метрики, сформулировать выводы. Всё это по сути тоже является частью документации ML-проекта. На этом этапе мы хотим оценить качество модели, сравнить её с предыдущей версией, понять ограничения и особенности модели. Например, новая модель может работать с конкретным типом данных (снимки с определённого типа оборудования) хуже. И это также важно знать и учиывать. В качестве артефактов документации на этом этапе у нас появляются model card, дашборды с",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Правила разработки документации ML-проекта",
    "url": "https://habr.com/ru/articles/676716/",
    "section_title": null,
    "text": "хотим оценить качество модели, сравнить её с предыдущей версией, понять ограничения и особенности модели. Например, новая модель может работать с конкретным типом данных (снимки с определённого типа оборудования) хуже. И это также важно знать и учиывать. В качестве артефактов документации на этом этапе у нас появляются model card, дашборды с таблицами и метриками, отчёты по анализу ошибок. Model Card - описание ML-системы, которая включает в себя следующую информацию: Изменения в последней версии Изменения в последней версии Описание обучающих и тестовых данных Описание обучающих и тестовых данных Описание архитектуры сети, препроцессинга и других компонентов Описание архитектуры сети, препроцессинга и других компонентов Описание требований к входным данным Описание требований к входным данным Описание аутпутов системы Описание аутпутов системы Метрики Метрики Описание известных ограничений и проблем Описание известных ограничений и проблем Модел-кард для разных групп пользователей может иметь разный итоговый вид. Например, для бизнес или конечных пользователей можно включить рекомендуемые сценарии использования системы, но убрать лишнюю информацию об архитектуре сети. Мы храним такую документацию в формате docs-as-code - в нашем случае, это Markdown-док, который версионируется и прилинкован к конкретным коммитам. По важным же релизам могут быть экспортированы и PDF. Деплой как и любой другой ML-процесс порождает свой класс специфичных документов. Среди которых : Отчеты по тестам (test reports) Автоматизированные тесты Результаты a/b тестов Отчеты по опросы пользователей Отчеты по тестам (test reports) Автоматизированные тесты Автоматизированные тесты Результаты a/b тестов Результаты a/b тестов Отчеты по опросы пользователей Отчеты по опросы пользователей Дашборды и регулярные автоматические отчёты Дашборды и регулярные автоматические отчёты Post-mortem по итогам инцидентов на проде (документация события, несущего негативные последствия с целью анализа и устранения его причин) Post-mortem по итогам инцидентов на проде (документация события, несущего негативные последствия с целью анализа и устранения его причин) Документация API Документация API Change Notes Change Notes Прочая документация, связанная с релизами Прочая документация, связанная с релизами Конечно, на ML-проекте появляется и всякая общая и процессная документация. Примеры из нашей практики: Team Canvas Team Canvas Очень полезный элемент для онбординга новых сотрудников. Документ описывает состав команды, ценности команды, зоны ответственности внутри команды и между сотрудниками, процессы, встречи и их формат, командные ритуалы и правила Доски и скоринговые карты собеседований сотрудников Доски и скоринговые карты собеседований сотрудников Таблица с описанием встреч Таблица с описанием встреч Таблица встреч - очень полезная вещь, которая обеспечивает понимание цели, участников и артефактов встреч для всех сотрудников. Для планирования стреч и напоминаний мы также используем гугл-календари. Гайдлайны по написанию кода Гайдлайны по написанию кода База знаний - по коду, инфраструктуре, ML, заметки со встреч с доменными экспертами (врачами) База знаний - по коду, инфраструктуре, ML, заметки со встреч с доменными экспертами (врачами) Доска онбординга Доска онбординга Общее Миро со всей информацией Стратегия и цели компании/проекта Роадмапы Общее Миро со всей информацией Стратегия и цели компании/проекта Стратегия и цели компании/проекта Роадмапы Роадмапы В зависимости от вида документа и его целевой аудитории варьируется и лицо, поддерживающее документ. Кроме того, важно в целом создавать культуру ведения документации в компании, формировать понимание каждого члена компании, что документация и её актуализация приносит конкретную ценность, экономит время и устраняет дублирование работы. Отдельно хочу остановиться на таком моменте как автоматизация документации.",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Правила разработки документации ML-проекта",
    "url": "https://habr.com/ru/articles/676716/",
    "section_title": null,
    "text": "вида документа и его целевой аудитории варьируется и лицо, поддерживающее документ. Кроме того, важно в целом создавать культуру ведения документации в компании, формировать понимание каждого члена компании, что документация и её актуализация приносит конкретную ценность, экономит время и устраняет дублирование работы. Отдельно хочу остановиться на таком моменте как автоматизация документации. Во-первых, чем меньше мы в целом делаем руками - тем меньше нужды в ручном написании документации. Например, если мы ставим эксперименты в джупитере или меняем данные руками в эксель-табличках, то и документацию нужно будет написать руками. А работа с эксперимент-трекером или БД с разметкой автоматически создаёт нужные артефакты. Помимо этого, есть разные инструменты, которые позволяют автоматизировать процесс создания и актуализация документации - Swagger, плагины для IDE, интерактивные датасет-карды (о них можно прочесть выше), DVC-пайплайны, методология docs-as-code. Качественная документация - залог возможности успешного масштабирования как разработки, так и бизнеса в целом. Что бы я предложил вам сделать уже сейчас? Провести аудит документации и по каждому документу ответить на вопросы из списка (можно найти в первой части статьи), сформировать бэклог техдолга по документации Провести аудит документации и по каждому документу ответить на вопросы из списка (можно найти в первой части статьи), сформировать бэклог техдолга по документации Создать единую точку входа в документации (если её еще нет) Создать единую точку входа в документации (если её еще нет) Оценить, для каких документов подходит методология docs-as-code, актуализацию каких документов можно автоматизировать Оценить, для каких документов подходит методология docs-as-code, актуализацию каких документов можно автоматизировать Собрать обратную связь от разных групп (ML-инженеры, пользователи, разметчики, бизнес и другие команды) Собрать обратную связь от разных групп (ML-инженеры, пользователи, разметчики, бизнес и другие команды) Тренироваться писать хорошие технические (и не только) тексты Тренироваться писать хорошие технические (и не только) тексты Если вы хотите узнать ещё больше об организации процессов ML-разработки, подписывайтесь на наш Телеграм-канал Варим ML .",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
    "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
    "section_title": null,
    "text": "Всем привет! Меня зовут Герман Кравец, я больше десяти лет в IT. В МойОфис работаю руководителем группы Календаря в отделе разработки Mailion — это наша отказоустойчивая корпоративная почта для крупного бизнеса. В этой статье расскажу, как мы с командой искали новое решение для нашего API Gateway: зачем вообще понадобилось его менять, с какими проблемами столкнулись и как проходили все этапы — от первых «что-то идёт не так» до финального рефакторинга и запуска нового Gateway в прод. Будет немного боли, немного архитектуры и чуть-чуть магии. Если вам интересно, как решать нетривиальные задачи в продуктовой разработке, где стоит использовать готовые решения, а где всё писать вручную, или просто хочется узнать, как мы сократили простои на регрессе с 4–6 часов до пары минут, — добро пожаловать под кат! API Gateway — это единая точка входа для всех запросов, особенно когда в системе много микросервисов. Публиковать наружу порты каждого из них неудобно, да и с точки зрения безопасности и мониторинга это быстро превращается в хаос. Gateway решает эту проблему: он берёт на себя маршрутизацию, защиту и контроль трафика. Помимо этого, он помогает обрабатывать и модифицировать запросы на лету. В реальных системах это происходит постоянно: запросы нужно обогащать дополнительными метаданными, информацией о пользователе или клиенте, добавлять данные для статистики и аналитики. Gateway становится универсальным фильтром, через который проходит всё взаимодействие между клиентом и микросервисами. С его помощью также значительно упрощается аутентификация и авторизация: достаточно один раз проверить, имеет ли конкретный клиент доступ к нужному ресурсу, и дальше распространять эти права централизованно. Встроенные механизмы безопасности позволяют защитить систему от DDoS-атак, ограничить частоту запросов (Rate Limiting) и контролировать подозрительную активность. API Gateway отвечает и за наблюдаемость: через него проходят логи, метрики и трейсы, что делает анализ работы всей системы прозрачным. Главный плюс подхода в том, что внешний мир не зависит от внутренней архитектуры. Gateway предоставляет единый публичный контракт — по нему с нами интегрируются клиенты и смежные системы. При этом внутренняя структура может меняться сколько угодно: можно оптимизировать алгоритмы, переписывать сервисы или перестраивать связи между ними без риска что-то «сломать» для пользователя. Это основные фишки, которые будут важны для нашей истории, а дальше расскажу, как мы использовали API Gateway. Так у нас выглядела архитектура до того, как мы занялись поиском нового решения. С внешним миром API Gateway взаимодействует через HTTP и WebSockets, а внутри это набор плагинов, сгенерированных на основе прото-файлов, написанных вручную, и всей структуры системы. Когда мы начали искать новое решение, стало очевидно: плагинов накопилось прилично: раздача клиентской статики, работа с картинками, файлами, их было около восьми, не считая десятков вспомогательных. Всё общение между сервисами шло по gRPC, и таких сервисов в системе насчитывалось больше семидесяти. Их все нужно было как-то безопасно и стабильно опубликовать наружу. Как мы пришли к жизни такой? Проект Gateway мы начали разрабатывать примерно в 2017 году. Основным веб-сервисом выбрали Caddy — тогда это был довольно мощный инструмент с гибкой системой плагинов и возможностью писать свои. Мы вручную написали шестнадцать активных плагинов, по сути, шестнадцать отдельных репозиториев с разным уровнем вложенности и зависимостей. А вдобавок создали мощный инструмент, который генерировал эти плагины из proto. Можно сказать, что это был отдельный продукт, заточенный именно",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
    "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
    "section_title": null,
    "text": "это был довольно мощный инструмент с гибкой системой плагинов и возможностью писать свои. Мы вручную написали шестнадцать активных плагинов, по сути, шестнадцать отдельных репозиториев с разным уровнем вложенности и зависимостей. А вдобавок создали мощный инструмент, который генерировал эти плагины из proto. Можно сказать, что это был отдельный продукт, заточенный именно под генерацию плагинов для Caddy. Почему в своё время сделали именно такой выбор, сейчас можно только предполагать — исходный владелец сервиса уже не работает в компании, а значит, остаётся только анализировать решения по следам кода. Вероятно, решающими факторами стали несколько моментов. Во-первых, поддержка HTTP/2 : мы активно используем gRPC и gRPC-стримы, в том числе на клиентской стороне, и наличие полноценной поддержки протокола тогда было критично. Во-вторых, модульность и возможность генерации плагинов . Инструмент действительно мощный, и такая гибкость на этапе активной разработки казалась идеальным решением. Третий аргумент — Go-ориентированность . Наши бэкендеры все пишут на Go, поэтому порог входа был минимальным. Нужно добавить кастомный функционал — просто написал плагин или форкнул нужный модуль. Ну и, наконец, раздача статики из коробки . Caddy справлялся с этим не хуже NginX, поэтому выбор выглядел вполне оправданным. Звучит классно… Так в чём же проблема? На практике начали всплывать проблемы — и их оказалось немало. Главная — bus-фактор : ключевые знания о сервисе ушли вместе с людьми, а владельца у компонента не осталось. Поверх этого наложились сильная связанность со статикой , самописные генераторы плагинов и аж шестнадцать дочерних репозиториев . Сборки занимали от тридцати до шестидесяти минут: каждый из репозиториев тянул за собой зависимые сборки и деплой. Конфигурация тоже доставляла боль. Caddy первой версии использует Caddyfile, нечто вроде псевдо-YAML, и работать с ним было сложно даже для опытных инженеров. Ситуацию усугубляли C++-зависимости, которые повышали порог вхождения в проект, замедляли скорость сборки как локально,так и в CI/CD. Когда мы собрали всё это воедино, стало ясно, что система достигла точки, где поддерживать её дальше уже дороже, чем переписать. Мы были слегка в шоке от масштабов накопившихся проблем и поняли, что пора что-то менять. На старте у нас были жёсткие ограничения по ресурсам: фичи горят, баги горят, а сверху ещё навалился огромный ком техдолга. Выделить под это отдельную команду не получилось, поэтому техдолгом занимался один backend-разработчик в низком приоритете, между коммитами в основной релиз и правками продовых багов. В помощь ему подключили DevOps-инженера — тоже не на full time, а по мере возможности. В такой конфигурации мы решили идти двумя параллельными путями. Первый — сложный: поискать альтернативы текущему решению и оценить, во что выльется миграция. Второй — попроще и побыстрее: разделить статику и API Gateway , чтобы хоть немного разгрузить систему и перестать таскать лишнее между сборками. По классике всё разворачивалось в Docker: внутри и Caddy, и наши статики. Вроде все логично и красиво, но смотришь глубже и взрыв мозга: статики запускаются постепенно, а потом вольюмами запихиваются в веб-сервис. Этот пайплайн ещё и в Jenkins, в общем, очень больно. Кроме того, любое изменение или push в одну из статик заставлял пересобираться их все и передеплоиваться полностью вместе с Gateway. То есть на регрессе, когда мы активно стабилизировали продукт, выкатывали фичи, догоняли код фриз и фича фриз, порядка 120 разработчиков фиксили",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
    "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
    "section_title": null,
    "text": "пайплайн ещё и в Jenkins, в общем, очень больно. Кроме того, любое изменение или push в одну из статик заставлял пересобираться их все и передеплоиваться полностью вместе с Gateway. То есть на регрессе, когда мы активно стабилизировали продукт, выкатывали фичи, догоняли код фриз и фича фриз, порядка 120 разработчиков фиксили баги, пайплайн на всё это триггерился и API Gateway мог лежать 4-6 часов. От этого люто страдали команды FE, BE и QA. Мы решили отделить статику от Gateway и пошли по самому очевидному пути — взяли nginx в качестве базового образа для статики и заодно использовали его как балансировщик. Решение оказалось не только простым, но и прагматичным: nginx уже был согласован с ИБ и юристами, использовался в других командах, а значит — не требовал бюрократии. Инструмент популярный, сообщество большое, документация понятная, и самое главное, у нас уже были все нужные компетенции. Любой разработчик мог что-то поправить, а команда поддержки кастомизировать конфигурацию прямо на площадке заказчика. В итоге получилась архитектура, в которой впереди стоит nginx-балансировщик , за ним — API Gateway , а статики живут отдельно и разворачиваются независимо . Никаких вольюмов, никаких общих сборок — каждый компонент выкатывается сам по себе. Результат почувствовали сразу: мы начали работать по новым пайплайнам, по новой архитектуре, и снизили время deploy с 30 до 2 минут. И боли на регрессе прекратились, потому что пайплайны выкатки стали незаметными, а время простоя API Gateway снизилось до считанных минут. Мы — продуктовая компания, и у нас есть собственный отдел ИБ, который проверяет все продукты на уязвимости. У коллег есть свои инструменты для анализа, но они не всегда успевают за обновлениями языков и библиотек. Поэтому разрешение на использование новой версии Go мы получаем только тогда, когда их стек готов это переварить. В этот раз, наконец, дали добро на Go 1.21 . Отлично — побежали обновлять сервисы. Всё шло по плану: обновили зависимости, подтянули библиотеки, ничего критичного не меняли, код не трогали. Локальная сборка прошла, запускаем... и сразу ловим панику. Окей, так быть точно не должно, надо искать, где собака зарыта. Gateway у нас построен на Caddy v1 , а тот, в свою очередь, зависит от ряда библиотек. Проблема в том, что актуальная open-source версия qTLS поддерживает максимум Go 1.15 , и именно на этом уровне начинает рушиться ядро Caddy. Самое неприятное, что паника срабатывает не при компиляции, а только при запуске. Мы пошли в отладку и довольно быстро докопались до корня: знакомьтесь, функция init() в одной из библиотек. Внутри — проверки вроде structsEqual для нескольких структур. Если сравнить TLS из стандартной библиотеки с тем, что лежит внутри qTLS, то они совпадают буквально один в один. И сразу возникает закономерный вопрос: зачем вообще делать такое сравнение на этапе инициализации? Дальше ещё интереснее. Ошибка, которая валится в лог, указывает на несовпадение структур. Первое, на что мы наткнулись, — различие в количестве полей. На этом моменте стало ясно: заплатками это не вытащить. Нужно всё выносить, перепроверять зависимости и фактически перекапывать Gateway заново, чтобы перейти на новую версию Go и при этом не сломать прод. На момент начала работы у нас было 16 репозиториев, и уровень вложенности у некоторых доходил до шести. Каждый отвечал",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
    "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
    "section_title": null,
    "text": "На этом моменте стало ясно: заплатками это не вытащить. Нужно всё выносить, перепроверять зависимости и фактически перекапывать Gateway заново, чтобы перейти на новую версию Go и при этом не сломать прод. На момент начала работы у нас было 16 репозиториев, и уровень вложенности у некоторых доходил до шести. Каждый отвечал за свой кусок плагинов и зависимостей. Казалось удобно — микросервисный подход, всё по науке. Но на практике это вылилось в настоящий CI/CD-кошмар. Пайплайн для одного репозитория занимал около пяти минут: сборка, тесты, сканеры безопасности — полный набор. А из-за вложенности одно изменение на самом нижнем уровне тянуло за собой цепочку пересборок. В итоге простая правка одной строчки кода могла превращаться в полчаса ожидания, пока вся цепочка отрабатывает. Cкорость вывода изменений в прод страдала, а разработчики страдали вместе с ней. Даже не говоря уже о случаях, когда на инфраструктуре что-то падало и весь CI/CD превращался в домино. В какой-то момент стало очевидно, что нужно выбираться из этого болота. Мы объединили всё в один репозиторий, убрав ненужную вложенность. Теперь каждый пайплайн стабильно выполняется за те же пять минут, но без накопительного эффекта. Всё стало проще, прозрачнее и быстрее. Радуемся, архитектуру поправили, идём дальше. Пора было искать альтернативы Caddy v1. Первым делом решили проверить очевидное — может, сам Caddy уже эволюционировал. Вбиваем в Google, открываем официальную документацию и сразу видим: есть вторая версия! Да ещё и с поддержкой Go 1.21. Отлично, наконец-то шанс обновиться без костылей. Начали разбираться. Архитектурно Caddy v2 похож на своего предшественника: тот же модульный подход, тот же Go под капотом, активная разработка. Появилась и приятная новинка — JSON-конфигурация. После их псевдо-YAML в первой версии это просто глоток свежего воздуха. Главный плюс JSON-конфига — возможность hot-reload: можно обновлять настройки плагинов на лету, без полного перезапуска сервиса. Захотел — подхватил новый конфиг, перезагрузил нужный модуль и продолжаешь работать. Красота. Казалось бы, решение найдено. Но, как обычно, без подводных камней не обошлось. Во-первых, bus-фактор никуда не делся. Один человек из всей команды (а нас больше сотни) изучит новый стек, разберётся в конфигурации, соберёт систему и станет единственной точкой знаний. Дальше классика: отпуск? нельзя. больничный? не вовремя. Горячая пора релиза, и этот человек буквально живёт в деплое. Такой сценарий недопустим, если мы хотим держать стабильный продукт. Во-вторых, документация у v2 — это боль . Два соседних плагина: у одного есть описание, у другого тишина. Конфигурации половины плагинов задокументированы только в формате JSON, другой половины только в Caddyfile, и между ними нет совместимости. Даже ключи параметров могут отличаться. Это сразу оборачивается проблемой поддержки: DevOps-ы и сопровождение не смогут быстро разобраться, а значит, продукт станет заложником своей сложности. Дальше, неприятное открытие. В Caddy v1 можно было сделать небольшой костыль: считать исходный config-файл и построчно проверить каждый параметр, вытащить сквозные ссылки между плагинами. В v2, с переходом на JSON, эту возможность убрали, вероятно, из соображений безопасности. В результате стало невозможно реализовать привычный контекст между модулями. И наконец — порядок инициализации . Если итоговый JSON-файл формируется генератором не в той последовательности, в какой планировалась загрузка модулей, сервис может повести себя непредсказуемо. Иногда просто меняешь два блока местами и всё, поведение при запуске другое. При нашей сложной связности между плагинами",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
    "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
    "section_title": null,
    "text": "стало невозможно реализовать привычный контекст между модулями. И наконец — порядок инициализации . Если итоговый JSON-файл формируется генератором не в той последовательности, в какой планировалась загрузка модулей, сервис может повести себя непредсказуемо. Иногда просто меняешь два блока местами и всё, поведение при запуске другое. При нашей сложной связности между плагинами это недопустимо: сервис может стартовать «не так», а часть модулей просто отвалится. В Caddy v1 у нас была обёртка, которая обеспечивала единый контекст загрузки — в v2 такого механизма нет вообще. После всех экспериментов стало ясно: зачем страдать с коробочными решениями, которые вроде бы предлагают модульность, но по факту не вписываются в архитектуру нашего сервиса и плагинов? Мы пришли к очевидному выводу — проще и надёжнее написать своё решение с нуля, полностью подконтрольное команде. Тогда можно будет кастомизировать всё, что угодно, и не зависеть от чьей-то документации, обновлений или внезапных несовместимостей. Но тут важно не впасть в другую крайность — не делать «всё своё» руками. В начале статьи я уже упоминал, что раньше мы писали собственные генераторы, которые создавали плагины для Caddy прямо из прото-файлов на лету. Эти генераторы со временем разрослись до состояния отдельных монстров — по объёму кода они превосходили большинство наших микросервисов. Повторять эту историю не хотелось. Писать третий генератор, если завтра опять изменится вектор — это бессмысленный оверхед. Нам нужно было решение, где архитектура остаётся под контролем, но при этом есть готовый, устойчивый фреймворк с предсказуемой производительностью и зрелым сообществом. Ключевые критерии были простые: стабильность, высокая скорость обработки запросов, нормальные бенчмарки и адекватное поведение под нагрузкой. Пусть сейчас Gateway не был узким местом по RPS — мы хотели предусмотреть запас на будущее. Выбор в итоге пал на Fiber. Почему он, а не FastHTTP? Когда мы выбирали фреймворк, времени было в обрез: фичи горели, инфраструктура стояла на паузе, и писать низкоуровневую обвязку с нуля было просто некогда. FastHTTP, конечно, быстрый и мощный, но требует ручной сборки экосистемы вокруг — middleware, логирования, ошибок, хэндлеров. На это нужны недели, которых у нас не было. Fiber, наоборот, подошёл идеально по балансу «готовое / контролируемое». Это, по сути, аналог Express.js в мире Go: простой, понятный, с нормальной документацией и логичной архитектурой. Порог вхождения низкий — любой разработчик может быстро разобраться, а коллеги с фронтенда даже получили возможность при необходимости зайти, поправить заголовки или плагин вручную, не залезая в дебри бэкенда. Fiber оказался лаконичным и предсказуемым, а документация — человеческой: всё описано, читается легко, без копания в исходниках. Построив архитектуру на нём, мы сразу выиграли в читаемости и поддерживаемости кода. Плюс, JSON-конфигурация у Fiber оказалась очень близка к тому, как устроены наши остальные gRPC-сервисы. В Caddy-файлах синтаксис был уникальный и никак не стыковался с инфраструктурой продукта, а тут всё единообразно: те же структуры, те же подходы. Это важно не только для разработчиков, но и для DevOps-ов и сопровождения — всё знакомо, всё на автомате. Мы не изобретаем велосипед, а просто берём то, что уже хорошо работает у соседей. Начали тестировать и сразу влетели в проблему. Мы активно используем стримы, и примерно половина клиентских запросов работает именно через них. Первые тесты шли нормально: запросы отрабатывали, ответы возвращались, всё красиво. Но потом — бах. На десятом,",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
    "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
    "section_title": null,
    "text": "Мы не изобретаем велосипед, а просто берём то, что уже хорошо работает у соседей. Начали тестировать и сразу влетели в проблему. Мы активно используем стримы, и примерно половина клиентских запросов работает именно через них. Первые тесты шли нормально: запросы отрабатывали, ответы возвращались, всё красиво. Но потом — бах. На десятом, пятидесятом или сотом запросе (зависело от случая) страница переставала отвечать. Проверяем — сервис упал в панику. Проблема воспроизводилась хаотично: иногда с первого запроса, иногда только после сотого. Разбор показал: Fiber не поддерживает HTTP/2, а у нас стримы как раз шли поверх него, через обвязку gRPC Gateway. В результате — несовпадение дескрипшенов запросов на уровне ядра net/http, и сервер просто рушился. На этом этапе стало ясно: починить такое в лоб не получится. Мы снова оказались у развилки и пошли искать другой фреймворк, который умеет работать с HTTP/2 из коробки. Когда начали искать фреймворк с нормальной поддержкой HTTP/2, вариантов оказалось не так уж много. После серии тестов и чтения исходников остановились на Gin. Из всех кандидатов у него оказались лучшие документация и комьюнити, внятная архитектура и богатый набор middleware из коробки. Порог вхождения низкий даже для тех, кто раньше с ним не работал. Да, по RPS Gin немного проседает по сравнению с Fiber, но для нас это не критично: Gateway никогда не был узким местом по производительности, зато стабильность и поддерживаемость для нас приоритет. Интегрировав Gin, запустили всё прекрасно. Но наши приключения на этом не закончились. Разработчику всегда попадётся на глаза что-то, что нужно подрефачить. У нас было большое дублирование соединений. Каждый плагин по идеологии Caddy — это инкапсулированная, изолированная единица. Поэтому, чтобы прокинуть наши gRPC-соединения, их приходилось дублировать в каждом плагине и каждой конфигурации, хотя по факту все они стучались в один и тот же сервис. Мы сделали единую точку — фабрику соединений, которая по запросу «дай мне соединение к такому-то сервису» проверяет: если соединения нет — создаёт его, если есть — просто переиспользует и отдаёт плагину. Так мы сократили количество соединений по ключевым сервисам с восьми до одного, что в будущем заметно снизит нагрузку. C++-зависимость была нашей болью на протяжении всего существования Gateway. Это одна из причин, почему при виде задач по этому проекту разработчики думали: «О нет, только не он». Ни нормального readme, ни инструкций: запускаешь и получаешь сообщение «Отдай мне библиотеку». На Linux это ещё можно было пережить — где-то в Confluence можно найти, что именно нужно поставить. А вот на Mac библиотек просто нет, и приходилось проходить через эту боль вручную. Разобравшись, откуда растут ноги, я выяснил, что у нас есть плагин для работы с аватарками, который тянул зависимость соседнего модуля, тоже работающего с аватарками. А у соседа под капотом жила библиотека libmagic, используемая для изменения размеров, кропов и прочих операций с изображениями. В коде всё выглядело просто: интерфейс, конструктор и обработчик запроса. В конструктор подтягивался дочерний модуль соседа, и тот — libmagic. Обработчик же делал запрос к соседнему сервису, получал данные и отдавал их клиенту. Мы посмотрели внимательнее — действительно ли всё это нужно, ведь мы работаем по gRPC? Открыли прото соседа и обнаружили метод, который полностью закрывал нашу потребность. Мы удалили зависимость, переписали обработчик так, чтобы он",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
    "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
    "section_title": null,
    "text": "и тот — libmagic. Обработчик же делал запрос к соседнему сервису, получал данные и отдавал их клиенту. Мы посмотрели внимательнее — действительно ли всё это нужно, ведь мы работаем по gRPC? Открыли прото соседа и обнаружили метод, который полностью закрывал нашу потребность. Мы удалили зависимость, переписали обработчик так, чтобы он просто вызывал этот метод через gRPC-стрим, и всё заработало. 40–50 строк кода заменились несколькими строками, ушла боль с C++, сборка стала заметно быстрее, а настройка проще. Теперь проект собирается чистым Go, без лишних зависимостей, а разработчики наконец могут просто запустить, скомпилировать и работать без шаманства. Первое, что мы почувствовали, — ушёл bus-фактор . Теперь любой бэкенд-разработчик в команде может спокойно запустить наш Gateway локально и разобраться, как он работает. Никаких «коробочных» ограничений, странных зависимостей и «магии». Код открыт, структурирован, модули логично разбиты по бизнес-областям. Если нужно что-то поправить — просто проваливаешься в нужный блок и сразу понимаешь, где внести изменения. Конфигурация стала лаконичной и унифицированной . Теперь она полностью соответствует подходам, принятым в других наших сервисах: понятна разработчикам, девопсам и поддержке. Раньше конфиг-файл старого Gateway был настоящей болью — около трёх тысяч строк ручного кода. В нём нужно было заполнять параметры для всех плагинов сразу: нельзя было отключить ненужные, даже если они не использовались при инициализации. Некоторые плагины требовали интеграции с NATS и другими инфраструктурными зависимостями, поэтому любое изменение превращалось в мучение. Генератора не было вовсе: сервис был «белой вороной», особенным и непонятным. Теперь всё иначе. Мы собрали локальный конфиг из примерно 200 строк — только базовые блоки: HTTP, аутентификация и авторизация. Всё остальное стало управляемым: если плагин нужен, то включаешь его в конфиг, не нужен — просто не указываешь. Плагины раньше не знали об общих блоках и дублировали кучу кода. Мы решили это с помощью механизма мёржа . Теперь достаточно указать дефолтное соединение с gRPC-балансировщиком, а Gateway сам подхватывает недостающие настройки. Если конфиг для конкретного сервиса пустой, он подставляет базовые параметры: ключи, таймауты, адреса — и спокойно ходит к балансировщику с готовыми данными. Это позволило заметно сократить размер конфигурации и сделать её человекочитаемой. Архитектура упростилась, а вместе с ней и процесс разработки. Всё стало прозрачнее, быстрее и предсказуемее. Мы также интегрировались с корпоративным PaaS-решением , которое коллеги из другой команды используют для централизованной работы с логами и трейсам. Раньше Gateway мешал полноценной интеграции: именно он был входной точкой для трейсов, а из-за ограничений старой версии Go мы не могли подключить нужные SDK. После обновления языка и переписывания Gateway мы наконец подтянули нужный пакет и успешно встали в общую систему мониторинга. И, наконец, мы избавились от CVE . История получилась показательной. Пока мы активно рефакторили Gateway, не спешили его выкатывать в релизы — и вовремя: через один релиз коллеги из ИБ сообщили, что найденные уязвимости в Go 1.19 получили критичный статус. Это означало риск блокировки релиза. К счастью, к тому моменту мы уже были готовы с новой версией Gateway и в следующий релиз ушли в прод именно с ним, полностью закрыв проблему. Такой вот получился тернистый, но очень полезный путь. Мы переписали Gateway почти с нуля, избавились от боли, старых зависимостей и хаоса в конфигах, а заодно укрепили связь между командами и",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
    "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
    "section_title": null,
    "text": "уже были готовы с новой версией Gateway и в следующий релиз ушли в прод именно с ним, полностью закрыв проблему. Такой вот получился тернистый, но очень полезный путь. Мы переписали Gateway почти с нуля, избавились от боли, старых зависимостей и хаоса в конфигах, а заодно укрепили связь между командами и встроились в экосистему компании гораздо плотнее. Если интересно узнать больше — пишите в комментариях, с удовольствием расскажу детали и подводные камни. А если вам близка тематика масштабных инфраструктурных решений, распределённых систем и высоконагруженных сервисов — заходите в наши вакансии . Будем рады пообщаться с теми, кто хочет строить такие же сложные и красивые системы вместе с нами.",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Автоматизация рутинных задач на VPS с помощью cron и скриптов",
    "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
    "section_title": null,
    "text": "Мы каждый день сталкиваемся со множеством однотипных задач. Постоянно возвращаясь к ним, мы расходуем самый ценный ресурс — время. В итоге застреваем в рутине, рискуем не уложиться в сроки и совершить ошибку. Но можно остановиться и передать повторяющуюся работу тому, кто не забудет и не промахнётся. Нас спасёт автоматизация! Сегодня расскажем о том, как автоматизировать рутинные задачи на Linux-сервере при помощи cron и немного с помощью скриптов. Cron — стандартный планировщик в Unix-подобных операционных системах. Он работает как фоновый демон: непрерывно следит за расписанием и в нужный момент запускает указанную команду или скрипт. Cron — от греческого «χρόνος» (chronos) — время. Он появился в Unix ещё в 1970-х и с тех пор не потерял своей значимости в администрировании систем. Cron запускает задачу с точностью до минуты. Его расписание может быть очень гибким: от «каждую минуту» до «один раз в год». Cron может иметь отдельные планы заданий для каждого пользователя системы, и после настройки он работает автономно и не требует вмешательства пользователя. По факту, любую повторяющуюся задачу, которую вы делаете вручную по расписанию, можно автоматизировать через cron. Любую на Linux. Почти любую. Для работы с cron используется утилита crontab, которая управляет таблицей заданий для текущего пользователя. В основных Linux-системах каждый пользователь может иметь собственный crontab, независимый от других. А может и не иметь, ведь crontab создаётся только тогда, когда пользователь впервые запускает команду: Данная команда открывает файл задач в текстовом редакторе, обычно это — vi или nano, и после сохранения cron сразу же подхватывает изменения без перезапуска сервиса. Задание в cron задаётся в следующем формате: Звёздочку (*) система воспринимает как любое значение, то есть задание будет выполняться при каждом значении соответствующего поля. Кроме звёздочки, поля в задании могут содержать: одно какое-либо число, например, 29 или 6; одно какое-либо число, например, 29 или 6; диапазон чисел, например, 1-4, то есть все значения от 1 до 4 включительно из диапазона, допустимого для данного поля; диапазон чисел, например, 1-4, то есть все значения от 1 до 4 включительно из диапазона, допустимого для данного поля; список чисел, например, 2,5,6; список чисел, например, 2,5,6; шаг, например, */5 означает каждые 5 единиц, начиная с минимального значения. шаг, например, */5 означает каждые 5 единиц, начиная с минимального значения. Здесь есть некоторые неочевидные для новичков тонкости. Например, дни недели могут принимать значения от 0 до 7. Не от одного, а от нуля. В итоге получается целых 8 значений, а дней недели — всего 7. Почему так? Потому что в cron два воскресенья — 0 и 7. Дело в том, что в старых его реализациях для воскресенья использовался 0, но чтобы упростить совместимость с ISO-стандартом, позже разрешили ещё и 7 для обозначения воскресного дня. Или, вот шаг. В нём число после знака / определяет, через сколько единиц значений будет выполняться задание, начиная с минимально допустимого в этом поле значения. Например, /10 для минут будет означать, что задание будет выполняться в минимально возможное количество минут, а затем каждые +10 пока не закончится нумерация минут в пределах часа. То есть, данная запись означает выполнение задания в 0, 10, 20, 30, 40 и 50 минут означенного часа. В отношении часов такая запись означает запуск задачи",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Автоматизация рутинных задач на VPS с помощью cron и скриптов",
    "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
    "section_title": null,
    "text": "минут будет означать, что задание будет выполняться в минимально возможное количество минут, а затем каждые +10 пока не закончится нумерация минут в пределах часа. То есть, данная запись означает выполнение задания в 0, 10, 20, 30, 40 и 50 минут означенного часа. В отношении часов такая запись означает запуск задачи в 0 (полночь), 10 и 20 часов означенных суток. Для дней месяца минимальным значением является 1 — первый день месяца. Это означает. что запись /10 в третьей слева позиции инициирует выполнение задачи в первый день месяца, а затем в каждый +10-й день, пока не закончится месяц — 11, 21 и 31-е число, при условии, что последнее значение присутствует в нумерации текущего месяца. Аналогично для месяцев: /10 означает 1-й и 11-й месяцы, то есть январь и ноябрь. Применительно к дням недели запись /10 не имеет практического смысла, так как диапазон значений здесь ограничен числами от 0 до 7, то есть всего восемь возможных значений. Таким образом, шаг 10 превышает длину диапазона, и задание будет выполняться только для минимального значения, то есть для 0 — воскресенья. Здесь важно понимать, что указанное в шаге число не означает каждые x единиц времени от последнего запуска или от текущего момента, а определяет выполнение задачи каждые x значений поля от его минимального значения. Это мы рассмотрели запись */10. А ведь можно вместо звёздочки использовать число, например, 3/10. Такая запись означает, что планировщик будет прибавлять 10, но уже не к минимальному значению, а к значению 3. То есть, для минут задание будет выполняться в 3, 13, 23, 33, 43, 53 минуты; для часов и чисел месяца — в 3, 13, 23; для месяцев и дней недели — только в 3 (март или среда). Для некоторых значений времени в cron существуют специальные директивы: @yearly или @annually означает один раз в год и заменяет собой комбинацию 0 0 1 1 * , то есть в 00:00 1 января каждого года; @yearly или @annually означает один раз в год и заменяет собой комбинацию 0 0 1 1 * , то есть в 00:00 1 января каждого года; @monthly — раз в месяц, заменяет комбинацию 0 0 1 * * , то есть в 00:00 первого числа каждого месяца; @monthly — раз в месяц, заменяет комбинацию 0 0 1 * * , то есть в 00:00 первого числа каждого месяца; @weekly — раз в неделю, заменяет комбинацию 0 0 * * 0 и означает каждое воскресенье в 00:00; @weekly — раз в неделю, заменяет комбинацию 0 0 * * 0 и означает каждое воскресенье в 00:00; @daily или @midnight — раз в день, заменяет комбинацию 0 0 * * * и означает в полночь каждый день; @daily или @midnight — раз в день, заменяет комбинацию 0 0 * * * и означает в полночь каждый день; @hourly — догадайтесь сами :-) (ответ — ноль и четыре звёздочки). @hourly — догадайтесь сами :-) (ответ — ноль и четыре звёздочки). Есть ещё одна полезная директива — @reboot . Она позволяет выполнять указанную команду один раз при запуске системы. Полезность данной директивы заключается в том, что она не зависит от времени или дня и запускается только",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Автоматизация рутинных задач на VPS с помощью cron и скриптов",
    "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
    "section_title": null,
    "text": "ноль и четыре звёздочки). @hourly — догадайтесь сами :-) (ответ — ноль и четыре звёздочки). Есть ещё одна полезная директива — @reboot . Она позволяет выполнять указанную команду один раз при запуске системы. Полезность данной директивы заключается в том, что она не зависит от времени или дня и запускается только при перезагрузке или старте сервера. Ну если разобрались с форматом записи месяцев, дней, часов и минут, то в шестом поле указываем команду, которая должна выполняться в указанное время. Что можно использовать в качестве команды? Во-первых, любые shell-команды: ls , cp , rm и т.д. Во-вторых, скрипты: bash, python, php и т.п. В-третьих, исполняемые файлы. А также, цепочки команд с операторами &&, ||, ; и перенаправление вывода типа > , >> , 2>&1 . Из важных моментов можно отметить следующее: всегда используйте полные абсолютные пути к скриптам и файлам, в противном случае cron не всегда сможет их отыскать. И ещё — старайтесь логировать вывод. Поверьте, это пригождается чаще, чем хотелось бы. Основное назначение cron — делегирование системе задач, для выполнения которых можно использовать расписание, чтобы разгрузить администратора данной системы, оградив его от определённого количества рутинной работы. Давайте рассмотрим некоторые типы и примеры задач, решить которые может помочь cron. Обсуждение важности создания резервных копий чего бы то ни было, наверное, уже набило оскомину. И хотя cron и не является полноценным инструментом бэкапирования, но всё же с его помощью можно кое-что реализовать, поскольку расписание плюс копирование это и есть несложное решение для подобной задачи. Например: Такая строка в cron представляет собой пример ежедневного создания дампа базы данных MySQL или MariaDB с сохранением его в директории /backup/ под именем, частью которого будет текущая дата. Это, чтобы можно было понять, когда этот бэкап сделан. Ещё один пример — еженедельное создание tar-архива каталога /var/www/html/ , в котором, вероятно, находятся файлы веб-сайта. 0 в пятой позиции означает запуск команды каждое воскресенье, а имя архива, как и в предыдущем примере, будет содержать дату архивирования данных: Подобным же образом при помощи rsync — утилиты для быстрой и надёжной синхронизации файлов и каталогов, можно с определённой периодичностью копировать данные из одной Linux-системы в другую: Прелесть данной утилиты в том, что она копирует только изменённые данные, что позволяет экономить трафик и время. Конкретно в этой команде: /important/data/ — каталог, содержимое которого подлежит синхронизации с удалённым ресурсом. Обратите внимание на слэш в конце: он означает, что копировать нужно только содержимое каталога, а не сам каталог. /important/data/ — каталог, содержимое которого подлежит синхронизации с удалённым ресурсом. Обратите внимание на слэш в конце: он означает, что копировать нужно только содержимое каталога, а не сам каталог. remote-user@192.168.0.11:/backup/ — место назначения, где: remote-user — это имя пользователя на удалённой системе; 192.168.0.11 — IP-адрес удалённой системы; /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. remote-user@192.168.0.11:/backup/ — место назначения, где: remote-user — это имя пользователя на удалённой системе; remote-user — это имя пользователя на удалённой системе; 192.168.0.11 — IP-адрес удалённой системы; 192.168.0.11 — IP-адрес удалённой системы; /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. На VPS всё",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Автоматизация рутинных задач на VPS с помощью cron и скриптов",
    "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
    "section_title": null,
    "text": "на удалённой системе; remote-user — это имя пользователя на удалённой системе; 192.168.0.11 — IP-адрес удалённой системы; 192.168.0.11 — IP-адрес удалённой системы; /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. На VPS всё это особенно актуально: регулярные дампы, архивация и перенос данных между серверами — типичная практика. На виртуальных серверах UltraVDS , например, можно настроить такие задачи буквально за несколько минут. Это — ещё одно направление в администрировании Linux-систем, где использование планировщика является частью повседневности. При работе операционной системы, служб и приложений появляются и накапливаются временные файлы, которые создаются при установке, обновлении или обработке данных, и после выполнения своей задачи зачастую становятся бесполезными. Ниже — пример простенького скрипта, который удаляет из каталога /tmp файлы, не изменявшиеся больше семи дней: Такая запись в cron позволит запускать этот скрипт раз в сутки: Можно обойтись и без скрипта, записав команду удаления файлов сразу в cron: То же относится к логам — записям о событиях, ошибках и действиях системы. Логи полезны для диагностики, но со временем становятся слишком объёмными и могут занимать полезное пространство. Так может выглядеть задача по еженедельному удалению старых лог-файлов в директории /var/log. Здесь опция -mtime +30 говорит нам, что необходимо найти и удалить файлы старше тридцати дней: Или вот кэш — временное хранилище данных, которое призвано ускорить загрузку приложения, но по прошествии времени в нём накапливается много устаревших и ненужных данных. Пример ниже — ежедневное принудительное удаление содержимого кэш-директории условного приложения app: Планировщик cron в том числе можно использовать как простейший инструмент мониторинга системы. Например, так можно настроить периодическую отправку отчёта об использовании дискового пространства на электронную почту администратора: Правда, чтобы отправка писем действительно работала, сервер нужно заранее настроить — почтовая система должна понимать, куда и каким способом доставлять сообщения. Мониторинг используется не только как внимательный наблюдатель за состоянием сервисов и процессов. При помощи планировщика и несложного скрипта можно попытаться своевременно, или почти своевременно, поднять упавшую службу. Например, следующим образом каждые 10 минут cron проверяет, запущена ли служба Nginx, и если не запущена — перезапускает её: Классическая задача для cron — обновление бесплатного SSL-сертификата от Let's Encrypt с использованием Certbot. Как правило, такой сертификат выдаётся на 90 дней и перед истечением данного срока его нужно обновить, чтобы сайт продолжал быть доступным через HTTPS. Certbot — это утилита, которая позволяет автоматизировать процесс получения и продления SSL-сертификата от Let's Encrypt. Для проверки срока действия сертификата и его обновления в Certbot используется cron. Официальная документация Let's Encrypt рекомендует запускать проверку дважды в день, что должно гарантировать обновление сертификата даже при временном отсутствии интернета. Здесь: certbot renew — команда, которая пытается обновить SSL-сертификаты Let’s Encrypt, срок которых подходит к концу; certbot renew — команда, которая пытается обновить SSL-сертификаты Let’s Encrypt, срок которых подходит к концу; --quiet — опция, определяющая запуск команд в «тихом» режиме, то есть без вывода сообщений; --quiet — опция, определяющая запуск команд в «тихом» режиме, то есть без вывода сообщений; --deploy-hook — команда, которая выполнится только при успешном обновлении сертификата — перезапустит конфигурацию веб-сервера, в данном случае Nginx, чтобы он применил новый сертификат. --deploy-hook — команда,",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Автоматизация рутинных задач на VPS с помощью cron и скриптов",
    "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
    "section_title": null,
    "text": "запуск команд в «тихом» режиме, то есть без вывода сообщений; --quiet — опция, определяющая запуск команд в «тихом» режиме, то есть без вывода сообщений; --deploy-hook — команда, которая выполнится только при успешном обновлении сертификата — перезапустит конфигурацию веб-сервера, в данном случае Nginx, чтобы он применил новый сертификат. --deploy-hook — команда, которая выполнится только при успешном обновлении сертификата — перезапустит конфигурацию веб-сервера, в данном случае Nginx, чтобы он применил новый сертификат. Ещё один популярный сценарий для cron — автоматическая обработка данных. Например, регулярная генерация разных отчётов без вашего участия. Вместо ежедневной или еженедельной ручной сборки данных можно создать скрипт, который будет выполнять такую задачу, и автоматизировать процесс при помощи расписания. Примером могут послужить ежедневные отчёты, которые необходимо собирать в нерабочее время — до начала или, наоборот, после окончания рабочего дня. Сюда же можно отнести различную периодическую аналитику или статистику за определённый регулярно повторяющийся период. Такой отчёт, как правило, сохраняется в файл для последующей отправки на email, загрузки на файлообменник или ещё куда-либо. Python-скрипт, допустим, собирает данные из SQLite: Потом формирует текстовый отчёт и отправляет его на электронную почту: Запуск задачи поручаем cron — в 8 утра каждый понедельник: Кроме команды crontab -e , упомянутой в самом начале, при работе с планировщиком будут полезны инструменты командной строки, как, например, просмотр текущих задач: Команда выводит список всех запланированных заданий для текущего пользователя. Удобно, например, для того, чтобы убедиться в корректном добавлении задачи. Для удаления всех заданий запускаем: Команда полностью очищает crontab текущего пользователя. Поэтому используйте её осторожно, при выполнении команды не выводится никаких подтверждений. Команда для просмотра логов cron выглядит как: Вывод показывает записи о событиях при запуске задач cron. Потратив немного времени на настройку и проверку заданий для планировщика, мы получаем отличный бонус — больше не нужно вручную выполнять однообразные задачи и переживать, что что-то пойдёт не так. Теперь всё происходит по расписанию и без лишних нервов. Так мы постепенно переключаемся с вечного «тушения пожаров» на спокойное, продуманное управление. А своё время наконец можно потратить на то, что действительно требует человеческих мозгов или творчества.",
    "source_type": "habr",
    "useful_links": []
  },
  {
    "document_title": "Задача LCS - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-lcs",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Что такое наибольшая общая подпоследовательность и как её находить? Почему простой перебор работает медленно и как ускорить решение с помощью динамического программирования? Как устроен алгоритм LCS для двух и трёх последовательностей и как реализовать его эффективно?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача LCS - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-lcs",
    "section_title": "Наибольшая общая подпоследовательность из двух последовательностей",
    "text": "Мы имеем две последовательностии, их общая подпоследовательность длиной— это набориндексов при котором Наибольшая общая подпоследовательность — общая подпоследовательность, которая обладает наибольшей длиной из всех подпоследовательностей. Такая задача может применяться, например:— в сопоставлении данных — утилита diff, операция слияния в разных системах управления версиями;— в биоинформатике — поиск сходств в генах разных видов;— в проверке орфографии. Входные данные:Первая строка: количество элементов первой подпоследовательности. Вторая строка:. Третья строка: количество элементов второй подпоследовательности. Четвёртая строка:. Выходные данные:. Ограничения:;для всех. Общая подпоследовательность длиной 2 — это. У двух последовательностей нет общих элементов. Одна общая подпоследовательность —. Ещё одна —. Рассмотрим наибольшую общую подпоследовательность, определённую индексамии(так, для каждого,):— Последние символыиприводятся в. В этом случаеи. Тогда— это наибольшая общая подпоследовательность оти.— Как минимум один из последних символовине приводится в. В этом случае или, или. Тогданаходится полностью вили. Таким образом, мы сводим задачу с изначальными строкамиидо такой же задачи с их префиксами. Пусть— длина наибольшей общей подпоследовательностии. Выходит, что эта функция удовлетворяет следующее рекуррентное соотношение: Базовый случай для этого рекуррентного соотношения —или: Полученный алгоритм приведён ниже. Его время выполнения составляет. Скопировать код1LCS(A[1…n],B[1…m]):2table =2d array ofsize(n+1)×(m+1)3table[i][0] =0andtable[0][j] =0forall i,j4fori from1to n:5forj from1to m:6table[i][j] = table[i−1][j]7table[i][j] =max(table[i][j], table[i][j−1])8ifA[i]=B[j]:9table[i][j] =max(table[i][j], table[i−1][j−1]+1)10returntable[n][m] Так задача «Наибольшая общая подпоследовательность» — всего лишь задача «Редакционное расстояние», в которой запрещены операции «замены».",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача LCS - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-lcs",
    "section_title": "Наибольшая общая подпоследовательность из трёх последовательностей",
    "text": "Имея три последовательности:,и— нужно найти длину наибольшей общей подпоследовательности для них, то есть наибольшее неотрицательное целое число, при котором существуют индексы при котором Входные данные: Первая строка:. Вторая строка:. Третья строка:. Четвёртая строка:. Пятая строка:. Шестая строка:. Выходные данные:. Ограничения:;. Общая подпоследовательность длиной 2 — это. В этом случае одна общая подпоследовательность длиной 3 — это. Ещё одна —. Пусть— это максимальная длина общей подпоследовательности от,и. Тогда Базовый случай: Время выполнения соответствующего алгоритма составляет.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача LCS - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-lcs",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете находить наибольшую общую подпоследовательность двух или трёх строк с помощью алгоритма динамического программирования. Вы увидели, как рекурсивные зависимости помогают выразить решение через подзадачи, и научились реализовывать алгоритм так, чтобы он был быстрым и устойчивым на практике. Далее — задача о рюкзаке. Вы узнаете, как использовать похожие техники динамики, чтобы выбирать оптимальное подмножество предметов с максимальной суммарной ценностью при ограниченном объёме. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. LCS — это задача поиска самой длинной общей подпоследовательности двух или трёх строк. Полный перебор всех подпоследовательностей даёт экспоненциальную сложность, но динамическое программирование решает задачу заили. Решение строится на сравнении последних символов и рекурсивном переходе к префиксам строк. Алгоритм можно реализовать итеративно с таблицей и дополнительно восстановить саму подпоследовательность.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80780"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задачи о числах Фибоначчи - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как устроены числа Фибоначчи и какие есть способы их вычисления? Почему важно учитывать время выполнения, типы данных и переполнение даже в простых задачах? Что такое период Пизано и как он помогает находить остатки от огромных чисел Фибоначчи?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задачи о числах Фибоначчи - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
    "section_title": "Числа Фибоначчи",
    "text": "Прежде чем начать, коротко напомним, что числа Фибоначчи — числовой ряд, при котором каждое последующее число равно сумме двух предыдущих. Такие числа определяются рекурсивно: Это приводит к следующему рекурсивному алгоритму: Скопировать код1Fibonacci(n):2ifn <=1:3returnn4else:5returnFibonacci(n−2)+Fibonacci(n−1) Рассмотрим совсем простую задачу. Входные данные: Целое число. Выходные данные:. Ограничения:. Примеры Ниже мы описываем простую реализацию рекурсивного псевдокода дляPython. В неё входит инструкция по обнаружению багов, которая выводит то, что вычисляется в данный момент. Мы пробуем вычислитьс помощью этого кода. Скопировать код1deffibonacci(n):2ifn <=1:3returnn4else:5print(f'Computing F{n}recursively...')6returnfibonacci(n -2) + fibonacci(n -1)789print(fibonacci(7)) Скопировать код1Computing F7 recursively...2Computing F5 recursively...3Computing F3 recursively...4Computing F2 recursively...5Computing F4 recursively...6Computing F2 recursively...7Computing F3 recursively...8Computing F2 recursively...9Computing F6 recursively...10Computing F4 recursively...11Computing F2 recursively...12Computing F3 recursively...13Computing F2 recursively...14Computing F5 recursively...15Computing F3 recursively...16Computing F2 recursively...17Computing F4 recursively...18Computing F2 recursively...19Computing F3 recursively...20Computing F2 recursively...2113 Как видите, код даёт нам верный результат (), но многие вычисления повторяются. Если вы решите вычислитьс помощью этого кода, то Солнце потухнет раньше, чем компьютер выдаст вам результат. Скорее всего вы бы взяли лист бумаги и написали что-то вроде: Вполне разумно попросить компьютер вычислитьтаким жеитерационнымспособом: Скопировать код1Fibonacci(n):2ifn <=1:3returnn4allocate an array F[0..n]5F[0] =06F[1] =17fori from2to n:8F[i] = F[i −2] + F[i −1]9returnF[n] Приблизительное количество операций, необходимых алгоритму, —. Этот алгоритм хорошо работает на практике. Как вы могли заметить, нет необходимости хранить все числа последовательности Фибоначчи: чтобы вычислить текущее число, достаточно знать два предыдущих. Скопировать код1Fibonacci(n):2ifn <=1:3returnn4previous =05current =16foriter inrange(n-1):7oldPrevious = previous8previous = current9current = oldPevious + previous10returncurrent Рекурсивный алгоритм требует так много времени, потому что он повторяет множество одинаковых вычислений: напримерFibonacci(7)вызываетFibonacci(3)пять раз. Не проще ли сохранить, как только это значение вычислено, и при необходимости использовать сохранённое значение вместо того, чтобы вычислять его с нуля? Такой простой подход называется «мемоизация» — при вычислении чего-либо сохраните это в структуре данных, чтобы избежать повторных вычислений в будущем. Давайте добавим мемоизацию в рекурсивный алгоритм, чтобы сделать его практичнее. Скопировать код1table — некоторый ассоциативный контейнер (в table[i] будем сохранять F[i])23Fibonacci(n):4iftable[n] ещё не вычисляли:5ifn <=1:6table[n] = n7else:8table[n] =Fibonacci(n−2)+Fibonacci(n−1)9returntable[n] По сравнению с изначальным рекурсивным алгоритмом этот сделает максимум«серьёзных» рекурсивных вызовов: для каждогопервый вызовFibonacci(i)вычисляет, сохраняя в; затем все дальнейшие вызовыFibonacci(i)становятся просто поиском по таблице.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задачи о числах Фибоначчи - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
    "section_title": "Последняя цифра числа Фибоначчи",
    "text": "Формат ввода: Целое число. Формат вывода: Последняя цифра. Ограничения:. Примеры Для решения этой задачи мы вычислими просто выведем последнюю цифру последовательности: Скопировать код1FibonacciLastDigit(n):2ifn <=1:3returnn4F[0..n] — массив для промежуточных значений5F[0] =06F[1] =17fori from2to n:8F[i] = F[i −1] + F[i −2]9returnF[n] mod10 Таким образом, если вы используете типы C++int32илиint64для хранения, вы быстро придёте к целочисленному переполнению. Если вы используете числа произвольной точности, например,BigIntegerв Java или встроенные целые числа в Python, то вы заметите, что цикл проходит намного медленнее при повышающемся числе итераций. Несложно увидеть, что последняя цифра вравна, и она полностью определена последними цифрами ви. Это подсказывает нам, как сделать алгоритм практичнее: вместо вычисленияи использования последней цифры можно взять каждое промежуточное звено по модулю 10. Главный посыл этой задачи: когда вам нужно вычислить результат последовательности арифметических операций по модулю, берите результат каждой операции по модулю. Так можно гарантировать, что числа, с которыми вы работаете, будут маленькими (они уместятся в стандартный тип языка программирования, который вы предпочитаете) и что арифметические операции с ними будут выполняться быстро. Скопировать код1FibonacciLastDigit(n):2ifn <=1:3returnn4F[0..n] — массив для промежуточных значений5F[0] =06F[1] =17fori from2to n:8F[i] = (F[i −1] + F[i −2]) mod109returnF[n]",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задачи о числах Фибоначчи - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
    "section_title": "Огромное число Фибоначчи",
    "text": "Формат ввода:Целые числаи. Формат вывода:. Ограничения:,. Примеры Предупреждение: . . содержит миллионы цифр, но. В этой задачеможет быть настолько большим, что алгоритму потребуется слишком много времени, чтобы пройти через все числа Фибоначчидляотдо. Чтобы понять, как решить эту задачу, не проходя через все числа, взгляните на таблицу ниже: Обе эти последовательности — периодические! Период для—. Его длина —. Дляпериод будет, и его длина —. В итоге, чтобы вычислить, например,, нам понадобится найти остальную частьпри делении на. Так как, мы можем заключить, что. Оказывается, что для любого целого числапоследовательностьбудет периодической. Период всегда начинается с. Он называется «период Пизано» (Фибоначчи также называют «Пизано»). Каким будет период? Докажите, что для каждого числапоследовательностьбудет периодической. Докажите, что период последовательностине превышает. Таблица ниже демонстрирует, что последовательность— периодическая. Последние цифры повторяются по периоду Пизано длиной. Другими словами: Например: Чтобы доказать, что последние цифры чисел Фибоначчи периодические, обратите внимание на пары остатков по модулю, следующих друг за другом чисел Фибоначчи: Каждую из колонок таблицы можно вычислить на основе предыдущей колонки как . По такой же логике колонка перед колонкой будет . Следовательно, для любой колонки в таблице выше можно однозначно определить соседей слева и справа. А значит, из любой позиции можно заполнить всю таблицу. Поскольку остатков по модулютолько, есть тольковозможных пар остатков, то есть максимумвозможных колонок. Таким образом, некоторые колонки в таблице повторяются и будут это делать до бесконечности. Докажите, что первая повторяющаяся колонка таблицы длябудет Это наводит нас на следующий простой псевдокод, который рассчитывает период Пизанодля произвольного остатка по модулю. Скопировать код1PisanoPeriod(m):2current =03next =14period =05whileTrue:6oldNext = next7next = (current + next) mod m8current = oldNext9period = period +110ifcurrent =0andnext =1:11returnperiod Объединяя изложенные идеи, получаем приемлемое по скорости работы решение. Ещё один способ вычислить— обратить внимание на то, что уравнения могут быть представлены как умножение матрицы—— и вектора: Следовательно: Поэтому— просто элемент справа вверху-й степени матрицы. Мы продемонстрируем быстрое возведение в степень с помощью целых чисел вместо матриц. Имея целое число, можно было бы примитивно вычислить, используя умножение 8 раз. Однако есть и более быстрый способ вычислить, используя умножение лишь 4 раза: В целом, при чётномвычислениепотребует выполнить умножение лишь еще один раз по сравнению с, так как. Если— нечетное, то вычислениепотребует выполнить умножение лишь ещё два раза — по сравнению с, так как. Скопировать код1FastIntegerExponentiation(x, n):2ifn =0:3return14ifn %2==0: # чётное значение5y =FastIntegerExponentiation(x, n/2)6returny * y7else: # нечётное значение8y =FastIntegerExponentiation(x, (n−1)/2)9returny * y * x Поскольку каждый рекурсивный вызовFastIntegerExponentiationприводит к двум операциям умножения целых чисел и разделяетпополам, он выполнит максимумопераций умножения. Скопировать код1FastMatrixExponentiation(D, n, m):2ifn =0:3return[[1,0], [0,1]] # единичная2×2матрица4ifn %2==0: # чётное значение5Y =FastMatrixExponentiation(D, n/2, m)6returnMultiply2x2Matrices(Y, Y, m)7else:8Y =FastMatrixExponentiation(D, (n−1)/2, m)9Y2 =Multiply2x2Matrices(Y, Y, m)10returnMultiply2x2Matrices(Y2, D, m) Скопировать код1Multiply2x2Matrices(A, B, m):2C[1][1] = (A[1][1]*B[1][1] + A[1][2]*B[2][1]) mod m3C[1][2] = (A[1][1]*B[1][2] + A[1][2]*B[2][2]) mod m4C[2][1] = (A[2][1]*B[1][1] + A[2][2]*B[2][1]) mod m5C[2][2] = (A[2][1]*B[1][2] + A[2][2]*B[2][2]) mod m6returnC Наконец, вычисление нужного значения выглядит следующим образом: Скопировать код1FibonacciModuloM(n, m):2M = [[0,1], [1,1]]3P =FastMatrixExponentiation(M, n, m)4returnP[0][1]",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задачи о числах Фибоначчи - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
    "section_title": "Последняя цифра суммы чисел Фибоначчи",
    "text": "Формат ввода: Целое число. Формат вывода:. Ограничения:. Примеры Подсказка.Раз исчерпывающий поиск будет слишком медленным для этой задачи, попробуйте придумать формулу для. Для лучшего понимания поиграйте с маленькими значениями. Затем используйте решение для предыдущей задачи. В таблице ниже указаны первые одиннадцать чисел Фибоначчи и первые одиннадцать чисел. Похоже, что. Давайте докажем это по индукции. Это условие определённо выполняется для первого шага (), так как. Для шага с индукцией предположим, что утверждение верно для, и докажем его для: Ещё один способ прийти к формуле— сложить равенства. Так как элементы в правых частях взаимоуничтожаются, то сумма всех элементов справа —, а сумма всех элементов слева будет, Так задача сводится к тому, чтобы найти последнюю цифру в. Благодаря предыдущей задаче мы знаем, как можно быстро это сделать: исходя из того, что период Пизано по модулюравен, мы имеем",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задачи о числах Фибоначчи - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
    "section_title": "Последняя цифра частичной суммы чисел Фибоначчи",
    "text": "Формат ввода: Целые числаи. Формат вывода:. Ограничения:. Примеры Сумма частичной суммы чисел Фибоначчи равна разнице между двумя частичными суммами: Более обобщённо, Благодаря предыдущей задаче мы знаем, как быстро вычислять префиксные, то есть первые элементы последовательности, суммы.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задачи о числах Фибоначчи - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
    "section_title": "Последняя цифра суммы квадратов чисел Фибоначчи",
    "text": "Формат ввода: Целое число. Формат вывода:. Ограничения:. Примеры . . Подсказка.Раз алгоритм исчерпывающего поиска будет слишком медленным для этой задачи (может доходить до), нам нужно найти простую формулу для. Рисунок выше представляет суммукак площадь прямоугольника с вертикальным реброми горизонтальным ребром. Рисунок выше подсказывает, что для каждого неотрицательного целого числа Мы докажем это по индукции. Для двух первых случаевиполучается: Для шага с индукцией предположим, что. Так, В итоге остаётся вычислить последние цифрыи.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задачи о числах Фибоначчи - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadachi-o-chislah-fibonachchi",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете вычислять числа Фибоначчи разными способами: от наивной рекурсии до оптимизированных алгоритмов с мемоизацией, итерацией и быстрым модулем. Вы познакомились с понятием периода Пизано и научились искать остатки от огромных чисел — быстро и точно. Далее — задачи на наибольший общий делитель и наименьшее общее кратное. Вы познакомитесь с алгоритмом Евклида, поймёте, почему он работает, и научитесь использовать его для ускорения решения задач с делением. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Числа Фибоначчи можно вычислять по-разному — от наивной рекурсии до оптимизированных итерационных алгоритмов. Важно уметь оценивать эффективность решений: простые на вид алгоритмы могут работать слишком долго. Мемоизация и вычисление по модулю позволяют ускорить программу и избежать переполнения. Даже в знакомых задачах важно думать об ограничениях, типах данных и тестах на больших входах.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80763"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Природа графа - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/priroda-grafa",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Что такое граф и где он применяется в жизни и программировании? Какие виды графов существуют и чем они отличаются? Какие свойства графа важно учитывать при решении задач?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Природа графа - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/priroda-grafa",
    "section_title": "Определение графа",
    "text": "Граф состоит из множества вершин, соединённых ребрами. По сути, рёбра и вершины — базовые понятия. Обычно граф обозначают, где— множество вершин,— множество рёбер/дуг. Проведём аналогию с картой метро, которую можно рассматривать как граф, где станции — вершины, а перегоны — рёбра. Другим примером может служить обычная карта, где населенные пункты — вершины графа, а рёбра — соединяющие их дороги. Генеалогические деревья, блок-схемы, схемы авиалиний и железных дорог — всё это примеры графов. Рёбра и вершины графа могут иметь свои имена. Посмотрим на пример графа на рисунке ниже. Граф может быть ориентированным или неориентированным. В неориентированном графе рёбра не имеют направления, то есть движение по ним возможно в двух направлениях. В ориентированном графе рёбра обычно называют дугами. Пройти по дуге можно только в заданном направлении. Пример ориентированного графа приведён на рисунке ниже. В дальнейшем под понятием «граф» мы будем понимать именно неориентированный граф. В графе могут быть рёбра и дуги особого типа, которые входят и выходят из одной вершины. Такие рёбра и дуги называются петлями. Между рёбрами и вершинами в графах существуют отношения смежности и инцидентности. Термин смежность применяется к объектам одного вида — смежными между собой могут быть вершины и рёбра. Одна вершина смежна другой, если они соединены дугой или ребром. Одно ребро смежно другому ребру, если у них есть общая вершина, из которой они выходят. Понятие инцидентности применяется к рёбрам и вершинам. Ребро инцидентно вершине, если это ребро выходит из вершины. Помимо обычных графов, существуют ещё графы особого вида. Например, мультиграф — граф, у которого может быть несколько кратных рёбер или дуг. Пример ориентированного и неориентированного мультиграфа приведён на рисунке ниже. Рёбрам графа, при необходимости, можно задать веса. В таком случае граф становится взвешенным или нагруженным. В качестве веса может выступать, например, расстояние между городами. На рисунке ниже показан пример взвешенного графа. В рамках данного параграфа нам также понадобится знать определение двудольного графа. Как следует из названия, граф состоит из двух долей, в каждой из которых никакие две вершины не смежны. На рисунке ниже можно увидеть, что вершины 1, 2 и 3 принадлежат одной доле, а вершины 4 и 5 другой. Как вы думаете, а может ли граф вообще не содержать ребер? Да, такое бывает. В этом случае говорят о нуль-графе. А может быть и обратная ситуация, когда граф содержит все возможные ребра или дуги. Такие графы называются полными. Посмотрите на пример полного графа ниже. Двудольный граф также может быть полным. Полный двудольный граф — граф, содержащий все возможные рёбра или дуги. Пример полного двудольного графа изображён ниже. В графе можно построить путь — последовательность связанных рёбер, которые соединяют вершины графа. Цикл — путь, который начинается и заканчивается в одной и той же вершине. А может ли в графе отсутствовать цикл? Да, может, и в этом случае речь о таком графе как дерево. Дерево — граф без циклов. Графы могут быть связными и не связными. Связный граф тот, в котором от всех вершин до каждой существует путь. Пример несвязного графа приведён на рисунке ниже. При этом в ориентированном графе говорят о сильной и слабой связности. Ориентированный граф называется: слабо связным - если его неориентированный аналог является связным; сильно связным - если всякая вершина v достижима из любой вершины u. Очевидно, что любой сильно связный граф, также является и слабо связным. Важно отметить, что графы имеют свои характеристики. Например, для вершин графа существует понятие степени. Степень вершины — число инцидентных этой вершине рёбер. Обычно степень вершины обозначают функцией. На рисунке ниже,,,,. В ориентированном графе говорят про полустепени исхода и захода. Под полустепенью исхода понимается количество дуг, выходящих из вершины. Под полустепенью захода понимают число дуг, заходящих в вершину. Обычно, полустепень исхода обозначают, а полустепень захода —. Если речь про петли, то в случае неориентированного графа она учитывается как два ребра, а в случае ориентированного для вершины эта дуга учитывается и в полустепени исхода, и в полустепени захода. Для ориентированного графа, изображенного на рисунке 2 посчитайте полустепени исхода и захода.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Природа графа - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/priroda-grafa",
    "section_title": "Что дальше",
    "text": "Теперь вы понимаете, как устроены графы и почему они важны для алгоритмов. Вы узнали, что графы могут описывать карты, деревья, схемы и связи между объектами, а также познакомились с их разновидностями и свойствами. Далее — узнаем, как хранить граф в памяти компьютера. Разберёмся с матрицами и списками, сравним их по эффективности и применимости к разным задачам. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Граф состоит из вершин и рёбер, которые задают структуру связей между объектами. Графы бывают ориентированные, неориентированные, взвешенные, полные, деревья и другие. Важные свойства графов: связность, степень вершин, наличие циклов, двудольность. Графы широко применяются — от транспортных схем до анализа социальных сетей.",
    "source_type": null,
    "useful_links": [
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Динамическое программирование - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dinamicheskoe-programmirovanie",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как работает динамическое программирование и зачем оно нужно? Как разбивать задачу на подзадачи и переиспользовать решения? Когда стоит выбрать универсальный алгоритм, а когда — частный и быстрый?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Динамическое программирование - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dinamicheskoe-programmirovanie",
    "section_title": "Что такое динамическое программирование",
    "text": "Некоторые алгоритмы разбивают задачу на более мелкие подзадачи и используют решения подзадач, чтобы собрать решение для главной. Во время этого процесса количество подзадач может стать очень большим, и некоторые алгоритмы решают одну и ту же подзадачу многократно, что чрезмерно увеличивает время выполнения. Динамическое программирование упорядочивает вычисления и позволяет не вычислять уже известные значения повторно. Зачастую это экономит массу времени. Задача со звонящим телефоном не подразумевает решения с помощью динамического программирования, поэтому мы рассмотрим другую. Представьте, что вместо ответа на звонок вы решаете поиграть в «Камни»: игру для двух игроков с двумя наборами камней по десять штук. С каждым ходом один игрок может взять один камень (из любого набора) или два камня (по одному из обоих). Когда камень забрали, он выходит из игры. Побеждает игрок, который заберет последний камень. Первый ход за вами. Чтобы найти стратегию для выигрыша в игре на, мы можем составить таблицу, которую мы назовем(рис.). Вместо того, чтобы решать задачу скамнями в каждом из наборов, мы решим более общую задачу скамней в одном наборе икамней в другом (игра на), гдеи— это произвольные целые неотрицательные числа. Если игрок 1 может гарантированно выигрывать игру на, тогда мы будем говорить, что. Если у игрока 1 нет стратегии для выигрыша против игрока, который всегда делает правильные ходы, мы будем писать. Вычислениедля произвольныхиможет звучать сложно, но мы воспользуемся результатами вычислений для меньших значений. Некоторые варианты игры, — в особенности,и, — явно приведут к победе игрока 1, так как игрок 1 может выиграть первым ходом. Таким образом, мы заполняем ячейки,икак.рис. (a) Заполнив ячейки,и, можно попробовать заполнить другие. Например, в случае сединственный ход, который может сделать игрок 1, приводит к— это выигрышный вариант для оппонента. Аналогичный анализ применим к случаю, что приводит к таблице из рис.рис. (b). В случаеигрок 1 может сделать три разных хода, которые приведут к,исоответственно. Один из этих случаев,, приводит к проигрышной позиции оппонента. Соответственно,— это выигрышная позиция. Случаиисимметричны, поэтому мы получаем таблицу из рис.рис. (c). Теперь мы можем заполнить. В случаеигрок 1 может сделать три разных хода, которые приведут к ячейкам,и. Эти ячейки — выигрышные позиции для оппонента. Так,: см рис.рис. (d). Мы можем продолжить заполнять, обращая внимание на то, что ячейкабудет, если ячейки сверху, слева и слева по диагонали будут. Эти ячейки (,и) соответствуют трем ходам, которые может сделать игрок 1. См. рис.рис. (e) АлгоритмRocksопределяет, выиграет игрок 1 или нет. Если игрок 1 выигрывает, тоRocksвыдаст. Если игрок 1 проигрывает, тоRocksвыдаст. Мы ввели искусственное начальное условие,, чтобы упростить псевдокод. Скопировать код1Rocks(n, m):2R(0,0) = L3fori from1to n:4ifR(i-1,0) = W:5R(i,0) = L6else:7R(i,0) = W8forj from1to m:9ifR(0,j-1) = W:10R(0,j) = L11else:12R(0,j) = W13fori from1to n:14forj from1to m:15ifR(i-1,j-1)=WandR(i,j-1)=WandR(i-1,j)=W:16R(i,j) = L17else:18R(i,j) = W19returnR(n,m) Более быстрый алгоритм для решения этой головоломки опирается на простую закономерность ви проверяет, чётныеиили нет. Если оба числа чётные, то игрок проигрывает (см. таблицу выше). Скопировать код1FastRocks(n, m):2ifn %2==0andm %2==0:// оба числа чётные3returnL4else:5returnW Тем не менее, хотяFastRocksи эффективнее, чемRocks, изменить его для схожих вариантов игры может быть сложно. Например, вариант, в котором игрок может убирать до трёх камней из наборов. Перед нами пример того, как более медленный алгоритм может быть полезнее, чем быстрый.",
    "source_type": null,
    "useful_links": [
      {
        "text": "рис.",
        "url": "#Placeholder-1-6"
      },
      {
        "text": "рис. (a)",
        "url": "#Placeholder-1-6"
      },
      {
        "text": "рис. (b)",
        "url": "#Placeholder-1-6"
      },
      {
        "text": "рис. (c)",
        "url": "#Placeholder-1-6"
      },
      {
        "text": "рис. (d)",
        "url": "#Placeholder-1-6"
      },
      {
        "text": "рис. (e)",
        "url": "#Placeholder-1-6"
      }
    ]
  },
  {
    "document_title": "Динамическое программирование - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dinamicheskoe-programmirovanie",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как динамическое программирование помогает ускорять решение задач за счёт переиспользования уже найденных ответов. Вы научились формулировать подзадачи, заполнять таблицы и избегать лишних вычислений. Далее — рекурсивные алгоритмы. Мы разберём, как строить решение через самого себя, почему рекурсия бывает полезной и когда она может привести к проблемам. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Динамическое программирование позволяет решать задачи быстрее за счёт повторного использования подзадач. Вместо того чтобы пересчитывать, мы сохраняем уже найденные решения и используем их повторно. Метод особенно полезен, когда подзадачи пересекаются и их много. Иногда универсальный, но медленный алгоритм оказывается практичнее, чем быстрый, но узкоспециализированный.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/79927"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Словарь - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/slovar",
    "section_title": "Определения словаря",
    "text": "Следующей структурой данных, которую мы рассмотрим, будет словарь (map, dictionary), или так называемый ассоциативный массив, позволяющий хранить пары вида «ключ — значение». Ключ — уникальный идентификатор, а значение может быть любой объектной переменной, включая другие структуры данных. Например, списки или другие словари. Ключи и значения могут выводиться в различном порядке, потому что словари не упорядочены. Аналогично множеству, у словаря существует мультисловарь (multimap), который позволяет хранить несколько элементов с одинаковым ключом. Посмотрите на примеры ниже. Довольно часто словари реализуют с использованием хеш-таблиц. Говоря об асимптотической сложности операций со словарём, будем иметь ввиду реализацию на хеш-таблицах. Основные операции со словарем и их асимптотическая сложность: Добавление нового элемента с уникальным ключом —. Удаление элемента по ключу —. Изменение значения по ключу —. Получение значения по ключу —.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Словарь - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/slovar",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как устроен словарь, и умеете использовать его для хранения данных, связанных с уникальными ключами, и быстрого поиска по этим ключам. Вы познакомились с операциями вставки, удаления, изменения и извлечения значений. Следующий шаг — дек (двусторонняя очередь). В отличие от обычной очереди, здесь можно добавлять и удалять элементы как с начала, так и с конца. Вы увидите, как дек сочетает свойства очереди и стека и где именно такая гибкость оказывается особенно полезной. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Словарь хранит пары «ключ — значение» и обеспечивает быстрый доступ по ключу. Большинство операций (добавление, удаление, поиск) выполняются за константное время при реализации через хеш-таблицу. Словари часто используют для подсчёта, группировки и хранения вложенных структур. Мультимапы позволяют хранить несколько значений для одного ключа.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80786"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Размен» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как работает жадный алгоритм в задаче про размен монет и чем он отличается от полного перебора? Почему важно обосновывать правильность жадных решений и как это сделать?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Размен» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen",
    "section_title": "Простой жадный алгоритм",
    "text": "Давайте реализуем простой жадный алгоритм, которым пользуются кассиры по всему миру. Предположим, что у кассира есть бесконечное количество монет всех номиналов. Входные данные: Целое число. Выходные данные: Минимальное количество монет номиналами,,, чтобы выдать сдачу. Ограничения:. . . Ограничение по времени (с): 1 секунда. Ограничение по памяти: 512 Mb. Рассмотрим основную идею решения. Пока сдача положительна, мы выбираем монету с самым большим номиналом, не превышающем, отнимаем значение номинала выбранной монеты оти увеличиваем количество монет: Скопировать код1Change(money):2numCoins =03whilemoney >0:4ifmoney >=10:5money = money −106elseifmoney >=5:7money = money −58else:9money = money −110numCoins = numCoins +111returnnumCoins Также эту задачу можно решить в одну строку: Скопировать код1returnfloor(money/10) +floor((money mod10)/5) + (money mod5) Проектировать жадные алгоритмы просто, но вот доказывать их правильность — нередко сложная задача. И возможно, вас интересует, почему мы тратим время, чтобы доказать работоспособность очевидного алгоритмаChange. Дождитесь, пока мы попадем в алгоритмическую ловушку, и она убедит вас, что доказательство ниже — не трата времени. Чтобы доказать, что этот жадный алгоритм работает правильно, мы покажем, что выбор монеты с самым большим номиналом соответствует некому оптимальному решению. То есть нам нужно доказать, что для каждого положительного целого числасуществует оптимальный способ выдать сдачу с, который использует как минимум одну монету с номиналом, где— самое большое число из, не превышающее. Чтобы доказать это, мы рассмотрим несколько примеров. В каждом из примеров мы выбираем оптимальное решение (то есть конкретную сдачу с) и преобразовываем его так, что количество монет не увеличивается и содержит как минимум одну монету с номиналом. Мы также получаемспособ выдать сдачу с, который содержит монету, если начинаем сподхода к сдаче. . В этом случае, и единственный способ выдать сдачу с— это использоватьмонет номиналом 1. . В таком случае. Безусловно, любая сдача с money будет состоять только из монет с номиналами 1 и 5. Если в неё не входит монета с номиналом 5, то входят как минимум пять монет номиналом 1 (так как). Заменив их на одну монету номиналом 5, мы улучшим это решение. . В таком случае. Рассмотрим способ выдать сдачу си предположим, что в нём не используется монета номиналом 10. Простое, но важное замечание: сумма некой подгруппы использованных монет — 10. Это можно продемонстрировать, рассмотрев количество монет номиналом 5 в данном решении: если таких монет нет, тогда есть как минимум десять монет номиналом 1, и мы заменяем их на одну 10; если есть лишь одна монета номиналом 5, тогда есть как минимум пять монет по 1, и мы снова заменяем все монеты на одну монету номиналом 10; если есть хотя бы две монеты по 5, тогда их снова можно заменить. Хотя это доказательство длинное и довольно скучное, каждый раз, когда вы придумываете жадный алгоритм, вам нужно доказательство! Следующее упражнение показывает более компактный способ доказать правильность алгоритма выше. Продемонстрируйте, что money mod 5 монет номиналом 1 необходимы для любого решения, а остальные следует заменить монетами номиналами 10 и максимум одной монетой номиналом 5. Время выполнения.Время выполнения алгоритмаChange—, но его однострочная версия требует лишь несколько арифметических операций.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Размен» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как устроена жадная стратегия и как она работает в задаче размена. Вы увидели, что можно принимать решения, не заглядывая вперёд, — и при этом получить оптимальный результат. А ещё убедились, что даже простая стратегия требует проверки и не всегда даёт правильный ответ. Далее — новая задача: как выбрать самые ценные предметы, если ресурсы ограничены. Здесь используется жадный отбор по плотности: ценность на единицу веса или объёма. Вы познакомитесь с жадным отбором по плотности и научитесь использовать этот подход, когда важно получить максимум от доступного. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный алгоритм принимает решение на каждом шаге, выбирая наиболее выгодный вариант здесь и сейчас. В задаче размена такая стратегия работает, если номиналы монет удовлетворяют определённым условиям. Даже для простых на вид задач важно доказывать корректность жадного подхода, а не полагаться на интуицию. Жадные алгоритмы просты и быстры, но требуют проверки: в некоторых задачах они могут давать неверный результат.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80765"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Рандомизированные алгоритмы - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/randomizirovannye-algoritmy",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Что такое рандомизированные алгоритмы и как они работают? В чём разница между худшим и ожидаемым временем выполнения? Зачем алгоритмам случайность и когда она даёт преимущество?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Рандомизированные алгоритмы - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/randomizirovannye-algoritmy",
    "section_title": "Что такое рандомизированные алгоритмы",
    "text": "Если у вас есть монетка, то прежде чем начать искать телефон, вы можете подбросить её и решить, откуда начать поиск: если выпадет решка, то сначала ищем на первом этаже, если орёл — на втором. А для выбора конкретной комнаты можно использовать игральный кубик. Хотя бросать монеты и кубики весело, этот подход однозначно не интуитивен. К тому же непонятно, даёт ли это алгоритмическое преимущество по сравнению с детерминированным алгоритмом. Наши задачи помогут разобраться, в каких ситуациях вероятностные алгоритмы будут лучше детерминированных. Чтобы продемонстрировать пример вероятностного алгоритма, обсудим сначала быстрый метод сортировки, который называетсяQuickSort. Для упрощения будем считать, что все элементы данного массиваразные. QuickSortвыбирает элемент(например, первый) изи просто разделяет массив на два подмассива:, в который входят все элементыменьше; и, в который входят все элементы больше. Это разделение можно выполнить за линейное время, далее, следуя стратегии «разделяй и властвуй»,QuickSortрекурсивно сортирует каждый подмассив. Итоговый отсортированный список может быть легко получен с помощью конкатенации отсортированного, элементаи отсортированного. Скопировать код1QuickSort(c):2if|c| =1:// только один элемент3returnc4m = c[1]// возьмем первый элемент c5// определим элементы c_small меньше m6// определим элементы c_large больше m7QuickSort(c_small)8QuickSort(c_large)9// объединим c_small, m и c_large в сортированный список c_sorted10returnc_sorted Для данного подхода требуется выделить дополнительную память, в которой будут храниться массивыи. Лучший подход — переставить элементы входного массива на месте, чтобы наборшёл первым, затем, а затем(см. ниже) — однако неясно, как это сделать. Нико Ломуто предложил изящный алгоритм, позволяющий выполнить такую перестановку элементов на месте. Рисунок ниже показывает, как работает разбиение Ломуто. Посмотрите на рисунок. Сможете ли вы воссоздать логику подхода Ломуто? Оказывается, что время выполненияQuickSortзависит от нашей удачи при отборе элемента. Если мы выберемтак, что массивразделяется на две равные части (то есть), тогда гдеозначает время, которое требуетсяQuickSortдля сортировки массива изчисел, иозначает время, которое потребуется для разделения массива длинына две части;— положительная константа. Это абсолютно такое же рекуррентное соотношение, как и вMergeSort, соответствующее времени выполнения. Тем не менее если мы выберемтак, чторазделится неровно (например, возникает крайний случай, когда наборпуст, а в набореэлементов), тогда рекуррентное соотношение будет Это соотношение и приводит к времени выполнения, а этого мы пытаемся избежать. Сортировка массивас помощьюQuickSortдействительно занимает квадратичное время. Что ещё хуже, на обработкутребуется время. Это выглядит излишним, ведь массив уже отсортирован. Пока что алгоритмQuickSortпохож на плохую имитациюMergeSort. Однако если мы сможем выбрать хороший «разделитель», который разбивает массив на две равные части, мы сможем улучшить время выполнения. На самом деле, не обязательно пытаться достичь идеального разделения (50/50), чтобы получить время выполнения. Например, также подойдет разделение на примерно равные части (скажем, 51/49). Фактически можно доказать, что алгоритм будет иметь время выполненияпри условии, что оба набораибольше, чем. Из этого следует, что извозможных вариантов для, выбранного в качестве элементов массива, как минимумхорошо подойдут для разделения! Другими словами, если мы возьмемслучайным образом (вероятность выбрать любой из элементоводинакова), то у нас будет шанс 50% получить хорошее разделение. Такой вывод ложится в основу следующего вероятностного алгоритма: Скопировать код1RandomizedQuickSort(c):2if|c| =1:// только один элемент3returnc4m = ...// возьмем случайный элемент из c5// определим элементы c_small меньше m6// определим элементы c_large больше m7RandomizedQuickSort(c_small)8RandomizedQuickSort(c_large)9// объединим c_small, m и c_large в сортированный список c_sorted10returnc_sorted На практикеRandomizedQuickSort— это быстрый алгоритм. Однако его худшее время выполнения остается, так как все еще есть вероятность, что он выберет плохой разделитель. При одном и том же вводе поведение вероятностного алгоритма отличается от одного выполнения к другому. Тем не менее мы можем доказать, что его ожидаемое время выполнения —. Слово «ожидаемое» подмечает следующий эффект. Так какRandomizedQuickSort— это вероятностный алгоритм, два разных запуска (при одинаковом вводе) могут занять разное количество времени: некоторые будут быстрыми, некоторые — медленными. Таким образом, время выполнения вероятностного алгоритма — это случайная величина. Разработчики нередко интересуются средним значением этой случайной величины, что и называется ожидаемым временем выполнения. Можно продемонстрировать, что для каждого массива размером вожидаемое время выполненияRandomizedQuickSortбудет.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Рандомизированные алгоритмы - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/randomizirovannye-algoritmy",
    "section_title": "Преимущество вероятностных алгоритмов",
    "text": "Главное преимущество вероятностных алгоритмов — это производительность. Вероятностные алгоритмы решают многие реальные задачи быстрее (с точки зрения ожидаемого времени выполнения), чем детерминированные алгоритмы. Еще одна привлекательная особенность — это их простота. Она демонстрируется, например, вRandomizedQuickSort. Мы подчеркиваем, что хотяRandomizedQuickSortи принимает решения случайным образом, он всегда выдаёт правильное решение задачи сортировки. Единственный изменяющийся параметр от одного прогона к другому — это время выполнения, но не результат. В противоположность этому, другие вероятностные алгоритмы обычно приводят к неправильным (или точнее, приблизительным) решениям. Вероятностные алгоритмы, которые всегда дают верные решения, называются «Лас-Вегас». Алгоритмы, которые не приводят к верным решениям — «Монте-Карло».",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Рандомизированные алгоритмы - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/randomizirovannye-algoritmy",
    "section_title": "Что дальше",
    "text": "Теперь вы познакомились с разными подходами к построению алгоритмов — от рекурсии до динамического программирования, от «Разделяй и властвуй» до рандомизированных стратегий. Вы научились оценивать, насколько эффективен алгоритм, и выбирать подходящий метод в зависимости от задачи. В следующем параграфе мы подведём итоги и сравним основные стратегии: где срабатывает жадность, где помогает случайность, а где лучше хранить промежуточные результаты. Это поможет вам научиться видеть за конкретной задачей типовую структуру — и сразу подбирать подходящий алгоритм. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Рандомизированные алгоритмы используют случайность для ускорения решения задач. Алгоритм RandomizedQuickSort в среднем работает за O(n log n), хотя в худшем случае даёт O(n²). Ожидаемое время выполнения может быть надёжным ориентиром, даже если поведение алгоритма меняется от запуска к запуску.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/79936"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Алгоритм нахождения компонент связности в графе - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algoritm-nahozhdeniya-komponent-svyaznosti-v-grafe",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Что именно называют компонентой связности в неориентированном графе? Как применить DFS и BFS, чтобы выделить все компоненты? Зачем обход нужно запускать от каждой непосещённой вершины?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Алгоритм нахождения компонент связности в графе - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algoritm-nahozhdeniya-komponent-svyaznosti-v-grafe",
    "section_title": "Применение алгоритмов поиска в глубину и ширину",
    "text": "Алгоритмы поиска в глубину и ширину находят широкое применение и могут использоваться в других алгоритмах. Рассмотрим один из таких алгоритмов для поиска компонент связности в графе. Под компонентой связности в графе понимают множество вершин графа достижимых попарно и рёбра их связывающие. Для поиска компонент связности необходимо из каждой не посещённой вершины запускать алгоритм обхода, накапливая результаты каждого в отдельный контейнер. Пример ниже поможет понять алгоритм. Асимптотическая сложность нахождения компонент связности в графе — O(V+E), где V — число вершин, а E — число рёбер и дуг. Попробуйте реализовать данный алгоритм.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Алгоритм нахождения компонент связности в графе - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algoritm-nahozhdeniya-komponent-svyaznosti-v-grafe",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете находить компоненты связности в графе и применять для этого DFS или BFS. Вы поняли, почему одного обхода недостаточно и как обойти весь граф по частям. Далее — более сложные задачи, в которых нужно находить кратчайшие пути между вершинами. Вы узнаете, как работает алгоритм Дейкстры и в каких ситуациях его можно применять. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Компоненты связности — это группы вершин неориентированного графа, внутри которых существует путь между любыми двумя вершинами. Чтобы найти все компоненты, используют обход графа: в глубину (Depth-First Search, DFS) или в ширину (Breadth-First Search, BFS), начиная каждый раз с новой не посещённой вершины. Важно правильно отмечать посещённые вершины и учитывать номер компоненты, к которой они принадлежат. Выделение компонент связности помогает понять структуру графа и служит основой для последующего анализа и алгоритмов кластеризации.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80792"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Рекурсивные алгоритмы - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/rekursivnye-algoritmy",
    "section_title": "Ключевые вопросы параграфа",
    "text": "В чём сила и в чём слабость рекурсии по сравнению с итеративным подходом? Как разложение задачи на подзадачи помогает описывать решения? Что показывает пример «Ханойских башен» о возможностях и ограничениях рекурсивных алгоритмов?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Рекурсивные алгоритмы - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/rekursivnye-algoritmy",
    "section_title": "Что такое рекурсия",
    "text": "Рекурсия — одно из самых распространенных алгоритмических понятий. Если говорить просто, то рекурсивным алгоритм становится, если вызывает сам себя. Головоломка «Ханойские башни» состоит из трёх стержней, пронумеруем их слева направо: 1, 2 и 3. Также в головоломке используется стопка дисков с отверстием посередине. Радиус дисков уменьшается снизу вверх. Изначально диски расположены на левом стержне (стержень 1), самый большой диск находится внизу. Диски в игре перемещаются по одному со стержня на стержень. Диск можно надеть на стержень, только если он пустой или верхний диск на нём большего размера, чем перемещаемый. Цель головоломки — перенести все диски со стержня 1 на стержень 3. Попробуйте нашу интерактивную версию «Ханойских башен» и узнайте, как переместить все диски с одного стержня на другой. Вывод списка действий, необходимых для решения головоломки «Ханойские башни». Входные данные: Целое число. Выходные данные: Последовательность ходов для решения головоломки «Ханойские башни» издисков. Решить головоломку с одним диском легко — просто переместите его на правый стержень. Головоломка на два диска ненамного сложнее. Сначала нужно переместить маленький диск на стержень посередине, а большой — на стержень справа. Затем переместить маленький диск на большой на правом стержне. Версия на три диска чуть сложнее, но и ее можно решить с помощью следующих семи шагов: Переместить диск со стержня 1 на стержень 3 Переместить диск со стержня 1 на стержень 2 Переместить диск со стержня 3 на стержень 2 Переместить диск со стержня 1 на стержень 3 Переместить диск со стержня 2 на стержень 1 Переместить диск со стержня 2 на стержень 3 Переместить диск со стержня 1 на стержень 3 Теперь давайте посчитаем, сколько шагов потребуется для решения версии на четыре диска. Нам нужно обязательно переместить самый большой диск, но для этого придётся сперва поместить все остальные диски на пустой стержень. Если у нас не три диска, а четыре, то нужно переложить три верхних диска на пустой стержень (7 действий), а затем переместить самый большой диск (1 действие). Теперь нужно снова переместить три диска с «временного» стержня на самый большой диск (еще 7 действий). Весь процесс будет состоять издействий. Чтобы переместитьдисков с левого стержня на правый, сначала необходимо переместитьдисков на стержень посередине. Затем, когда диск под номером, самый большой, оказывается на правом стержне, нужно переместить на него оставшиеся диски со стержня посередине. Чтобы переместитьдисков со стержня посередине направо, нужно сначала переместитьдисков на стержень слева, затем переместить-й диск вправо, потом переместитьдисков с левого стержня на правый и так далее. На первый взгляд задача «Ханойские башни» может показаться сложной. Тем не менее данный рекурсивный алгоритм находит нужные перемещения дисков всего за 8 строк! Скопировать код1HanoiTowers(n,fromPeg,toPeg)2ifn =1:3output “Move disk from peg fromPeg to peg toPeg”4return5unusedPeg =6- fromPeg - toPeg6HanoiTowers(n−1,fromPeg,unusedPeg)7output “Move disk from peg fromPeg to peg toPeg”8HanoiTowers(n−1,unusedPeg,toPeg) Переменныеиуказывают на три разных стержня. Таким образом,HanoiTowers(n, 1, 3)перемещает диски (шт.) с первого стержня на третий. Переменнаяуказывает, какой из трёх стержней можно использовать для временного хранения первых () дисков. Обратите внимание, чтовсегда равняется. Таким образом, значение переменнойможно определить как. Представленная таблица показывает результатыдля всех возможных переменныхи. Определивкак, операторы выполняют более простую задачу: они сначала перемещаютдисков на временный стержень, затем перекладывают большой диск, а потом складывают на него оставшиесядисков. Скопировать код1HanoiTowers(n−1,fromPeg,unusedPeg)2output “Move disk from peg fromPeg to peg toPeg”3HanoiTowers(n−1,unusedPeg,toPeg) Обратите внимание, что нет необходимости указывать, какой диск игрок должен переложить сна: перемещается всегда тот диск, что является верхним на. Хотя решение Ханойских башен можно уложить в 9 строк псевдокода, его выполнение займет на удивление много времени. Решение головоломки на пять дисков состоит из 31 действия. А в решении башни из сотни дисков количество действий будет исчисляться “страшными” нонилионами. Такое резкое увеличение числа действий дляHanoiTowersнеудивительно. Заметим, что каждый раз, когда вызываетсяHanoiTowers(n, 1, 3), алгоритм дважды вызывает сам себя для перемещениядисков, что запускает четыре вызова для перемещениядисков и так далее. Это можно проиллюстрировать с помощью рекурсивного дерева, изображенного нарис.. ВызовHanoiTowers(4, 1, 3)приводит к вызовамHanoiTowers(3, 1, 2)иHanoiTowers(3, 2, 3); каждый из них вызываетHanoiTowers(2, 1, 3),HanoiTowers(2, 3, 2)иHanoiTowers(2, 2, 1),HanoiTowers(2, 1, 3)и так далее. Каждый вызов подпрограммыHanoiTowersзанимает определенное время. Мы хотим узнать, сколько времени уйдёт на такой алгоритм. Чтобы вычислить время выполненияHanoiTowersразмера, мы введём в рассмотрение функцию— количество перемещений дисков, которые выполняетHanoiTowers(n). Получается следующее уравнение: Начиная с, это рекуррентное соотношение задаёт последовательность: и так далее. Мы можем вычислить, прибавив 1 с обеих сторон и обнаружив, что Если мы введём новое обозначение,, то. Таким образом, нужно решить следующее рекуррентное соотношение: Начиная с, получаем последовательность То есть,и. Следовательно,HanoiTowers(n)— экспоненциальный алгоритм.",
    "source_type": null,
    "useful_links": [
      {
        "text": "рис.",
        "url": "#Placeholder-1-15"
      }
    ]
  },
  {
    "document_title": "Рекурсивные алгоритмы - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/rekursivnye-algoritmy",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как работает рекурсия и почему она может быть мощным инструментом для построения алгоритма. Вы научились разбивать задачу на шаги, каждый из которых решается тем же способом, что и вся задача целиком. Далее — алгоритмы «Разделяй и властвуй». Мы разберём, как делить задачу на независимые части, решать каждую по отдельности и собирать общее решение. Вы увидите, как этот подход ложится в основу быстрой сортировки и других эффективных алгоритмов. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Рекурсия — это подход, при котором функция вызывает саму себя для решения подзадачи. Чтобы рекурсивное решение работало, важно определить базовый случай и убедиться, что каждый шаг приближает нас к нему. Задача «Ханойские башни» — классический пример, в котором рекурсивная стратегия описывает процесс из десятков или сотен шагов с минимальным кодом. Количество операций в рекурсивных алгоритмах может расти экспоненциально — это важно учитывать при выборе метода решения задачи.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/79930"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Размен 2» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen-2",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Почему жадный алгоритм не справляется с задачей оптимальной сдачи? Как составить рекуррентное соотношение для минимального числа монет? В чём отличие мемоизации от табличного (bottom-up) подхода? Как реализовать решение задачи с помощью динамического программирования?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Размен 2» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen-2",
    "section_title": "Сдача",
    "text": "Как нам уже известно, естественный «жадный» подход к этой задаче работает неправильно при любом наборе номиналов. Например, при номиналах,и«жадный» алгоритм разменяетцентов тремя монетами (), хотя это возможно сделать всего лишь двумя (). Ваша цель — использовать динамическое программирование для решения задачи «Сдача» с номиналами,и. Входные данные: Целое число. Выходные данные: Минимальное количество монет номиналами,,, чтобы выдать сдачу с. Ограничения:. . Для оптимального варианта сдачи снеобходимо семь монет. Рассмотрим произвольный поднабор оптимального решения — например, если сложить четыре монеты из приведённого ниже прямоугольника, то получится. Такая ситуация показывает нам важную особенность динамического программирования — решение задачи содержит решения всех её мелких подзадач. Эта особенность позволяет найти решение задачи, сначала выполняя мелкие подзадачи. Пусть— это минимальное количество монет номиналами,и, которые нужны для сдачи с, а— оптимальная сдача с. В таком случае Тогда Следовательно,. Таким образом, для решения задачи придостаточно решить её прии добавить единицу. Тем не менее мы знаем, чторавняется или, или, или. Такравно одному из следующих вариантов:,и. Так как мы ищем оптимальный способ выдать сдачу,равно минимальному из этих трёх выражений. В итоге мы получаем следующее рекуррентное соотношение: При небольших аргументах это соотношение выражает значениерекурсивным образом через собственные значения. Для такой нисходящей рекурсии нам необходимо указать базовый случай. У нас это будет:. Уравнение выше — самая важная часть алгоритма динамического программирования, так как из него легко сделать рекурсивный алгоритм. Скопировать код1Change(money):2ifmoney=0:3return04else:5result = +infinity6forc=1,3,4:7ifc <= money:8result =min(result,1+Change(money-c))9returnresult У этого алгоритма есть серьёзная проблема: он становится крайне медленным, потому что вызываетChange(money)снова и снова для одного и того же значения. Мемоизация — стандартный способ избежать этого: при вычисленииChange(money)мы можем использовать сохранение в таблице и тогда нам не придётся делать перевычисление. Скопировать код1table=associative array23Change(money):4iftable[money] isnotyet computed:5ifmoney=0:6table[money]←07else:8result = +infinity9forc=1,3,4:10ifc <= money:11result =min(result,1+Change(money-c))12table[money] = result13returntable[money] На практике такой алгоритм уже достаточно хорош, хотя у него есть проблемы с эффективностью: рекурсивные вызовы и уточняющие запросы для ассоциативного массива приводят к замедлению. Заметив, что все вычисляемые значения — это последовательные целые числа, мы можем реализовать улучшенный подход, в котором используется массив для хранения решений всех задач. Скопировать код1Change(money):2table[0..money] = [+infinity,…,+infinity]3table[0] =045form from1to money:6forc=1,3,4:7ifc <= m:8table[m] =min(table[m],1+table[m-c])9returntable[money] Время выполнения этого алгоритма составляет, так как каждая итерация внешнего циклаforпроходит за постоянное время.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Размен 2» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-razmen-2",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете использовать динамическое программирование для нахождения оптимального числа монет при сдаче. Вы поняли, почему жадный подход может давать неверный результат, научились строить рекурсивные решения с мемоизацией и ускорять их с помощью таблицы. А ещё увидели, что даже простая задача может быть связана с кратчайшими путями в графах. Далее — задача на построение выражения с минимальной стоимостью вычислений. Вы научитесь определять порядок операций, который экономит ресурсы, и познакомитесь с динамическим программированием на интервалах. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный подход может давать неоптимальные решения в задаче размена. Динамическое программирование позволяет учитывать все варианты и выбирать наилучший. Рекурсия с мемоизацией помогает избежать повторных вычислений, но может быть медленной. Табличный (bottom-up) подход эффективнее и позволяет решать задачу за линейное время. Такие задачи часто можно представить как поиск кратчайшего пути в графе.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80777"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Подсчет инверсий - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/podschet-inversij",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Что такое инверсии и как их находить? Почему перебор всех пар работает медленно и как это ускорить? Как работает алгоритм подсчёта инверсий на основе сортировки слиянием?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Подсчет инверсий - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/podschet-inversij",
    "section_title": "Количество инверсий в последовательности",
    "text": "Количество инверсий в последовательности — показатель того, насколько последовательность отсортирована. Например, в неубывающей последовательности не будет инверсий, а последовательность в порядке убывания содержитинверсий (каждые два элемента образуют инверсию). Решая задачу «Количество инверсий», примитивный алгоритм просматривает все возможные пары, что требует времени выполнения. Чтобы решить эту задачу за времяс помощью алгоритма «разделяй и властвуй», мы разделяем вводный массив на две половины и делаем рекурсивный вызов обоих из них. Остаётся только вычислить количество инверсий, которые образованы двумя элементами из разных частей. Если делать это примитивным образом, то мы снова придём к времени выполнения, так как общее количество таких пар составляет. Оказывается, что если обе части уже отсортированы, количество инверсий из элементов разных половин можно вычислить за время. Это подсказывает нам, что вместо решения изначальной задачи, нам стоит решить более общую: вычислить количество инверсий в заданном массиве и в то же время отсортировать его. Измените алгоритмMergeSortдля решения этой задачи. Формат ввода: Первая строка содержит целое число, следующая — последовательность целых чисел. Формат вывода: Количество инверсий в последовательности. Ограничения:,для всех. В примере две инверсии:() и(). Совет: используйте полуоткрытые интервалы для рекурсивных реализаций Попробуем использовать самый распространённый подход к методу «разделяй и властвуй»: разделим вводную последовательность на две половины,LeftHalfиRightHalf, и выполним рекурсивный вызов для каждой. Это позволит нам вычислить все инверсии, находящиеся в одной и той же половине. Однако это не подскажет нам количество разделённых инверсий, то есть количество пар, при которыхнаходится в левой половине,находится в правой, а. Даны массиви целое число. Пустьбудет количеством элементов, которые меньше. Так как ответ на вопрос выше — это, наша задача заключается в том, чтобы быстро вычислить. Таким образом, мы приходим к следующей задаче: имея последовательность целых чисели целое число, нам нужно найти вколичество элементов, которые меньше. В случае неотсортированного массива это можно сделать за время, так как необходимо проверить каждый элемент массива. В варианте же отсортированного за время, если использовать двоичный поиск. Продемонстрируйте, как реализовать методCountSmaller(List, x)для подсчёта количества элементовсо значением меньшеза время. Так мы приходим к следующему алгоритму «разделяй и властвуй». Скопировать код1CountInversions(List):2if∣List∣ <=1:3return04inversions =05// в случае нечётной длины6// центральный элемент может быть и слева, и справа7LeftHalf = левая половина List8RightHalf = правая половина List9inversions = inversions +CountInversions(LeftHalf)10inversions = inversions +CountInversions(RightHalf)11sort(RightHalf)// необходимо для двоичного поиска12forx in LeftHalf:13inversions = inversions +CountSmaller(RightHalf,x)14returninversions Время выполнения(где— длина) удовлетворяет рекуррентному соотношению Слагаемоевключает в себя два шага: сортировкуи ответ назапросовCountSmaller. Эту рекуррентное соотношение нельзя напрямую вставить в основную теорему о рекуррентных соотношениях, так как элементне имеет формупри константе. Однако мы можем проанализировать её таким же образом: рекурсивное дерево содержитуровней, общий размер всех задач на каждом уровне равен, а общее затраченное время на каждом уровне составляет. В итоге общее время выполнения составляет. Вместо того, чтобы формально это доказывать, мы улучшим вышеприведённый алгоритм так, чтобы он затрачивал время. Можно быстро найти все разделённые инверсии, если наряду с подсчётом инверсий сортировать входную последовательность. То есть можно предположить, что алгоритмCountInversionsAndSort(List)возвращает количество инверсий ви сортирует. После двух рекурсивных вызовов обе половиныотсортированы. На данном этапе нам нужно сделать две вещи: отсортировать всю последовательностьи вычислить количество разделённых инверсий. Мы уже знаем, как достичь первой цели: этим занимается процедура. Это выглядит следующим образом.Пустьибудут первыми элементами отсортированных последовательностейи. Далее выбирается самый маленький из них и перемещается в увеличивающийся отсортированный список. Рассмотрим два случая. . В этом случаене больше каждого элемента, и поэтому не образует разделённых инверсий. . В этом случаеменьше всех элементов, и поэтому образует разделённую инверсию с каждым из них. Это приводит нас к следующему расширению методаMerge. Скопировать код1Merge(LeftHalf, RightHalf):2SortedList = empty list3inversions =04whileboth LeftHalfandRightHalf are non-empty:5l = первый элемент LeftHalf6r = первый элемент RightHalf7ifl <= r:8переместить l в SortedList9l = следующий элемент в LeftHalf10else:11переместить r в SortedList12r = следующий элемент в RightHalf13// учитываются только не перемещенные элементы14inversions = inversions + ∣LeftHalf∣15добавить все оставшиеся элементы LeftHalf и RightHalf в SortedList16returnSortedList, inversions И окончательная версия алгоритмаCountInversions. Скопировать код1CountInversions(List):2// список List будет отсортирован3if∣List∣ <=1:4return05LeftHalf = левая половина List6RightHalf = правая половина List7leftInv =CountInversions(LeftHalf)8rightInv =CountInversions(RightHalf)9List, splitInv =Merge(LeftHalf, RightHalf)10returnleftInv + rightInv + splitInv",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Подсчет инверсий - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/podschet-inversij",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете находить количество инверсий в массиве с помощью модифицированной сортировки. Вы увидели, как объединять рекурсивное деление с анализом данных и использовать «побочные эффекты» сортировки для аналитических целей. Далее — последняя задача главы: вы узнаете, как найти пару ближайших точек на плоскости за, используя те же идеи — сортировку, деление и точный контроль над шагами объединения. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Инверсии — это пары элементов в неправильном порядке:и. Полный перебор всех пар даёт сложность, но можно улучшить до, используя сортировку слиянием. Во время слияния двух отсортированных частей можно одновременно считать количество инверсий. Такой подход позволяет комбинировать сортировку и подсчёт статистик за одно и то же время.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80775"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Очередь с приоритетом - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/ochered-s-prioritetom",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как работает очередь с приоритетом и чем она отличается от обычной очереди? Какими способами можно реализовать очередь с приоритетом (массив, куча, дерево)? В каких алгоритмах и прикладных задачах применяется очередь с приоритетом?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Очередь с приоритетом - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/ochered-s-prioritetom",
    "section_title": "Определение очереди с приоритетом",
    "text": "Очередь с приоритетом — коллекция элементов, где каждый элемент имеет связанный с ним приоритет. Элемент с высшим приоритетом будет обрабатываться раньше, чем элементы с более низким приоритетом. Очередь с приоритетом можно реализовать различными способами, но обычно главные операции над ними: Вставка элемента с приоритетом — добавление элемента в очередь с учётом его приоритета. В зависимости от реализации, элемент может быть добавлен в начало, в середину очереди или конец. Извлечение элемента с наивысшим приоритетом — удаление элемента из очереди с наивысшим приоритетом. В зависимости от реализации, удаление может происходить из начала, середины очереди или конца. Просмотр элемента с наивысшим приоритетом — просмотр элемента с наивысшим приоритетом без его удаления. Поиск элемента с определённым приоритетом — поиск элемента в очереди с опредёленным приоритетом. Основные способы реализации очереди с приоритетом включают в себя использование массивов, связанных списков, бинарных куч и древовидных структур. В зависимости от реализации, каждый из этих способов имеет свои преимущества и недостатки в терминах времени выполнения операций.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Очередь с приоритетом - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/ochered-s-prioritetom",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как работает очередь с приоритетом и как выбирать её реализацию под конкретную задачу. Вы освоили базовые операции, поняли роль этой структуры в алгоритмах на графах (например, в алгоритме Дейкстры) и в задачах планирования. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Очередь с приоритетом позволяет обрабатывать элементы в порядке их важности, а не добавления. Для реализации чаще всего используется структура «куча», обеспечивающая логарифмическое время на добавление и удаление. Такая очередь используется во многих алгоритмах, например в поиске кратчайшего пути или планировании задач.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80788"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Множество - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Чем множество отличается от списка и в каких случаях его удобнее использовать? Как реализованы множества в разных языках — упорядоченные и неупорядоченные? Какие операции над множествами поддерживаются и в чём их сложность?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Множество - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
    "section_title": "Определение множества (set)",
    "text": "Следующей структурой данных, которую мы рассмотрим, будет множество (set). Множество представляет собой контейнер, содержащий неповторяющиеся элементы в произвольном порядке. Далее в данном параграфе мы будем разграничивать упорядоченные и неупорядоченные множества. Кроме того, существует такое понятие, как мультимножество (multiset), которое может включать в себя несколько одинаковых элементов. Вы можете посмотреть на различия между множеством и мультимножеством на рисунке ниже. Внутренняя реализация множества осуществляется различными способами, включая использование хэш-таблицы, бинарного дерева поиска и других алгоритмов. В данном параграфе мы сосредоточимся на функциях, которые можно производить со множеством, а не на внутренней его реализации. Основные операции со множеством: Добавление элемента в множество. Удаление элемента из множества. Проверка наличия элемента в множестве. Объединение двух множеств. Пересечение двух множеств. Разность двух множеств. Рассмотрим основные операции со множеством на примере двух языков С++ и Python. В STL языка С++ реализовано упорядоченное множество, в то время как в Python — неупорядоченное множество.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Множество - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
    "section_title": "Добавление элемента",
    "text": "Добавление элемента в множество можно произвести следующим образом. Скопировать код1my_set = {1,2,3}2my_set.add(2)3print(my_set)4my_set.add(4)5print(my_set) В результате исполнения фрагмента кода выше на экран будет выведено две строки: 1 2 3 и 1 2 3 4. Сложность операции добавления элемента во множество в Python —, так как множество не упорядочено и не нужно искать позиции для его вставки. В языке С++ добавление элемента может быть осуществлено следующим образом (не забудьте добавить #include <set >в начало вашего кода). Скопировать код1set <int>val = {6,10,5,1};2val.insert(6);3val.insert(10);4val.insert(2);5cout <<val.size(); В итоге на экран будет выведено 5. В случае реализации на С++ мы имеем дело с упорядоченным множеством, что накладывает дополнительные временные издержки. Асимптотическая сложность добавления элемента —.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Множество - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
    "section_title": "Удаление элемента",
    "text": "Не менее важной операцией является операция удаления элемента из множества. Скопировать код1set <int>val = {6,10,5,1};2val.erase(6)3cout <<val.size(); Благодаря фрагменту кода выше произошло удаление элемента, поэтому на экране появится число 3. Сложность операции удаления в упорядоченном множестве —. Рассмотрим удаление элемента из множества в Python: Скопировать код1my_set = {1,2,3}2my_set.remove(1);3print(len(my_set)) Размер множества после удаления элемента становится равным двум. Сложность операции удаления в неупорядоченном множестве —.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Множество - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
    "section_title": "Другие операции",
    "text": "Проверка наличия элемента в множестве предполагает просмотр элементов в нём. В случае неупорядоченного множества, реализованного на хэш-таблицах, сложность — О(1). Однако, при использовании упорядоченного множества сложность становится O(logn). Объединение множеств предполагает их слияние в единое множество. Например, пусть было два множества. Первое содержало элементы 1, 2 и 3, а второе 2, 3 и 4. В результате объединения получится множество, содержащее четыре элемента 1, 2, 3 и 4. Пересечение множеств представляет из себя поиск в двух множествах одинаковых элементов. Пусть первое множество содержит элементы 1, 2 и 3, а второе — 2, 3 и 4. Тогда пересечением множеств будут являться элементы 2 и 3. Разность двух множеств предполагает нахождение всех элементов из первого множества, за исключением тех, которые находятся во втором множестве. Пусть первое множество содержит элементы 1, 2 и 3, а второе — 2, 3 и 4. Тогда разностью множеств будет элемент 1.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Множество - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
    "section_title": "Упражнение",
    "text": "Поработайте с двумя множествами А = {1, 3, 4, 5, 6}, B = {1, 2, 4, 6, 8, 9}. Для данных множеств найдите объединение, пересечение и разность.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Множество - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/mnozhestvo",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете работать с множествами: добавлять и удалять элементы, проверять их наличие, объединять и находить пересечение. Вы узнали, что множества полезны, когда важна уникальность, а не порядок, и что разные реализации дают разную эффективность. Далее — структура, где каждому ключу сопоставлено значение. Вы познакомитесь со словарями, научитесь использовать ассоциативные массивы и узнаете, в чём их сила. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Множество — это структура, содержащая только уникальные элементы. В Python используется неупорядоченное множество, а в C++ — упорядоченное. Основные операции: добавление, удаление, проверка наличия, объединение и пересечение. Эффективность зависит от реализации: хеш-таблицы обеспечивают быстрые операции, но не сохраняют порядок.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80785"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Расстояние редактирования» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Что такое редакционное расстояние и как оно используется на практике? Как устроена рекурсивная формулировка задачи и почему мемоизация помогает? Как динамически находить расстояние между всеми префиксами двух строк? Как оптимизировать решение по памяти и находить выравнивание?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Расстояние редактирования» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
    "section_title": "Варианты применения задачи",
    "text": "Есть множество вариантов, как применить задачу «Расстояние редактирования». Она подойдёт для обработки текстов на естественном языке, проверки правописания и других направлений. К примеру, биологи зачастую вычисляют редакционное расстояние, когда ищут мутации, вызывающие болезни. Редакционное расстояние между двумя строками определяется как минимальное число односимвольных вставок, удалений и замен, необходимых для преобразования одной строки в другую. Входные данные:Две строки, состоящие из строчных букв латинского алфавита. Выходные данные:Редакционное расстояние между строками. Ограничения:Длина обеих строк не меньшеи не больше. Вторую строку можно получить из первой, удалив s, заменив h на p и вставив s. Это можно компактно продемонстрировать следующим выравниванием. Удалить e, вставить s после i, заменить i на a, заменить g на c, вставить e в конце. Совет: будьте осторожны с рекурсией. Рассмотрим решение задачи. Выравнивание двух строк в двухрядной матрице осуществляется таким образом, чтобы первый (второй) ряд содержал упорядоченные символы первой (второй) строки, которые перемежаются пробелами («»).В колонке не может быть два пробела одновременно в обеих строках.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Расстояние редактирования» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
    "section_title": "Упражнение",
    "text": "Вычислите количество разных пар выравненных строк длинойи. Мы классифицируем колонки выравнивания следующим образом (первый символ из верхней строки, второй — из нижней): — колонка с символом и пробелом — это удаление; — колонка с пробелом и символом — вставка; — колонка с двумя одинаковыми символами — совпадение; — колонка с двумя разными символами — это несоответствие. Мы ищем выравнивание, при котором минимизируется общее количество несоответствий, удалений и вставок. Выравнивание считается оптимальным по сравнению со всеми другими возможными вариантами, если оно содержит минимум несоответствий, удалений и вставок.Стоит обратить внимание, что может быть несколько различных оптимальных выравниваний.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Расстояние редактирования» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
    "section_title": "Упражнение",
    "text": "Докажите, что задача на редакционное расстояние может быть сведена к поиску оптимального выравнивания двух строк. В примере выше последняя колонка — это вставка. Отбросив эту колонку, мы получаем оптимальное выравнивание первой строки и префикса второй. Рассмотрим идею рассчитать редакционное расстояние между каждой парой префиксов двух строк. Это более общая постановка задачи, но важно отметить, что, решив её, мы найдём ответ и на интересующий нас вопрос. Имея строкии, мы рассмотрим их префиксыидлинойии обозначим их редакционное расстояние. Так как последняя колонка оптимального выравниванияи— это или вставка, или удаление, или несоответствие, или совпадение, имеем, Базовый случай для этого рекуррентного соотношения —и: Это можно выразить более кратко: еслиили, тогда Псевдокод ниже делает из этого рекуррентного соотношения рекурсивный алгоритм и использует мемоизацию для избежания перевычислений. Скопировать код1table = associative array23EditDistance(A,B,i,j):4iftable[i,j] isnotyet computed:5ifi=0orj=0:6table[i,j] =max(i,j)7else:8insertion =EditDistance(A,B,i,j−1)+19deletion =EditDistance(A,B,i−1,j)+110match =EditDistance(A,B,i−1,j−1)11mismatch =EditDistance(A,B,i−1,j−1)+112ifA[i]=B[j]:13table[i,j] =min(insertion,deletion,match)14else:15table[i,j] =min(insertion,deletion,mismatch)16returntable[i,j] Время выполнения этого алгоритма составляет, так как выполняется не большерекурсивных вызовов, которые добавляют значения вtable.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Расстояние редактирования» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
    "section_title": "Рекурсивный алгоритм",
    "text": "Рекурсивный алгоритм вычисляетдля всехи. Из рекурсивного алгоритма можно сделать итерационный, который будет сохранять решения всех подзадач в двумерной таблице. Таблица заполняется по рядам проходами. Это гарантирует, что когда мы вычислим значение клетки, значения клеток,ибудут уже готовы. Скопировать код1EditDistance(A[1…n],B[1…m]):2table =2d array ofsize(n+1) * (m+1)3table[0][j] = jforall i,j4fori from1to n:5forj from1to m:6insertion = table[i][j−1]+17deletion = table[i−1][j]+18match = table[i−1][j−1]9mismatch = table[i−1][j−1]+110ifA[i]=B[j]:11table[i][j] =min(insertion,deletion,match)12else:13table[i][j] =min(insertion,deletion,mismatch)14returntable[n][m] Итоговая таблица для нашего примера изображена на рисунке ниже. Значение каждой клетки вычисляется, исходя из значений соседних клеток сверху, слева и слева-сверху. У каждой клетки входящие стрелки указывают на один или несколько случаев (вставка, удаление, несоответствие, или совпадение), которые приводят к значению этой клетки. Таблица соответствует ориентированному ациклическому графу, в котором все рёбра, за исключением синих, имеют длину. А синие ребра соответствуют совпадающим символам и имеют длину. Алгоритм находит на графе самый короткий путь от узла слева сверху до узла справа снизу. Время выполнения алгоритма составляет. Ему требуетсяячеек памяти для хранения двумерного массиваtable. Расход места может быть снижен до(и даже до), если мы обратим внимание на то, что при заполнении текущего ряда таблицы нам нужны только клетки из текущего и предыдущего. Таким образом, вместо хранения всей таблицы достаточно сохранить текущий и предыдущие ряды. Отметим, что любой путь отдона рисунке образовывает оптимальное выравнивание строки. Путь, изображённый на рисунке ниже, соответствует оптимальному выравниванию editing и distance. Сколько в этом выравнивании вставок, удалений, совпадений и несоответствий? Постройте оптимальное выравнивание, соответствующее этому пути. Оптимальное выравнивание можно обнаружить с помощью перехода по стрелкам в обратную сторону от нижнего правого угла вдоль любого пути, приводящего к верхнему левому углу.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Расстояние редактирования» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstoyanie-redaktirovaniya",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете вычислять редакционное расстояние — минимальное число правок, необходимых для преобразования одной строки в другую. Вы поняли, как формулируется задача рекурсивно, как работает динамическое программирование с таблицей и даже как найти оптимальное выравнивание. Далее — задача на поиск наибольшей общей подпоследовательности (LCS). Вы увидите, как похожие идеи помогают решать другую важную задачу сравнения строк, и научитесь отличать LCS от редакционного расстояния. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Редакционное расстояние — это минимальное число вставок, удалений и замен для превращения одной строки в другую. Его можно вычислить с помощью динамического программирования, заполняя таблицу расстояний между префиксами. Переходы в таблице соответствуют операциям редактирования и дают кратчайший путь в сетке выравнивания. Можно восстановить оптимальное выравнивание, двигаясь по таблице в обратную сторону. Решение можно оптимизировать по памяти, если хранить только два ряда таблицы одновременно.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80779"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Обходы графа - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/obhody-grafa",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как работает обход графа в глубину и в ширину и в чём между ними разница? Что важно учитывать при реализации DFS и BFS? Как не попасть в бесконечный цикл и правильно отслеживать посещённые вершины?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обходы графа - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/obhody-grafa",
    "section_title": "Алгоритмы на графах",
    "text": "Пришла пора рассмотреть первые алгоритмы на графах. К классическим алгоритмам относятся обходы графов. Под обходом графа обычно понимают процесс систематического просмотра всех вершин или рёбер графа, чтобы найти некоторые вершины, удовлетворяющие определённым условиям. Мы рассмотрим обход в ширину и обход в глубину. Обход в глубину заключается в систематическом просмотре вершин графа и прохождении его ветвями. Иными словами, идея поиска в глубину — когда возможные пути по рёбрам, выходящим из вершин, разветвляются, нужно сначала полностью исследовать одну ветку и только потом переходить к другим веткам (если они останутся нерассмотренными). Опишем алгоритм поиска в глубину: Шаг 1. Все вершины графа отмечаем, как не посещенные. Выбирается первая вершина и помечается как посещённая. Шаг 2. Для последней помеченной как посещённой вершины выбирается смежная вершина, которая первая помеченная как не посещенная, и ей присваивается значение посещённой. Если таких вершин нет, то берётся предыдущая помеченная вершина. Шаг 3. Повторяем шаг 2 до тех пор, пока все вершины не будут помечены как посещённые. Пример реализации приведён ниже. Скопировать код1DFS(graph, v, used):2used[v] =13for(var u : graph[v])4if(!used[u])5DFS(graph, u, used) Попробуйте выполнить алгоритм поиска в глубину пошагово для графа. Обратите внимание, сейчас мы посмотрели на рекурсивную реализацию. Конечно, преимущество использования рекурсивного подхода заключается в простоте его написания, однако, рекурсивный подход имеет свои ограничения. Можно переписать алгоритм поиска в глубину с использованием особых структур данных. Например, стека. Опишем алгоритм поиска в глубину в нерекурсивной форме: Шаг 1. Все вершины графа отмечаем, как не посещённые. Выбирается первая вершина и помечается как посещённая. Эту вершину кладем в контейнер — стек. Шаг 2. Пока стек не пустой:Извлекаем последнюю добавленную вершину.Просматриваем все смежные с ней не посещённые вершины и помещаем их в стек.Порядок выхода вершин из стека и будет порядком обхода вершин графа. Извлекаем последнюю добавленную вершину. Просматриваем все смежные с ней не посещённые вершины и помещаем их в стек.Порядок выхода вершин из стека и будет порядком обхода вершин графа. Пример работы не рекурсивного алгоритма можно посмотреть на анимации. Пример реализации приведён ниже. Скопировать код1DFS(graph, v, used):2stack q3q.push(v)4used[v] =15while(!q.empty())6v = q.front()7q.pop()8for(var to : graph[v]):9if(!used[to]):10used[to] =true11q.push(to) Ещё один способ обхода графа — обход в ширину. Основное его отличие в том, что сначала исследуются смежные вершины, а уже потом вершины на следующем уровне. Иначе говоря, сначала исследуются все вершины, смежные с начальной вершиной (вершина с которой начинается обход). Эти вершины находятся на расстоянии 1 от начальной. Затем исследуются все вершины на расстоянии 2 от начальной, затем все на расстоянии 3 и так далее. Обратим внимание, что при этом для каждой вершины сразу находятся длина кратчайшего маршрута от начальной вершины. Опишем алгоритм поиска в ширину: Шаг 1. Всем вершинам графа присваивается значение не посещённой. Выбирается первая вершина и помечается как посещённая и заносится в очередь. Шаг 2. Посещается первая вершина из очереди (если она не помечена как посещённая). Все её соседние вершины заносятся в очередь. После этого она удаляется из очереди. Шаг 3. Повторяется шаг 2 до тех пор, пока очередь не станет пустой. Пример реализации алгоритма можно посмотреть на анимации Пример реализации приведён ниже. Скопировать код1BFS(graph, v, used):2queue q3q.push(v)4used[v] =15while(!q.empty())6v = q.front()7q.pop()8for(var to : graph[v]):9if(!used[to]):10used[to] =true11q.push(to) Подумайте, какое отличие алгоритма поиска в ширину от алгоритма поиска в глубину? Асимптотическая сложность алгоритма поиска в глубину и ширину —, где— число вершин, а— число рёбер и дуг. Обходы графов могут применяться для решения задач, связанных с теорией графов: Волновой алгоритм поиска пути в лабиринте. Волновая трассировка печатных плат. Поиск компонент связности в графе. Поиск кратчайшего пути между двумя узлами невзвешенного графа. Поиск в пространстве состояний: нахождение решения задачи с наименьшим числом ходов, если каждое состояние системы можно представить вершиной графа, а переходы из одного состояния в другое — рёбрами графа. Нахождение кратчайшего цикла в ориентированном невзвешенном графе. Нахождение всех вершин и рёбер, лежащих на каком-либо кратчайшем пути между двумя вершинами. Поиск увеличивающего пути в алгоритме Форда-Фалкерсона (алгоритм Эдмондса-Карпа).",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обходы графа - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/obhody-grafa",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете реализовывать обходы графа — DFS и BFS — и использовать их для решения базовых задач, таких как проверка достижимости и построение пути. Вы научились работать с очередью и стеком, отмечать посещённые вершины и корректно обходить даже сложные структуры. Далее — задача на использование обходов. Вы узнаете, как при помощи DFS или BFS найти компоненты связности и почему важно запускать обход из каждой новой вершины. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. DFS и BFS — базовые алгоритмы, применимые ко многим задачам на графах. DFS использует стек (в том числе неявный при рекурсии), а BFS — очередь. Для корректного обхода важно отслеживать посещённые вершины. Выбор между DFS и BFS зависит от задачи: от поиска пути до анализа структуры графа.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80791"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Специи» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-specii",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как работает жадный алгоритм в задаче выбора по критерию «цена за единицу веса»? Почему важно доказывать корректность жадной стратегии, даже если она кажется очевидной? Как оформить решение, чтобы избежать ошибок округления и сохранить точность при работе с вещественными числами?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Специи» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-specii",
    "section_title": "Выбор предметов с наибольшей ценностью при ограниченной вместимости",
    "text": "Вор пробрался в лавку специй и нашёл там четыре фунта шафрана, три фунта ванили и пять фунтов корицы. В его рюкзак можно сложить до девяти фунтов, поэтому забрать всё он не сможет. Предположим, что цены на шафран, ваниль и корицу $5000, $200 и $10 соответственно. Как унести максимально дорогую добычу? Если вор заберётфунтов шафрана,фунтов ванили ифунтов корицы, общая ценность украденного составит. Вор хотел бы найти максимальное значение этого выражения при следующих ограничениях:,,,. Входные данные: Первая строка ввода содержитспеций и вместимость рюкзака. Следующиестрок указывают цену и вес специй.-я строка включает в себя ценуи вес-й специи. Выходные данные: Максимальное значение специй, которые вместятся в рюкзак. Ограничения:,;,для всех. Все числа — целые. В дополнение: Хотя ввод для этой задачи состоит из целых чисел, вывести необходимо нецелое число. Таким образом, абсолютное значение разницы между ответом вашей программы и оптимальным значением не должно превышать. Для этого ваш ответ должен содержать не меньше четырёх цифр в дробной части (иначе даже правильно вычисленный ответ может стать неправильным из-за проблем с округлением). Чтобы получить значение, вор возьмёт и первую, и третью специи полностью. Вору нужно забрать десять фунтов единственной доступной специи. Совет: по возможности старайтесь избегать чисел с плавающей дробной частью. Определим стоимость специикак. Естественной стратегией для вора было бы брать как можно больше самой дорогой специи. Чтобы доказать, что эта стратегия приводит к оптимальному решению, рассмотрим самую дорогую специю. Каков максимальный объём-й специи, который вор может положить в рюкзак? Во-первых, она должна уместиться в рюкзак:. Во-вторых, она не должна превышать доступный объём-й специи:. Следовательно,. Мы утверждаем, что существует оптимальное решение, включающее в себяфунтов-й специи. Чтобы это доказать, рассмотрим оптимальное решение, при котором мы получаем максимальное количествосамой дорогой-й специи из всех оптимальных решений (означает количество-й специи). Если, то ничего доказывать не нужно. Иначе. Поэтомуи. Рассмотрим два варианта. При нынешнем решениирюкзак заполнен не до конца. Так как, можно взять немного больше-й специи: так, мы получаем новое решение, которое лучше и оптимальнее нынешнего. Рюкзак заполнен до конца:. Так как, при подбореможно получить. Так, вместо маленького количества-й специи, можно взять такое же количество-й специи. Таким образом мы сохраним общий вес, но увеличим общую ценность и количество самой дорогой-й специи в рюкзаке. Это противоречит идее, что в изначальном решении был максимум-й специи. Доказав, что мы можем взять самой дорогой специи столько, сколько получится, мы можем спроектировать жадный алгоритм: взять как можно больше самой дорогой специи и повторить. Мы прекратим, когда больше не останется специй или когда рюкзак будет заполнен до конца. В псевдокоде, приведённом ниже,и— массивы, содержащие значения веса и цены. Скопировать код1MaximumLoot(W, Weight, Cost)2ifW=0orWeight is empty:3return04m = the index of the most expensive item5amount =min(Weight[m], W)6value = Cost[m] / Weight[m] * amount7remove the m-th element from WeightandCost8returnvalue +MaximumLoot(W - amount, Weight, Cost) Время выполнения.Время выполнения этого алгоритма —. При каждой итерации сканируется список специй и находится самая дорогая. Максимальное количество итераций —, так как каждая итерация снижает количество рассматриваемых специй.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Специи» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-specii",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как устроена жадная стратегия и как она работает в задаче размена. Вы увидели, что можно принимать решения, не заглядывая вперёд, и при этом получить оптимальный результат. А ещё убедились, что даже простая стратегия требует проверки и не всегда даёт правильный ответ. Далее — новая задача: как выбрать самое выгодное, если ресурсы ограничены. Вы познакомитесь с жадным отбором по плотности и научитесь использовать этот подход, когда важно получить максимум от доступного. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный алгоритм принимает решение на каждом шагу, выбирая наиболее выгодный вариант здесь и сейчас. В задаче размена такая стратегия работает, если номиналы монет удовлетворяют определённым условиям. Даже для простых на вид задач важно доказывать корректность жадного подхода, а не полагаться на интуицию. Жадные алгоритмы просты и быстры, но требуют проверки: в некоторых задачах они могут давать неверный результат.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80766"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Сбор подписей» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-sbor-podpisej",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Чем задача «Сбор подписей» отличается от других задач с ограниченными ресурсами? Почему стратегия «максимальная прибыль на единицу ресурса» оказывается оптимальной? Как корректно оформить и проверить такое решение?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Сбор подписей» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-sbor-podpisej",
    "section_title": "Максимальная выгода при ограниченных ресурсах",
    "text": "На этот раз ваша задача — собрать подписи со всех жильцов дома. Вам известно время, в которое каждый из них будет у себя. Естественно, вам хочется собрать все подписи, заходя в дом минимальное количество раз. Для простоты давайте предположим, что вы, зайдя в дом, собираете подписи сразу со всех жильцов, которые на месте. В дальнейшем под сегментом будем понимать интервал времени нахождения жильца в доме. Количество жильцов будет соответствовать количеству сегментов. Входные данные: Количество сегментов в первой строке —. Каждая из следующихстрок содержит два целых числаи(разделены пробелом), которые указывают на координаты границ-го сегмента. Выходные данные: Минимальное количествоточек на первой строке и координатыточек целыми числами (разделены пробелом) на второй строке. Выводить точки можно в любом порядке. При наличии нескольких наборов точек, можно вывести любой из них. Ограничения:;для всех. Все три сегмента,,содержат точку с координатами 3. Второй и третий сегменты содержат точку с координатами, в то время как первый и четвертый содержат точку с координатами. Одной точкой покрыть все сегменты нельзя, так какине пересекаются. В этом случае есть еще одно верное решение — точки 2 и 5. Решение заключается в выявлении сегмента с наименьшим значением правой границы. Самое маленькое значение границы сегмента:. Мы утверждаем, что существует оптимальное решение, включающее в себя точку. Чтобы доказать это, возьмём оптимальное решение. Оно должно покрывать сегмент, поэтомусодержит точку, что приводит к. Если, то наша работа закончена. Иначе. В этом случае мы можем заменитьнав. Понятно, что это не меняет размер решения. Чтобы доказать, чтовсё ещё является решением, подойдём от противного и предположим, что некий сегментпокрывается, но не покрывается. Это означаети противоречит тому, что— самое маленькое значение правой границы. Таким образом, мы приходим к следующему алгоритму: добавить в решение минимальное значение правой границы, отбросить все сегменты, покрытые, повторить. Скопировать код1SegmentsCover(segments):2points←empty set3whilesegments isnotempty:4r_m = minimum right endpoint of a segment from segments5add r_m points6remove segments covered by r_m from the set segments7returnpoints На рисунке ниже показан пример. Время выполнения составит, где, так как используется не болееитераций циклаwhile(при каждой итерации отбрасывается как минимум один сегмент), и каждая итерация сводится к проверке списка(одним сканированием находится значение, а другим убираются сегменты, покрываемые). Этот алгоритм уже достаточно быстрый, чтобы успешно пройти оценку. Однако можно дополнительно сократить время выполнения сдо, если отсортировать сегменты от малых до больших значений правой границы и затем просто просканировать список один раз.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Сбор подписей» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-sbor-podpisej",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете применять жадные алгоритмы, когда нужно максимизировать результат при ограниченном ресурсе, используя критерий эффективности на единицу ресурса. Далее — задача с другим типом цели: теперь ресурс нужно распределить так, чтобы увеличить количество получателей. Вы узнаете, как простая сортировка помогает достичь справедливого распределения и почему жадный подход оказывается удачным и в этой ситуации. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный алгоритм может работать не только с абсолютными значениями, но и с относительными критериями, например «выгода на единицу ресурса». Оптимальность жадного критерия нужно обосновывать — иначе легко получить неверное решение. Работа с вещественными числами требует особой аккуратности в сравнении и реализации.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80768"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Сувениры» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-suveniry",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Почему результат арифметического выражения зависит от порядка скобок? Как использовать динамическое программирование для перебора всех вариантов группировки? Как устроены таблицы для хранения минимальных и максимальных значений подвыражений?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Сувениры» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-suveniry",
    "section_title": "Условие задачи",
    "text": "Три пирата делят свою добычу, в которую входятпредметов разной ценности. Получится у вас помочь разделить добычу поровну? Входные данные:Первая строка содержит целое число. Вторая строка содержит целые числа, разделённые пробелами. Выходные данные:Вывести 1, еслиможно разделить на три поднабора с одинаковыми суммами; в противном случае — вывести 0. Ограничения:,для всех. Пример 1 Пример 2 Пример 3 . Рассмотрим решение задачи. Обозначимкак. Разделить набор изпредметов на три части возможно, только если их общая ценность делится на три. То есть, где— это целое число. Так, нам необходимо разделитьчисел на три части, где сумма чисел в каждой части равна. Одна из этих частей содержит-й трофей (с ценностью). Если мы его уберём, то получим разделение первыхтрофеев на три части таким образом, что ценность двух из них будет равна, а сумма оставшейся части —. Вместо разделения всехпредметов, попробуем решить более мелкую задачу, состоящую в делении первыхпредметов на части с ценностью,и. Если такое разделение возможно, мы присваиваем(в противном случае —) и отмечаем, что пираты могут разделить добычу честно, только если. Предположим, что. Тогда первыечисел можно разделить на три части таким образом, чтобы сумма чисел в первой части составляла, а сумма чисел во второй части —. -й предмет принадлежит первой части. Тогда. Убрав его из первой части, мы разделим первыечисел на три части так, что сумма первых двух частей составити, то есть. -й предмет принадлежит второй части. Как и в предыдущем случае,и. -й предмет принадлежит третьей части. Тогда. Так, значениеможно вычислить, посмотрев на Базовый случай для этого рекуррентного соотношения:и, если. Скопировать код1Split(v[1],…,v[n]):2ifv[1] + … + v[n] не делится целочисленно на3:3returnfalse4V = (v[1] + … + v[n]) /35split = ...// массив размера (n+1) × (V+1) × (V+1)6// заполнить массив split значениями false7split[0][0][0] =true8fori from1to n:9fors1 from0to V:10fors2 from0to V:11split[i][s1][s2] = split[i−1][s1][s2]12ifs1 >= v[i]:13split[i][s1][s2] = split[i][s1][s2] OR split[i -1][s1 - v[i]][s2]14ifs2 >= v[i]:15split[i][s1][s2] = split[i][s1][s2] OR split[i -1][s1][s2 - v[i]]16returnsplit[n][V][V] Время выполнения составляет.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Сувениры» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-suveniry",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете вычислять максимальное значение арифметического выражения, расставляя скобки в нужном порядке. Вы научились использовать динамическое программирование с запоминанием минимальных и максимальных значений и применять аккуратные рекурсивные формулы. Далее — финальный параграф главы. В нём мы кратко обобщим ключевые идеи, которые вы встретили, и покажем, как они складываются в систему. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Порядок выполнения операций влияет на результат арифметического выражения — важно правильно расставить скобки. Можно эффективно найти максимальное значение, если сохранять минимумы и максимумы всех подвыражений в таблицах. Динамическое программирование позволяет избежать повторных вычислений и уменьшает время работы с экспоненциального до кубического. Даже при небольшом числе операций количество возможных расстановок скобок велико — поэтому важно автоматизировать перебор.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80782"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Односвязный список - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/odnosvyaznyj-spisok",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как устроен односвязный список и чем он отличается от массива? Какие операции можно выполнять со списком и какова их сложность? Когда стоит использовать односвязный список вместо других структур?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Односвязный список - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/odnosvyaznyj-spisok",
    "section_title": "Элементы односвязного списка",
    "text": "Односвязный список (иногда «связный список») — базовая структура данных, представляющая собой соединённые узлы с однотипными данными. Каждый узел состоит из элемента и ссылки на следующий элемент (см. рисунок). Самый первый элемент списка называют головой (head) односвязного списка, а последний — хвостом (tail). Последний элемент односвязного списка в качестве ссылки содержит null-значение. В отличие от классического массива, где данные в памяти расположены строго последовательно, в односвязном списке, наоборот, данные расположены хаотично и связывание узлов списка происходит посредством ссылок. За счёт этой особенности в односвязный список можно добавлять произвольное число элементов, однако доступ будет осуществляться только последовательно. Произвольного доступа к элементам в односвязном списке нет. Со списком можно производить ряд операций: Добавить элемент (add). Удалить элемент (remove). Найти элемент (find). Посчитать количество элементов по условию (count). Операция добавления элемента (add) может быть представлена в нескольких вариантах. В случае добавления в начало списка ссылка нового узла будет указывать на голову списка, а голова списка должна быть перемещена на новый узел. Сложность этого варианта —. Если добавление идёт в конце списка, то ссылка хвоста списка должна указывать на новый узел, а после должна быть перемещена на новый узел. Сложность этого варианта —. Вставка промежуточного элемента предполагает, что будет найдена позиция после которой будет вставлено новое значение. Сложность этого варианта —, где n число элементов в списке. Удаление элемента (remove) предполагает, что будет найден заданный элемент и следом он будет удалён. Нахождение узла требует прохода по односвязному списку, после чего необходимо ссылку с элемента перед удаляемым перенаправить на элемент после удаляемого. Сложность операции —, где— число элементов в списке. Нахождение элемента (find) предполагает простой однократный проход по списку с нахождением ссылки на заданный элемент. Сложность операции —, где— число элементов в списке. Подсчёт числа элементов по условию (count) предполагает проход по списку и сравнение всех элементов с заданным с подсчётом количества удовлетворяющих условию элементов. Сложность операции —, где— число элементов в списке.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Односвязный список - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/odnosvyaznyj-spisok",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как устроен односвязный список и как с ним работать: добавлять, удалять, искать и считать элементы. Вы поняли, чем он отличается от массива и в каких случаях может быть полезен. Далее — ещё одна важная структура данных: множество. Вы увидите, как оно позволяет хранить уникальные элементы и выполнять быстрые проверки на принадлежность. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткий гайд о том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Односвязный список состоит из узлов, где каждый узел хранит значение и ссылку на следующий элемент. В отличие от массива, доступ к элементам возможен только через последовательный обход списка. Основные операции (добавление, удаление) могут выполняться эффективно при работе с началом списка, но поиск элемента занимает больше времени. Односвязный список удобен, когда важнее динамическое изменение структуры, чем быстрый доступ по индексу.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80784"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Алгоритмы и сложность - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Чем задача отличается от её конкретного экземпляра и почему это различие важно? Какие ошибки может допустить алгоритм и как проверить его корректность? В чём преимущества описания алгоритма на псевдокоде? Как измерять «быстроту» алгоритма и почему не всегда важно абсолютное время работы? Почему полиномиальные алгоритмы считаются приемлемыми, а экспоненциальные — проблемными?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Алгоритмы и сложность - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
    "section_title": "Что такое алгоритм?",
    "text": "Алгоритм — это последовательность указаний, которые нужно исполнить, чтобы решить чётко сформулированную задачу. Мы описываем задачи, исходя из ввода и вывода, и алгоритм становится способом превращения ввода в вывод. При этом формулировка задачи должна быть точной и недвусмысленной — это помогает избежать неверной интерпретации. Когда вы закончили проектировать алгоритм, необходимо ответить на два важных вопроса: «Правильно ли он работает?» и «Сколько времени занимает выполнение?». Разумеется, вас не устроит алгоритм, который выдаёт правильный результат лишь в половине случаев или требуетлет для поиска ответа.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Алгоритмы и сложность - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
    "section_title": "Псевдокод",
    "text": "Чтобы понять, как работает алгоритм, нам необходимо перечислить шаги, которые он выполняет. Для этого мы будем использовать псевдокод — язык, которым пользуются разработчики для описания алгоритмов. Он игнорирует многие детали, необходимые в языках программирования, но он более точен, чем рецепт из кулинарной книги.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Алгоритмы и сложность - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
    "section_title": "Задача и экземпляр задачи",
    "text": "Задача описывает класс возможных входных данных. Экземпляр задачи — это один конкретный ввод такого класса. Чтобы продемонстрировать понятия задачи и экземпляра задачи, рассмотрим следующий пример. Вы оказались в книжном магазине и собираетесь купить книгу за, расплатившись купюрой в. Вам должны вернутьцентов в качестве сдачи. Теперь кассир принимает решение, как именно это сделать. Согласитесь, неприятно получить горсть изпенни илиникелей ипенни. Возникает вопрос: как выдать сдачу, не расстроив клиента? Большинство кассиров стараются уместить сумму сдачи в наименьшее количество монет. Пример сцентами представляет собой экземпляр задачиРазмен. Предполагается, что естьноминалов, которые представлены массивом. Для упрощения будем считать, что номиналы даны в порядке убывания. Например,для монет, используемых в США. Переведите определенное количество денег в данные номиналы, используя как можно меньше монет. Входные данные: Целое числои массив изноминаловв порядке убывания (). Выходные данные: Список изцелых чисел, в которомикак можно меньше. Кассиры по всему миру решают эту проблему с помощью простого алгоритма: Скопировать код1Change(money, c, d):2whilemoney >0:3coin = ...// монета с самым большим номиналом, который не превышает money4// дать монету с номиналом coin клиенту5money = money - coin Вот быстрая версия Change: Скопировать код1Change(money, c, d):2fork inrange(1, d +1)3i_k=floor(money / c[k])// наибольшее количество монет номинала c[k]4// дать i_k монет с номиналом c[k] клиенту5money = money - c[k] * i_k",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Алгоритмы и сложность - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
    "section_title": "Корректные и некорректные алгоритмы",
    "text": "Мы называем алгоритм корректным, если на каждый получаемый ввод он делает правильный вывод. Алгоритм считается некорректным, если хотя бы один ввод приводит к неправильному выводу. Change— это некорректный алгоритм! Представьте сдачу в 40 центов, выданную в номиналах,,,и. Changeпривел бы к неправильному результату: он выдал бы 1 четвертак (25 центов), 1 дайм (10 центов) и 1 никель (5 центов) вместо 2 монет по двадцать центов. Хоть это и может выглядеть надуманно, в 1875 году в США существовала монета в двадцать центов. Насколько мы можем быть уверены, чтоChangeвыдаст минимальное количество монет в современных номиналах Соединенных Штатов или любой другой страны? Чтобы исправить алгоритмChange, нам нужно рассмотреть все возможные комбинации монет с номиналами, которые дают в сумме, и выдать комбинацию с минимальным количеством монет. Мы рассматриваем только комбинации, в которыхи(в целом, величинане должна превышать), в ином случае мы вернем большее количество денег, чем. В псевдокоде, приведенном ниже, используется символ. Он обозначает суммирование:. Псевдокод также использует концепт «бесконечность» (обозначается) в качестве начального значения для. Реализация описанного подхода на реальных языках программирования может различаться, но сейчас подробности для нас не важны. Скопировать код1BruteForceChange(money, c, d):2smallestNumberOfCoins = ∞3foreach combinations ofcoins(i_1,...,i_d)4// от (0,...,0) до (money/c[1],...,money/c[d])5valueOfCoins = ∑ i_k*c_k// сумма по всем k от 1 до d6ifvalueOfCoins = money:7numberOfCoins = ∑ i_k// суммарное количество монет8ifnumberOfCoins <smallestNumberOfCoins:9smallestNumberOfCoins = numberOfCoins10change = (i_1, i_2, ... ,i_d)11returnchange Цикл повторяется с каждой возможной комбинациейизиндексов и останавливается, когда достигает Как мы можем узнать, чтоBruteForceChangeне содержит ту же проблему, что иChange, — неверный результат при каком-то вводе? РазBruteForceChangeрассматривает все возможные комбинации номиналов, рано или поздно алгоритм придёт к оптимальному решению и запишет его в массив. В любой комбинации монет, которая даёт в сумме, должно быть как минимум столько же монет, сколько и в оптимальной. Таким образом,BruteForceChangeникогда не завершит работу с неоптимальным набором. На данный момент мы ответили только на один из двух важных вопросов об алгоритмах: \"Работает ли он?\". Однако мы не ответили на вопрос: \"Сколько времени занимает выполнение?\".",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Алгоритмы и сложность - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
    "section_title": "Быстрые и медленные алгоритмы",
    "text": "Настоящие компьютеры требуют определенное количество времени на выполнение таких операций, как сложение, вычитание или проверка условий цикла while. Суперкомпьютер может выполнить сложение засекунды, а калькулятор — за. Представьте, что у вас есть компьютер, которому требуетсясекунды на выполнение простой операции (например, сложения), и вы знаете, сколько операций выполняет какой-то конкретный алгоритм. Вы могли бы рассчитать время выполнения алгоритма, просто взяв произведение количества операций и времени, которое занимает одна операция. Однако компьютеры постоянно улучшаются, благодаря чему им требуется меньше времени на операцию. Так, ваше представление о времени выполнения быстро стало бы устаревшим. Вместо того, чтобы рассчитывать время выполнения на каждом компьютере, мы описываем время выполнения через общее количество операций, необходимых алгоритму, — это характеристика самого алгоритма, а не компьютера, который вы используете. К сожалению, нам не всегда легко определить, сколько операций выполнит алгоритм. Однако если мы можем рассчитать количество базовых операций, выполняемых алгоритмом, то это позволит сравнить его с другим алгоритмом, решающим ту же задачу. Чтобы мучительно не подсчитывать каждое умножение и сложение, можно сравнивать только те участки кода, которые при увеличении размера ввода потребуют больше операций. Представьте, что алгоритмвыполняетопераций при вводе размера, и алгоритмрешает ту же задачу заопераций. Какой алгоритм быстрее:или? Хотяи может быть быстрее, чем, при более малом значении(например, примежду 1 и 3),будет быстрее при больших значениях(например,). (См. рис.). Так как— это, в каком-то смысле, более «быстрорастущая» функция относительно, чем. При этом константы 3 и 2 вне влияют на конкуренцию между двумя алгоритмами при больших значениях. Мы называемквадратичным алгоритмом и— линейным.менее эффективен, чем, потому что он выполняет больше операций для решения задачи, когда значениебольшое. Так, иногда мы будем допускать неточности при подсчете операций алгоритма: поведение алгоритма при маленьком вводе неважно. Рассчитаем примерное количество операций, которое потребуется дляBruteForceChangeпри вводе изцентов и номиналов. Чтобы рассчитать общее количество операций в цикле for, нам необходимо взять примерное число операций, выполняемое при каждой итерации, и умножить его на общее количество итераций. В нашем случае количество операций можно оценить сверху величиной Такой тип алгоритмов называется экспоненциальным в противоположность квадратичным, кубическим или другим полиномиальным алгоритмам. Выражение времени выполнения экспоненциального алгоритма использует, гдеи— это параметры задачи (например,иможно произвольно сделать большими, изменив ввод для алгоритма). Время выполнения полиномиального алгоритма ограничено, где— это константа, не связанная с тестовыми данными. Например, алгоритм с временем выполнения(линейный),(квадратичный),(кубический) или дажебудет полиномиальным. Конечно, алгоритм с временем выполненияне очень практичен. Возможно, даже менее практичен, чем некоторые экспоненциальные алгоритмы. Впрочем, разработчики тратят много усилий, чтобы проектировать всё более и более быстрые полиномиальные алгоритмы. Раз значениеможет быть большим при вызове алгоритма с большим количеством номиналов (например,), мы видим, что выполнениеBruteForceChangeможет потребовать много времени.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Алгоритмы и сложность - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algoritmy-i-slozhnost",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, что такое алгоритм, чем задача отличается от её экземпляра и как алгоритмы помогают решать поставленные задачи. Вы познакомились с псевдокодом, понятием корректности алгоритма и идеей оценки его эффективности. А ещё узнали, почему время выполнения важно и как отличать «быстрые» алгоритмы от «медленных» с точки зрения роста числа операций. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Алгоритм — это способ преобразования входных данных в выходные. Он решает задачу, формулируемую через множество возможных входов и условий. Псевдокод помогает описывать шаги алгоритма понятно и точно, а корректность означает, что алгоритм всегда выдаёт правильный результат. Эффективность алгоритма оценивается по количеству операций, которые он выполняет, — это позволяет сравнивать алгоритмы независимо от устройства. Полиномиальные алгоритмы масштабируются лучше и считаются эффективными, тогда как экспоненциальные быстро становятся непрактичными при росте входных данных. В следующей главе вы познакомитесь со структурами данных: стеком, очередью, словарём, множеством и списками. Вы узнаете, как они устроены, где используются и чем отличаются друг от друга, — а заодно научитесь применять их в задачах.",
    "source_type": null,
    "useful_links": [
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Представление графа в памяти компьютера - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/predstavlenie-grafa-v-pamyati-kompyutera",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Какие основные способы хранения графа применяются на практике? Как различия в представлениях отражаются на скорости работы алгоритмов и потреблении памяти? По каким критериям выбирать подходящее представление графа для конкретной задачи?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Представление графа в памяти компьютера - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/predstavlenie-grafa-v-pamyati-kompyutera",
    "section_title": "Способ хранения графа",
    "text": "В прошлом параграфе мы обсудили основные определения теории графов. Однако, чтобы работать с графами, необходимо их как-то хранить в памяти компьютера. К сожалению, не существует универсального способа хранения графов, потому что каждый имеет свои достоинства и недостатки. Рассмотрим такой способ хранения графа, как матрица смежности. Матрица смежности представляет собой матрицу, где по строкам и столбцам располагаются номера вершин. Если рёбра между вершинами отсутствует, то на пересечении-ой строки и-ого столбца ставится 0. Если ребро есть, то ставят 1. Пример графа и его матрицы смежности приведён на рисунке ниже. Рассмотрим пример матрицы смежности для ориентированного графа. В целом, отличий не так много, кроме того, что матрица смежности перестала быть симметричной. Подумайте, почему. Также при работе с графами применяется и матрица инцидентности. По столбцам располагаются рёбра, а по строкам номера вершин. На пересечении-ой вершины и-ого ребра ставится 1, если одним из концов ребрабыла вершина. Пример приведён ниже. В случае ориентированного графа матрица инцидентности не сильно меняется, за исключением того, что на пересечении-ой вершины и-ого ребра ставится 1, когда дугавходит в вершинуи -1, когда выходит. Для экономии памяти может использоваться список смежности, который представляет из себя набор списков по числу вершин в графе. Каждый список представляет из себя перечисление всех смежных данной вершине. В случае ориентированного графа список смежности выглядит аналогичным образом. В некоторых случаях удобнее использовать список рёбер. Он представляет собой перечисление всех рёбер графа. Пример приведен ниже. Подумайте, а какой вариант хранения графа в памяти компьютера самый оптимальный. Почему?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Представление графа в памяти компьютера - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/predstavlenie-grafa-v-pamyati-kompyutera",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете представлять граф в памяти с помощью разных структур: матриц и списков. Вы знаете, в каких задачах использовать матрицу смежности, а где лучше подойдёт список смежности или рёбер. Далее — перейдём к алгоритмам работы с графами. Начнём с базового действия — обхода графа, то есть последовательного просмотра всех его вершин и рёбер. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Граф можно хранить с помощью матрицы смежности, инцидентности, списка смежности или списка рёбер. Выбор способа зависит от размера графа, плотности связей и требований к скорости доступа. Нет универсального способа — у каждого формата есть свои плюсы и минусы. Эффективное представление графа — залог быстрого и надёжного алгоритма.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80790"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Дэк (deque, double-ended queue) - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dek-(veque-double-ended-queue)",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Что такое дек и как он отличается от обычной очереди или стека? Какие операции поддерживает дек и с какой сложностью? Как реализовать дек на практике и где он пригодится?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Дэк (deque, double-ended queue) - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dek-(veque-double-ended-queue)",
    "section_title": "Определение дека",
    "text": "Дек (deque, double-ended queue) — универсальная структура данных; представляет собой последовательность элементов, у которой есть два конца. Причём добавление и удаление элементов может происходить как в начало, так и в конец структуры. Структура дека обладает следующими особенностями: Доступ к первому и последнему элементу производится за константное время. Доступ к элементам в середине дека осуществляется за линейное время, так как элементы хранятся последовательно. В целом дек представляет собой смесь стека и очереди. Структура дек может реализовываться различными способами, например с использованием двух стеков или двусвязного списка.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Дэк (deque, double-ended queue) - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dek-(veque-double-ended-queue)",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете использовать дек — структуру, которая совмещает свойства очереди и стека. Вы увидели, как с помощью дека можно реализовать гибкие алгоритмы обработки данных с доступом к обоим концам последовательности. Далее — базовые структуры стека и очереди, с помощью которых можно удобно организовывать данные в процессе выполнения алгоритмов. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Дек — структура данных, которая позволяет добавлять и удалять элементы с обеих сторон за O(1). Он совмещает поведение очереди и стека, сохраняя гибкость и эффективность. Часто используется в задачах, где нужен доступ к краям списка или симметричная обработка элементов.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80789"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Модификация быстрой сортировки - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/modifikaciya-bystroj-sortirovki",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Почему стандартная быстрая сортировка может работать медленно на массивах с повторяющимися элементами? Как изменить алгоритм так, чтобы избежать деградации производительности? Как реализовать трёхчастное разбиение и почему оно даёт прирост в эффективности?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модификация быстрой сортировки - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/modifikaciya-bystroj-sortirovki",
    "section_title": "Псевдокод",
    "text": "Скопировать код1RandomizedQuickSort(c):2if|c| <=1: # тут и сортировать нечего3returnc4m =random_choice(c) # выбираем случайный элемент из массива5определяем элементы c_small меньшие m6определяем элементы c_large большие m7RandomizedQuickSort(c_small) # рекурсивный вызов алгоритма8RandomizedQuickSort(c_large)9объединяем c_small, m и c_large в итоговый массив c_sorted10returnc_sorted В этом псевдокоде подразумевается, что все элементы массива разные. Ожидаемое время выполнения алгоритма составляет.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модификация быстрой сортировки - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/modifikaciya-bystroj-sortirovki",
    "section_title": "Изменение массива",
    "text": "Алгоритм легко изменить для случая, когда в этом массиве есть повторы. Чтобы это сделать, пусть всодержатся все элементы со значением не более, а не элементы со значением менее. Тем не менее такая модификация становится медленной даже относительно ожидаемого времени выполнения. Например, если все элементыодинаковы,разделяется на две части: размерсоставляет, а внет элементов. Так как это разделение требует отRandomizedQuickSortвремени, общее время выполнения составляет: то естьвместо. Ваша цель — изменить описанный выше алгоритмRandomizedQuickSortтак, чтобы даже при последовательностях с множеством повторяющихся элементов ожидаемое время выполнения стало. Формат ввода: Первая строка содержит целое число. В следующей строке содержится последовательность изцелых чисел. Формат вывода: Вывод последовательности в неубывающем порядке. Ограничения:;для всех. Для ускоренияRandomizedQuickSortмы разделим входной массив на три подмассива: элементы меньше опорного, равные ему и элементы больше. В более простом подходе достаточно сканировать массив трижды и собрать необходимые элементы. Продемонстрируйте, как разделить массив на три части (меньше опорного элемента m, равняется ему и больше него) на месте— без использования дополнительной памяти.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модификация быстрой сортировки - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/modifikaciya-bystroj-sortirovki",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете модифицировать быструю сортировку так, чтобы она оставалась эффективной даже при наличии большого числа одинаковых элементов. Вы освоили идею трёхчастного разбиения и поняли, как оно помогает избежать худших сценариев и ускорить работу алгоритма. Далее — задача на подсчёт инверсий. Вы узнаете, как можно сочетать сортировку и рекурсию, чтобы вычислять количество нарушений порядка быстрее, чем простым перебором. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Стандартная быстрая сортировка может деградировать, если в данных много одинаковых значений. Модификация с трёхчастным разбиением (на меньше, равные и больше опорного) делает сортировку стабильной по времени. Случайный выбор опорного элемента помогает избежать худших случаев. Алгоритм остаётся простым, но работает существенно быстрее в практических задачах.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80775"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Максимальное произведение» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Почему наивное решение не всегда укладывается в ограничение по времени? Как реализовать быстрый и надёжный алгоритм для вычисления максимального попарного произведения? Зачем нужно стресс-тестирование и как оно помогает найти ошибки, незаметные при обычной проверке?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Максимальное произведение» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
    "section_title": "Разбор задачи",
    "text": "Разберём чуть более сложную задачу. Итак, вам дана последовательность неотрицательных целых чисел. Вычислите Обратите внимание, чтоидолжны быть разными, хотя в каких-то случаях можно наблюдать, что. Формат ввода: Первая строка содержит целое число. Следующая строка содержитнеотрицательных целых чисел(разделены пробелами). Формат вывода: Максимальное попарное произведение. Ограничения:;. Примеры",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Максимальное произведение» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
    "section_title": "Наивный подход",
    "text": "Наивный способ решить задачуМаксимальное произведение— перебрать все возможные пары вводных элементови найти пару, которая даёт наибольшее произведение. Скопировать код1MaxPairwiseProductNaive(A[1..n]):2product =03fori from1to n4forj from1to n5ifi != j6ifproduct <A[i] * A[j]7product = A[i] * A[j]8returnproduct Этот код можно оптимизировать и сократить следующим образом. Скопировать код1MaxPairwiseProductNaive(A[1..n]):2product =03fori from1to n4forj from i+1to n5product =max(product, A[i] * A[j])6returnproduct Реализуйте этот алгоритм, используя ваш любимый язык программирования. Если вы используетеC++,JavaилиPython3, вам могут пригодиться начальные заготовки (для всех задач из хендбука мы предлагаем стартовые заготовки с использованием этих трёх языков в интерфейсе тестирующей системы). С другими языками вам понадобится сделать работу с нуля. Стартовые заготовки решений дляC++,JavaиPython3представлены ниже. Скопировать код1#include<iostream >2#include<vector >3#include<algorithm >45intMaxPairwiseProduct(conststd::vector <int>&numbers){6intmax_product =0;7intn = numbers.size();89for(intfirst =0; first <n; ++first) {10for(intsecond = first +1; second <n; ++second) {11max_product = std::max(max_product,12numbers[first] * numbers[second]);13}14}1516returnmax_product;17}1819intmain(){20intn;21std::cin >>n;22std::vector <int>numbers(n);23for(inti =0; i <n; ++i) {24std::cin >>numbers[i];25}2627std::cout <<MaxPairwiseProduct(numbers) <<\"\\n\";28return0;29} Скопировать код1importjava.util.*;2importjava.io.*;34publicclassMaxPairwiseProduct{5staticintgetMaxPairwiseProduct(int[] numbers){6intmax_product=0;7intn=numbers.length;89for(intfirst=0; first <n; ++first) {10for(intsecond=first +1; second <n; ++second) {11max_product = Math.max(max_product,12numbers[first] * numbers[second]);13}14}1516returnmax_product;17}1819publicstaticvoidmain(String[] args){20FastScannerscanner=newFastScanner(System.in);21intn=scanner.nextInt();22int[] numbers =newint[n];23for(inti=0; i <n; i++) {24numbers[i] = scanner.nextInt();25}26System.out.println(getMaxPairwiseProduct(numbers));27}2829staticclassFastScanner{30BufferedReader br;31StringTokenizer st;3233FastScanner(InputStream stream) {34try{35br =newBufferedReader(new36InputStreamReader(stream));37}catch(Exception e) {38e.printStackTrace();39}40}4142Stringnext(){43while(st ==null|| !st.hasMoreTokens()) {44try{45st =newStringTokenizer(br.readLine());46}catch(IOException e) {47e.printStackTrace();48}49}50returnst.nextToken();51}5253intnextInt(){54returnInteger.parseInt(next());55}56}5758} Скопировать код1defmax_pairwise_product(numbers):2n =len(numbers)3max_product =04forfirstinrange(n):5forsecondinrange(first +1, n):6max_product =max(max_product,7numbers[first] * numbers[second])89returnmax_product101112if__name__ =='__main__':13_ =int(input())14input_numbers =list(map(int,input().split()))15print(max_pairwise_product(input_numbers)) После проверки вы можете увидеть такое сообщение: Дело в том, что мы проверяем ваше решение на тестовых примерах — это помогает убедиться, что программа работает быстро и без ошибок. В результате мы, как правило, знаем, какие ошибки вы допустили. Сообщение выше говорит о том, что предложенная программа превышает ограничение по времени в 4-м тестовом примере из 17. MaxPairwiseProductNaiveвыполняет порядкашагов при последовательности длиной. При максимальном возможном значенииколичество шагов будет порядка. Так как большинство современных компьютеров выполняют около–базовых операций в секунду (разумеется, это зависит от компьютера), выполнениеMaxPairwiseProductNaiveможет занять десятки секунд. Это превысит временное ограничение задачи. Нам нужен более быстрый алгоритм!",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Максимальное произведение» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
    "section_title": "Быстрый алгоритм",
    "text": "А что если внимательнее рассмотреть более мелкие примеры— скажем,? Эврика! Достаточно помножить два самых больших элемента массива —и. То есть нам достаточно просканировать последовательность лишь дважды. При первом сканировании мы найдем самый большой элемент, затем — второй по величине. Скопировать код1MaxPairwiseProductFast(A[1..n]):2index_1 =13fori from2to n4ifA[i] >A[index_1]5index_1 = i6index_2 =17fori from2to n8ifA[i] != A[index_1]andA[i] >A[index_2]9index_2 = i10returnA[index_1] * A[index_2]",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Максимальное произведение» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
    "section_title": "Тестирование и отладка",
    "text": "Реализуйте этот алгоритм и протестируйте его на вводе. Как и ожидалось, алгоритм выводит. Затем проверьте на вводе. На удивление, алгоритм выводит. Изучив код, вы обнаружите, что после первого цикла. Далее алгоритм инициализируетзначением, и цикл for не обновляет. В результате перед возвратом. Чтобы этого избежать, необходимо изменить псевдокод следующим образом: Скопировать код1MaxPairwiseProductFast(A[1..n]):2index_1 =13fori from2to n4ifA[i] >A[index_1]:5index_1 = i6ifindex_1 =17index_2 =28else:9index_2 =110fori from1to n11ifA[i] != A[index_1]andA[i] >A[index_2]12index_2 = i13returnA[index_1] * A[index_2] Опробуйте этот код на маленьких наборах данных, чтобы убедиться, что он выдает правильные результаты. Затем попробуйте ввод. Может оказаться, что программа выдает что-то вродеили даже отрицательное число вместо правильного результата —. Вероятнее всего, это вызвано целочисленным переполнением. Например, на языкеC++такое большое число, как, не умещается в стандартный типint, который занимает 4 байта на большинстве компьютеров и варьируется отдопри Соответственно, вместо использования типаintвC++при вычислении произведения и сохранении результата вам нужно использовать типint64_t. Это предотвратит целочисленное переполнение, так как типint64_tзанимает 8 байтов и хранимые значения варьируются отдопри Протестируйте вашу программу с большими наборами данных, например с массивом, гдедля всех. Это можно сделать двумя способами: Создать массив в программе и передать егоMaxPairwiseProductFast(чтобы не считывать его из стандартного ввода). Создать отдельную программу, которая запишет такой массив в файлdataset.txt. Затем передать этот набор данных вашей программе из консоли: Убедитесь, что при обработке данных ваша программа укладывается в ограничение по времени и выдаёт верный результат:. Теперь вы можете быть уверенным, что ваша программа работает! Однако система оценки снова ругается: Но как создать такой тестовый сценарий, который приведет к сбою программы и поможет понять, что с ней не так? Вероятно, вас интересует, почему мы не предоставили 5-й набор данных из 17 — тот, который привел к сбою программы? Причина проста: в реальности вам не будут показывать тестовые примеры. Даже опытные программисты при решении задач с алгоритмами часто совершают ошибки, которые трудно обнаружить. Поэтому важно научиться находить баги как можно раньше. Когда авторы этой книги только начинали программировать, они ошибочно полагали, что почти все их программы правильные. Сейчас же мы знаем, что при первом запуске наши программы почти никогда не верны. Когда разработчик уверен в работе своей программы, он зачастую использует всего лишь несколько примеров для тестирования. Если результаты выглядят приемлемо, он считает свою работу законченной — но это путь к катастрофе. Если вы хотите убедиться, что ваша программа работает всегда, то советуем тщательно подобрать примеры для тестирования. Реализация алгоритмов, а также их тестирование и отладка будут бесценным навыком для вашей будущей карьеры программиста. Представляем вам стресс-тестирование — технику, которая позволяет генерировать тысячи тестовых сценариев. С её помощью можно найти тот, из-за которого провалилось ваше решение. Стресс-тестирование состоит из четырёх частей: Реализация алгоритма. Альтернативная, банальная и медленная, но правильная реализация алгоритма для той же самой задачи. Генератор случайных тестов. Бесконечный цикл, генерирующий тесты и передающий их обоим вариантам реализации для сравнения результатов. Если результаты разнятся, выводятся оба результата и пример для тестирования, а программа останавливается. В ином случае цикл повторяется. Стресс-тестирование основано на идее, что две правильных реализации с каждым тестом должны приводить к одному ответу (при условии, что ответ на задачу уникален). Однако если одна из реализаций неправильна, должен существовать такой тест, который приводит к разным ответам. Единственный случай, при котором это не так, — когда в обеих реализациях есть одна и та же ошибка. Но это маловероятно — если ошибка не где-то в программе ввода/вывода, общей для обоих решений. Действительно, если одно решение правильно, а другое — нет, то существует сценарий тестирования, при котором они различаются. Если оба решения неверны, но баги отличаются — скорее всего, есть тест, при котором два решения дают разные результаты. Продемонстрируем стресс-тестированиеMaxPairwiseProductFast, используя MaxPairwiseProductNaiveв качестве тривиальной реализации: Скопировать код1StressTest(N, M):2whiletrue:3n = ...// случайное целое число между 2 и N4// создать массив A[1..n]5fori from1to n6A[i] = ...// случайное целое число между 0 и M7print(A[1..n])8result_1 =MaxPairwiseProductNaive(A)9result_2 =MaxPairwiseProductFast(A)10ifresult_1 = result_2:11print(\"OK\")12else:13print(\"Wrong answer:\", result_1, result_2)14return Представленный выше циклwhileсначала генерирует длину вводной последовательности, случайное число междуи. Оно должно быть не менее: формулировка задачи гласит, что. Параметрдолжен быть достаточно маленьким, чтобы позволить нам рассмотреть множество тестов, несмотря на то, что наши решения медленные. Сгенерировав, мы генерируем массивсцелыми числами отдои выводим его, чтобы по ходу бесконечного цикла мы всегда знали, какой тест проходит сейчас. Это упростит нахождение ошибок в коде для генерации теста. Затем мы вызываем два алгоритма дляи сравниваем результаты. Если результаты отличаются, мы их печатаем и останавливаемся. В ином случае мы продолжаем цикл while. Давайте запустимStressTest(10, 100'000)и скрестим пальцы в надежде, что он выдастWrong answer. Для нас это выглядит как-то так (результат может отличаться на вашем компьютере из-за другого генератора случайных чисел). Ура! Мы нашли пример, в которомMaxPairwiseProductNaiveиMaxPairwiseProductFastприводят к разным результатам, и теперь можем проверить, что именно пошло не так. Затем мы отлаживаем это решение через этот пример, находим баг, исправляем его и повторяем стресс-тестирование. Обратите внимание, что генерировать тесты автоматически и проводить стресс-тестирование легко, но находить и исправлять баги — сложно. Прежде чем углубиться в отладку багов, давайте попробуем сгенерировать тестовый пример поменьше — это упростит нам работу. Для этого мы поменяемс 10 на 5 исна. Затем мы заново начинаем стресс-тестирование и получаем следующее: Медленный алгоритмMaxPairwiseProductNaiveдаёт верный ответ(), но быстрыйMaxPairwiseProductFast— неверный (). Чтобы избавиться от багов в первом решении, давайте проверим, какие два числа он считает наибольшими. Для этого мы добавим следующую строку передreturnв функцииMaxPairwiseProductFast: Скопировать код1print(index_1, index_2) Когда мы снова начинаем стресс-тестирование, мы получаем следующее: Это значит, что последовательность выглядит случайной, но она одинакова каждый раз, когда работает программа. Такое свойство удобно и важно. Советуем вам использовать эту практику, потому что в детерминированных программах (тех, что всегда выдают одинаковый результат при одинаковых вводных данных) легче находить баги, чем в недетерминированных. Давайте теперь рассмотрими. Если мы обратим внимание на код для определения второго максимального числа, то заметим неочевидный баг. Когда мы использовали условие для(число не должно быть таким же, как предыдущее самое большое), вместо сравненияимы сравнилии. Это означает, что второе максимальное число отличается от первого по значению, а не по индексу элемента, который мы выбрали для решения задачи. Так, наше решение не работает при любом тесте, в котором второе самое большое число равно первому. Теперь изменим условие: вместо Скопировать код1A[i] != A[index_1] мы используем Скопировать код1i != index_1 Проведя стресс-тестирование еще раз, мы видим на экране шквал сообщенийOK. Ждём минуту, пока нам не надоест, и заключаем, чтоMaxPairwiseProductFastнаконец-то работает правильно! Однако не стоит останавливаться на этом, так как вы сгенерировали только очень маленькие тесты си. Теперь нужно проверить, работает ли наша программа при большеми бо́льших элементах массива. Таким образом, мы меняемна(при большемпримитивное решение будет довольно медленным из-за квадратичного времени выполнения). Мы также меняемнаи запускаем программу. Ещё раз наблюдаем, как экран заполняется сообщениямиOK. Затем ждём минуту, а потом решаем, чтоMaxPairwiseProductFastдействительно работает верно. После этого мы сдаём получившееся решение системе оценки и успешно проходим тест! Как вы можете заметить, даже при решении такой простой задачи какМаксимальное попарное произведениесложно избежать труднораспознаваемых ошибок на этапе проектирования и реализации алгоритма. Приведённый ниже псевдокод — это пример болеенадежногоспособа реализации алгоритма. Скопировать код1MaxPairwiseProductFast(A[1..n]):2index =13fori from2to n4ifA[i] >A[index]:5index = i6swap(A[index], A[n])// поставим наибольшее значение в конец массива7index =1:8fori from2to n -19ifA[i] >A[index]:10index = i11swap(A[index], A[n -1])// поставим второй по величине элемент предпоследним12returnA[n -1] * A[n] В этом хендбуке вы узнаете, как проектировать и реализовывать алгоритмы так, чтобы минимизировать вероятность ошибок. А заодно научитесь тестировать вашу реализацию.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Максимальное произведение» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
    "section_title": "Ещё более быстрый алгоритм",
    "text": "АлгоритмMaxPairwiseProductFastнаходит два самых больших числа примерно засравнений. Когда вы решите эту задачу, вас ждет ещё более сложное упражнение. Попробуйте с ним справиться! Если это упражнение показалось вам слишком простым, посмотрите задачи ниже. Они вполне могут оказаться на следующем собеседовании! Докажите, что не существует алгоритма, которому потребуется менеесравнений, чтобы найти два самых больших элемента массива. Какой алгоритм найдёт три самых больших элемента быстрее всего?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Максимальное произведение» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
    "section_title": "Более компактный алгоритм",
    "text": "ЗадачуМаксимальное попарное произведениеможно решить с помощью следующего компактного алгоритма, который использует сортировку (в неубывающем порядке). Скопировать код1MaxPairwiseProductBySorting(A[1..n]):2Sort(A)3returnA[n-1]*A[n] Этот алгоритм делает даже больше, чем нам нужно: вместо того, чтобы найти два самых больших элемента, он сортирует весь массив. Поэтому его время выполнения, а не. Однако для таких ограничений () он достаточно быстрый, чтобы выполнить задачу за секунду и успешно пройти тесты в нашей системе оценки.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Максимальное произведение» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie",
    "section_title": "Что дальше",
    "text": "Теперь вы увидели, как задача на попарное произведение помогает отработать сразу несколько важных умений: оценку сложности алгоритма, поиск оптимального решения, работу с переполнением и стресс-тестирование. Вы научились сравнивать наивные и быстрые реализации, находить баги и проверять программу на надёжность с помощью генератора случайных тестов. Далее — небольшой параграф с итогами: вспомним, что вы узнали в этой главе, и наметим, куда двигаться дальше. А пока закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Даже в простой на первый взгляд задаче важно учитывать эффективность: наивный перебор может не уложиться в ограничение по времени. Быстрый алгоритм позволяет решить задачу линейно, но требует аккуратности в работе с индексами и типами данных. Стресс-тестирование помогает находить ошибки, которые не видны на демонстрационных примерах, и делает решение по-настоящему надёжным.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80762"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача поиска кратчайшего пути в графе - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-poiska-kratchajshego-puti-v-grafe",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как устроен алгоритм Дейкстры и зачем нужны веса рёбер? Почему алгоритм не работает с отрицательными весами? Как восстановить кратчайший путь после завершения алгоритма?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача поиска кратчайшего пути в графе - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-poiska-kratchajshego-puti-v-grafe",
    "section_title": "Принцип работы алгоритма Дейкстры",
    "text": "Зачастую в графах требуется находить между вершинами кратчайшие пути. Один из алгоритмов нахождения кратчайших путей от заданной вершины до любой другой — алгоритм Дейкстры. Алгоритм работает только для графов без рёбер отрицательного веса. Асимптотическая сложность нахождения компонент связности в графе — O(V+E), где V — число вершин, а E — число рёбер и дуг. Опишем принцип работы алгоритма Дейкстры: Шаг 1. Всем вершинам, за исключением первой, присваивается вес равный бесконечности, а первой вершине — 0. Шаг 2. Все вершины не посещены. Шаг 3. Первая вершина объявляется текущей. Шаг 4. Вес всех невыделенных вершин пересчитывается по формуле: вес невыделенной вершины есть минимальное число из старого веса данной вершины, суммы веса текущей вершины и веса ребра, соединяющего текущую вершину с невыделенной. Шаг 5. Среди невыделенных вершин ищется вершина с минимальным весом. Если такова не найдена, то есть вес всех вершин равен бесконечности, то маршрута не существует. Следовательно, выход. Иначе, текущей становится найденная вершина. Она же выделяется. Шаг 6. Если текущей вершиной оказывается конечная, то путь найден, и его вес есть вес конечной вершины. Шаг 7. Переход на шаг 4. Пример работы алгоритма показан на картинке ниже. Посмотрим на реализацию. Скопировать код1Dijkstra(graph, start, finish, used):2vectord(n, inf),p(n,-1)3n=len(graph)4graph[v] =15for(inti =0; i <n; ++i)6intv =-17for(intj =0; j <n; ++j)8if(!used[j]and(v ==-1ord[j] <d[v]))9v = j10used[v] =true11for(intj =0; j <len(graph[v]); ++j)12to = graph[v][i].vertex13len = graph[v][i].edge14if(d[v] + len <d[to])15d[to] = d[v] + len16p[to] = v Асимптотическая сложность алгоритма Дейкстры —, где— число вершин, а— число рёбер и дуг. Подумайте, как восстановить путь, используя введённый массив p? Как изменится кратчайший путь, если все веса рёбер увеличить на какое-то число? Как изменится кратчайший путь, если все веса рёбер увеличить в какое-то число раз? Подумайте, почему алгоритм работает только для графов без рёбер отрицательного веса?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача поиска кратчайшего пути в графе - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-poiska-kratchajshego-puti-v-grafe",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете находить кратчайшие пути в графах с помощью алгоритма Дейкстры. Вы научились пошагово уточнять расстояния до вершин, работать с массивом предков и восстанавливать путь. Вы также поняли, в каких случаях алгоритм применим, а в каких — нет. Далее — завершение главы. Мы кратко подведём итоги, сравним изученные подходы и обобщим стратегии, которые помогут вам уверенно решать задачи на графы. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Алгоритм Дейкстры находит кратчайшие пути от одной вершины до всех остальных в графе без отрицательных рёбер. Идея алгоритма — постепенно уточнять расстояния, переходя от ближайших вершин к более дальним. Для восстановления пути используется массив предков. Алгоритм не работает корректно при наличии отрицательных весов — для таких случаев нужны другие подходы (например, Беллмана — Форда).",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80793"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Максимальный оклад» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnyj-oklad",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Почему обычная сортировка по убыванию не работает для составления максимального числа? Как сравнивать строки чисел, чтобы результат был действительно максимальным? Какие ошибки чаще всего возникают при реализации таких задач — и как их избежать?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Максимальный оклад» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnyj-oklad",
    "section_title": "Вопрос на собеседовании",
    "text": "Перед вами, возможно, самая важная задача в хендбуке. В качестве последнего вопроса на собеседовании будущий начальник даёт вам пять бумажек с одним числом на каждой и просит составить из них самое большое число. Получившееся число — ваша зарплата, поэтому мотивация, чтобы решить эту задачу, зашкаливает. Вспомните алгоритм для этой задачи, который работает с однозначными числами. Скопировать код1LargestConcatenate(Numbers):2yourSalary =\"\"# пустая строка3whileNumbers isnotempty:4maxNumber = -infinity5foreach number in Numbers:6ifnumber >= maxNumber:7maxNumber = number8yourSalary = yourSalary + maxNumber # добавляем число в конец9Numbers.remove(maxNumber) # удалить из рассмотрения число maxNumber10returnyourSalary Такой алгоритм не всегда будет приводить к самой большой зарплате: например, при вводе из двух целых чисел 23 и 3 он выдаст 233, в то время как самое большое число — 323. Не беспокойтесь, чтобы получить самую большую зарплату, вам всего лишь нужно заменить строку Скопировать код1ifnumber >= maxNumber: на следующую: Скопировать код1ifIsBetter(number, maxNumber):2 Для надлежаще реализованной функцииIsBetterнужно учесть порядок цифр и их количество. ФункцииIsBetter(first, second)должна возвращать булеву величину сооветствующую ответу на вопрос: нужно ли ставить числоfirstраньше числаsecond. Например,IsBetter(3, 23)выдастTrue. Входные данные: Первая строка ввода содержит целое число. Вторая строка содержит целые числа. Выходные данные: Самое большое возможное число, которое состоит из. Ограничения:;для всех. Обратите внимание, что в этом случае приведённый выше алгоритм также выдаёт неправильный ответ 212. Ввод состоит только из однозначных чисел, поэтому алгоритм выше выдаёт правильный ответ. Тем не менее алгоритмLargestConcatenate(неверный) в этом случае приводит к правильному результату — ещё одно напоминание, что всегда стоит проверять правильность жадных алгоритмов!",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Максимальный оклад» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnyj-oklad",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как применять жадную стратегию не только к числам, но и к строкам. Вы научились сравнивать строки так, чтобы получить максимальное число, — и поняли, что простой порядок убывания не всегда работает. Эта задача — отличный пример того, как важно выбрать правильный критерий сравнения, даже если идея кажется простой. Далее — подведение итогов. Вы вспомните, какие приёмы жадных алгоритмов вы освоили, в чём их сила и в чём ограничения. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. В некоторых задачах важно уметь сравнивать строки нестандартным способом — не по алфавиту, а по результату объединения. Простая сортировка не всегда даёт правильный результат: нужно чётко задать правило, по которому элементы упорядочиваются. Жадные стратегии применимы и к строкам, но требуют особенно внимательной формулировки критерия выбора.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80771"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Практические задания с автоматической проверкой - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/prakticheskie-zadaniya-s-avtomaticheskoj-proverkoj",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Какие шаги проходит программист при решении алгоритмической задачи? Как проверить корректность и эффективность своего решения до его сдачи?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Практические задания с автоматической проверкой - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/prakticheskie-zadaniya-s-avtomaticheskoj-proverkoj",
    "section_title": "Пять простых шагов для решения задачи по программированию",
    "text": "Чтобы рассказать, как работает наша система автоматической оценки, мы по шагам разберём две простые задачи. А заодно покажем несколько распространённых проблем и способы их преодоления. Итак, решение задач по программированию состоит из пяти шагов: Разбор условия задачи.Формулировка задачи указывает формат ввода и вывода, ограничения для данных ввода и использования памяти. От вас требуется написать быструю программу, которая уложится в ограничения по времени и использованию памяти. Проектирование алгоритма.Когда вы поняли, в чём состоит задача, начинайте проектировать алгоритм. Не забудьте доказать, что он работает правильно. Реализация алгоритма.Когда алгоритм спроектирован, его можно реализовать в вашем языке программирования. Тестирование и отладка.Тестирование — это искусство поиска багов. Отладка — это искусство устранения багов. Когда программа готова, приступайте к тестированию! А если обнаружите баг — исправьте его и протестируйте программу снова. Отправка программы на оценку.Когда программа протестирована, сдайте её системе оценки. Если вы увидите сообщениеOK, значит всё в порядке. Если нет — возвращайтесь к предыдущим шагам. Для начала прочтите формулировку задачи. В неё входят описание вычислительной части, ограничения по времени и использованию памяти и несколько демонстрационных тестов. Убедитесь, что вы понимаете, как вывод соотносится с вводом в каждом из демонстрационных примеров. Если ограничения по времени и памяти не указаны прямо в формулировке задачи, используются следующие значения по умолчанию. Ограничение по времени (с):1 Ограничение памяти:512 Mb Когда вы разработали алгоритм, докажите, что он работает верно, и попробуйте оценить время выполнения с помощью самых сложных вводных данных, указанных в секции об ограничениях. Если ваш ноутбук выполняет около–операций в секунду, и максимальный размер набора данных в описании задачи, тогда алгоритм с квадратичным временем выполнения вряд ли уложится в ограничение по времени (так как), в то время как решение с временем выполнениясможет это сделать. Тем не менее решение сподойдёт, еслии если. Сработать могут даже решения с. Хотя для некоторых трудных задач в книге полиномиальные алгоритмы и остаются неизвестными, решение с временем выполненияможет уложиться в ограничение по времени приниже. Начните реализацию алгоритма на одном из языков программирования, которые поддерживаются нашей системой автоматической оценки. Напоминаем, это:C++,Java,Python3. ДляC++,Java, иPython3есть примеры (авторские решения) с правильным решением задачи, учитывающие ее ограничения. Они тратят максимум 1/3 заданного лимита по времени и максимум 1/2 по памяти. Сдавать вашу реализацию на оценку, не проверив её, — это плохая идея! Начните с маленьких наборов данных и убедитесь, что ваша программа выдаёт верный результат со всеми предложенными наборами данных. Затем проверьте, сколько времени занимает обработка большого набора данных. Для оценки времени выполнения имеет смысл реализовать ваш алгоритм как функцию — например,solve(dataset)— и потом реализовать дополнительную процедуруgenerate(), которая выдаст большой набор данных. Например, если ввод задачи — это последовательность целых чисел длиной, тогда сгенерируйте последовательность длиной, передайте её функцииsolve()и убедитесь, что программа выдаёт правильный результат. Проверьте ограничивающие значения, чтобы можно было гарантировать, что программа правильно обрабатывает и короткие (например, из 2 элементов), и длинные последовательности (например, из 105105 элементов). Если последовательность целых чисел от 00 до 106106 даётся в качестве ввода — проверьте, как ваша программа ведёт себя с последовательностью 0,0,…,00,0,…,0 или с 106,106,…,106106,106,…,106. После этого проверьте программу на случайном наборе данных. Дополнительно советуем проверить экстремальные случаи: пустой набор данных, три точки на одной строке, дерево из одного узла и так далее. Убедившись, что ваша программа выполняет все эти тесты, переходите к стресс-тестированию. Реализуйте медленный, но простой и верный алгоритм. Проверьте, выдают ли две программы одинаковый результат, — однако обратите внимание, что это не применимо к задачам, в которых вывод не уникален. Сгенерируйте случайные тестовые сценарии, а также тесты с изменением параметров — например, с использованием только маленького диапазона больших чисел, строки с одной буквойaили только двумя разными буквами (вместо строк, использующих все буквы латинского алфавита) и так далее. Подумайте, какие ещё тесты могут быть в каком-то смысле необычными. Например, если вы генерируете графы, попробуйте генерировать древовидные, несвязные, полные, двудольные и так далее. Если вы генерируете древовидные графы, попробуйте генерировать пути, двоичные деревья, звезды и так далее. Если вы генерируете целые числа, попробуйте генерировать и простые, и составные числа. Когда вы закончили тестирование, сдавайте вашу программу на проверку. Перейдите на страницу, где сдаются задания, и создайте новое выполненное задание. Загрузите файл с вашей программой (обязательно загрузите исходный файл, а не готовое приложение). После этого система оценки скомпилирует вашу программу и использует набор тщательно продуманных тестов, чтобы убедиться, что программа выдаёт правильный результат для всех тестов и что она укладывается в ограничения по времени и памяти. В большинстве случаев оценка занимает около минуты, но в редких случаях, когда серверы загружены, может потребоваться больше времени. Пожалуйста, наберитесь терпения. После загрузки решения можно спокойно уходить со страницы. В качестве результата вы получите обратную связь от системы оценки. Вам нужно получить вердиктOK— он обозначает, что ваша программа прошла все тесты. СообщенияWrong answer,Time limit exceeded,Memory limit exceededозначают, что программа не прошла тест по одной из этих причин. Если ваша программа даёт сбой, проходя один из первых двух тестовых сценариев, система оценки скажет вам об этом и покажет тестовый сценарий и вывод вашей программы. Это должно помочь вам использовать правильный формат ввода/вывода. В остальных случаях система оценки не будет показывать вам тестовый сценарий, который ваша программа не смогла выполнить.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Практические задания с автоматической проверкой - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/prakticheskie-zadaniya-s-avtomaticheskoj-proverkoj",
    "section_title": "Что дальше",
    "text": "Теперь вы понимаете, как проходит полный цикл работы над задачей: от разбора условия до уверенного тестирования решения. Вы научились не только писать алгоритмы, но и проверять их корректность и производительность. Далее — простейшая задача, с которой удобно начать практику. Вы увидите, как её можно решить на C++, Java и Python 3, и попробуете реализовать свой первый рабочий код. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Решение задачи по программированию проходит через пять ключевых этапов: разбор условия, проектирование алгоритма, реализация, тестирование и анализ результатов. Оценка корректности и эффективности алгоритма помогает убедиться, что решение работает правильно и укладывается в заданные ограничения. Хорошее тестирование — это не просто проверка на примерах, а систематический подход: граничные случаи, случайные данные, стресс-тесты.",
    "source_type": null,
    "useful_links": [
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Поиск доминирующего элемента - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/poisk-dominiruyushego-elementa",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Почему стандартная быстрая сортировка может работать медленно на массивах с повторяющимися элементами? Как изменить алгоритм так, чтобы избежать деградации производительности? Как реализовать трёхчастное разбиение и почему оно даёт прирост в эффективности?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Поиск доминирующего элемента - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/poisk-dominiruyushego-elementa",
    "section_title": "Проверка последовательности",
    "text": "Ваша задача — проверить, содержит ли данная последовательность элемент, который встречается более половины раз. Формат ввода: Первая строка содержит целое число, следующая — последовательностьцелых неотрицательных чисел. Формат вывода: Выведите, если в последовательности содержится элемент, который встречается больше, чемраз, ив противном случае. Ограничения:;для всех. Примеры: В первом примере— доминирующий элемент. Во втором примере у последовательности нет доминирующего элемента. Обратите внимание, что элемент— не доминирующий. Здесь приведён примитивный алгоритм, который решает задачу «Поиск доминирующего элемента» за квадратичное время: Скопировать код1MajorityElement(A[1..n]):2fori from1to n:3currentElement = A[i]4count =05forj from1to n:6ifA[j] = currentElement:7count = count +18ifcount >n/2:9return110return0 На практике входную последовательность можно просканировать и сохранить число вхождений каждого элемента в ассоциативном массиве. Время выполнения этого решения зависит от конкретной реализации ассоциативного массива. Если реализация представляет собой сбалансированное дерево поиска, тогда каждый уточняющий запрос в массиве занимает, а общее время выполнения составляет. Для хеш-таблиц уточняющие запросы эффективны на практике, хотя и могут варьироваться в зависимости от вводных данных. Стратегия «разделяй и властвуй» приводит к простому алгоритму с временем выполнения. Несложная, но невероятно важная вещь: если— это доминирующий элемент последовательности, тогдадолжен быть доминирующим элементом как минимум в одной из половин. Однако обратите внимание, что обратное неверно: обе половины последовательностисодержат доминирующие элементы (исоответственно), но ни один из них не является доминирующим элементом изначальной последовательности. Это приводит нас к следующему алгоритму: найти доминирующий элемент в обоих половинах с помощью рекурсии и для каждой из половин проверить количество вхождений в изначальную последовательность. Для последнего шага нам необходимо ещё раз сделать линейное сканирование, что может занять время. Следовательно, время выполненияудовлетворяет, поэтому.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Поиск доминирующего элемента - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/poisk-dominiruyushego-elementa",
    "section_title": "Упражнение",
    "text": "Сможете ли вы спроектировать еще более быстрый алгоритм с временем выполнения? В основе лежит следующая идея. Разделить вводные элементы на пары. Рассмотреть каждую пару: если два элемента различны, отбросить оба; в противном случае отбросить один из них.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Поиск доминирующего элемента - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/poisk-dominiruyushego-elementa",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете модифицировать быструю сортировку так, чтобы она работала эффективно даже на массивах с повторяющимися элементами. Вы узнали, как устроено трёхчастное разбиение, и научились избегать худших случаев, когда обычная реализация деградирует до квадратичного времени. Далее — задача на подсчёт инверсий. Вы увидите, как можно сочетать сортировку и рекурсию, чтобы решать аналитические задачи быстрее, чем простым перебором. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Стратегия «Разделяй и властвуй» позволяет находить доминирующий элемент за, разбивая задачу на части. Элемент считается доминирующим, если он встречается больше чем в половине элементов последовательности. Проверки в обеих половинах не гарантируют общий результат — требуется финальное сканирование. Можно спроектировать и более быстрый алгоритм за, если использовать идею попарного сравнения и отбрасывания.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80773"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Расставить скобки» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstavit-skobki",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Почему результат арифметического выражения зависит от порядка скобок? Как использовать динамическое программирование для перебора всех вариантов группировки? Как устроены таблицы для хранения минимальных и максимальных значений подвыражений?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Расставить скобки» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstavit-skobki",
    "section_title": "Упражнение",
    "text": "Для выражениясуществуют два способа расставить скобки:и. Для максимального значения нужно поставить в скобки выражение. Входные данные: Ввод содержит только строкудлинойдля некогос символами. Каждый символ на чётной позиции— это цифра (то есть целое число от 0 до 9), а на нечетной позиции — одна из трёх операций из. Выходные данные: Максимальное значение данного арифметического выражения из всех возможных порядков арифметических операций. Ограничения:— таким образом, строка содержит максимумсимволов. Пример 1 Рассмотрим решение задачи. Каждая из пяти операций в выражении может быть последней — внешней. Рассмотрим случай, в котором последняя операция — «», то есть умножение. В этой ситуации нам необходимо поместить дваподвыраженияв скобки таким образом, чтобы произведение значений было максимальным. Чтобы это выяснить, мы находим минимальные и максимальные значения данных двух подвыражений: На основании этих значений мы заключаем, что общее значение произведения составляет. Предположим, что вводный набор данных имеет форму где каждая— это цифра, а каждая— базовая арифметическая операция. Сказанное выше предполагает, что мы вычисляем минимальное и максимальное значение каждого подвыражения в форме где. Пустьи— минимальное и максимальное значениесоответственно. Тогда Базовый случай — это: Эти два рекуррентных соотношения позволяют нам вычислить оптимальные значения, изучив все возможные варианты разделенияна два подвыраженияи. Тогда наше рекуррентное соотношение говорит о том, что дерево состоит из корня и двух поддеревьев. Для нахождения оптимальной формы дерева мы анализируем все возможные корни (за это отвечает параметр), а затем составляем дерево из двух оптимальных поддеревьев.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Расставить скобки» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstavit-skobki",
    "section_title": "Как сделать из рекуррентного соотношения рекурсивный алгоритм",
    "text": "Как обычно, сделать из рекуррентного соотношения рекурсивный алгоритм довольно просто. Рекурсивная процедура берёт индексыив качестве параметров и использует их для вычисления минимального и максимального значения подвыражения. Перед тем, как начать вычисления, проверяется, не сохранены ли уже эти значения в, где— это ассоциативный массив, хранящий уже вычисленные результаты. Если записьотсутствует, рекурсивная процедура вычисляет два значения, используя рекуррентное соотношение, сохраняет их в таблицу и выдаёт их. Конечный ответ соответствуети. Время выполнения составляет: естьвозможных пар, для каждой из которых рекурсивная процедура проверяет возможные значения для. Для переведения рекурсивного алгоритма в итерационный используются двумерные таблицыи, в которых хранятся минимальные и максимальные значения всех подвыражений. Заполняя данные таблицы, нам нужно убедиться, что к окончанию вычислений оптимальных значений дляоптимальные значенияидля всехуже вычислены. Один из способов сделать это — перечислить все парыв порядке возрастания значения. Чтобы это сделать, в псевдокоде ниже используется параметр. Скопировать код1MaxValue(d[0],op[0],d[1],op[1],…d[n]):2mins, maxs =2d-arrays ofsize(n+1)×(n+1)3fill mins with +infinity, fill maxs with -infinity4fori from0to n:5mins[i][i]=d[i], maxs[i][i]←d[i]​6fors from1to n:7forl from1to n-s:8r = l+s9form from l to r-1:10a = mins[l][m] op[m] mins[m+1][r]11b = mins[l][m] op[m] maxs[m+1][r]12c = maxs[l][m] op[m] mins[m+1][r]13d = maxs[l][m] op[m] maxs[m+1][r]14mins[l][r] =min(mins[l][r],a,b,c,d)15maxs[l][r] =max(maxs[l][r],a,b,c,d)16returnmaxs[0][n]",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Расставить скобки» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-rasstavit-skobki",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете вычислять максимальное значение арифметического выражения, расставляя скобки в нужном порядке. Вы научились использовать динамическое программирование с запоминанием минимальных и максимальных значений и применять аккуратные рекурсивные формулы. Далее — финальный параграф главы. В нём мы кратко обобщим ключевые идеи, которые вы встретили, и покажем, как они складываются в систему. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Порядок выполнения операций влияет на результат арифметического выражения — важно правильно расставить скобки. Можно эффективно найти максимальное значение, если сохранять минимумы и максимумы всех подвыражений в таблицах. Динамическое программирование позволяет избежать повторных вычислений и уменьшает время работы с экспоненциального до кубического. Даже при небольшом числе операций количество возможных расстановок скобок велико — поэтому важно автоматизировать перебор.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80783"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Вычисление НОК и НОД - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/vychislenie-nok-i-nod",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как работает алгоритм Евклида и чем он лучше наивных подходов? Как связаны НОД и НОК, и как их вычислить быстро даже для больших чисел? Почему важно контролировать сложность алгоритма даже в задачах с простой формулировкой?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вычисление НОК и НОД - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/vychislenie-nok-i-nod",
    "section_title": "Наибольший общий делитель",
    "text": "Наибольший общий делительдвух положительных целых чисели— это самое большое целое число, на которое можно поделитьибез остатка. Двадцать три века назад греческий математик Евклид впервые описал, как найти самый большой общий делитель.Однако нам до сих пор неизвестно имя математика, разработавшего этот алгоритм за век до Евклида. Спустя много веков алгоритм Евклида ещё раз обнаружили индийские и китайские астрономы. Теперь эффективный алгоритм, вычисляющий наибольший общий делитель, — важный ингредиент для современных криптографических алгоритмов. Ваша задача — использовать алгоритм Евклида для вычисления. Формат ввода: Целые числаи(разделённые пробелом). Формат вывода:. Ограничения:. Примеры Числа 18 и 35 не обладают общими нетривиальными делителями. ,. Простой, но ужасно медленный способ вычислить наибольший общий делитель: Скопировать код1GCD(a, b):2ford отmin(a,b) вниз до1:3ifa % d ==0andb % d ==0:// d делит a и d делит b4returnd Рисунок к задаче даёт нам простую, но чрезвычайно важную подсказку: если и, иможно разделить на, значит иможно разделить на. Оказывается, что верно и обратное. Докажите, чтопри. Это наблюдение позволяет нам вычислить наибольший общий делитель,отнимая меньшее число от большего снова и снова.В конце концов одно из чисел дойдет до нуля. В таком случае мы просто возвращаем другое число (если, то). Скопировать код1GCD(a, b):2whilea >0andb >0:3ifa >= b:4a = a−b5else:6b = b−a7returnmax(a,b) Насколько этот алгоритм быстрый? Этот алгоритм всё ещё слишком медленный. Например, приион продолжает отниматьот— более миллиона раз (в то время как изначальный алгоритм находит наибольший общий делитель приимоментально), так как ему нужно только пройти через. Но не беспокойтесь. Сейчас мы сделаем наш алгоритм эффективнее. Правильно! Мы получим 6 — остатокпри делении на 7. Сказанное выше приводит нас к алгоритму Евклида. Скопировать код1GCD(a, b):2whilea >0andb >0:3ifa >= b:4a = a % b5else:6b = b % a7returnmax(a,b) Это быстрый алгоритм: при любых, он вычисляет их наибольший общий делитель мгновенно. Для значенийв этом диапазоне количество итераций циклаwhileне превышает сотни. Обоснование этого утверждения можно построить на факте, что после каждой итерации одно из чисел становится как минимум в два раза меньше. Следовательно, после максимумитераций или, илидойдёт до нуля. Так как,. В качестве последнего комментария мы подметим, что такой же алгоритм можно использовать рекурсивно, занимая всего три строки кода. Скопировать код1GCD(a, b):2ifa =0orb =0:3returnmax(a,b)4returnGCD(b,a mod b)",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вычисление НОК и НОД - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/vychislenie-nok-i-nod",
    "section_title": "Наименьшее общее кратное",
    "text": "Наименьшее общее кратноедля двух положительных целых чисели— это самое маленькое целое число, которое можно разделить и на, и на. Рисунок выше демонстрируетдля каждой пары чисел,и, а также наименьшее общее кратное для всех трёх. Рисунок ниже показывает наибольший общий делитель для этих же чисел. Формат ввода: Целые числаи(разделённые пробелом). Формат вывода: Ограничения:. Примеры — Среди всех положительных целых чисел, которые можно разделить и на 6, и на 8 (например, 48, 480 и 24), 24 — наименьшее число.— Совет: для деления целых чисел вPython3используйте//(вместо/) Для обоснования соотношениярассмотрим разложениеина простые множители. Если простоевходит в разложениев степении в разложение— в степени, тоделится на, адолжно делиться на. Для завершения обоснования формулы стоит использовать соотношение.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вычисление НОК и НОД - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/vychislenie-nok-i-nod",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как эффективно вычислять наибольший общий делитель при помощи алгоритма Евклида — и почему он работает в разы быстрее наивных подходов. Вы также научились находить наименьшее общее кратное и увидели, как связаны эти два понятия. Всё это — основа для задач, в которых важно понимать делимость и оптимально работать с числами. Далее — короткое заключение, в котором мы подведём итоги главы и соберём всё, чему вы научились в задачах на Фибоначчи, НОД и НОК. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Алгоритм Евклида позволяет быстро находить наибольший общий делитель и работает значительно эффективнее наивных решений. НОК удобно вычислять через НОД, используя формулу LCM(a,b)= a⋅b​ / GCD(a,b).",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80764"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Сумма двух чисел» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-summa-dvuh-chisel",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как выглядит корректное решение самой простой задачи на разных языках программирования? Что важно учитывать при оформлении и тестировании даже самых базовых программ?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Сумма двух чисел» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-summa-dvuh-chisel",
    "section_title": "Разбор примера",
    "text": "Рассмотрим совсем простую задачу. Входные данные: Целые числаина одной строке (разделённые пробелом). Выходные данные: Суммаи. Ограничения:. Пример Ограничение по времени (с): 1 секунда Ограничение по памяти: 512 Mb. Поскольку задача решается в одно действие, шагСпроектировать алгоритммы пропустим и перейдём сразу к псевдокоду. Скопировать код1SumOfTwoDigits(a, b):2returna + b Так как псевдокод не уточняет вводи, ниже мы приводим решения для языковC++,JavaиPython3, а также рекомендации по компиляции и реализации. Вы можете скопировать и вставить код в файл, скомпилировать, запустить и протестировать с разными данными, а затем сдать исходный файл в систему проверки. Разумеется, мы рассчитываем, что вы знакомы с основами одного из языков программирования, который используется в нашей системе тестирования:C++,Python3,Java. Скопировать код1#include<iostream >23intsum_of_digits(intfirst,intsecond){4returnfirst + second;5}67intmain(){8inta =0;9intb =0;10std::cin >>a;11std::cin >>b;12std::cout <<sum_of_digits(a, b);13return0;14} Скопировать код1importjava.util.Scanner;23classSumOfTwoDigits{4staticintsumOfTwoDigits(intfirst_digit,intsecond_digit){5returnfirst_digit + second_digit;6}78publicstaticvoidmain(String[] args){9Scanners=newScanner(System.in);10inta=s.nextInt();11intb=s.nextInt();12System.out.println(sumOfTwoDigits(a, b));13}14} Скопировать код1defsum_of_digits(first_digit, second_digit):2returnfirst_digit + second_digit34if__name__ =='__main__':5a, b =map(int,input().split())6print(sum_of_digits(a, b)) Ваша цель — реализовать алгоритм, который даёт верный результат с ограничениями по времени и памяти и при любом вводе. Нет необходимости проверять, что входные данные соответствуют ограничениям, — например, в задачеСумма двух чиселвам не нужно следить за тем, чтобы целые числаидействительно были однозначными (это гарантировано).",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Сумма двух чисел» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-summa-dvuh-chisel",
    "section_title": "Что дальше",
    "text": "Теперь вы разобрались, как выглядит самая простая задача и как оформить корректное решение на разных языках программирования. Это важный шаг: вы научились уверенно работать с вводом, выводом и базовой логикой программы. Далее — задача посложнее. Она потребует не только корректной реализации, но и оценки эффективности. Вы увидите, почему наивный алгоритм не всегда подходит, и научитесь искать более быстрые решения. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Даже у простой задачи есть структура: ввод, обработка, вывод. Важно уметь оформить решение понятно и корректно, чтобы можно было уверенно работать с ним, проверять и развивать его дальше.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80761"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Стек - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/stek",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Что такое стек и как он устроен? Какие операции поддерживает стек и какова их сложность? Где и как стек применяется в алгоритмах и повседневных задачах?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Стек - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/stek",
    "section_title": "Определение стека",
    "text": "Стек (stack) — структура данных, которая работает по принципу «последним пришёл, первым ушёл» (LIFO — last in, first out). Стек можно представить как некий контейнер, в котором элементы (например, числа, символы и так далее) могут быть добавлены в вершину, а затем извлечены только из вершины. В бытовом плане стек напоминает стопку тарелок. Тарелка, которую положили первой, в самый низ, будет использована последней. Существуют различные реализации стека. Например, стек может быть реализован на массиве, на односвязном списке, на двусвязном списке и так далее. В параграфе будем говорить о реализации стека на односвязном списке. Основные операции, которые можно производить со стеком, включают: Добавление элемента в вершину стека (push) —. Удаление элемента из вершины стека (pop) —. Возврат верхнего элемента без его удаления (peek) —. Проверка стека на пустоту (isEmpty) —. Стоит отметить, что стек представляет собой список с элементами и указателя на вершину стека, указывающего на последний элемент, добавленный в стек. Каждый раз, когда в стек добавляется новый элемент, указатель на вершину смещается на следующий элемент. Когда элемент удаляется из вершины стека, указатель смещается на предыдущий элемент. Если указатель находится в конце стека, то стек пуст.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Стек - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/stek",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как устроен стек и как использовать его для решения задач с вложенностью, отменой действий или разворотом данных. Вы освоили основные операции и поняли, почему стек важен в алгоритмах. Далее — структура, которая позволяет не просто сохранять элементы, а учитывать их приоритет. Вы узнаете, как работает очередь с приоритетом и где она применяется в реальных алгоритмах. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Стек — структура данных, работающая по принципу LIFO («последним пришёл — первым вышел»). Основные операции: добавление (push), удаление (pop) и просмотр верхнего элемента (peek) — выполняются заO(1). Стек удобен для задач со вложенной структурой: проверка корректности скобок в выражениях (каждая открывающая должна иметь соответствующую закрывающую); поддержка рекурсии (системный стек вызовов); откат действий в редакторах и программах. Прост в реализации и широко используется в парсерах, алгоритмах обхода графов и обработке выражений.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80787"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Простой калькулятор» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-prostoj-kalkulyator",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Почему жадная стратегия не гарантирует оптимальный результат при построении последовательности операций? Как использовать динамическое программирование для поиска минимального числа шагов? Как восстановить оптимальную последовательность действий из таблицы значений?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Простой калькулятор» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-prostoj-kalkulyator",
    "section_title": "Вводная информация по задаче",
    "text": "У вас есть калькулятор, который выполняет с целым числомтолько следующие операции: сложитьи, умножитьнаили умножитьна. Имея положительное целое число, вы должны найти минимальное количество операций, необходимых для получения числаиз числа. Попробуем решить эту задачу с помощью «жадной» стратегии: если текущее число не превышает, то умножим его на 3; если оно больше, но не больше, то умножим его на 2; в остальных случаях добавим к нему 1. Это приводит к следующему псевдокоду. Скопировать код1GreedyCalculator(n):2numOperations =03currentNumber =14whilecurrentNumber <n:5ifcurrentNumber <= n/3:6currentNumber =3*currentNumber7elseifcurrentNumber <= n/2:8currentNumber =2*currentNumber9else:10currentNumber =1+currentNumber11numOperations = numOperations+112returnnumOperations Входные данные: Целое число. Выходные данные: В первой строке:— минимальное число необходимых операций для полученияиз. Во второй строке: последовательность промежуточных чисел. Так, вторая строка должна содержать положительные целые числа, при которых,, и для всехравно,или. Если таких последовательностей много, то можно вывести любую из них. Ограничения:. Ещё один корректный вывод в этом случае — это «1 3 9 10 11 33 99 297 891 2673 8019 16038 16039 48117 96234». Рассмотрим решение задачи. Пусть— минимальное количество операций, необходимых для получения числаиз числа. Так как последняя операция в оптимальной последовательности — это «», «» или «», мы получаем следующее рекуррентное соотношение для: Данное рекуррентное соотношение, вместе с базовым случаем, можно трансформировать в рекурсивный, а затем в итерационный алгоритм. Скопировать код1Calculator(n):2table[1..n]←[+infinity,…,+infinity]3table[1] =045fork from2to n:6table[k]=1+table[k−1]7ifk is divisible by2:8table[k]=min(table[k],1+table[k/2])9ifk is divisible by3:10table[k]=min(table[k],1+table[k/3])11returntable[n] Помните, что помимо оптимального значения необходимо вывести оптимальную последовательность операций. Для этого обратим внимание на то, что мы можем найти последнюю операцию следующим образом: это «», если; это «», еслиможно разделить наи; это «», еслиможно разделить наи. Эти действия позволяют нам выявить оптимальную последовательность: найти последнюю операцию; заменитьна,или(в зависимости от того, какой это из трёх случаев выше); повторить (пока). Скопировать код1Calculator(n):2table[1..n]←[+infinity,…,+infinity]3table[1] =045fork from2to n:6table[k]=1+table[k−1]7ifk is divisible by2:8table[k]=min(table[k],1+table[k/2])9ifk is divisible by3:10table[k]=min(table[k],1+table[k/3])1112operations = empty list13whilen >1:14append n to operations15iftable[n]=1+table[n−1]:16n = n -117elseifn is divisible by2andtable[n]=1+table[n/2]:18n = n/219elseifn is divisible by3andtable[n]=1+table[n/3]:20n = n/321returnoperations Время выполнения алгоритма составляет.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Простой калькулятор» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-prostoj-kalkulyator",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как находить минимальную последовательность операций для получения заданного числа, используя динамическое программирование. Вы научились строить таблицу значений и восстанавливать по ней путь — от цели к началу. А ещё убедились, что жадный подход может подвести, даже если кажется логичным. Далее — задача на редактирование строк. Вы узнаете, как рассчитать расстояние между двумя строками, используя матрицу изменений, и зачем это нужно в задачах на сравнение, поиск и коррекцию. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный алгоритм может не давать оптимальный результат — даже если кажется разумным. Динамическое программирование позволяет найти кратчайшую последовательность операций с минимальными затратами. Чтобы восстановить путь, нужно не только посчитать значения, но и зафиксировать переходы. Умение строить такие цепочки важно для задач, где нужно не только посчитать, но и объяснить, как получить ответ.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80778"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Алгоритмы «Разделяй и властвуй» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/razdelyaj-i-vlastvuj",
    "section_title": "Ключевые вопросы параграфа",
    "text": "В чём суть подхода «Разделяй и властвуй» и как он помогает ускорить решение задач? Как работает MergeSort и чем он отличается от наивных алгоритмов сортировки? Почему объединение результатов подзадач — не менее важный шаг, чем их решение?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Алгоритмы «Разделяй и властвуй» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/razdelyaj-i-vlastvuj",
    "section_title": "Алгоритм «Разделяй и властвуй»",
    "text": "Одна большая задача может казаться трудной. Но если разделить её на две задачи в два раза меньше, она станет намного проще. Для таких случаев хорошо подходят алгоритмы «разделяй и властвуй». Они так и работают: разделяют задачу на более мелкие подзадачи, независимо находят решения для них и соединяют результаты в решение изначальной задачи. Конечно, реальные ситуации бывают более сложными, чем мы описали. После разделения одной задачи на подзадачи, алгоритм обычно делит их на ещё более мелкие под-подзадачи и так далее. Он продолжает это делать, пока не дойдёт до точки, где в рекурсии уже нет необходимости. В качестве примера алгоритма «разделяй и властвуй» приведём задачу сортировки: Сортировка: Отсортируйте набор целых чисел. Входные данные: Список изразных чисел. Выходные данные: Отсортированный список целых чисел. Измененный порядокцелых чисел от, где. SelectionSort— это простой итерационный метод решения задачи по сортировке. Сначала он находит самый маленький элемент в, а затем меняет его местами с первым элементом (то есть с). Затем он находит второй самый маленький элемент ви переставляет его на второе место, меняя элемент местами с. Повторяя это действие в-й раз,SelectionSortнаходит-й самый маленький элемент ви переставляет его на-е место. Если,SelectionSort(a)будет состоять из следующих семи шагов: Время выполненияSelectionSortквадратично, то есть: используетсяитераций, для каждого из которых требуется время, чтобы просканировать не болееэлементов и найти самый большой из них для суффикса. Тем не менее общее время выполнения растёт как:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Алгоритмы «Разделяй и властвуй» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/razdelyaj-i-vlastvuj",
    "section_title": "АлгоритмMergeSort",
    "text": "MergeSort— классический пример алгоритма «разделяй и властвуй» для сортировки. Он намного быстрее, чемSelectionSort. Начнём с задачи слияния, в которой нам нужно будет объединить два отсортированных списка —и— в один отсортированный список. АлгоритмMergeобъединяет два отсортированных списка в один за время. Для этого алгоритм повторно выбирает самый маленький элемент из оставшихся вии перемещает его в растущий отсортированный список. Скопировать код1Merge(List_1,List_2):2SortedList = ...// empty list3whileboth List_1andList_2 are non-empty:4ifthe smallest element in List_1 is smaller than the smallest element in List_2:5move the smallest element from List_1 to the end of SortedList6else:7move the smallest element from List_2 to the end of SortedList8move any remaining elements from either List_1orList_2 to the end of SortedList9returnSortedList Merge— полезный инструмент для сортировки произвольного списка, если мы знаем, как разделить неотсортированный список на две отсортированные половины. Вам может показаться, что мы вернулись к тому, с чего начали, только теперь нам нужно отсортировать два меньших списка вместо одного большого. Но сортировка двух мелких списков — более предпочтительная алгоритмическая задача. Чтобы понять, почему это так, мы рассмотрим алгоритмMergeSort. Он разделяет неотсортированный список на две части и использует рекурсию для выполнения мелких задач перед тем, как объединить отсортированные списки. Скопировать код1MergeSort(List):2ifList consists of a single element:3returnList4FirstHalf = first half of List5SecondHalf = second half of List6SortedFirstHalf =MergeSort(FirstHalf)7SortedSecondHalf =MergeSort(SecondHalf)8SortedList =Merge(SortedFirstHalf,SortedSecondHalf)9returnSortedList Нарис.изображено рекурсивное деревоMergeSort, состоящее изуровней, где— размер изначального неотсортированного списка. На нижнем уровне нам нужно объединить два отсортированных списка размером примерно вэлементов, что займётвремени. На следующем самом высоком уровне нам нужно объединить четыре списка изэлементов, что потребуетвремени. Такой шаблон можно описать следующим образом:-й уровень состоит изсписков, каждый из которых включает в себя приблизительноэлементов и занимаетвремени для объединения. Так как в рекурсивном деревеуровней, выполнениеMergeSortпотребует в общемвремени, что даёт нам большое ускорение по сравнению с более наивнымалгоритмом сортировки.",
    "source_type": null,
    "useful_links": [
      {
        "text": "рис.",
        "url": "#Placeholder-1-18"
      }
    ]
  },
  {
    "document_title": "Алгоритмы «Разделяй и властвуй» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/razdelyaj-i-vlastvuj",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как работает подход «Разделяй и властвуй» и как с его помощью ускорить решение задач. Вы научились использовать рекурсию, объединять подзадачи и применять это к сортировке. Далее — рандомизированные алгоритмы. Вы увидите, как случайность может стать преимуществом в вычислениях, и узнаете, почему некоторые вероятностные алгоритмы работают быстрее, чем детерминированные. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Подход «Разделяй и властвуй» помогает решать задачи, разбивая их на части и объединяя решения. Алгоритм MergeSort сортирует список за O(n log n) благодаря рекурсивному делению и слиянию. Такие алгоритмы часто быстрее наивных и хорошо масштабируются.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/79935"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Основы алгоритмов: Работа с системой проверки заданий",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii",
    "section_title": "Интерфейс",
    "text": "Мы рекомендуем решать задачи с компьютера: так удобнее, и интерфейс отображается корректно. Когда вы открываете задачу, экран делится на две части: слева — описание задания, справа — редактор, где вы пишете код.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Основы алгоритмов: Работа с системой проверки заданий",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii",
    "section_title": "Структура описания задачи",
    "text": "Описание включает: условие задачи; формат ввода и вывода — какие данные программа получает и должна вернуть; пример — демонстрирует ожидаемый результат; ограничения — по времени и памяти. Вы можете ввести код прямо в редакторе или загрузить файл с решением.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Основы алгоритмов: Работа с системой проверки заданий",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii",
    "section_title": "Отправка решения",
    "text": "После этого начнётся проверка — код будет протестирован на разных входных данных. Этот процесс занимает некоторое время.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Основы алгоритмов: Работа с системой проверки заданий",
    "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii",
    "section_title": "Проверка и тесты",
    "text": "Эти данные не всегда совпадают с примерами из условия задачи — они подобраны так, чтобы проверить решение на корректность, граничные случаи и эффективность. Проверка занимает несколько секунд. Прогресс и историю можно отследить на вкладке «Отправленные решения». Результаты отображаются в виде вердиктов. Вот основные из них: OK (Accepted) — решение прошло все тесты успешно. WA (Wrong Answer) — программа выдала неверный результат хотя бы на одном из тестов. CE (Compilation Error) — ошибка компиляции. RE (Runtime Error) — ошибка выполнения. TM (Time Limit) — при выполнении превышено допустимое время. ML (Memory Limit) — при выполнении превышена допустимая память. В случае WA для тестов из примеров отображаются: входные данные; вывод вашей программы; ожидаемый правильный ответ; вывод системы. Это поможет вам отладить решение. Остальные тесты остаются скрытыми — попробуйте сами смоделировать граничные случаи. Означает, что в коде допущена синтаксическая или другая ошибка, из-за которой программа не запускается. Перейдите в «Лог компиляции», чтобы увидеть подробности: тип ошибки; строка, где она возникла; комментарий от компилятора. Это ошибка, которая возникает во время выполнения программы. Возможные причины: деление на ноль; выход за границы массива; необработанное исключение и т. п. Эти ошибки возникают в ответ на плохо оптимизированный код. Например, если встречается «матрёшка» из циклов. Решение тут только одно — вдумчиво изучить код и попробовать его оптимизировать, сделав менее ресурсоёмким. Если не удаётся разобраться с ошибкой — не спешите расстраиваться. Попробуйте: упростить тест и воссоздать ситуацию локально; добавить отладочный вывод; обсудить решение с участникамисообществахендбука.",
    "source_type": null,
    "useful_links": [
      {
        "text": "сообщества",
        "url": "https://t.me/handbook_python"
      }
    ]
  },
  {
    "document_title": "Принципы построения алгоритмов - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/principy-postroeniya-algoritmov",
    "section_title": "Ключевые вопросы параграфа",
    "text": "В чём суть динамического программирования и как оно отличается от других стратегий? Как выделить подзадачи и сформулировать рекуррентное соотношение? Как реализовать и оптимизировать алгоритм, чтобы он работал быстро и экономно?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Принципы построения алгоритмов - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/principy-postroeniya-algoritmov",
    "section_title": "Алгоритмы динамического программирования",
    "text": "Динамическое программирование на практике применяется в большом числе случаев. Оно подходит и для поиска похожих страниц в интернете, и для предсказывания генов в последовательностях ДНК.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Принципы построения алгоритмов - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/principy-postroeniya-algoritmov",
    "section_title": "Основная идея",
    "text": "Для понимания идеи, которая используется в подходе динамического программирования, предлагаем вам попробовать решить следующую головоломку. Интерактивная головоломка «Количество путей». В нижеприведённой сети есть множество путей ведущих отк, — например:и. Каково общее количество путей? Так как мы начинаем с, существует уникальный способ добраться до. Давайте запишем: Дляитакже существует просто один путь. Так как существует только один путь ки только один к, количество путей ксоставляет(и). Аналогичным образом для достижениянеобходимо прийти либо к, либо к. Существует только один путь дои два пути до. Так количество путей, которые ведут к, составляет(,и). Количество путей, заканчивающихся на, равно, так как кможно прийти только от. Доесть два пути, до— три пути, до— один. Выходит, что путей досуществует. Рассмотрим наше решение головоломки «Количество путей» и изложим основные идеи динамического программирования. Для узла—будет количеством путей от стартового узлак узлу. Несомненно,. Это называется базовый случай. Соответствующее значение для всех других узлов можно найти с помощью рекуррентного соотношения: где предшественник— это узел, связанный ребром с. Многие алгоритмы динамического программирования используют одну схему: — Вместо того, чтобы решать изначальную задачу, алгоритм решает несколько подзадач такого же типа.— Алгоритм вычисляет решение для каждой подзадачи с помощью рекуррентного соотношения, в которое входят решения более мелких подзадач.— Алгоритм сохраняет решения подзадач и таким образом избегает перевычисления. Теперь рассмотрим взвешенный граф, в котором у каждого ребраобозначена длина. Длина пути в таком графе определяется суммой длины рёбер. Например, длина путисоставляет. Какова минимальная длина пути отдо? Так как каждый путь отдопроходит через,илиперед тем, как прийти к, где— минимальная длина пути отдо. Расстояния до,иможно найти с помощью похожих рекуррентных соотношений: Приведём рекуррентные соотношения дляи: Наконец, базовый случай — это. С его помощью можно найти расстояние до всех узлов сети, включая наш узел. Для этого нужно использовать вышеприведённые рекуррентные соотношения, которые можно записать в компактной форме: Для модельной ситуации удобно записывать результаты по мере того, как мы выполняем вычисления, прямо на изображении. Мы получаем следующие результаты. В алгоритме динамического программирования для этого выполняется бэктрекинг («поиск с возвратом») решений, которые привели к оптимальному результату. В особенности отметим один из трёх выборов, который приводит нас к значению. Исходя из этого, мы можем заключить, что последнее ребро оптимального пути — это. Аналогично, так мы приходим отк. Таким образом, путь отдодлинойсоставляет У вышеприведённой сети есть удобное свойство. Оно заключается в том, что мы можем определять порядок её узлов, что обеспечивает следующее: каждый узел идет после всех предшествующих — то есть узлы, которые указывают на текущий узел (например,,ипредшествуют). Сети с таким свойством называются ориентированные ациклические графы. Мы увидим, что многие алгоритмы динамического программирования используют ориентированные ациклические графы — явно или неявно.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Принципы построения алгоритмов - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/principy-postroeniya-algoritmov",
    "section_title": "Проектирование алгоритмов динамического программирования",
    "text": "Теперь, когда вы познакомились с несколькими алгоритмами динамического программирования, подведём итог и повторим основные шаги для проектирования таких алгоритмов. Определить подпроблемы.Первый и самый важный шаг — это идентифицировать подпроблемы и записать рекуррентное соотношение (с базовым случаем). Как правило, это делается через анализ структуры оптимального решения или через оптимизацию решения, использующего исчерпывающий поиск. Спроектировать рекурсивный алгоритм.Сделать из рекуррентного соотношения рекурсивный алгоритм:сохранить решение каждой подзадачи в таблице;перед решением подзадачи проверить, нет ли уже в таблице её решения (мемоизация). сохранить решение каждой подзадачи в таблице; перед решением подзадачи проверить, нет ли уже в таблице её решения (мемоизация). Спроектировать итерационный алгоритм.Сделать из рекурсивного алгоритма итерационный алгоритм:инициализировать таблицу;продвигаться от мелких подзадач к большим. инициализировать таблицу; продвигаться от мелких подзадач к большим. Оценить время выполнения.Доказать верхнее ограничение времени выполнения. Обычно произведение количества подпроблем и времени, необходимого для решения подзадачи, предоставляет верхнее ограничение времени выполнения. Обнаружить решение.Обнаружить оптимальное решение, используя бэктрекинг рекуррентного соотношения. Экономить место.Использовать обычную структуру таблицы, чтобы проверить, можно ли сэкономить место по сравнению с более прямым решением.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Принципы построения алгоритмов - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/principy-postroeniya-algoritmov",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как работает динамическое программирование, — от базовых случаев и рекурсии до оптимизированных решений с таблицами и перебором подзадач. Вы познакомились с идеей сохранения промежуточных результатов, научились вычислять количество путей в графе и находить кратчайшие маршруты. Этот подход ляжет в основу всех задач этой главы. Далее — задача «Размен-2». Вы увидите, как динамическое программирование позволяет находить минимальное количество монет, даже когда жадный алгоритм не справляется. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться.",
    "source_type": null,
    "useful_links": [
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Пара ближайших точек» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-para-blizhajshih-tochek",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Почему перебор всех пар точек работает медленно и как этого избежать? Как устроен алгоритм поиска ближайшей пары с помощью деления и сканирования полосы? Как добиться точного и стабильного результата при вычислениях с вещественными числами?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Пара ближайших точек» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-para-blizhajshih-tochek",
    "section_title": "Задача",
    "text": "Ваша задача — найти ближайшую пару точек из заданного множества. В компьютерных графике и зрении есть множество вариантов применения этой задачи из вычислительной геометрии. Примитивный алгоритм с квадратичным временем выполнения делает итерации, проходя через все пары точек, чтобы найти ближайшие друг к другу. Ваша цель — спроектировать алгоритм «разделяй и властвуй», время выполнения которого составит. Чтобы решить эту задачу за время, разобьём с помощью правильно подобранной вертикальной линии данныеточек пополам — множестваиразмера. Ради простоты предположим, что все координатыдля данных точек различные и количество точек чётное. С помощью двух рекурсивных вызовов с параметрамиимы находим минимальные расстоянияив этих поднаборах. Пусть. Остаётся проверить, существуют ли такие точкии, при которых расстояние между ними меньше. Мы не можем себе позволить проверять все возможные такие пары, так как их. Для более быстрой проверки мы отбросим все точки изи, расстояние которых от центральной линии побольше, чем. Таким образом, мы сосредотачиваемся на следующей полосе: Теперь отсортируем точки из полосы по координатами обозначим получившийся отсортированный список. Оказывается, что если, то расстояние между точкамииоднозначно будет больше. Упражнение ниже это демонстрирует. Разделите полосу наквадратов, как показано ниже, и продемонстрируйте, что каждый из таких квадратов содержит максимум четыре точки ввода. Это приводит к следующему алгоритму. Сначала мы сортируем данные намточек по их координатам, затем делим получившийся отсортированный список на две половиныиразмера. Находим минимальные расстоянияис помощью рекурсивных вызовов для каждого из наборови. Пусть. Тем не менее наша работа ещё не закончена, потому что нам также нужно найти минимальное расстояние между точками из разных наборов (то есть точкой изи точкой из) и проверить, ниже ли это расстояние, чем. Чтобы в этом убедиться, мы отфильтруем изначальный набор и оставим только точки с дистанцией подо средней линии, не превышающей. После этого мы сортируем набор точек в получившейся линии по координатами сканируем получившийся список. Вычислим расстояние от каждой точки до семи последующих точек списка и вычислим— минимальное расстояние, которое нам встретилось во время сканирования. Затем выведем. Время выполнения алгоритма соответствует рекуррентному соотношению. — результат сортировки точек в полосе по координатепри каждой итерации. Проанализируйте рекурсивное дерево алгоритма и докажите, что. Продемонстрируйте, как избежать сортировки при каждом рекурсивном вызове и понизить время выполнения до.* Формат ввода: Первая строка содержитточек. Каждая из следующихстрок определяет точку. Формат вывода: Минимальное расстояние. Ограничения:;— целые числа. Примеры Во втором примере самое маленькое расстояние —. Есть две пары точек на этом расстоянии. Ниже они выделены голубым и красным:и;и. Помните, что расстояние между точкамииравно. Так, хотя ввод и содержит только целые числа, ответ не обязательно будет целым числом, и потому вам нужно обратить внимание на точность при выводе результатов. Абсолютное значение разницы между ответом вашей программы и оптимальным значением не должно превышать. Для этого ваш ответ должен содержать не меньше четырех цифр в дробной части. Иначе даже правильно вычисленный результат может не пройти нашу систему проверки из-за ошибок при округлении. ✅ Получилось разобраться, как найти пару ближайших точек быстрее, чем за? 👉Оценить этот параграф",
    "source_type": null,
    "useful_links": [
      {
        "text": "Оценить этот параграф",
        "url": "https://forms.yandex.ru/surveys/academy/?proekt=handbooks"
      }
    ]
  },
  {
    "document_title": "Задача «Пара ближайших точек» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-para-blizhajshih-tochek",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете находить пару ближайших точек на плоскости с помощью алгоритма «Разделяй и властвуй». Вы увидели, как сортировка, аккуратное разбиение и сканирование узкой полосы позволяют снизить сложность задачи до, сохранив точность вычислений. Далее — заключительный параграф главы: мы кратко подведём итоги и соберём воедино все стратегии, с которыми вы познакомились. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Задачу нахождения пары ближайших точек можно решить не за, а за, если использовать стратегию «Разделяй и властвуй». Алгоритм включает сортировку точек по координате, рекурсивное деление множества и слияние с анализом узкой полосы шириной. При слиянии достаточно проверить не все пары, а только точки в полосе, отсортированные по второй координате, — это снижает число сравнений. Точная реализация требует аккуратности: важно корректно обрабатывать базовые случаи, следить за порядком точек и не упустить минимум.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/47636"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/python/article/python-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача о рюкзаке - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-o-ryukzake",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Почему жадный алгоритм не подходит для задачи о рюкзаке? Как с помощью рекурсии и мемоизации находить решение без перебора всех подмножеств? В чём разница между рекурсивной и итерационной реализациями алгоритма?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача о рюкзаке - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-o-ryukzake",
    "section_title": "Условие",
    "text": "Вы нашли несколько золотых слитков. Ваша цель — положить как можно больше золота в рюкзак вместимостьюфунтов. Каждый слиток существует только в одном экземпляре. При этом можно либо взять слиток целиком, либо не брать его вовсе. И хотя все слитки на рисунке выше выглядят одинаково, они обладают разным весом — он приведён ниже. Естественная жадная стратегия — взять самый тяжелый слиток, на который хватает вместимости рюкзака, и повторно проверить, а осталось ли место на ещё один слиток. При наборе слитков, приведённом выше, и рюкзаке вместимостью«жадный» алгоритм выбирает слитки весоми. Однако оптимальное решение — использовать слитки весом 4, 6 и 10! Входные данные: Первая строка ввода содержит целое число(вместимость рюкзака) и количество золотых слитков. В следующей строке приведеныцелых чисел, которые определяют вес золотых слитков. Выходные данные: Максимальный вес золотых слитков, который можно уместить в рюкзак вместимостью. Ограничения:;;. Сумма веса первого и последнего слитков равна. Вместо решения изначальной задачи проверим, можно ли выбрать поднабор слитков с общим весом, если имеемслитков весом(мы перешли на отсчёт с нуля)?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача о рюкзаке - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-o-ryukzake",
    "section_title": "Упражнение",
    "text": "Продемонстрируйте, как можно использовать это решение для выполнения задачи «Максимальное количество золота». Предположим, что заполнить рюкзак до конца действительно возможно: существует наборс общим весом. Включает ли он в себя последний слиток с весом? Случай 1: Если, тогда рюкзак вместимостьюможет быть заполнен первымислитками. Случай 2: Если, тогда мы можем убрать слиток с весомиз рюкзака, и вес оставшихся слитков составит. Таким образом, рюкзак с вместимостьюможно полностью заполнить первымислитками. В обоих случаях мы свели задачу к практически такой же, но с меньшим количеством слитков и меньшей вместимостью рюкзака. Так, переменнаябудет иметь значение, если существует возможность заполнить рюкзак с вместимостьюпервымислитками, и значениев остальных случаях. Анализ двух вышеприведённых случаев приводит нас к следующему рекуррентному соотношению для: Кроме того,идля любого. В целом Так как значенияварьируются между 0 и, а значения— между 0 и, мы имеемпеременных. Так какзависит от, мы обрабатываем все переменные в возрастающем порядке. В приведённом ниже псевдокоде мы используем двумерный массив pack размера, асохраняет значение. Время выполнения данного решения составляет. Скопировать код1Knapsack([w[0],…,w[n−1]],W):2pack = two-dimensional array ofsize(W+1)×(n+1)3initialize all elements of pack tofalse4pack[0][0] =true5fori from1to n:6forw from0to W:7ifw[i-1] >w:8pack[w][i] = pack[w][i−1]9else:10pack[w][i]←pack[w][i−1] OR pack[w−w[i−1]][i−1]11returnpack[W][n] В приведённой ниже двумерной таблице представлены результаты вызоваKnapsack([1,3,4], 8. F и T означают значенияfalseиtrue. Другое решение будет заключаться в анализе поднаборов всех слитков. Наша цель — найти поднабор изслитков с общим весом. Простой подход к такой задаче — просматривать все поднаборы и проверять, есть ли поднабор с весом. Так как каждый слиток можно или пропустить, или взять, каждый поднабор из трёх слитков, который мы анализируем (,,), можно представить сине-красным бинарным вектором: Теперь мы представим каждый поднабор слитков как путь, начинающийся от узласетки. Если первый бит — синий, то он соответствует синему горизонтальному сегменту сетки, связывающемус. Если первый бит — красный, то он соответствует красному сегменту сетки, связывающемус. Обработав первыебитов, мы получаем сине-красный путь отдо некого узлана сетке. Если следующий бит — синий, мы связываемс. Если следующий бит — красный, мы связываемс, как показано ниже для вектора 101: Рисунок ниже демонстрирует пути, которые соответствуют всем восьми бинарным векторам с длиной 3. Теперь мы накладываем все эти восемь путей на одну сетку: Мы классифицируем узелна сетке как истинный («true») при наличии пути откна рисунке выше. В других случаях — ложный («false»). Теперь мы можем полностью заполнить рюкзак с вместимостьюподнабором из первыхслитков, если узел— истинный («true»). Узел будет истинным в случаях, если в него проходит или синее, или красное ребро. То есть, еслиилиистинны. Это наблюдение приводит нас к предыдущему рекуррентному соотношению и к такому же решению с динамическим программированием. А вот ещё один вариант решения, который основан на мемоизации. Приведённый ниже псевдокод рекурсивно вычисляет рекуррентное соотношение из решения 1: Скопировать код1RecursiveKnapsack([w[0],…,w[n−1]],w,i):2ifi=0andw=0:3returntrue4elseifi=0andw >0:5returnfalse6elseifi >0andw_[i-1]>w:7returnRecursiveKnapsack([w[0],…,w[n−1]],w,i−1)8else:9returnRecursiveKnapsack([w[0],…,w[n−1]],w,i−1) ORRecursiveKnapsack([w[0],…,w[n−1]],w−w[i−1],i−1) ВызовRecursiveKnapsack([w_0, ..., w_{n-1}],W, n)решает задачу, но он сильно замедлен из-за необходимости перевычислять одни и те же значения снова и снова. Чтобы это продемонстрировать, рассмотрим рюкзак с вместимостьюислитков с весом,,. ВызовRecursiveKnapsack([1, 1, 1], 4, 3)создаёт рекурсивное дерево, приведённое ниже — каждый узел показывает значения. Даже в этом простом примере значениевычисляется дважды. С 20 слитками рекурсивное дерево может достичь гигантских размеров — одно и то же значение может вычисляться миллионы раз. Во избежание такого рекурсивного взрыва мы «оборачиваем» код мемоизацией с помощью ассоциативного массива, который изначально пуст. Ассоциативный массив — это абстрактный тип данных, в котором хранятся пары. Он поддерживается многими языками программирования и, как правило, реализуется как хеш-таблица или дерево поиска. К примеру, вC++иJavaассоциативный массив называется картой («map»), а вPython— словарём («dictionary»). В реализации, приведённой ниже, ассоциативный массивиспользуется для хранения логических значений для пар. Скопировать код1MemoizedKnapsack([w[0],…,w[n−1]],pack,w,i):2if(w,i) isnotin pack:3ifi=0andw=0:4pack[(w,i)] =true5elseifi=0andw >0:6pack[(w,i)] =false7elseifi >0andw_[i-1]>w:8pack[(w,i)] =MemoizedKnapsack([w[0],…,w[n−1]],pack,w,i−1)9else:10pack[(w,i)] =MemoizedKnapsack([w[0],…,w[n−1]],pack,w,i−1) ORMemoizedKnapsack([w[0],…,w[n−1]],pack,w−w[i−1],i−1)11returnpack[(w,i)] Время выполнения итогового решения составляет, так как количество рекурсивных вызовов, не являющихся уточняющими запросами в ассоциативный массив, не превышает это число. Следовательно, это такое же время выполнения, как и у соответствующего итерационного алгоритма. На практике же итерационное решение, как правило, быстрее, потому что в нём нет рекурсивных издержек и оно использует более простые структуры данных. Например, массив вместо хеш-таблицы. Тем не менее с рассматриваемой задачей ситуация иная: при некоторых наборах данных, рекурсивная версия быстрее итерационной. К примеру, если мы умножим все весовые значения на, то время выполнения итерационного алгоритма также умножится на, в то время как время выполнения рекурсивного останется таким же. В целом, если необходимо решить все возможные подзадачи, итерационный вариант обычно быстрее.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача о рюкзаке - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-o-ryukzake",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете решать задачу о рюкзаке с помощью динамического программирования — как рекурсивно с мемоизацией, так и итерационно. Вы научились строить таблицу достижимости весов и поняли, почему простая жадность здесь не работает. Далее — задача про сувениры: вы узнаете, как свести динамическую задачу к более простой, если ограничен не вес, а количество предметов и целевая сумма. Новый подход позволит взглянуть на подмножества и веса под другим углом. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадная стратегия не даёт оптимального решения в задаче о рюкзаке — нужно перебрать возможные комбинации. Решение строится через рекурсию с мемоизацией или итеративное заполнение таблицы достижимости. Итерационный подход обычно быстрее, но рекурсивный с мемоизацией может быть удобнее в реализации. Количество подзадач ограничено, поэтому решение работает за O(nW) — достаточно эффективно даже для больших входов.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80780"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Полный перебор и оптимизация перебора - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/polnyj-perebor-i-optimizaciya-perebora",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Что такое алгоритм полного перебора и когда его стоит применять? Почему переборные алгоритмы считаются неэффективными? Как метод ветвей и границ помогает ускорить перебор?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Полный перебор и оптимизация перебора - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/polnyj-perebor-i-optimizaciya-perebora",
    "section_title": "Основные методы проектирования алгоритмов",
    "text": "За полвека программисты обнаружили, что многие алгоритмы основаны на схожих концептах, хотя и используются для решения разных проблем. Получается, основных методов проектирования алгоритмов относительно немного. Некоторые из них мы охватим в задачах, а пока расскажем о наиболее распространённых. Последующие примеры можно будет категоризировать по методологии проектирования. Для демонстрации мы рассмотрим очень простую ситуацию, с которой может столкнуться едва ли не каждый обладатель беспроводного домашнего телефона. Алгоритм, использующий полный перебор (также этот метод называют «исчерпывающий поиск» или «метод грубой силы»), рассматривает все возможные варианты и находит определенное решение. Если бы вы искали телефон по такому алгоритму, то игнорировали бы звонок и проверяли бы каждый квадратный сантиметр вашего дома. Вряд ли вы бы успели взять трубку, — иначе вашей удаче можно позавидовать, — но исчерпывающий поиск гарантирует, что рано или поздно вы найдете телефон, где бы он ни был. BruteForceChange— это алгоритм «грубой силы». Наши задачи включают несколько дополнительных примеров таких алгоритмов. Они самые легкие с точки зрения проектирования, но слишком медленные для решения более серьёзных задач, нежели самых маленьких. Мы советуем или избегать алгоритмов «грубой силы» или находить решения, которые ускоряют их работу. Если рассмотреть варианты, предложенные алгоритмом «грубой силы», мы увидим, что многие из них можно опустить. Эта техника называется методом ветвей и границ. Представьте, что вы прочёсываете первый этаж и слышите, как над вами звонит телефон. Значит, на первом этаже и в подвале можно больше не искать — и вы сэкономили себе время. Хотя алгоритмы полного перебора и не подходят для построения эффективных алгоритмов, мы рекомендуем использовать их для стресс-тестирования — техники поиска ошибок в алгоритмах, подробнее о которой мы поговорим впараграфе 4.3.",
    "source_type": null,
    "useful_links": [
      {
        "text": "параграфе 4.3",
        "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-maksimalnoe-proizvedenie"
      }
    ]
  },
  {
    "document_title": "Полный перебор и оптимизация перебора - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/polnyj-perebor-i-optimizaciya-perebora",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как работает полный перебор и почему он не всегда подходит для сложных задач. Вы также познакомились с методом ветвей и границ — первым шагом к ускорению перебора. Далее — жадные алгоритмы. Вы узнаете, когда можно принимать решения на каждом шаге, не заглядывая вперёд, и почему это иногда приводит к оптимальному результату, а иногда — нет. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Полный перебор перебирает все возможные варианты и гарантирует нахождение решения, если оно существует. Такой подход прост, но становится неэффективным при росте объёма входных данных. Метод ветвей и границ помогает отсекать заведомо бесполезные варианты и ускорять перебор. Несмотря на неэффективность, переборные алгоритмы полезны для тестирования и понимания структуры задач.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/79921"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Жадные алгоритмы - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zhadnye-algoritmy",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Что такое жадный алгоритм и в чём его идея? Почему не всякая жадная стратегия приводит к оптимальному решению? Как формализовать и доказать корректность жадного алгоритма?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Жадные алгоритмы - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zhadnye-algoritmy",
    "section_title": "Итерационный принцип алгоритмов",
    "text": "Многие алгоритмы — это итерационные процедуры: с каждым повтором они делают выбор из определенного количества вариантов. Например, для кассира задача «Размен» может быть представлена как последовательность решений: какую монету (изценностей) вернуть первой, какую второй и так далее. Некоторые из этих вариантов приведут к правильному ответу, а некоторые — нет. При каждом повторе жадный алгоритм выбирает «самый привлекательный» вариант. Например, самый большой номинал из доступных монет. В случае с американскими деньгамиChangeиспользует номиналы четвертак (25 центов), дайм (10 центов), никель (5 центов) и пенни (1 цент), чтобы выдать сдачу, в данном порядке. Разумеется, мы показывали, как такой «жадный» подход приводит к неправильным результатам при добавлении монет некоторых новых номиналов. В примере с телефоном «жадная» стратегия состояла бы в том, чтобы идти на звук, пока вы его не найдете. Но есть проблема: между вами и телефоном может оказаться стена (или хрупкая ваза). К сожалению, такие сложности часто возникают и в реальных задачах. Во многих случаях «жадный» подход выглядит естественным и очевидным, но может оказаться неправильным. В задаче «Бронирование переговорки» вам дается несколько временных отрезков, и нужно выбрать как можно больше отрезков таким образом, чтобы ни один из них не пересекался с другим (отрезки пересекаются, если у них есть общая точка). Название задачи основано на следующей гипотетической ситуации. Представьте, что у вас есть зал для переговоров, и вам присылают заявки на бронирование 11 компаний. Нельзя удовлетворить все запросы (так как некоторые из них пересекаются), но мы хотим удовлетворить как можно больше. Для этого мы представим входные данные более удобным способом. Так как мы говорим о «жадных» стратегиях, давайте поэкспериментируем с разными «наиболее выгодными» подходами. Интуиция может нам подсказать, что нужно выбрать самый короткий отрезок, удалить пересекающиеся отрезки и повторить данное действие. Возможно, логичнее было бы выбрать отрезок слева (тот, что начинается раньше всех), убрать все остальные и повторить данное действие. Оказывается, что следующий «жадный» алгоритм максимизирует количество непересекающихся отрезков: выбрать чемпионский отрезок, убрать все пересекающиеся с ним отрезки, повторить выбор. Докажите, что если набор непересекающихся отрезков не содержит чемпионский отрезок, то при замене первого отрезка в этом наборе на чемпионский мы получаем набор непересекающихся отрезков. Вот мы и нашли оптимальную «жадную» стратегию. И действительно, если существует решение задачи, включающее в себя чемпионский интервал, мы можем выбрать этот интервал на первом шаге и решить задачу выбора непересекающихся отрезков из оставшихся. В нашем примере алгоритм работает следующим образом. Выбрать сегменти отбросить сегменты,,, и. Выбрать сегменти отбросить сегментыи. Выбрать сегмент. Выбрать сегмент. Выбрать сегмент.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Жадные алгоритмы - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zhadnye-algoritmy",
    "section_title": "Что дальше",
    "text": "Теперь вы понимаете, как устроены жадные алгоритмы и почему они могут быть одновременно простыми и опасными. Вы научились проверять, работает ли жадная стратегия в конкретной задаче, и даже доказывать её оптимальность. Далее — динамическое программирование. Это подход, который позволяет решать сложные задачи, разбивая их на подзадачи и используя уже найденные решения. Вы узнаете, как избежать повторных вычислений и добиться эффективности там, где перебор и жадность не справляются. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадный алгоритм на каждом шаге выбирает наиболее выгодный вариант, не заглядывая вперёд. Такой подход прост и работает быстро, но не всегда даёт оптимальное решение. Чтобы жадная стратегия была корректной, необходимо доказать, что локальный выбор всегда ведёт к глобально лучшему результату. В некоторых задачах — например, при выборе максимального числа непересекающихся отрезков — удаётся найти и обосновать корректную жадную стратегию.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/79922"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Двоичный поиск - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как работает стратегия «Разделяй и властвуй» и как она применяется в двоичном поиске? Почему двоичный поиск так эффективен и в чём его отличие от линейного поиска? Как корректно реализовать двоичный поиск и что важно учесть при работе с границами и условиями?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Двоичный поиск - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
    "section_title": "Разделяй и властвуй",
    "text": "В этом параграфе вы узнаете об алгоритмах «разделяй и властвуй», которые помогают выполнять поиск по огромным базам данных в миллион раз быстрее, чем алгоритмы исчерпывающего поиска. Вооружившись этой техникой, вы узнаете, что стандартный способ умножать числа (которому вас учили в начальной школе) далеко не самый быстрый. Затем мы применим подход «разделяй и властвуй», чтобы спроектировать быстрые алгоритмы для сортировки. Вы узнаете, что эти алгоритмы оптимальны — то есть даже легендарный ученый Алан Тьюринг не смог бы спроектировать алгоритм сортировки быстрее! Если вы хотите решить задачу с помощью стратегии «разделяй и властвуй», вам нужно подумать о следующих трёх шагах: Разделение задачи на подзадачи поменьше. Рекурсивное решение каждой подзадачи. Объединение выполненных подзадач в решение изначальной задачи. Первые два шага — это и есть «разделяй», а последний — «властвуй». Мы продемонстрируем такой подход в нескольких примерах, сложность которых будет возрастать. Игра «Угадать число» состоит в том, что оппонент загадывает целое число. Вы задаёте вопрос: «?». Оппонент отвечает либо «да», либо «» (то есть «мое число меньше»), либо «» (то есть «мое число больше»). Ваша задача — получить ответ «да», задав минимальное количество вопросов. Пусть: ваша задача — угадать, задав не больше двух вопросов. Вы можете спросить: «?». Если ответ положительный, то вы победили.Но оппонент может ответить: «». Вы решаете, чторавенили, но у вас остаётся только один вопрос. Точно так же вы можете спросить: «?». Тогда ваш оппонент может ответить: «». В этом случае вы не сможете получить желаемый положительный ответ, задав лишь один вопрос. Посмотрим, что будет, если вы сначала спросите: «?». Если оппонент отвечает, что, тогда игра окончена. Если ответ —, то вы уже знаете, что. Следовательно, второй раз вы просто спрашиваете: «?». И теперь вы получаете положительный ответ. Если оппонент ответит, что, то вы спрашиваете: «?». Ответ на него: «Да». Угадать целое число, задав не больше трёх вопросов. Вы уже могли догадаться, что мы начнём с вопроса: «?». Дело в том, что в обоих случаях —и— мы сокращаем пространство поиска с 7 до 3 вариантов (нам уже известно, как решить задачу свозможными вариантами): если, тобудет 1, 2 или 3; если, тобудет 5, 6 или 7. Это означает, что в обоих случаях вы можете воспользоваться решением разобранного ранее случая. Получившийся протокол вопросов показан на рисунке. Следующий код имитирует процесс угадывания. Функцияquery«знает» целое число. Вызовquery(y)сообщает нам:, или, или. Функцияguess()находит числос помощью вызоваquery(). Она вызывается с двумя параметрами:lowerиupper— так, чтобы то естьнаходится в сегменте. Сначала она рассчитывает середину (middle) сегмента, затем вызывает. Если, тогда она продолжает работать с интервалом. Если, тогда она переходит к интервалу. Скопировать код1query(y):2x =16182353ifx == y:4return'equal'5ifx <y:6return'smaller'7else:8return'greater'91011guess(lower, upper):12middle = (lower + upper) /2// целочисленное деление13answer =query(middle)14// можно напечатать запрос и соответствующий результат15ifanswer =='equal':16return17ifanswer =='smaller':18guess(lower, middle -1)19else:20guess(middle +1, upper)212223guess(1,2097151)// начальный возможный диапазон значений Реализуйте этот алгоритм, измените значениеи запустите код, чтобы увидеть последовательность вопросов (удостоверьтесь, чтонаходится в сегменте, который используется при вызовеguess). В целом стратегия, угадывающая целое число, потребует околовопросов. Напомним, чторавняется, если. Это значит, что если мы продолжим делитьна 2, пока не получим 1, будет околоопераций деления. Важно здесь то, что— медленно растущая функция. К примеру, если, то. Метод, который мы использовали для угадывания числа, известен как двоичный поиск. Пожалуй, самый важный случай применения двоичного поиска — это поиск по отсортированным данным. Поиск — фундаментальная задача: имея последовательность и элемент, мы хотим проверить, входит лив последовательность. Например, 3 входит в последовательность, а 4 — не входит. Зная о важности задачи по поиску, неудивительно, что методы для её решения есть почти во всех языках программирования. Скопировать код1print(3in[7,2,5,6,11,3,2,9])2print(4in[7,2,5,6,11,3,2,9]) Что происходит внутри, когда мы вызываем методin? Ожидаемо,Pythonвыполняет линейное сканирование. На это требуетсясравнений при последовательности длиной. Если в последовательность не входит, нам необходимо просканировать все элементы: если мы будем пропускать, то мы не можем точно знать, отсутствует ли. Ситуация кардинально меняется, если полученные данные отсортированы, то есть составляют собой отсортированную последовательностьв порядке возрастания. Оказывается, что в этом случае достаточно околосравнений! Это значительное ускорение: линейный поиск по отсортированному массиву с миллиардом элементов потребует миллиарда сравнений, двоичному же поиску будет достаточно не больше!",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Двоичный поиск - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
    "section_title": "Двоичный поиск",
    "text": "Ваша задача — найти индекс элемента в сортированной последовательности равного. Формат ввода: Отсортированный массивнеповторяющихся целых чисел и целое число. Первые две строки ввода содержат целое числои последовательностьизнеповторяющихся положительных целых чисел в возрастающем порядке. Следующая строка содержит целое число. Формат вывода: Позиция элемента вравногоилипри отсутствии такого элемента. Ограничения:;для всех;. Примеры Можно решить эту задачу примитивным способом — просканировать массив(время выполнения составит). Время решения этой задачи для алгоритмаBinarySearch—. Он инициализируется при присвоениизначения 0 изначения. Сначала алгоритм присваиваетзначение, а затем проверяет, больше, чем, или нет. Еслибольше, чем это значение, тоBinarySearchпроводит итерацию на подмассивеот minIndex до. В ином случае он проводит итерацию на подмассивеотдо. В конечном счёте алгоримт определит, находитсявили нет. Скопировать код1BinarySearch(K[0..n−1], q)2minIndex =03maxIndex = n−14whilemaxIndex >= minIndex:5midIndex = (minIndex+maxIndex) /2// целочисленное деление6ifK[midIndex] = q:7returnmidIndex8elseK[midIndex] <q:9minIndex = midIndex +110else:11maxIndex = midIndex -112return-1 Например, еслии,BinarySearchсначала задаст следующее:,и. Так какбольше, чем, мы рассматриваем подмассив, элементы которого больше, установив, и таким образомперевычисляется как. В этот разменьше, чем, поэтому мы рассматриваем подмассив, элементы которого ниже этого значения. Этот подмассив состоит из одного элемента —. Время выполненияBinarySearchсоставляет, так как алгоритм снижает длину подмассива минимум в два раза при каждой итерации циклаwhile. Дело в том, что любой программе требуется линейное время для чтения данных ввода. По этой причине мы предлагаем вам решить следующую более общую задачу.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Двоичный поиск - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
    "section_title": "Множественный поиск ключей в отсортированной последовательности",
    "text": "Вывод: При каждомнеобходимо проверить, входит лив. Формат ввода: Отсортированный массивнеповторяющихся целых чисел и массив целых чисел. Первые две строки ввода содержат целое числои последовательностьизнеповторяющихся положительных целых чисел в возрастающем порядке. Следующие две строки содержат целое числоиположительных целых чисел. Формат вывода: Для всехотдовыведите индекс, чтобыилипри отсутствии такого индекса. Ограничения:;;для всех;для всех. Примеры Совет: не используйте встроенный двоичный поиск",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Двоичный поиск - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
    "section_title": "Двоичный поиск с дублированием",
    "text": "Как пишет автор книги «Искусство программирования» Дональд Кнут: «Хотя основная идея двоичного поиска относительно проста, детали могут быть на удивление сложными». Он подразумевает изменённую версию классической задачи двоичного поиска: Когда Кнут попросил профессиональных программистов из таких ведущих компаний, как IBM, реализовать эффективный алгоритм двоичного поиска с дублированием, в 90% из них были баги — год за годом. И правда, хотя первый алгоритм двоичного поиска был опубликован в 1946 году, первый алгоритм для поиска с дублированием, в котором не было багов, впервые опубликовали только в 1962 году. По аналогии с предыдущей задачей здесь мы предлагаем найтицелых чисел, а не одно. Формат ввода: Первые две строки ввода содержат целое числои последовательностьизположительных целых чисел в неубывающем порядке. Следующие две строки содержат целое числоиположительных целых чисел. Формат вывода: Для всехотдовывод индексапервого встречающегося(то есть) или— если такого индекса нет. Ограничения:;;для всех;для всех. Примеры Совет: не используйте встроенный двоичный поиск У вас есть ключи вам необходимо найти первое, самое раннее место, где этот ключ встречается в массиве. Например, еслии ключ— это, тогда первое место, где он встречается, — это индекс. Разумеется, вы можете найти одно из мест, просто начав двоичный поиск. Чтобы найти первое место, где ключ встречается, вы можете последовательно проверять элемент перед позицией того, который был найден, — что и демонстрируется в выделенных голубым строках приведенного ниже псевдокода. Скопировать код1NaiveBinarySearchWithDuplicates(K[0..n−1], q)2minIndex =03maxIndex = n−14whilemaxIndex >= minIndex:5midIndex = (minIndex + maxIndex) /26ifK[midIndex] = q:7top = midIndex8whiletop >0andK[top −1] = K[top]:9top = top -110returntop11ifK[midIndex] <q:12minIndex = midIndex +113else:14maxIndex = midIndex −115return-1 Этот алгоритм может существенно замедлиться при массиве с большим количеством повторов. Например, если повторяющийся элемент занимает половину массива, тоNaiveBinarySearchWithDuplicatesпотребует линейное времявместо логарифмического времени. Эта проблема устранена в псевдокоде ниже. Скопировать код1NaiveBinarySearchWithDuplicates(K[0..n−1], q)2minIndex =03maxIndex = n−14result =-15whilemaxIndex >= minIndex:6midIndex = (minIndex + maxIndex) /27ifK[midIndex] = q:8maxIndex = midIndex -19result = midIndex10elseifK[midIndex] <q:11minIndex = midIndex +112else:13maxIndex = midIndex −114returnresult",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Двоичный поиск - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/dvoichnyj-poisk",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как работает двоичный поиск — быстрый и надёжный способ находить элементы в отсортированных структурах. Вы научились реализовывать его корректно, аккуратно обращаться с границами и условиями, а также оценивать его эффективность. Далее — задача на определение доминирующего элемента. Представьте, что в базе заказов вам нужно быстро определить, какой товар покупают чаще всего и действительно ли он занимает больше половины всех покупок. Эта задача покажет, как использовать стратегию «Разделяй и властвуй» для анализа последовательностей и комбинировать рекурсию с постобработкой для точного результата. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Двоичный поиск — это способ найти элемент в отсортированной последовательности за логарифмическое время. Корректная реализация требует аккуратной работы с границами, особенно при вычислении середины. Ошибки в условиях цикла или смещении границ — частая причина багов, особенно на больших входах. Двоичный поиск можно адаптировать для решения более сложных задач — например, нахождения первого/последнего вхождения или границы условий.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80772"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Рекламная кампания» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-reklamnaya-kampaniya",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как работает жадный алгоритм в задаче выбора по критерию «прибыль за ресурс»? Почему важно доказывать корректность жадного подхода, а не полагаться только на интуицию? Как оформить решение, чтобы оно было корректным, понятным и быстрым?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Рекламная кампания» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-reklamnaya-kampaniya",
    "section_title": "Дробный выбор",
    "text": "Представим, что вы владелец популярной страницы в интернете, на которой естьрекламных мест. Вы хотите продать их рекламодателям, которые рассчитывают на,икликов в день и при этом готовы платить,иза клик. Как подобрать пары рекламных мест и рекламодателей так, чтобы получить максимальную прибыль? Например, доход от отмеченных голубым цветом пар, приведённых выше, составитдолларов; от отмеченных чёрным —. Входные данные: В первой строке приведено целое число, во второй — последовательность целых чисел, в третьей — последовательность целых чисел. Выходные данные: Максимальное значение, где— это перестановка. Ограничения:;для всех. . . Суть решения заключается в том, чтобы отдать самое популярное рекламное место самому дорогому объявлению. Вас вряд ли удивит, что жадный подход даст максимальную прибыль. Предположим, чтои— самые большие элементы:идля всех. Мы утверждаем, что существует оптимальное решение, объединяющеес. Чтобы доказать это, возьмём оптимальное решение и предположим, что в нём объединеныидляиидля. Покажем, что замена парина парыитолько повысит прибыль. Давайте оценим, как такая замена повлияет на общую прибыль. До замены рассматриваемые элементы давали следующую прибыль: После замены: Таким образом, замена увеличивает общую прибыль на Это приводит нас к алгоритму, который объединяет рекламное объявление с максимальным количеством кликов за максимальную цену, исключает их из вариантов на рассмотрение и повторяет то же самое. Скопировать код1Revenue(Click,Price):2revenue =03whileclicks isnotempty:4p = index with largest Click[p]5q = index with largest Price[q]6revenue = revenue+Clicks[p]⋅Price[q]7remove p-th element of Click8remove q-th element of Price9returnrevenue Время выполнения. Время выполнения этого алгоритма —. В каждой изитераций мы проводим линейное сканирование и находим два самых больших элемента. Также можно отсортировать эти два списка заранее, чтобы не искать самый большой элемент с нуля при каждой итерации. Это приводит нас к решению с временем выполнения.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Рекламная кампания» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-reklamnaya-kampaniya",
    "section_title": "Что дальше",
    "text": "Теперь вы знаете, как работать с задачами, где допускается дробный выбор, и почему жадный отбор по плотности гарантирует оптимальное решение. Вы также увидели, что при работе с вещественными числами важно следить за точностью вычислений и оформлением кода. Далее — задача с другим типом постановки: нужно покрыть набор отрезков минимальным числом точек. Такой приём встречается, например, в планировании размещения рекламных щитов вдоль трассы или выборе минимального числа дат для встреч, чтобы все участники могли присутствовать. Это ещё один пример, где жадный алгоритм работает эффективно, — если правильно обосновать его корректность. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. В задачах с «дробным» выбором можно брать часть объекта, чтобы максимизировать результат — это принципиально отличается от дискретных задач. Жадная стратегия по убыванию плотности гарантирует оптимальное решение именно в дробном случае, но не всегда работает для целочисленных вариантов. Доказательство оптимальности помогает понять границы применения жадных алгоритмов и увидеть, где они перестают работать. Работа с вещественными числами требует особой аккуратности, чтобы избежать ошибок округления и потери точности.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80767"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Задача «Количество призов» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-kolichestvo-prizov",
    "section_title": "Ключевые вопросы параграфа",
    "text": "Как спланировать последовательность наград, чтобы максимизировать число получателей? Почему здесь работает жадный подход и как доказать его корректность? Как использовать свойства суммы арифметической прогрессии при решении алгоритмических задач?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Количество призов» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-kolichestvo-prizov",
    "section_title": "Нестандартная задача и жадный алгоритм",
    "text": "Вы занимаетесь организацией соревнований для детей, и у вас естьконфет, которые собираетесь раздать в качестве призов. Вы хотите отдать эти конфеты тем, кто займёт первыемест в соревнованиях, и распределить конфеты так, чтобы за более высокое место всегда выходило больше конфет. Чтобы порадовать как можно больше детей, вам понадобится найти самое большое значение, при котором это возможно. Входные данные: Целое число. Выходные данные: Первая строка содержит максимальное число, при которомможно представить как суммупар неповторяющихся положительных целых чисел. Вторая строка —пар неповторяющихся положительных целых чисел, сумма которых будет(если есть несколько таких вариантов, то можно использовать любой из них). Ограничения:. Можно ли представить 8 как сумму четырёх неповторяющихся положительных целых чисел? Нетрудно понять, что ответ на этот вопрос: «Нет». Предположим, чтои. Тогда,,и. Однако тогда. По этой же причине, еслиравно сумменеповторяющихся положительных целых чисел, то. Верно и обратное: если, то можно представитькак суммунеповторяющихся целых чисел. Действительно, пусть. Тогдабудет равно сумме следующих целых чисел:. Несложно заметить, что все они отличаются друг от друга. Алгоритм состоит в нахождении самого большого значения, при котором. Время выполнения —или.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Задача «Количество призов» - Основы алгоритмов",
    "url": "https://education.yandex.ru/handbook/algorithms/article/zadacha-kolichestvo-prizov",
    "section_title": "Что дальше",
    "text": "Теперь вы умеете применять жадные алгоритмы для распределения ограниченного ресурса и знаете, в каких случаях такая стратегия приводит к оптимальному решению. Далее — финальная задача главы. Она покажет, что даже на собеседовании можно столкнуться с подводными камнями жадной стратегии: чтобы получить максимальный «оклад», придётся сравнивать не числа, а строки. А пока вы не ушли дальше — закрепите материал на практике: Отметьте, что урок прочитан, при помощи кнопки ниже. Пройдите мини-квиз, чтобы проверить, насколько хорошо вы усвоили тему. Перейдите кзадачамэтого параграфа и потренируйтесь. Перед этим — загляните в короткийгайдо том, как работает система проверки. Хотите обсудить, задать вопрос или не понимаете, почему код не работает? Мы всё предусмотрели — вступайте всообщество Хендбука! Там студенты помогают друг другу разобраться. Жадные алгоритмы хорошо работают в задачах распределения, когда нужно покрыть максимум с минимальными затратами. Иногда достаточно отсортировать входные данные и обрабатывать их по порядку — это уже даёт оптимальный результат. Простые стратегии требуют точной формулировки и аккуратной реализации — особенно при работе с ограничениями.",
    "source_type": null,
    "useful_links": [
      {
        "text": "задачам",
        "url": "https://new.contest.yandex.ru/contest/80770"
      },
      {
        "text": "гайд",
        "url": "https://education.yandex.ru/handbook/algorithms/article/algo-kak-rabotat-s-sistemoi-proverki-zadanii"
      },
      {
        "text": "сообщество Хендбука",
        "url": "https://t.me/handbook_algorithms"
      }
    ]
  },
  {
    "document_title": "Диффузионные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/diffuzionnye-modeli",
    "section_title": "Введение",
    "text": "В этом параграфе мы снова попробуем решить задачу генерации, когда нам дана выборка объектов из распределения, и хотим научиться генерировать новые объекты из распределения , которых нет в нашей выборке. Вероятно, вы уже знакомы с другими генеративными моделями, например VAE или GAN-ы. Здесь же мы познакомим вас с еще одним видом генеративных моделей:диффузионные модели, которые стали крайне популярны в последнее время благодаря своему высокому качеству генерации объектов из заданного распределения. В общий чертах, они работают следующим образом: берем шум изи шаг за шагом удаляем компоненты шума до тех пор, пока не получим объектиз распределения, см. иллюстрацию ниже.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Диффузионные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/diffuzionnye-modeli",
    "section_title": "Более детально",
    "text": "Для детального понимания стоит объяснить, что такоепрямой и обратный диффузионные процессы.Прямойпроцесс заключается в постепенном зашумлении картинки с помощью распределения, аобратный, наоборот, в расшумлении с помощью распределения. Их можно схематично изобразить следующим образом: Прямойдиффузионный процесс определяется как апостериорное распределение. Это распределение также является Марковской цепочкой, которая постепенно добавляет гауссовский шум к объекту. На каждом шаге шум добавляется с различной магнитудой, которая определяется расписанием дисперсий. При правильном выборе расписания в пределе по числу шаговмы должны сойтись к шуму из. В качестве распределенийберут нормальные распределения: Теперь перейдем кобратномупроцессу и к самойдиффузионной модели. Диффузионная модель- это вероятностная модель с латентными переменными вида, где промежуточные состояниясоответствуют зашумленным объектам, a- объект из распределения. Совместное распределениеназываетобратным диффузионным процессом, который представляет собой Марковскую цепочку из гауссовских распределений: Таким образом, обратный процесс параметризуется моделью, которая по зашумленному объектуи шагупредсказывает среднееи дисперсию.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Диффузионные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/diffuzionnye-modeli",
    "section_title": "Обучение диффузионной модели",
    "text": "Диффузионный модели обучаются, максимизируя вариационную нижнюю оценку (ELBO) логарифма правдоподобия. По тому же принципу обучаются VAE, с тем лишь отличием, что у диффузионных моделей другая форма модели с латентными переменными. Итак, давайте выведем ELBO для диффузии: Комментарий Если вы знакомы с VAE, то выводдолжен быть вам понятен, однако ниже приведен вывод с помощью неравенства Йенсена Теперь вернемся к распределению. Для того чтобы получить, придется итеративно получать. Однако это можно сделать более эффективно благодаря нормальным распределениям. Для этого обозначими, тогда Формальный вывод этого факта (*) Пояснение ко второму переходу. У нас выходит Тогдаможет быть переписано как Долгий вывод Серым в скобках комментарий к последующему переходу. Пояснение (*). Пользуемся тем, что у нас Марковский процесс, и теоремой Байеса: Таким образом во время обучения, на каждой итерации параллельно оптимизируются случайные членс помощью градиентного спуск (сэмлируем). Поскольку все распределения нормальные, то KL между ними можно выписать в явной форме (см. ниже). Формула KL между двумя нормальными Если Осталось только выписать. Мы знаем, поскольку у нас все распределения нормальные, то ибудет нормальным. Обозначим Вывод Применим формулу Байеса и распишем. Тут мы просто пытаемся понять, как будут выглядеть среднее и дисперсия, выделяя квадратичную форму в показателе экспоненты Далее перепишем красные и синие выражения в более красивой форме В прошлой подсекции наша модель предсказывала среднее и дисперсию нормального распределения. Давайте зафиксируем. Обычно берутилиТогдаиз предыдущей секции можно переписать как Это первый момент, как меняется функционал, если мы не хотим предсказывать, а фиксируем её. Теперь вспомним, что, но благодаря тому, что у нас гауссовское распределение, это можно переписать в виде Выразим отсюдаи получим, что, тогда подставим это выражение в формулу для(из подсекции «Вывод») и получим Теперь скажем, что наша модель будет предсказывать. И просто будем «подставлять» его в выражение длявыше. Обозначим предсказание модели как— предсказанный шум. Тогда лосспревратиться в Тем не менее лосс можно еще больше упростить и просто обучать с помощью MSE на. Итак, алгоритмы обучения и сэмплирования выглядят вот так (на картинке). Стоит отметить, что важным недостатком диффузионных моделей является низкая скорость сэмплирования. СогласноSong et al. 2020: «Требуется 20 часов на генерацию 50 тысяч картинок размера 32х32, используя DDPM, и меньше минуты, используя GAN» (Nvidia 2080 Ti GPU). Тем не менее, в данном направлении был достигнут значительный прогресс и в целом проблема медленного сэмплирования была частично решена:Jiaming Song et al. (2021),Kong &Ping (2021),Bond-Taylor et al. (2021) Давайте зафиксируем, какие функции потерь можно использовать. Для всех них справедлив тот факт, что мы сэмплируем шаг равномерно во время обучениеи оптимизируем соответствующий. Оптимизируя член из суммы. Это KL дивергенция между двумя нормальными распределениями При фиксированной дисперсииможно оптимизировать взвешенную MSE между средними нормальных распределений При фиксированной дисперсии и при предсказании шума с помощью взвешенной MSE. Или просто MSE.являетсясамым популярнымвариантом, который на практике дает лучшие результаты. Расписание является гиперпараметром, основными требованиями на который являются невозрастаниеи чтобы прямой процесс сходился кв пределе по. Второе может гарантироваться тем, что. Вспомним, Однако на практикеонотакже проверяется, чтобыбыло близко к 0. Также стоит упомянуть, что обычно берут. Но также важно помнить про требования выше, ведь расписание шума непосредственно зависит от. Чаще всего используют линейное расписание, где. У данных констант нет никакой мотивации, кроме той, которая описана выше. Они были предложены вHo et al. (2020). ВNichol &Dhariwal (2021)было предложено косинусное расписание, которое помогло диффузионным моделям достичь лучшего NLL (negative loglikelihood): Авторы обнаружили, что линейное расписание плохо работает на картинках 64х64 и меньше. А именно, последнии шаги прямого прохода были шумными и малоинформатиыными (просто зашумляем шум еще больше): Также они обнаружили, что если обучать модель с линейным расписанием только на 80% первых шагов, то модель не становится сильно хуже, что подтверждает неиформативность последних шагов. Далее, они подобрали расписание так, чтобыубывало линейно на большей части отрезка (от 0 до) и почти не менялось рядом с 0 и. Разницу вдля разных расписаний можно увидеть на картинке ниже: Детали Также они ограничиваютчислом 0.999, чтобы в конце процесса не было проблем с численной устойчивостью. Коэффициентиспользуется, чтобыне были слишком малы рядом с нулем. Он равен 0.008. Такое число было выбрано так, чтобы «была немного меньше, чем размер бина одного пикселя, то есть» ВNichol &Dhariwal (2021)был предложен метод условной генерации, который повышает качество генерируемых картинок, при этом уменьшая их разнообразие. Для этого предобучается «шумный» классификатор на зашумленных картинках, то есть. Затем он используется во время сэмплирования, корректируя предсказанное среднее на. ВNichol &Dhariwal (2021)(Секция 4.1) показывают, что данная добавка позволяет превратить распределениев. Важно, что исходная диффузионная модель никак не меняется, что делает трюк еще более привлекательным. Алгоритм сэмплирования можно видеть на картинке ниже. Коэффициентотвечает за силу guidance. МотивацияУ генеративной модели GAN есть способ, который позволяет «балансировать» между разнообразием картинок и их качеством —truncation trick.Он заключается в сэмплировании латентного вектораtruncated normal distibution. Данный трюк был хорошо описан и исследован в статье проBigGAN. Поэтому в диффузионных моделях тоже хотелось бы иметь метод, который позволяет балансировать между качеством и разнообразием. Авторы предложили classifier guidance, сравнили его сtruncation trickи показали, что их метод строго лучше. Ho &Salimans (2021)предложили метод, в котором guidance достигается без использования дополнительной модели, поскольку это достаточно затратно. Для этого они обучали условную модель, у которой во время обучения реальная метказаменялась с какой-то фиксированной вероятностью (10%) на пустую метку (). Это по сути позволяет нам обучать безусловную модельодновременно с условнойТогда во время сэмплирования делаем так, чтобы предсказание немного менялось в сторону, а именно: Мотивация этой формулы следовала из формулы Байеса: Тогда мы можем просто подставитьв формулу для classifier guidance из предыдущей подсекции и получить желаемое равенство с точностью до коэффициента.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Song et al. 2020",
        "url": "https://arxiv.org/abs/2010.02502"
      },
      {
        "text": "Jiaming Song et al. (2021)",
        "url": "https://arxiv.org/abs/2010.02502"
      },
      {
        "text": "Kong &Ping (2021)",
        "url": "https://openreview.net/pdf?id=agj4cdOfrAP"
      },
      {
        "text": "Bond-Taylor et al. (2021)",
        "url": "https://arxiv.org/abs/2111.12701"
      },
      {
        "text": "оно",
        "url": "https://arxiv.org/abs/2006.11239"
      },
      {
        "text": "Ho et al. (2020)",
        "url": "https://arxiv.org/abs/2006.11239"
      },
      {
        "text": "Nichol &Dhariwal (2021)",
        "url": "https://arxiv.org/abs/2102.09672"
      },
      {
        "text": "Nichol &Dhariwal (2021)",
        "url": "https://arxiv.org/pdf/2105.05233.pdf"
      },
      {
        "text": "Nichol &Dhariwal (2021)",
        "url": "https://arxiv.org/pdf/2105.05233.pdf"
      },
      {
        "text": "truncated normal distibution",
        "url": "https://en.wikipedia.org/wiki/Truncated_normal_distribution"
      },
      {
        "text": "BigGAN",
        "url": "https://arxiv.org/abs/1809.11096"
      },
      {
        "text": "Ho &Salimans (2021)",
        "url": "https://openreview.net/pdf?id=qw8AKxfYbI"
      }
    ]
  },
  {
    "document_title": "Диффузионные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/diffuzionnye-modeli",
    "section_title": "Овервью ключевых работ на сегодняшний день",
    "text": "Jonathan Ho et al.«Denoising diffusion probabilistic models.»arxiv Preprint arxiv:2006.11239 (2020) Основная работа, в которой диффузионные модели (Denoising Diffusion Probabilistic Models, DDPMs) были применены для генерации картинок. Параграф в основном построен на ней. Jiaming Song et al.«Denoising diffusion implicit models.»arxiv Preprint arxiv:2010.02502 (2020) Одна из первых попыток ускорить генерацию объектов. Идея следущая: давайте изменим прямой диффузионный процесс так, чтобы используя предобученную DDPM, приближать новый обратный процесс за меньшее число шагов. Чтобы не обучать новую модель, нам нужен прямой диффузионный процесс, у которого будет такая же (суррогатная) функция потерь, а обратный процесс все еще останется Марковским. Оказалось, что существует целое семейство не-Марковских прямых процессов, удовлетворяющих этим требования. Это семейство имеет следующий вид: гдеи для всех Среднее было выбрано так, чтобыдля всех. (см. Лемму 1 в Приложении B к статье). То есть важно лишь то, чтобы маргинальное распределениене менялось по сравнению с обычным Марковским случаем. Прямой процесс может быть получен с помощью теоремы Байеса: Тутконтролирует степень стохастичности прямого процесса. Можно заметить, что в отличии от исходного диффузионного процесса, предложенный прямой процесс больше не является Марковским, так как каждыйтеперь зависит и оти от. Схематично, это можно изобразить как на картинке справа. (Слева исходный диффузионный процесс для сравнения) ЗаметкаАвторы обращают внимание, что функция потерь в DDPM зависит от, а не отнапрямую. Это означает, что нам нужно выбрать любой другой прямой диффузионный процесс, у которогоостались те же. Далее, мы можем переписать обратный процесс в данном виде: Заметим, что припрямой процесс становится марковским, а обратный как у DDPM (обычное сэмплирование, описанное в основной секции). Припроцесс сэмплирования становится детерминистичным (данный способ и называется DDIM). Ускорение сэмплирования достигается засчет использования лишь какого-то подмножества шагов (). Также одним из плюсов детерминистичного сэмплирования является возможность делать семантическую интерполяцию в латентном пространстве (как у GANов). Alex Nichol &Prafulla Dhariwal.«Improved denoising diffusion probabilistic models»arxiv Preprint arxiv:2102.09672 (2021) Улучшение DDPM, в котором был предложен новое расписание шума, что улучшило NLL. Также был изучен вариант, в котором дисперсияпредсказывается моделью. Prafula Dhariwal &Alex Nichol.«Diffusion Models Beat GANs on Image Synthesis.»arxiv Preprint arxiv:2105.05233 (2021). Статья, в которой показывается, что DDPM могут генерировать более качественные картинки по сравнению с GANами. Также был предложен метод conditional сэмплирования. Для этого предобучается классификатор на зашумленных сэмплах, а во время сэмплирования среднее нормального распределения «корректируется» на градиент классификатора. Jacob Austin et al.«Structured Denoising Diffusion Models in Discrete State-Spaces».arXiv:2107.03006 (2021) Диффузионные модели на дискретных данных (например, текст). Вместо нормальных распределений используются категориальные. Также была обобщенамультиномиальная диффузияс помощью «матриц перехода», которые задают способ зашумления дискретных данных. Более подробно: у нас есть— дискретная величина на всех шагах диффузии, тогда для каждого шагаопределенаматрица прямого переходатакая, что. То есть строки матрицы суммируются в единицу. Тогда если обозначить черезone-hot-закодированную версию, то прямой процесс можно описать через категориальные распределения: Как и в нормальных распределениях, можем выписать Поскольку тут нет такой хорошей параметризации через, как у нормальных распределений, то единственный способ обучать — с помощью KL дивергенции (членами). Остается только понять, как выбирать. Помимо того, чтобы сумма в каждой строчке была один, требуется, чтобысходилось (при) к равномерному распределению в каждой строчке (аналог нормального шума). За конкретными примерами стоит обратиться к статье. Серия работ про text-conditional diffusions:GLIDE,ImaGen,DALLE-2 Опишем работу метода GLIDE. Стоит задача генерировать картинки по заданному текстовому описанию. Для этого используется classifier-free guided diffusion model илиCLIP. Это два разных варианта модели, которые авторы сравнивают. В первом случае модель обуславливается на эмбеддинги текста, которые были получены из обучаемого трансформера. Во втором случае guidance осуществляется за счет(это по сути градиент лосса метода CLIP) . Тут— это картиночный энкодер (на зашумленных картинках), а— это энкодер текстового входа. В целом, авторы получили, что classifier-free guidance генерирует более качественные картинки. Song et al.«Score-Based Generative Modeling through Stochastic Differential Equations» Способ описать диффузионные модели через стохастические дифференциальные уравнения. What are Diffusion Models?. Прекрасный блог от Lilian Weng (OpenAI).",
    "source_type": null,
    "useful_links": [
      {
        "text": "«Denoising diffusion probabilistic models.»",
        "url": "https://arxiv.org/abs/2006.11239"
      },
      {
        "text": "«Denoising diffusion implicit models.»",
        "url": "https://arxiv.org/abs/2010.02502"
      },
      {
        "text": "«Improved denoising diffusion probabilistic models»",
        "url": "https://arxiv.org/abs/2102.09672"
      },
      {
        "text": "«Diffusion Models Beat GANs on Image Synthesis.»",
        "url": "https://arxiv.org/abs/2105.05233"
      },
      {
        "text": "«Structured Denoising Diffusion Models in Discrete State-Spaces»",
        "url": "https://arxiv.org/abs/2107.03006"
      },
      {
        "text": "мультиномиальная диффузия",
        "url": "https://arxiv.org/abs/2102.05379"
      },
      {
        "text": "GLIDE",
        "url": "https://arxiv.org/pdf/2112.10741.pdf"
      },
      {
        "text": "ImaGen",
        "url": "https://arxiv.org/pdf/2205.11487.pdf"
      },
      {
        "text": "DALLE-2",
        "url": "https://cdn.openai.com/papers/dall-e-2.pdf"
      },
      {
        "text": "CLIP",
        "url": "https://openai.com/blog/clip/"
      },
      {
        "text": "«Score-Based Generative Modeling through Stochastic Differential Equations»",
        "url": "https://openreview.net/forum?id=PxTIG12RRHS"
      },
      {
        "text": "What are Diffusion Models?",
        "url": "https://lilianweng.github.io/posts/2021-07-11-diffusion-models/#reverse-diffusion-process"
      }
    ]
  },
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Смещение и разброс",
    "text": "Предположим, мы решаем задачу регрессии с квадратичной функцией потерь. При использовании квадратичной функции потерь для оценки качества работы алгоритмаможно воспользоваться следующим функционалом: где — обучающая выборка — точка из тестового множества — целевая зависимость, которую мы можем измерить с точностью до случайного шума — значение алгоритма, обученного на выборке, в точке — среднее по всем тестовым точкам и— среднее по всем обучающим выборками случайному шуму Длясуществует разложение на три компоненты — шум, смещение и разброс. Это разложение называетсяbias-variance decomposition, оно — одно из мощных средств для анализа работы ансамблей. О том, как его вывести, вы узнаете в соответствующемпараграфе, а здесь мы приведём его формулировку. Существует представлениев виде трёх компонент: где этосмещениепредсказания алгоритма в точке, усреднённого по всем возможным обучающим выборкам, относительно истинной зависимости, этодисперсия (разброс)предсказаний алгоритма в зависимости от обучающей выборки, это неустранимыйшумв данных. Раз нам известно, что ошибка алгоритма раскладывается на шум, смещение и разброс, можно подумать над способом сократить ошибку. Будет разумно попытаться сначала уменьшить одну из составляющих. Понятно, что с шумом уже ничего не сделать — это минимально возможная ошибка. Какую можно придумать процедуру, чтобы, например, сократить разброс, не увеличивая смещение? Пример приходит из жизни древних греков: если много человек проголосуют независимо друг от друга, то вместе они придут к разумному решению несмотря на то, что опыт каждого из них субъективен. Аналогом голосования в мире машинного обучения является бэггинг.",
    "source_type": null,
    "useful_links": [
      {
        "text": "параграфе",
        "url": "https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition"
      }
    ]
  },
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Бэггинг",
    "text": "Идеябэггинга(bagging,bootstrap aggregation) заключается в следующем. Пусть обучающая выборка состояла изобъектов. Выберем из неёпримеров равновероятно, с возвращением. Получим новую выборку, в которой некоторых элементов исходной выборки не будет, а какие-то могут войти несколько раз. С помощью некоторого алгоритмаобучим на этой выборке модель. Повторим процедуру: сформируем вторую выборкуизэлементов с возвращением и с помощью того же алгоритма обучим на ней модель. Повторив процедурураз, получиммоделей, обученных навыборках. Чтобы получить одно предсказание, усредним предсказания всех моделей: Процесс генерации подвыборок с помощью семплирования с возвращением называетсябутстрепом(bootstrap), а моделичасто называютбазовыми алгоритмами(хотя, наверное, лучше было бы назвать их базовыми моделями). Модельназывается ансамблем этих моделей. Посмотрим, что происходит с качеством предсказания при переходе от одной модели к ансамблю. Сначала убедимся, что смещение ансамбля не изменилось по сравнению со средним смещением отдельных моделей. Будем считать, что когда мы берём матожидание по всем обучающим выборкам, то в эти выборки включены также все подвыборки, полученные бутстрепом. Получили, что смещение композиции равно смещению одного алгоритма. Теперь посмотрим, что происходит с разбросом. Если предположить, что базовые алгоритмы некоррелированы, то: Получилось, что в этом случае дисперсия композиции враз меньше дисперсии отдельного алгоритма. Пусть наша целевая зависимостьзадаётся как и к ней добавляется нормальный шум. Пример семпла из таких данных: Попробуем посмотреть, как выглядят предсказания решающих деревьев глубины 7 и бэггинга над такими деревьями в зависимости от обучающей выборки. Обучим решающие деревья 100 раз на различных случайных семплах размера 20. Возьмём также бэггинг над 10 решающими деревьями глубины 7 в качестве базовых классификаторов и тоже 100 раз обучим его на случайных выборках размера 20. Если изобразить предсказания обученных моделей на каждой из 100 итераций, то можно увидеть примерно такую картину: По этому рисунку видно, что общая дисперсия предсказаний в зависимости от обучающего множества у бэггинга значительно ниже, чем у отдельных деревьев, а в среднем предсказания деревьев и бэггинга не отличаются. Чтобы подтвердить это наблюдение, мы можем изобразить смещение и разброс случайных деревьев и бэггинга в зависимости от максимальной глубины: На графике видно, как значительно бэггинг сократил дисперсию. На самом деле, дисперсия уменьшилась практически в 10 раз, что равняется числу базовых алгоритмов (), которые бэггинг использовал для предсказания: Код для отрисовки картинок и подсчёта смещения и разброса можно найтитут.",
    "source_type": null,
    "useful_links": [
      {
        "text": "тут",
        "url": "https://github.com/yandexdataschool/ML-Handbook-materials/blob/main/chapters/ensembles/bias_variance.ipynb"
      }
    ]
  },
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Random Forest",
    "text": "В предыдущем разделе мы сделали предположение, что базовые алгоритмы некоррелированы, и за счёт этого получили очень сильное уменьшение дисперсии у ансамбля относительно входящих в него базовых алгоритмов. Однако в реальной жизни добиться этого сложно: ведь базовые алгоритмы учили одну и ту же зависимость на пересекающихся выборках. Поэтому будет странно, если корреляция на самом деле нулевая. Но на практике оказывается, чтострогое выполнение этого предположения не обязательно. Достаточно, чтобы алгоритмы были в некоторой степени не похожи друг на друга. На этом строится развитие идеи бэггинга для решающих деревьев — случайный лес. Построим ансамбль алгоритмов, где базовый алгоритм — это решающее дерево. Будем строить по следующей схеме: Для построения-го дерева:Сначала, как в обычном бэггинге, из обучающей выборкивыбирается с возвращением случайная подвыборкатого же размера, что и.В процессе обучения каждого деревав каждой вершинеслучайно выбираютсяпризнаков, где— полное число признаков (метод случайных подпространств), и среди них ищется оптимальный сплит. Такой приём как раз позволяет управлять степенью скоррелированности базовых алгоритмов. Сначала, как в обычном бэггинге, из обучающей выборкивыбирается с возвращением случайная подвыборкатого же размера, что и. В процессе обучения каждого деревав каждой вершинеслучайно выбираютсяпризнаков, где— полное число признаков (метод случайных подпространств), и среди них ищется оптимальный сплит. Такой приём как раз позволяет управлять степенью скоррелированности базовых алгоритмов. Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев (для регрессии) или берём самый популярный класс (для классификации). Profit. Мы построилиRandom Forest (случайный лес)— комбинацию бэггинга и метода случайных подпространств над решающими деревьями. Внимательный читатель мог заметить, что при построении случайного леса у специалиста по машинному обучению есть несколько степеней свободы. Давайте обсудим их подробнее. Ошибка модели (на которую мы можем повлиять) состоит из смещения и разброса. Разброс мы уменьшаем с помощью процедуры бэггинга. На смещение бэггинг не влияет, а хочется, чтобы у леса оно было небольшим. Поэтому смещение должно быть небольшим у самих деревьев, из которых строится ансамбль. У неглубоких деревьев малое число параметров, то есть дерево способно запомнить только верхнеуровневые статистики обучающей подвыборки. Они во всех подвыборках будут похожи, но будут не очень подробно описывать целевую зависимость. Поэтому при изменении обучающей подвыборки предсказание на тестовом объекте будет стабильным, но не точным (низкая дисперсия, высокое смещение). Наоборот, у глубоких деревьев нет проблем запомнить подвыборку подробно. Поэтому предсказание на тестовом объекте будет сильнее меняться в зависимости от обучающей подвыборки, зато в среднем будет близко к истине (высокая дисперсия, низкое смещение). Вывод: используем глубокие деревья. Ограничивая число признаков, которые используются в обучении одного дерева, мы также управляем качеством случайного леса. Чем больше признаков, тем больше корреляция между деревьями и тем меньше чувствуется эффект от ансамблирования. Чем меньше признаков, тем слабее сами деревья. Практическая рекомендация — брать корень из числа всех признаков для классификации и треть признаков для регрессии. Выше было показано, что увеличение числа элементарных алгоритмов в ансамбле не меняет смещения и уменьшает разброс. Так как число признаков и варианты подвыборок, на которых строятся деревья в случайном лесе, ограничены, уменьшать разброс до бесконечности не получится. Поэтому имеет смысл построить график ошибки от числа деревьев и ограничить размер леса в тот момент, когда ошибка перестанет значимо уменьшаться. Вторым практическим ограничением на количество деревьев может быть время работы ансамбля. Однако есть положительное свойство случайного леса: случайный лес можно строить и применять параллельно, что сокращает время работы, если у нас есть несколько процессоров. Но процессоров, скорее всего, всё же сильно меньше числа деревьев, а сами деревья обычно глубокие. Поэтому на большом числе деревьев Random Forest может работать дольше желаемого и количество деревьев можно сократить, немного пожертвовав качеством.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Бустинг",
    "text": "Бустинг (boosting)— это ансамблевый метод, в котором так же, как и в методах выше, строится множество базовых алгоритмов из одного семейства, объединяющихся затем в более сильную модель. Отличие состоит в том, что в бэггинге и случайном лесе базовые алгоритмы учатся независимо и параллельно, а в бустинге — последовательно. Каждый следующий базовый алгоритм в бустинге обучается так, чтобы уменьшить общую ошибку всех своих предшественников. Как следствие, итоговая композиция будет иметь меньшее смещение, чем каждый отдельный базовый алгоритм (хотя уменьшение разброса также может происходить). Поскольку основная цель бустинга — уменьшение смещения, в качестве базовых алгоритмов часто выбирают алгоритмы с высоким смещением и небольшим разбросом. Например, если в качестве базовых классификаторов выступают деревья, то их глубина должна быть небольшой — обычно не больше 2-3 уровней. Ещё одной важной причиной для выбора моделей с высоким смещением в качестве базовых является то, что такие модели, как правило, быстрее учатся. Это важно для их последовательного обучения, которое может стать очень дорогим по времени, если на каждой итерации будет учиться сложная модель. На текущий момент основным видом бустинга с точки зрения применения на практике являетсяградиентный бустинг, о котором подробно рассказывается в соответствующемпараграфе. Хотя случайный лес — мощный и достаточно простой для понимания и реализации алгоритм, на практике он чаще всего уступает градиентному бустингу. Поэтому градиентный бустинг сейчас — основное продакшн-решение, если работа происходит с табличными данными (в работе с однородными данными — картинками, текстами — доминируют нейросети).",
    "source_type": null,
    "useful_links": [
      {
        "text": "параграфе",
        "url": "https://academy.yandex.ru/handbook/ml/article/gradientnyj-busting"
      }
    ]
  },
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Стекинг",
    "text": "Стекинг (stacking)— алгоритм ансамблирования, основные отличия которого от предыдущих состоят в следующем: он может использовать алгоритмы разного типа, а не только из какого-то фиксированного семейства. Например, в качестве базовых алгоритмов могут выступать метод ближайших соседей и линейная регрессия результаты базовых алгоритмов объединяются в один с помощью обучаемой мета-модели, а не с помощью какого-либо обычного способа агрегации (суммирования или усреднения) Обучение стекинга проходит в несколько этапов: общая выборка разделяется на тренировочную и тестовую тренировочная выборка делится нафолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации: на каждом шаге фиксируютсяфолдов для обучения базовых алгоритмов и один — для их предсказаний (вычисления мета-факторов). Такой подход нужен для того, чтобы можно было использовать всё тренировочное множество, и при этом базовые алгоритмы не переобучались на полученных мета-факторах обучается мета-модель. Кроме мета-факторов, она может принимать на вход и фичи из исходного датасета. Выбор зависит от решаемой задачи Для получения мета-факторов на тестовом множестве базовые алгоритмы можно обучить на всём тренировочном множестве — переобучения в данном случае возникнуть не должно. Если данных достаточно много, то можно просто разделить обучающие данные на две непересекающиеся части: ту, на которой учатся базовые алгоритмы, и ту, на которой они делают свои предсказания и обучается мета-модель. Использование такого простого разбиения вместо кросс-валидации на тренировочных данных иногда называютблендингом (blending). Если данных совсем много, то тестовое множество тоже можно разделить на две части: тестовую и валидационную, и использовать последнюю для подбора гиперпараметров моделей-участников. С точки зрения смещения и разброса стекинг не имеет прямой интерпретации, так как не минимизирует напрямую ни ту, ни другую компоненту ошибки. Удачно работающий стекинг просто уменьшает ошибку, и, как следствие, её компоненты тоже будут убывать.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Ансамбли в машинном обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/ansambli-v-mashinnom-obuchenii",
    "section_title": "Почитать по теме",
    "text": "ЛекцияЕвгения Соколова про bias-variance decomposition и бэггинг Блог-постпро ансамбли от Joseph Rocca Блог-постпро стекинг и блендинг от Steven Yu",
    "source_type": null,
    "useful_links": [
      {
        "text": "Лекция",
        "url": "https://github.com/esokolov/ml-course-hse/blob/master/2020-fall/lecture-notes/lecture08-ensembles.pdf"
      },
      {
        "text": "Блог-пост",
        "url": "https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205"
      },
      {
        "text": "Блог-пост",
        "url": "https://medium.com/@stevenyu530_73989/stacking-and-blending-intuitive-explanation-of-advanced-ensemble-methods-46b295da413c"
      }
    ]
  },
  {
    "document_title": "Обобщающая способность – классическая теория",
    "url": "https://education.yandex.ru/handbook/ml/article/obobshayushaya-sposobnost-klassicheskaya-teoriya",
    "section_title": "Оценка супремума",
    "text": "Попробуем оценить супремум разницы рисков. Будем считать, что выборкавыбирается случайным (и равновероятным) образом из распределения данных. Некоторые из выборок могут быть катастрофически плохими, поэтому мы будем рассматривать оценки, которые верны не обязательно всегда, а просто с достаточно большой вероятностью. Предположим сначала, что класс моделейконечен. Тогда Заметим, что. Поэтому при фиксированномразницу рисковможно оценить с помощью неравенства Хёффдинга. Неравенство Хёффдинга (Hoeffding's inequality). Пусть– независимые одинаково распределённые случайные величины со значениями в. Тогда для всехимеют место неравенства Как следствие неравенства Хёффдинга, получаем, что для любогои для любой. Заметим, что тогда для любой, Несмотря на то, что эта оценка является оценкой на обобщающую способность, она не имеет смысла, так как модельв ней задана априори и не зависит от. Другими словами, она верна для необученных моделей. Возвращаясь к нашей оценке, получаем: где– мощность класса. Следовательно, В случае бесконечногоиспользуем следующее обобщение неравенства Хёффдинга: Неравенство МакДайармида (McDiarmid's inequality). Пусть– независимые одинаково распределённые случайные величины,– скалярная функция саргументами, такая что для некоторых. Тогда для любогоимеет место неравенство Применяя теорему к, получаем: из чего следует: где– эмпирический риск на выборке. В следующем подразделе мы постараемся оценить жёлтое слагаемое. Оценим сверху матожидание супремума: Этот шаг называется «симметризация»: теперь выражение выше зависит от двух равнозначных обучающих выбороки. Ниже для краткости будем обозначатьи. Как оценить сверху супремум разности рисков? Наивная оценка, супремум суммы, слишком слаба: в самом деле, при фиксированном наборе данных вполне вероятно может существовать модель, имеющая большой риск на нём (достаточно взять модель, обученную на тех же данных, но с «неправильными» метками), поэтому матожидание супремума эмпирического риска может быть велико. Для обхода этой сложности заметим, что выражение выше симметрично относительно перестановки местами двух выборок: Более того, так как элементы обеих выборок выбираются независимо, значение выражения не меняется и при перестановке местами отдельно-ых элементов двух выборок. А именно, для любого набора Будем выбиратьнезависимо и равновероятно из. Такие случайные величины называютсяпеременными Радемахера. Поскольку оценки выше были верны для любых сигм, они верны и в среднем по переменным Радемахера, выбранным независимо от выборки: После введения переменных Радемахера оценка супремума разницы рисков через сумму супремумов становится не такой плохой. В самом деле, рассмотрим бинарную классификацию с помощью линейной модели. Если данные хорошо разделяются плоскостью, тобудет большим, так как в качествеможно взять линейную модель с противоположно ориентированной разделяющей плоскостью для. В то же время для того, чтобыбыло большим, необходимо, чтобы существовала модель, отвечающая правильно на тех примерах, где, и неправильно, где; для линейной модели это невозможно при большинстве конфигураций сигм. Величина называетсясложностью Радемахеракласса функций(для распределениянаи длины выборок). Она велика, если в классесодержатся функции, принимающие большие значения с заданными знаками на любом наборе данных фиксированного размера. Другими словами, сложность Радемахера измеряет, насколько выходы функций из классамогут коррелировать со случайным шумом. Для нас актуальна сложность Радемахера классов вида, то есть композиций моделей из классаи функции риска. Если– класс линейных моделей в пространстве размерности меньшей, чем, то сложность Радемахера невелика. В то же время если– множество всех возможных решающих деревьев, то, если только наборы данных непротиворечивы, она равна единице. В самом деле, решающее дерево способно запомнить всю обучающую выборку, то есть добиться единичной корреляции с любым случайным шумом. Вернёмся к оценке разницы рисков: Сложность Радемахера зависит от функции риска. Рассмотрим задачу бинарной классификации с классамии. Возьмём в качестве функции риска индикатор ошибки бинарной классификации, или «0/1-риск»: Название «0/1-риск» обусловлено тем, что риск принимает значенияи. Заметим следующее: где– класс эквивалентности функций из, в котором две функции считаются эквивалентными тогда и только тогда, когда их образы на выборкеимеют одинаковые знаки. Другими словами, среди всех функций, принимающих одни и те же знаки на, мы выберем по одной и сформируем из них множество. Заметим, что это множество конечно:. Нам понадобится следующая Лемма. Пусть– случайная величина со значениями ви нулевым средним. Тогда для любыхимеет место неравенство С её помощью получаем: Эта оценка верна для любого. Минимизируем её по. Легко видеть, что оптимальноеравняется; подставляя его, получаем: Определимфункцию ростаклассакак Эта функция показывает, сколько различных разметок класс функцийможет породить на наборе данных, в зависимости от размера этого набора. Очевидно, чтои монотонно не убывает. Например, для линейной модели на-мерном пространстве признаковпри(любое подмножествоточек в общем положении в-мерном пространстве всегда можно отделить гиперплоскостью), но строго меньше этого числа при(например, если точки – углы квадрата на плоскости, его диагонали нельзя разделить прямой). Когда, будем говорить, что «разделяет». Определимразмерность Вапника-Червоненкиса(илиVC-размерность) как максимальное, при котором семействоразделяет любой датасет: Таким образом, VC-размерность линейной модели равна. Следующая лемма даёт связь между размерностью Вапника-Червоненкиса и функцией роста: Лемма(Sauer–Shelah, см. подробнеездесь) Изучим асимптотическое поведение сложности Радемахера при. Обозначим. Дляимеем, а для: Подставляя это выражение в (1), получаем окончательную оценку на сложность Радемахера: Соответствующая оценка на истинный риск тогда примёт вид: Для того, чтобы эта оценка была осмыслена, необходимо гарантировать. Для линейных моделей, при условии(данных намного больше, чем признаков), оценки действительно получаются осмысленными. К сожалению, для нейронных сетей это подчас неверно. В работеNearly-tight VC-dimension and Pseudodimension Bounds for Piecewise Linear Neural Networksпоказано, что еслиобозначает класс моделей, реализуемых полносвязной сетью шириныспараметрами, то. Таким образом, наша оценка на сложность Радемахера становится бесполезной в реалистичных сценариях, когда число весов сетимного больше числа примеров в обучающей выборке. Если априори известно, что результат обучения лежит в некотором классе, то в оценке сложности Радемахера можно использовать именно этот класс, а не полный класс моделей. Очевидно, что сложность, лежащего в, не больше сложности. Так, в работеSpectrally-normalized margin bounds for neural networksполучены оценки для сложности полносвязной сети с липшицевыми функциями активации при условии, что нормы весов ограничены; см. такжеполный конспект лекций. В этом случае подбудем понимать класс сетей с весами нормы не больше. Обозначим соответствующую оценку через: К сожалению, нет гарантий, что градиентный спуск всегда сходится в решение с нормой меньше какого-то числа. Чтобы обойти это ограничение, используют следующую технику. Возьмём последовательность ограничений, такую что Также возьмём последовательность, монотонно убывающую к нулю и суммирующуюся в. Тогда для любого А значит, Из этого следует, что где– минимальное, при котором. Такая техника используется, например, в работахSpectrally-normalized margin bounds for neural networksиA PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks.",
    "source_type": null,
    "useful_links": [
      {
        "text": "здесь",
        "url": "https://en.wikipedia.org/wiki/Sauer%E2%80%93Shelah_lemma"
      },
      {
        "text": "Nearly-tight VC-dimension and Pseudodimension Bounds for Piecewise Linear Neural Networks",
        "url": "https://arxiv.org/pdf/1703.02930.pdf"
      },
      {
        "text": "Spectrally-normalized margin bounds for neural networks",
        "url": "https://arxiv.org/pdf/1706.08498.pdf"
      },
      {
        "text": "полный конспект лекций",
        "url": "https://arxiv.org/pdf/2012.05760.pdf"
      },
      {
        "text": "Spectrally-normalized margin bounds for neural networks",
        "url": "https://arxiv.org/pdf/1706.08498.pdf"
      },
      {
        "text": "A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks",
        "url": "https://arxiv.org/pdf/1707.09564.pdf"
      }
    ]
  },
  {
    "document_title": "Обобщающая способность – классическая теория",
    "url": "https://education.yandex.ru/handbook/ml/article/obobshayushaya-sposobnost-klassicheskaya-teoriya",
    "section_title": "Фундаментальная проблема равномерных оценок",
    "text": "Напомним, что построение равномерных оценок проходило в несколько шагов: Оценка супремумом Применение неравенства макДайармида: Оценка матожидания супремума (жёлтое слагаемое выше) с помощью симметризации с дальнейшим выходом на сложность Радемахера: На каждом шаге предыдущая величина оценивается сверху, и потенциально каждое из этих неравенств может оказаться слишком слабым и привести к бессмысленной оценке. Давайте это проиллюстрируем. Выше мы уже отмечали, что если класссодержит модель, для котороймал, авелик, то равномерная оценка становится бессмысленной. По этой причине, имеет смысл выбирать класскак можно более маленьким. Самым лучшим из возможных классов мог бы быть класс моделей, к которым сходится наш алгоритм обучения с высокой вероятностью. Рассмотрим случай, близкий к идеальному: тот, в котором существует, для которого при любыхимеем. Иными словами, предположим, что все модели классахорошо обобщают. В этом случае оценка выше близка к идеальной: Но что будет, если мы начнём честно воспроизводить процесс построения равномерных оценок? После второго шага мы получаем оценку вида которая не сильно хуже предыдущей, но в которой всё равно появилось лишнее слагаемое. Но допустим, что мы хотим честно проделать третий шаг процедуры получения равномерных оценок. Для этого нам необходимо было оценить матожидание супремума, которое после симметризации получает вот такую верхнюю оценку: Таким образом, малость истинного риска не гарантирует малость эмпирического риска на любом наборе данных. Так, авторы статьиUniform convergence may be unable to explain generalization in deep learningпредъявили пример, в котором для любогосуществует модель, такая что, но при этомималы. Иллюстрация такой ситуации приведена в начале параграфа. Тогдавелик, и оценки теряют смысл. К счастью, даже эта фундаментальная проблема не ставит крест на равномерных оценках. Так, работыUniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign OverfittingиStability and Deviation Optimal Risk Bounds with Convergence Rateрассматривают равномерную оценку в классе интерполирующих моделей, то есть, имеющих нулевой эмпирический риск: Для таких моделей контрпример выше не работает.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Uniform convergence may be unable to explain generalization in deep learning",
        "url": "https://arxiv.org/pdf/1902.04742.pdf"
      },
      {
        "text": "Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign Overfitting",
        "url": "https://arxiv.org/pdf/2106.09276.pdf"
      },
      {
        "text": "Stability and Deviation Optimal Risk Bounds with Convergence Rate",
        "url": "https://arxiv.org/pdf/2103.12024.pdf"
      }
    ]
  },
  {
    "document_title": "Оптимизация в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
    "section_title": "Введение",
    "text": "Зачастую задачи машинного обучения формулируются таким образом, что «веса» модели, которую мы строим, возникают, как решение оптимизационной задачи. В качестве VIP-примера рассмотрим задачу линейной регрессии: По сути, мы получили чистейшую задачу квадратичной оптимизации. В чем особенность конкретно этой задачи? Онавыпуклая. Важное свойство выпуклых функций – локальный минимум автоматически является глобальным (но не обязательно единственным!). Это позволяет избегать уродливых ситуаций, которые с теоретической точки зрения могут встретиться в невыпуклом случае, например, вот такой: Теорема(No free lunch theorem) Пусть– алгоритм оптимизации, использующий локальную информацию (все производные в точке). Тогда существует такая невыпуклая функция, что для нахождения глобального минимума на квадратес точностьютребуется совершить хотя бышагов. Мы видим, что в общем случае без выпуклости нас ожидает полное разочарование. Ничего лучше перебора по сетке придумать в принципе невозможно. В выпуклом случае же существуют алгоритмы, которые находят глобальный минимум за разумное время. Встречаются ли в жизни функции невыпуклые? Повсеместно! Например, функция потерь при обучении нейронных сетей, как правило, не является выпуклой. Но отсюда не следует, что любой алгоритм их оптимизации будет обязательно неэффективным: ведь «контрпример» из теоремы довольно специфичен. И, как мы увидим, оптимизировать невыпуклые функции очень даже возможно. Найти глобальный минимум невыпуклой функции – очень трудная задача, но зачастую нам хватает локального, который является, в частности, стационарной точкой: такой, в которой производная равна нулю. Все теоретические результаты в случае невыпуклых задач, как правило, касаются поиска таких точек, и алгоритмы тоже направлены на их отыскание. Этим объясняется и то, что большинство алгоритмов оптимизации, придуманных для выпуклого случая, дословно перешли в невыпуклый. Теоретическая причина в следующем: в выпуклом случае поиск стационарной точки и поиск минимума –буквальноодна и та же задача, поэтому то, что хорошо ищет минимум в выпуклом случае, ожидаемо будет хорошо искать стационарные точки в невыпуклом. Практическая же причина в том, что оптимизаторы в библиотеках никогда не спрашивают, выпуклую ли им функцию подают на вход, а просто работают и работают хорошо. Внимательный читатель мог возразить на моменте подмены задачи: подождите-ка, мы ведь хотим сделать функцию как можно меньше, а не стационарную точку искать какую-то непонятную. Доказать в невыпуклом случае тут, к сожалению, ничего невозможно, но на практике мы снова используем алгоритмы изначально для выпуклой оптимизации. Почему? Причина номер1: сойтись в локальный минимум лучше, чем никуда. Об этом речь уже шла. Причина номер2: в окрестности локального минимума функция становится выпуклой, и там мы сможем быстро сойтись. Причина номер3: иногда невыпуклая функция является в некотором смысле «зашумленной» версией выпуклой или похожей на выпуклую. Например, посмотрите на эту картинку (функция Леви): У этой функции огромное количество локальных минимумов, но «глобально» она кажется выпуклой. Что-то отдаленно похожее наблюдается ив случае нейронных сетей. Нашей задачей становится не скатиться в маленький локальный минимум, который всегда рядом с нами, а в большую-большую ложбину, где значение функции минимально и в некотором смысле стабильно. Причина номер4: оказывается, что градиентные методывесьма частосходятся именно к локальным минимумам. Сразу отметим важную разницу между выпуклой и невыпуклой задачами: в выпуклом случае работа алгоритма оптимизации не очень существенно зависит от начальной точки, поскольку мы всегда скатимся в точку оптимума. В невыпуклом же случае правильно выбранная точка старта – это уже половина успеха. Теперь перейдём к разбору важнейших алгоритмов оптимизации.",
    "source_type": null,
    "useful_links": [
      {
        "text": "в случае нейронных сетей",
        "url": "https://losslandscape.com/"
      },
      {
        "text": "весьма часто",
        "url": "http://proceedings.mlr.press/v49/lee16.html"
      }
    ]
  },
  {
    "document_title": "Оптимизация в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
    "section_title": "Градиентный спуск (GD)",
    "text": "Опишем самый простой метод, который только можно придумать – градиентный спуск. Для того, чтобы его определить, вспомним заклинание из любого курса матанализа: «градиент – это направление наискорейшего локального возрастания функции», тогда антиградиент – это направление наискорейшего локального убывания. Тогда пусть– начальная точка градиентного спуска. Тогда каждую следующую точку мы выбираем следующим образом: где– это размер шага (он же learning rate). Общий алгоритм градиентного спуска пишется крайне просто и элегантно: Скопировать код1x = normal(0,1)# можно пробовать и другие виды инициализации2repeat S times:# другой вариант: while abs(err) >tolerance3h = grad_f(x)# вычисляем направление спуска4x -= alpha * h# обновляем значение в точке Эту схему в приложении к линейной регрессии можно найти впараграфе про линейные модели. После всего этого начинаются тонкости: А как вычислять градиент? А как выбрать размер шага? А есть ли какие-то теоретические оценки сходимости? Начнем разбирать вопросы постепенно. Для вычисления градиентов современный человек может использовать инструменты автоматического дифференцирования. Идейно, это вариация на тему алгоритмаобратного распространения ошибки (backpropagation), ведь как правило человек задает функции, составленные из элементарных при помощи умножений/делений/сложений/композиций. Такой метод реализован во всех общих фреймворках для нейронных сетей (Tensorflow, PyTorch, Jax). Но, вообще говоря, возникает некоторая тонкость. Например, расмотрим задачу линейной регрессии. Запишем её следующим образом: Видим, что слагаемых суммарно– размер выборки. Припорядкаи(это количество признаков) порядкавычисление градиента застановится жутким мучением. Но если отизбавиться без дополнительных предположений (например, о разреженности) нельзя, то с зависимостью отв каком-то смысле удастся разделаться при помощи метода стохастического градиентного спуска. Хранение градиентов тоже доставит нам проблемы. У градиента столько же компонент, сколько параметров у модели, и если мы имеем дело с глубокой нейросетью, это даст значительные затраты дополнительной памяти. Хуже того, метод обратного распространения ошибки устроен так, что нам приходится помнить все промежуточные представления для вычисления градиентов. Поэтому вычислить градиент целиком невозможно ни для какой нормальной нейросети, и от этой беды тоже приходится спасаться с помощью стохастического градиентного спуска. Теперь перейдем к размеру шага. Теория говорит о том, что если функция гладкая, то можно брать достаточно маленький размер шага, где под достаточно маленьким подразумевается, где– некоторая константа, которая зависит от гладкости задачи (так называемая константа Липшица). Вычисление этой константы может быть задачей сложнее, чем изначальная задача оптимизации, поэтому этот вариант нам не годится. Более того, эта оценка крайне пессимистична – мы ведь хотим размер шага как можно больше, чтобы уменьшить функцию как можно больше, а тут мы будем изменять все очень мало. Существует так называемыйметод наискорейшего спуска: выбираем размер шага так, чтобы как можно сильнее уменьшить функцию: Одномерная оптимизация является не сильно сложной задачей, поэтому теоретически мы можем её совершать (например, методом бинарного/тернарного поиска или золотого сечения), можно этот шаг также совершать неточно. Но сразу стоит заметить, что это можно делать, только если функциявычислима более-менее точно за разумное время, в случае линейной регрессии это уже не так (не говоря уже о нейронных сетях). Также есть всевозможные правила Армихо/Гольдштейна/Вульфа и прочее и прочее, разработанные в давние 60-е, и для их проверки требуется снова вычислять значения функции в точке. Желающие могут посмотреть на эти условияна википедии. Про более хитрые вариации выбора шагов мы поговорим позже, но сразу стоит сказать, что эта задача довольно сложная. По поводу теории: сначала скажем что-то провыпуклыйслучай. В максимально общем выпуклом случае без дополнительных предположений оценки для градиентного спуска крайне и крайне пессимистичные: чтобы достичь качества, то есть достаточно сделатьшагов, где— это расстояние отдо. Выглядит очень плохо: ведь чтобы достичь точности, необходимо сделать порядкашагов градиентного спуска. Но на практике такого не происходит, потому что на самом деле верны разные предположения, дающие более приятные свойства. Для контраста, укажем оценку в случае гладкой и сильно выпуклой в точке оптимума функции: зашагов будет достигнута точность где– это так называемое число обусловленности задачи. По сути, это число измеряет, насколько линии уровня функции вытянуты в окрестности оптимума. Морали две: Скорость сходимости градиентного спуска сильно зависит от обусловленности задачи; Также она зависит от выбора хорошей точки старта, ведь везде входит расстояние от точки старта до оптимума. В качестве ссылки на доказательство укажем наработу Себастиана Стича, где оно довольно простое и общее. В невыпуклом же случае все куда хуже с точки зрения теории: требуется порядкашагов в худшем случае даже для гладкой функции, где– желаемая точность уменьшения нормы градиента.",
    "source_type": null,
    "useful_links": [
      {
        "text": "параграфе про линейные модели",
        "url": "https://academy.yandex.ru/handbook/ml/article/linejnye-modeli#pochemu-modeli-linejnye"
      },
      {
        "text": "обратного распространения ошибки (backpropagation)",
        "url": "https://academy.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki"
      },
      {
        "text": "на википедии",
        "url": "https://ru.wikipedia.org/wiki/%D0%A3%D1%81%D0%BB%D0%BE%D0%B2%D0%B8%D1%8F_%D0%92%D0%BE%D0%BB%D1%8C%D1%84%D0%B5"
      },
      {
        "text": "работу Себастиана Стича",
        "url": "https://arxiv.org/abs/1907.04232v2"
      }
    ]
  },
  {
    "document_title": "Оптимизация в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
    "section_title": "Стохастический градиентный спуск (SGD)",
    "text": "Теперь мы попробуем сэкономить в случае регрессии и подобных ей задач. Будем рассматривать функционалы вида где сумма проходится по всем объектам выборки (которых может быть очень много).Теперь сделаем следующий трюк: заметим, что это усреднение – это по сути взятие матожидания. Таким образом, мы говорим, что наша функция выглядит как гдеравномерно распределена по обучающей выборке. Задачи такого вида возникают не только в машинном обучении; иногда встречаются и просто задачистохастического программирования, где происходит минимизация матожидания по неизвестному (или слишком сложному) распределению. Для функционалов такого вида мы также можем посчитать градиент, он будет выглядеть довольно ожидаемо: Будем считать, что вычисление матожидания напрямую невозможно. Новый взгляд из статистики дает возможность воспользоваться классическим трюком: давайте подменим матожидание на его несмещенную Монте-Карло оценку. Получается то, что можно назватьстохастическим градиентом: Говоря инженерным языком, мы подменили вычисление градиента по всей выборке вычислением по случайной подвыборке. Подвыборкучасто называют (мини)батчем, а число– размером батча. По-хорошему, наука предписывает нам каждый раз независимо генерировать батчи, но это трудно с вычислительной точки зрения. Вместо этого воспользуемся следующим приёмом: сначала перемешаем нашу выборку (чтобы внести дополнительную случайность), а затем будем рассматривать последовательно блоки поэлементов выборки. Когда мы просмотрели всю выборку – перемешиваем еще раз и повторяем проход. Очередной прогон по обучающей выборке называетсяэпохой. И, хотя, казалось бы, независимо генерировать батчи лучше, чем перемешивать лишь между эпохами, есть несколько результатов, демонстрирующих обратное:одна работаивторая (более новая); главное условие успеха – правильно изменяющийся размер шага. Получаем следующий алгоритм, называемыйстохастическим градиентным спуском(stochastic gradient descent,SGD): Скопировать код1x = normal(0,1)# инициализация2repeat E times:# цикл по количеству эпох3fori =0; i <= N; i += B:4batch = data[i:i+B]5h = grad_loss(batch).mean()# вычисляем оценку градиента как среднее по батчу6x -= alpha * h Дополнительное удобство такого подхода – возможность работы с внешней памятью, ведь выборка может быть настолько большой, что она помещается только на жёсткий диск. Сразу отметим, что в таком случаестоит выбирать достаточно большим: обращение к данным с диска всегда медленнее, чем к данным из оперативной памяти, так что лучше бы сразу забирать оттуда побольше. Поскольку стохастические градиенты являются лишь оценками истинных градиентов, SGD может быть довольно шумным: Поэтому если вы обучаете глубокую нейросеть и у вас в память влезает лишь батч размером с 2-4 картинки, модель, возможно, ничего хорошего не сможет выучить. Аппроксимация градиента и поведение SGD может стать лучше с ростом размера батча– и обычно его действительно хочется подрастить, но парадоксальным образом слишком большие батчи могут порой испортить дело (об этом дальше в этом параграфе!). Теперь перейдем к теоретической стороне вопроса. Сходимость SGD обеспечивается несмещенностью стохастического градиента. Несмотря на то, что во время итераций копится шум, суммарно он зачастую оказывается довольно мал. Теперь приведем оценки. Сначала, по традиции, в выпуклом случае. Для выпуклой функции потерь зашагов будет достигнута точность порядка где– это дисперсия стохградиента, а– константа сильной выпуклости, показывающая, насколько функция является «не плоской» в окрестности точки оптимума. Доказательство в том жепрепринте С. Стича. Мораль в следующем: дисперсия стохастического градиента, вычисленного по батчу размераравна, где– это дисперсия одного градиента. То есть увеличение размера батча помогает и с теоретической точки зрения. В невыпуклом случае оценка сходимости SGD просто катастрофически плохая: требуетсяшагов для того, чтобы сделать норму градиента меньше. В теории есть всевозможные дополнительные способы снижения дисперсии с лучшими теоретическими оценками (Stochastic Variance Reduced Gradient (SVRGD), Spider, etc), но на практике они активно не используются.",
    "source_type": null,
    "useful_links": [
      {
        "text": "одна работа",
        "url": "https://arxiv.org/abs/1806.10077"
      },
      {
        "text": "вторая (более новая)",
        "url": "https://arxiv.org/abs/2006.06946"
      },
      {
        "text": "препринте С. Стича",
        "url": "https://arxiv.org/abs/1907.04232v2"
      }
    ]
  },
  {
    "document_title": "Оптимизация в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
    "section_title": "Использование дополнительной информации о функции",
    "text": "Основной раздел. Постараемся усовершенствовать метод стохастического градиентного спуска. Сначала заметим, что мы используем явно не всю информацию об оптимизируемой функции. Вернемся к нашему VIP-примеру линейной регресии срегуляризацией: Эта функция достаточно гладкая, и может быть неплохой идеей использовать её старшие производные для ускорения сходимости алгоритма. В наиболее чистом виде этой философии следует метод Ньютона и подобные ему; о них вы можете прочитатьв соответствующем разделе. Отметим, что все такие методы, как правило, довольно дорогие (исключая L-BFGS), и при большом размере задачи и выборки ничего лучше вариаций SGD не придумали. Основной раздел. К сожалению, не всегда функции такие красивые и гладкие. Для примера рассмотрим Lasso-регресию: Второе, не гладкое слагаемое резко ломает все свойства этой задачи: теоретически оценки для градиентного спуска становятсягораздохуже (и на практике тоже). С другой стороны, регуляризационное слагаемое устроено очень просто, и эту дополнительную структурную особенность можно и нужно эксплуатировать. Методы решения задачи вида где– простая функция (в некотором смысле), а– гладкая, называются методамикомпозитной оптимизации. Глубже погрузиться в них можно всоответствующем разделе, посвященном проксимальным методам.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Основной раздел.",
        "url": "https://academy.yandex.ru/handbook/ml/article/metody-vtorogo-poryadka"
      },
      {
        "text": "в соответствующем разделе",
        "url": "https://academy.yandex.ru/handbook/ml/article/metody-vtorogo-poryadka"
      },
      {
        "text": "Основной раздел.",
        "url": "https://academy.yandex.ru/handbook/ml/article/proksimalnye-metody"
      },
      {
        "text": "соответствующем разделе",
        "url": "https://academy.yandex.ru/handbook/ml/article/proksimalnye-metody"
      }
    ]
  },
  {
    "document_title": "Оптимизация в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
    "section_title": "Использование информации о предыдущих шагах",
    "text": "Следующая претензия к методу градиентного спуска – мы не используем информацию о предыдущих шагах, хотя, кажется, там может храниться что-то полезное. Начнем с физической аналогии. Представим себе мячик, который катится с горы. В данном случае гора – это график функции потерь в пространстве параметров нашей модели, а мячик – её текущее значение. Реальный мячик не застрянет перед небольшой кочкой, так как у него есть некоторая масса и уже накопленный импульс – некоторое время он способен двигаться даже вверх по склону. Аналогичный прием может быть использован и в градиентной оптимизации. В англоязычной литературе он называетсяMomentum. С математической точки зрения, мы добавляем к градиентному шагу еще одно слагаемое: Сразу заметим, что мы немного усугубили ситуацию с подбором шага, ведь теперь нужно подбирать не только, но и. Для обычного, не стохастического градиентного спуска мы можем адаптировать метод наискорейшего и получитьметод тяжелого шарика: Но, увы, для SGD это работать не будет. Выгода в невыпуклом случае от метода инерции довольно понятна – мы будем пропускать паразитные локальные минимумы и седла и продолжать движение вниз. Но выгода есть также и в выпуклом случае. Рассмотрим плохо обусловленную квадратичную задачу, для которой линии уровня оптимизируемой функции будут очень вытянутыми эллипсами, и запустим на SGD с инерционным слагаемым и без него. Направление градиента будет иметь существенную вертикальную компоненту, а добавление инерции как раз «погасит» паразитное направление. Получаем следующую картинку: Также удобно бывает представить метод моментума в виде двух параллельных итерационных процессов: Рассмотрим некоторую дополнительную модификацию, которая была предложена в качестве оптимального метода первого порядка для решения выпуклых оптимизационных задач. Можно доказать, что в сильно выпуклом и гладком случае найти минимум с точностьюнельзя быстрее, чем за итераций, где– число обусловленности задачи. Напомним, что для обычного градиентного спуска в экспоненте у нас был не корень из, а просто, то есть, градиентный спуск справляется с плохой обусловленностью задачи хуже, чем мог бы. В 1983 году Ю.Нестеровым был предложен алгоритм, имеющий оптимальную по порядку оценку. Для этого модифицируем немного моментум и будем считать градиент не в текущей точке, а как бы в точке, в которую мы бы пошли, следуя импульсу: Сравним с обычным momentum: Комментарий: иногда упоминается, что Nesterov Momentum «заглядывает в будущее» и исправляет ошибки на данном шаге оптимизации. Конечно, никто не заглядывает в будущее в буквальном смысле. В работе Нестерова были предложены конкретные (и довольно магические) константы для импульса, которые получаются из некоторой еще более магической последовательности. Мы приводить их не будем, поскольку мы в первую очередь заинтересованы невыпуклым случаем. Nesterov Momentum позволяет значительно повысить устойчивость и скорость сходимости в некоторых случаях. Но, конечно, он не является серебряной пулей в задачах оптимизации, хотя в выпуклом мире и является теоретически неулучшаемым. Также отметим, что ускоренный метод может напрямую примениться к проксимальному градиентному спуску. В частности, применение ускоренного метода к проксимальному алгоритму решениярегрессии (ISTA) называется FISTA (Fast ISTA). Общие выводы: Добавление momentum к градиентному спуску позволяет повысить его устойчивость и избегать маленьких локальных минимумов/максимумов; В выпуклом случае добавление моментного слагаемого позволяет доказуемо улучшить асимптотику и уменьшить зависимость от плохой обусловленности задачи. Идея ускорения применяется к любым около-градиентным методам, в том числе и к проксимальным, позволяя получить, например, ускоренный метод для-регрессии.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Оптимизация в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
    "section_title": "Адаптивный подбор размера шага",
    "text": "Выше мы попытались эксплуатировать свойства градиентного спуска. Теперь же пришел момент взяться за больной вопрос: как подбирать размер шага? Он максимально остро встаёт в случае SGD: ведь посчитать значение функции потерь в точке очень дорого, так что методы в духе наискорейшего спуска нам не помогут! Нужно действовать несколько хитрее. Рассмотрим первый алгоритм, который является адаптацией стохастического градиентного спуска. Впервые он предложен встатье в JMLR 2011 года, но она написана в очень широкой общности, так что читать её достаточно сложно. Зафиксируем– исходный learning rate. Затем напишем следующую формулу обновления: Возведение в квадрат и деления векторов покомпонентные. По сути, мы добавляем некоторую квазиньютоновость и начинаем динамически подбирать размер шага для каждой координаты по отдельности. Наш размера шага для фиксированной координаты – это какая-то изначальная константа(learning rate), деленная на корень из суммы квадратов координат градиентов плюс дополнительный параметр сглаживания, предотвращающий деление на ноль. Добавкана практике оставляется дефолтными1e-8и не изменяется. Идея следующая: если мы вышли на плато по какой-то координате и соответствующая компонента градиента начала затухать, то нам нельзя уменьшать размер шага слишком сильно, поскольку мы рискуем на этом плато остаться, но в то же время уменьшать надо, потому что это плато может содержать оптимум. Если же градиент долгое время довольно большой, то это может быть знаком, что нам нужно уменьшить размер шага, чтобы не пропустить оптимум. Поэтому мы стараемся компенсировать слишком большие или слишком маленькие координаты градиента. Но довольно часто получается так, что размер шага уменьшается слишком быстро и для решения этой проблемы придумали другой алгоритм. Модифицируем слегка предыдущую идею: будем не просто складывать нормы градиентов, а усреднять их вскользящем режиме: Такой выбор позволяет все еще учитывать историю градиентов, но при этом размер шага уменьшается не так быстро. Общие выводы: Благодаря адаптивному подбору шага в современных оптимизаторах не нужно подбирать последовательностьразмеров всех шагов, а достаточно выбрать всего одно число – learning rate, всё остальное сделает за вас сам алгоритм. Но learning rate все еще нужно выбирать крайне аккуратно: алгоритм может либо преждевременно выйти на плато, либо вовсе разойтись. Пример приведен на иллюстрации ниже.",
    "source_type": null,
    "useful_links": [
      {
        "text": "статье в JMLR 2011 года",
        "url": "http://jmlr.org/papers/v12/duchi11a.html"
      }
    ]
  },
  {
    "document_title": "Оптимизация в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
    "section_title": "Объединяем все вместе...",
    "text": "Теперь покажем гвоздь нашей программы: алгоритм Adam, который считается решением по умолчанию и практически серебряной пулей в задачах стохастической оптимизации. Название Adam = ADAptive Momentum намекает на то, что мы объединим идеи двух последних разделов в один алгоритм. Приведем его алгоритм, он будет немного отличаться оторигинальной статьиотсутствием коррекций смещения (bias correction), но идея останется той же самой: Как правило, в этом алгоритме подбирают лишь один гиперпараметр– learning rate. Остальные же:,и– оставляют стандартными и равными0.9,0.99и1e-8соответственно. Подборсоставляет главное искусство. Зачастую, при начале работы с реальными данными начинают со значения learning rate равного 3e-4. История данного значения достаточно забавна: в 2016 году Андрей Карпатый (Andrej Karpathy) опубликовал шутливыйпост в Twitter. После чего сообщество подхватило эту идею (до такой степени, что иногда число3e-4называют Karpathy constant). Обращаем ваше внимание, что при работе с учебными данными зачастую полезно выбирать более высокий (на 1-2 порядка) начальный learning rate (например, при классификации MNIST, Fashion MNIST, CIFAR или при обучении языковой модели на примере поэзии выбранного поэта). Также стоит помнить, что Adam требует хранения как параметров модели, так и градиентов, накопленного импульса и нормировочных констант (cache). Т.е. достижение более быстрой (с точки зрения количества итераций/объема рассмотренных данных) сходимости требует больших объемов памяти. Кроме того, если вы решите продолжить обучение модели, остановленное на некоторой точке, необходимо восстановить из чекпоинта не только веса модели, но и накопленные параметры Adam. В противном случае оптимизатор начнёт сбор всех своих статистик с нуля, что может сильно сказаться на качестве дообучения. То же самое касается вообще всех описанных выше методов, так как каждый из них накапливает какие-то статистики во время обучения. Интересный факт:Adam расходится на одномерном контрпримере, что совершенно не мешает использовать его для обучения нейронных сетей. Этот факт отлично демонстрирует, насколько расходятся теория и практика в машинном обучении. В той же работе предложено исправление этого недоразумения, но его активно не применяют и продолжают пользоваться «неправильным» Adamом потому что он быстрее сходится на практике. А теперь давайте добавим-регуляризацию неявным образом, напрямую в оптимизатор и минуя адаптивный размер шага: Это сделано для того, чтобы эффект-регуляризации не затухал со временем и обобщающая способность модели была выше. Оставим ссылку на однузаметкупро этот эффект. Отметим, впрочем, что этот алгоритм особо не используется.",
    "source_type": null,
    "useful_links": [
      {
        "text": "оригинальной статьи",
        "url": "https://arxiv.org/pdf/1412.6980"
      },
      {
        "text": "пост в Twitter",
        "url": "https://twitter.com/karpathy/status/801621764144971776"
      },
      {
        "text": "Adam расходится на одномерном контрпримере",
        "url": "https://arxiv.org/pdf/1904.09237"
      },
      {
        "text": "заметку",
        "url": "https://towardsdatascience.com/why-adamw-matters-736223f31b5d"
      }
    ]
  },
  {
    "document_title": "Оптимизация в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/optimizaciya-v-ml",
    "section_title": "Практические аспекты",
    "text": "Часто learning rate понижают итеративно: каждые условные 5 эпох (LRScheduler в Pytorch) или же при выходе функции потерь на плато. При этом лосс нередко ведет себя следующим схематичным образом: Помимо этого используют другие варианты «расписаний» для learning rate. Из часто применяемых неочевидных лайфхаков: сначала сделать warmup, то есть увеличивать learning rate, а затем начать постепенно понижать. Использовалось в известнойстатье про трансформеры. В ней предложили следующую формулу: По сути, первыешагов происходит линейный рост размера шага, а затем он начинает уменьшаться как, где— число итераций. Есть и вариант с косинусом изотдельной библиотеки для трансформеров. В этой же библиотеке можно также почерпнуть идею рестартов: с какого-то момента мы снова включаем warmup, увеличивая размер шага. Представим ситуацию, что мы хотим обучить свою нейронную сеть на нескольких GPU. Одно из решений выглядит следующим образом: загружаем на каждую видеокарту нейронную сеть и свой отдельный батч, вычисляем стохастические градиенты, а затем усредняем их по всем видеокартам и делаем шаг. Что плохого может быть в этом? По факту, эта схема в некотором смысле эквивалентна работе с одним очень большим батчем. Хорошо же, нет разве? На самом деле существует так называемый generalization gap: использование большого размера батча может приводить к худшей обобщающей способности итоговой модели. О причине этого эффекта можно поспекулировать, базируясь на текущих знаниях о ландшафтах функций потерьпри обучении нейронных сетей. Больший размер батча приводит к тому, что оптимизатор лучше «видит» ландшафт функции потерь для конкретной выборки и может скатиться в маленькие «узкие» паразитные локальные минимумы, которые не имеют обобщающий способности — при небольшом шевелении этого ландшафта (distributional shift c тренировочной на тестовую выборку) значение функции потерь резко подскакивает. В свою очередь, широкие локальные минимумы дают модель с лучшей обобщающей способностью. Эту идею можно увидеть на следующей картинке: Иными словами, большие батчи могут приводить к переобучению, но это можно исправить правильным динамическим подбором learning rate, как будет продемонстрировано далее. Сразу отметим, что совсем маленькие батчи – это тоже плохо, с ними ничего не получится выучить, так как каждая итерация SGD знает слишком мало о ландшафте функции потерь. Мы рассмотрим нестандартный оптимизатор для обучения нейронных сетей, которого нет в Pytorch по умолчанию, но который много где используется:Layer-wise Adaptive Rate Scaling (LARS). Он позволяет эффективно использовать большие размеры батчей, что очень важно при вычислении на нескольких GPU. Основная идея заключена в названии – нужно подбирать размер шага не один для всей сети или каждого нейрона, а отдельный длякаждого слояпо правилу, похожему на RMSProp. По сравнению с оригинальным RMSProp подбор learning rate для каждого слоя дает большую стабильность обучения. Теперь рассмотрим формулу пересчета: пусть– это веса слоя,. Параметры алгоритма: базовый learning rate(на который запускается расписание), коэффициент инерции, коэффециент затухания весов(как в AdamW). Скопировать код1forlinrange(L):# Цикл по слоям2g_l = stochgrad(w_prev)[l]# Вычисляем стохградиент из батча для текущего слоя3lr = eta * norm(w[l]) / (norm(g_l) + beta * norm(w[l]))# Вычислеяем learning rate для текущего слоя4v[l] = m * v[l] + lr * (g_l + beta * w[l])# Обновляем momentum5w[l] -= v[l]# Делаем градиентный шаг по всему слою сразу6w_prev = w# Обновляем веса Этот оптимизатор введен в статьеLarge Batch Optimization For Deep Learningи является идейным продолжателем LARS, более приближенным к Adam, чем к обычному RMSProp. Его параметры – это параметры Adam, которые берутся как в Adam, а также параметр, который отвечает за затухание весов (в LARS). Скопировать код1forlinrange(L):# Цикл по слоям2g_l = stochgrad(w_prev)[l]# Вычисляем стохградиент из батча для текущего слоя3m[l] = beta_1 * m[l] + (1- beta_1) * g_l# Вычисляем моментум4v[l] = beta_2 * v[l] + (1- beta_2) * g_l# Вычисляем новый размер шага5m[l] /= (1- beta_1**t)# Шаг для уменьшения смещения из Adam6v[l] /= (1- beta_2**t)7r[l] = m[l] / sqrt(v[l] + eps)# Нормируем моментум как предписывает Adam8lr = eta * norm(w[l]) / norm(r[l] + llambda * w[l])# Как в LARS9w[l] = w[l] - lr * (r[l] + llambda * w[l])# Делаем шаг по моментуму10w_prev = w# Обновляем веса Теперь снова заглянем в теорию: на самом деле, все хорошие теоретические оценки для SGD проявляются, когда берётся усреднение по точкам. Этот эффект при обучении нейронных сетей был исследован в статье проалгоритм SWA. Суть очень проста: давайте усреднять веса модели по каждой-й итерации; можно считать, что по эпохам. В итоге, веса финальной модели являются усреднением весов моделей, имевших место в конце каждой эпохи. В результате такого усреднения сильно повышается обобщающая способность модели: мы чаще попадаем в те самые широкие локальные минимумы, о которых мы говорили в разделе про большие батчи. Вдохновляющая картинка из статьи прилагается: На второй и третьей картинке изображено сравнение SGD и SWA при обучении нейронной сети (Preactivation ResNet-164 on CIFAR-100) при одной и той же инициализации. На первой же картинке изображено, как идеологически должен работать SWA. Также мы видим тут демонстрацию эффекта концентрации меры: после обучения стохастический градиентный спуск становится случайным блужданием по области в окрестности локального минимума. Если, например, предположить, что итоговая точка – это нормальное распределение с центром в реальном минимуме в размерности, то все эти точки с большой вероятности будут находиться в окрестности сферы радиуса. Интуитивную демонстрацию многомерного нормального распределения можно увидеть на следующей картинке из книги Р.Вершинина \"High-Dimensional Probability\" (слева в размерности 2, справа в большой размерности): Поэтому, чтобы вычислить центральную точку этой гауссианы, усреднение просто необходимо, по такому же принципу работает и SWA. Теперь мы снова обратимся к теории: скорость сходимости градиентного спуска (даже ускоренного) очень сильно зависит от числа обусловленности задачи. Разумной идеей будет попытаться использовать какие-то сведения о задаче и улучшить этот показатель, тем самым ускорив сходимость. В теории, здесь могут помочь техникипредобуславливания. Но, к сожалению, попытки наивно воплотить эту идею приводят к чему-то, похожему на метод Ньютона, в котором нужно хранить большую-большую матрицу для обучения больших моделей. Способ обойти эту проблему рассмотрели в статье о методеShampoo, который использует то, что веса нейронной сети зачастую удобно представлять как матрицу или даже многомерный тензор. Таким образом, Shampoo можно рассматривать как многомерный аналог AdaGrad.",
    "source_type": null,
    "useful_links": [
      {
        "text": "статье про трансформеры",
        "url": "https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf"
      },
      {
        "text": "отдельной библиотеки для трансформеров",
        "url": "https://huggingface.co/transformers/main_classes/optimizer_schedules.html"
      },
      {
        "text": "при обучении нейронных сетей",
        "url": "https://losslandscape.com/"
      },
      {
        "text": "Layer-wise Adaptive Rate Scaling (LARS)",
        "url": "https://arxiv.org/abs/1708.03888"
      },
      {
        "text": "Large Batch Optimization For Deep Learning",
        "url": "https://arxiv.org/abs/1904.00962"
      },
      {
        "text": "алгоритм SWA",
        "url": "https://arxiv.org/abs/1803.05407"
      },
      {
        "text": "предобуславливания",
        "url": "https://en.wikipedia.org/wiki/Preconditioner"
      },
      {
        "text": "Shampoo",
        "url": "https://arxiv.org/abs/1802.09568"
      }
    ]
  },
  {
    "document_title": "Введение в генеративное моделирование",
    "url": "https://education.yandex.ru/handbook/ml/article/vvedenie-v-generativnoe-modelirovanie",
    "section_title": "Интерполяции в латентном пространстве",
    "text": "Большинство моделей генеративного моделирования позволяют семплировать новые объекты. Как правило, в результате обучения генеративной модели мы получаем генератор — функцию, которая на выходе выдаёт объект. В таких моделях, как генеративные состязательные нейронные сети, диффузионные модели, вариационные автокодировщики, генератор на вход принимает вектор случайных значений из простого вероятностного распределения (например, нормального или равномерного). Получается, что, где— объект,— функция генератора, а— вектор случайных значений. Пространство, в котором располагается, называется латентным. Обычно распределениезадаётся ещё до обучения модели и не меняется в процессе. Поскольку мы знаем распределение, мы можем семплировать из него сколько угодно разных. Рассмотрим два вектораииз латентного пространства и два соответствующих им сгенерированных объекта. Так каки— это две точки в латентном пространстве, между ними можно провести линию. Точки, лежащие на этой линии, будут так же принадлежать этому пространству. Если двигаться по этой линии и использовать точки с неё в качестве входа для генератора, то можно получить плавно изменяющийся сгенерированный объект. В примере выше мы рассмотрели движение вдоль линии, однако на практике интерполяция может быть по более сложной траектории. Манипуляции с латентным пространством позволяют не только создавать плавные переходы между объектами, но так же редактировать объекты. Обычно в таких случаях требуется найти направления в латентном пространстве, которое отвечает за нужное свойство сгенерированных объектов. Например, направление, отвечающее за цвет волос или улыбку человека. Подробнее такие методы мы рассмотрим в параграфах про конкретные модели.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Введение в генеративное моделирование",
    "url": "https://education.yandex.ru/handbook/ml/article/vvedenie-v-generativnoe-modelirovanie",
    "section_title": "Применения генеративных моделей",
    "text": "Зачем может понадобиться генерировать новые данные или восстанавливать их плотность? Самый простой пример – это аугментация набора данных, которая мешает переобучению и улучшает обобщаемость модели. Простые аугментации данных (случайные сдвиги, повороты, масштабирование, изменения цвета и контраста) активно используются почти во всех методах машинного обучения. Генеративные же модели представляют собой более сложный вид аугментации данных, который способен существенно расширить датасет, или обогатить его совершенно новыми элементами. Например, генеративную модель, которая переносит стиль одного изображения на другое (style transfer), можно использовать для обучения более робастных моделей классификации. ВстатьеSandfort et al. используют аугментацию генеративными нейросетями, чтобы улучшить качество сегментации компьютерной томографии. Помимо этого, у генеративных моделей есть ряд других применений для редактирования изображений. Их используют, чтобы повысить разрешение картинок (задача super-resolution). На изображении ниже оригинальную картинку (original) сначала сжали в четыре раза, а потом попробовали восстановить до исходных размеров разными методами. Видно, что метод SRGAN, метод на основе генеративных состязательных нейронных сетях работает гораздо лучше бикубической интерполяции (bicubic), которая обычно применяется по умолчанию и смазывает картинку. С помощью генеративных моделей можно закрашивать пропущенные куски изображений. Это полезно, когда мы хотим удалить с фото других людей, и нам нужно закрасить участки, образовавшиеся после их удаления. Эта функция представлена в некоторых современных смартфонах. В последние несколько лет хорошо стали работать модели, которые генерируют изображения на основе их текстового описания. Среди таких моделей: Stable Diffusion (Демо). Модель с открытымисходным кодом DALLE 2. Доступ по платному API Midjourney. Доступ через Discord Imagen Появились даже специальные базы изображений, сгенерированных нейронными сетями:Lexica,Openart. Доступность таких моделей приводит к появлению множества приложений: Иллюстрации для книг Создание логотипов Создание дизайнов помещений Генерация тату Кроме этого, некоторые модели позволяют совместить несколько задач и делать закрашивание изображения на основе текстового описания. Например, удалять какую-то область и говорить модели, что там должно быть нарисовано. На основе этой технологии появились редакторы изображений с генеративными моделями внутри:Neural love,Photoroom,ZMO. Современные генеративные модели достигли очень хорошего качества и уже стали использоваться в реальных задачах, о которых мы вам рассказали. В следующих параграфах этой главы мы рассмотрим основные методы генеративного обучения более детально.",
    "source_type": null,
    "useful_links": [
      {
        "text": "статье",
        "url": "https://www.nature.com/articles/s41598-019-52737-x"
      },
      {
        "text": "Демо",
        "url": "https://huggingface.co/spaces/stabilityai/stable-diffusion"
      },
      {
        "text": "исходным кодом",
        "url": "https://github.com/CompVis/stable-diffusion"
      },
      {
        "text": "DALLE 2",
        "url": "https://openai.com/dall-e-2/"
      },
      {
        "text": "Midjourney",
        "url": "https://www.midjourney.com/"
      },
      {
        "text": "Imagen",
        "url": "https://imagen.research.google/"
      },
      {
        "text": "Lexica",
        "url": "https://lexica.art/"
      },
      {
        "text": "Openart",
        "url": "https://openart.ai/"
      },
      {
        "text": "Иллюстрации для книг",
        "url": "https://www.reddit.com/r/midjourney/comments/x4kk0r/i_created_a_graphic_novel_using_mj_and_now_its_on/"
      },
      {
        "text": "Создание логотипов",
        "url": "https://jacobmartins.com/posts/how-i-used-dalle2-to-generate-the-logo-for-octosql/"
      },
      {
        "text": "Создание дизайнов помещений",
        "url": "https://interiorai.com/"
      },
      {
        "text": "Генерация тату",
        "url": "https://www.tattoosai.com/"
      },
      {
        "text": "Neural love",
        "url": "https://neural.love/"
      },
      {
        "text": "Photoroom",
        "url": "https://www.photoroom.com/"
      },
      {
        "text": "ZMO",
        "url": "https://www.zmo.ai/"
      }
    ]
  },
  {
    "document_title": "Первое знакомство с полносвязными нейросетями",
    "url": "https://education.yandex.ru/handbook/ml/article/pervoe-znakomstvo-s-polnosvyaznymi-nejrosetyami",
    "section_title": "Forward &backward propagation",
    "text": "Информация может течь по графу в двух направлениях. Применение нейронной сети к данным (вычисление выхода по заданному входу) часто называютпрямым проходом, или жеforward propagation(forward pass). На этом этапе происходит преобразование исходного представления данных в целевое и последовательно строятся промежуточные (внутренние) представления данных — результаты применения слоёв к предыдущим представлениям. Именно поэтому проход называют прямым. Приобратном проходе, или жеbackward propagation(backward pass), информация (обычно об ошибке предсказания целевого представления) движется от финального представления (а чаще даже от функции потерь) к исходному через все преобразования. Механизм обратного распространения ошибки, играющий важнейшую роль в обучении нейронных сетей, как раз предполагаетобратноедвижение по вычислительному графу сети. С ним вы познакомитесь в следующемпараграфе.",
    "source_type": null,
    "useful_links": [
      {
        "text": "параграфе",
        "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki"
      }
    ]
  },
  {
    "document_title": "Первое знакомство с полносвязными нейросетями",
    "url": "https://education.yandex.ru/handbook/ml/article/pervoe-znakomstvo-s-polnosvyaznymi-nejrosetyami",
    "section_title": "Архитектуры для простейших задач",
    "text": "Как мы уже упоминали выше, нейросети — это универсальный конструктор, который из простых блоков позволяет собрать орудия для решения самых разных задач. Давайте посмотрим на конкретные примеры. Безусловно, мир намного разнообразнее того, что мы покажем вам в этом параграфе, но с чего-то ведь надо начинать, не так ли? В тех несложных ситуациях, которые мы сейчас рассмотрим, архитектура будет отличаться лишь самыми последними этапами вычисления (у сетей будут разные «головы»). Для иллюстрации приведём примеры нескольких игрушечных архитектур для решения игрушечных задач классификации и регрессии на двумерных данных: Для решения задачи бинарной классификации подойдёт любая архитектура, на выходе у которой одно число отдо, интерпретируемое как «вероятность класса 1». Обычно этого добиваются, взяв где— некоторая функция, превращающая представлениев число (если— матрица, то подойдёт, где— вектор-столбец), а— наша любимая сигмоида. При этомможет получаться как угодно, лишь бы хватало оперативной памяти и не было переобучения. В качестве функции потерь удобно брать уже знакомый нам log loss. Работая с другими моделями, мы порой вынуждены были выдумывать сложные стратегии многоклассовой классификации; нейросети позволяют это делать легко и элегантно. Достаточно построить сеть, которая будет выдаватьнеотрицательных чисел, суммирующихся в 1 (где— число классов); тогда им можно придать смысл вероятностей классов и предсказывать тот класс, «вероятность» которого максимальна. Превратить произвольный набор изчисел в набор из неотрицательных чисел, суммирующихся в 1, позволяет, к примеру, функция Наиболее популярные архитектуры для многоклассовой классификации имеют вид где— функция, превращающаяв матрицу(где— размер батча), аможет быть получен любым приятным вам образом. Но какой будет функция потерь для такой сети? Мы должны научиться сравнивать «распределение вероятностей классов» с истинным (в котором на месте истинного класса стоит 1, а в остальных местах 0). Сделать это позволяеткросс-энтропия, она жеnegative log-likelihood— некоторый аналог расстояния между распределениями: где снова— размер батча, а— число классов. Легко видеть, что приполучается та самая функция потерь, которую мы использовали для обучения бинарной классификации. С помощью нейросетей легко создать модель, которая предсказывает не одно число, а сразу несколько. Например, координаты ключевых точек лица — кончика носа, уголков рта и так далее. Достаточно сделать, чтобы последнее представление было матрицей, где— размер батча, а— количество предсказываемых чисел. Особенностью большинства моделей регрессии является то, что после последнего слоя (часто линейного) не ставят функций активации. Вы тоже этого не делайте, если только чётко не понимаете, зачем вам это. В качестве функции потерь можно брать, например,по всей матрице. Если вы используете нейросети, то ваши таргеты могут иметь и различную природу. Например, можно соорудить одну-единственную сеть, которая по фотографии нескольких котиков определяет их количество (регрессия) и породу каждого из них (многоклассовая классификация). Лосс для такой модели может быть равен (взвешенной) сумме лоссов для каждой из задач (правда, не факт, что это хорошая идея). Так что, по крайней мере в теории, сетям подвластны любые задачи. На практике, конечно, всё гораздо хитрей: для обучения слишком сложной сети у вас может не хватить данных или вычислительных мощностей.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Первое знакомство с полносвязными нейросетями",
    "url": "https://education.yandex.ru/handbook/ml/article/pervoe-znakomstvo-s-polnosvyaznymi-nejrosetyami",
    "section_title": "Популярные функции активации",
    "text": "Для начала поговорим о том, зачем они нужны. Казалось бы, можно последовательно выстраивать лишь линейные слои, но так не делают: после каждого линейного слоя обязательно вставляют функцию активации. Но зачем? Попробуем разобраться. Рассмотрим нейронную сеть из двух линейных слоёв. Что произойдёт, если между ними будет отсутствовать нелинейная функция активации? Линейная комбинация линейных отображений есть линейное отображение, то есть два последовательных линейных слоя эквивалентны одному линейному слою. Добавление функций активации после линейного слоя позволяет получить нелинейное преобразование, и подобной проблемы уже не возникает. Вдобавок правильный выбор функции активации позволяет получить преобразование, обладающее подходящими свойствами. В качестве функции активации может использоваться, например, уже знакомая вам из логистической регрессии сигмоидаили ReLU (Rectified linear unit). К более глубокому рассмотрению разновидностей и свойств различных функций активации вернёмся позднее. Примечание. На самом деле бывают ситуации, когда два линейных слоя подряд — это полезно. Например, если вы понимаете, что у вас очень много параметров, а информации в данных не так много, вы можете заменить линейный слой, превращающий-мерные векторы в-мерные, на два, вставив посередине-мерное представление, где: С точки зрения линейной алгебры это примерно то же самое, что потребовать, чтобы матрица исходного линейного слоя имела ранг не выше. И с точки зрения сужения «информационного канала» это иногда может сработать. Но в любом случае вы должны понимать, что два линейных слоя подряд стоит ставить, только если вы хорошо понимаете, чего хотите добиться. Вернёмся к функциям активации. Вот наиболее популярные: Рассмотрим их подробнее. Формула: ReLU это простая кусочно-линейная функция. Одна из наиболее популярных функций активации. В нуле производная доопределяется нулевым значением. Плюсы: простота вычисления активации и производной. Минусы: область значений является смещённой относительно нуля; для отрицательных значений производная равна нулю, что может привести к затуханию градиента. ReLU и её производная очень просты для вычисления: достаточно лишь сравнить значение с нулём. Благодаря этому использование ReLU позволяет достигать прироста в скорости до четырёх-шести раз относительно сигмоиды. Формула: Гиперпараметробеспечивает небольшой уклон слева от нуля, что позволяет получить более симметричную относительно нуля область значений. Также меньше провоцирует затухание градиента благодаря наличию ненулевого градиента и слева, и справа от нуля. Формула: Аналогична Leaky ReLU, но параметрнастраивается градиентными методами. ELU – это гладкая аппроксимация ReLU. Обладает более высокой вычислительной сложностью, достаточно редко используется на практике. Формула: Исторически одна из первых функций активации. Рассматривалась в том числе и как гладкая аппроксимация порогового правила, эмулирующая активацию естественного нейрона. Плюсы: Минусы: область значений смещена относительно нуля; сигмоида (как и её производная) требует вычисления экспоненты, что является достаточно сложной вычислительной операцией. Её приближённое значение вычисляется на основе ряда Тейлора или с помощью полиномов, Stack Overflowquestion 1,question 2; на «хвостах» обладает практически нулевой производной, что может привести к затуханию градиента; максимальное значение производной составляет, что также приводит к затуханию градиента. На практике сигмоида редко используется внутри сетей, чаще всего в случаях, когда внутри модели решается задача бинарной классификации (например, вероятность забывания информации в LSTM). Формула: Плюсы: как и сигмоида, имеет ограниченную область значений; в отличие от сигмоиды, область значений симметрична. Минусы: требует вычисления экспоненты, что является достаточно сложной вычислительной операцией; на «хвостах» обладает практически нулевой производной, что может привести к затуханию градиента. Вопрос на подумать. А почему симметричность области значений может быть ценным свойством?",
    "source_type": null,
    "useful_links": [
      {
        "text": "question 1",
        "url": "https://stackoverflow.com/questions/53419270/how-does-numpy-compute-an-exponential"
      },
      {
        "text": "question 2",
        "url": "https://stackoverflow.com/questions/9799041/efficient-implementation-of-natural-logarithm-ln-and-exponentiation"
      }
    ]
  },
  {
    "document_title": "Первое знакомство с полносвязными нейросетями",
    "url": "https://education.yandex.ru/handbook/ml/article/pervoe-znakomstvo-s-polnosvyaznymi-nejrosetyami",
    "section_title": "Немного о мощи нейросетей",
    "text": "Рассмотрим для начала задачу регрессии. Ясно, что линейная модель (то есть однослойная нейросеть) может приблизить только линейную функцию, но уже двухслойная нейросеть может приблизить почти что угодно. Есть ряд теорем на эту тему, мы упомянем одну из них. Обратите внимание на год: как мы уже упоминали, нейросети начали серьёзно изучать задолго до того, как они начали превращаться в state of the art. Теорема Цыбенко (1989).Для любой непрерывной функциии для любогонайдётся число, а также числа,, для которых для любыхиз единичного кубав. В сумме из теоремы Цыбенко легко опознать двуслойную нейросеть с сигмоидной функцией активации. В самом деле, сперва мы превращаемв— это можно представить в виде одной матричной операции (линейный слой!): где— вектор-столбцы, а каждое изприбавляется к-му столбцу, после чего поэлементно берём отсигмоиду (активация), после чего вычисляем и это второй линейный слой (без свободного члена). Правда, теорема не очень помогает находить такие функции, но это уже другое дело. В любом случае — если дать нейросети достаточно данных, она действительно может выучить почти что угодно. Упражнение.Мы не будем приводить результатов, касающихся классификации, но рекомендуем воспользоваться замечательнойпесочницей. Убедитесь сами, что при использовании одного скрытого слоя из двух нейронов и сигмоиды в качестве функции активации, можно неплохо классифицировать данные со сложной, совсем даже не линейной границей между классами. Вы также можете поиграть с разными функциями активации. А для получения решения нам необходим метод автоматической настройки всех параметров нейронной сети —метод обратного распространения ошибки, или жеerror backpropagation. Рассмотрим его в деталях в следующем параграфе.",
    "source_type": null,
    "useful_links": [
      {
        "text": "песочницей",
        "url": "https://playground.tensorflow.org"
      }
    ]
  },
  {
    "document_title": "Метод обратного распространения ошибки",
    "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
    "section_title": "Метод обратного распространения ошибки (backward propagation)",
    "text": "Открытие метода обратного распространения ошибки стало одним из наиболее значимых событий в области искусственного интеллекта. В актуальном виде он былпредложенв 1986 году Дэвидом Э. Румельхартом, Джеффри Э. Хинтоном и Рональдом Дж. Вильямсом, а также независимо и одновременно красноярскими математиками С. И. Барцевым и В. А. Охониным. С тех пор для нахождения градиентов параметров нейронной сети используется метод вычисления производной сложной функции, и оценка градиентов параметров сети стала хоть и сложной инженерной задачей, но уже не искусством. Несмотря на простоту используемого математического аппарата, появление этого метода привело к значительному скачку в развитии искусственных нейронных сетей. Суть метода можно записать одной формулой, тривиально следующей из формулы производной сложной функции: если, то. Уже сейчас мы видим, что градиенты можно вычислять последовательно, в ходе одного обратного прохода, начиная си умножая каждый раз на частные производные предыдущего слоя.",
    "source_type": null,
    "useful_links": [
      {
        "text": "предложен",
        "url": "https://web.stanford.edu/class/psych209a/ReadingsByDate/02_06/PDPVolIChapter8.pdf"
      }
    ]
  },
  {
    "document_title": "Метод обратного распространения ошибки",
    "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
    "section_title": "Backward propagation в одномерном случае",
    "text": "В одномерном случае всё выглядит особенно просто. Пусть— переменная, по которой мы хотим продифференцировать , причём сложная функция имеет вид где всескалярные. Тогда Суть этой формулы такова. Если мы уже совершили прямой проход (forward propagation), значит мы уже знаем Поэтому мы можем действовать следующим образом: берём производнуюв точке; умножаем на производнуюв точке; и так далее, пока не дойдём до производнойв точке. Проиллюстрируем это на картинке, расписав по шагам дифференцирование по весамфункции потерь логистической регрессии на одном объекте (то есть для батча размера 1): Собирая все множители вместе, получаем: Таким образом, сперва совершается forward propagation для вычисления всех промежуточных значений (да, все промежуточные представления нужно будет хранить в памяти), а потом запускается backward propagation, на котором в один проход вычисляются все градиенты.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метод обратного распространения ошибки",
    "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
    "section_title": "Почему же нельзя просто пойти и начать везде вычислять производные?",
    "text": "В параграфе, посвящённомматричным дифференцированиям, мы поднимаем вопрос о том, что вычислять частные производные по отдельности — это зло, лучше пользоваться матричными вычислениями. Но есть и ещё одна причина: даже и с матричной производной в принципе не всегда хочется иметь дело. Рассмотрим простой пример. Допустим, чтои— два последовательных промежуточных представленияи, связанных функцией. Предположим, что мы как-то посчитали производнуюфункции потерь, тогда И мы видим, что, хотя оба градиентаи— это просто матрицы, в ходе вычислений возникает «четырёхмерный кубик». Его болезненно даже хранить: уж больно много памяти он требует —мпо сравнению с безобидными, требуемыми для хранения градиентов. Поэтому хочется промежуточные производныерассматривать не как вычисляемые объекты, а как преобразования, которые превращаютв. Целью следующих параграфов будет именно это: понять, как преобразуется градиент в ходе error backward propagation при переходе через тот или иной слой. Вы спросите себя: надо ли мне сейчас пойти и прочитать параграф учебника про матричное дифференцирование? Короткий ответ: Зависит от ваших знаний. Длинный ответ: Найдите производную функции по вектору: А как всё поменяется, еслитоже зависит от? Чему равен градиент функции, еслиявляется скаляром? Если вы готовы прямо сейчас взять ручку и бумагу и посчитать всё, то вам, вероятно, не надо читать про матричные дифференцирования. Но мы советуем всё-таки заглянуть в этот параграф, если обозначения, которые мы будем дальше использовать, покажутся вам непонятными: единой нотации для матричных дифференцирований человечество пока, увы, не изобрело, и переводить с одной на другую не всегда легко. А мы же сразу перейдём к интересующей нас вещи: к вычислению градиентов сложных функций.",
    "source_type": null,
    "useful_links": [
      {
        "text": "матричным дифференцированиям",
        "url": "https://academy.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie"
      }
    ]
  },
  {
    "document_title": "Метод обратного распространения ошибки",
    "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
    "section_title": "Градиент сложной функции",
    "text": "Напомним, что формула производной сложной функции выглядит следующим образом: Теперь разберёмся с градиентами. Пусть– скалярная функция. Тогда С другой стороны, То есть— применение сопряжённого клинейного отображения к вектору. Эта формула — сердце механизма обратного распространения ошибки. Она говорит следующее: если мы каким-то образом получили градиент функции потерь по переменным из некоторого промежуточного представлениянейронной сети и при этом знаем, как преобразуется градиент при проходе через слоймеждуи(то есть как выглядит сопряжённое к дифференциалу слоя между ними отображение), то мы сразу же находим градиент и по переменным из: Таким образом слой за слоем мы посчитаем градиенты по всемвплоть до самых первых слоёв. Далее мы разберёмся, как именно преобразуются градиенты при переходе через некоторые распространённые слои.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метод обратного распространения ошибки",
    "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
    "section_title": "Градиенты для типичных слоёв",
    "text": "Рассмотрим несколько важных примеров. , где— вектор, а– поэлементное применение: Тогда, как мы знаем, Следовательно, гдеозначает поэлементное перемножение. Окончательно получаем Отметим, что еслии— это просто векторы, то мы могли бы вычислять всё и по формуле. В этом случае матрицабыла бы диагональной (так какзависит только от: ведьберётся поэлементно), и матричное умножение приводило бы к тому же результату. Однако еслии— матрицы, топредставлялась бы уже «четырёхмерным кубиком», и работать с ним было бы ужасно неудобно. , гдеи— матрицы. Как мы знаем, Тогда Здесь черезмы обозначили отображение, а в предпоследнем переходе использовалось следующее свойство следа: где— произвольные матрицы подходящих размеров (то есть допускающие перемножение в обоих приведённых порядках). Следовательно, получаем , гдеи— матрицы. Для приращенияимеем Тогда Здесь черезобозначено отображение. Значит, , где— матрица, а— функция, которая вычисляется построчно, причём для каждой строки: В этом примере нам будет удобно воспользоваться формализмом с частными производными. Сначала вычислимдля одной строки, где черезмы для краткости обозначим. Нетрудно проверить, что Так как softmax вычисляется независимо от каждой строчки, то где черезмы обозначили для краткости. Теперь пусть(пришедший со следующего слоя, уже известный градиент). Тогда Так какпри, мы можем убрать суммирование по: Таким образом, если мы хотим продифференцироватьв какой-то конкретной точке, то, смешивая математические обозначения с нотацией Python, мы можем записать:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метод обратного распространения ошибки",
    "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
    "section_title": "Backward propagation в общем виде",
    "text": "Подытожим предыдущее обсуждение, описав алгоритмerror backward propagation(алгоритм обратного распространения ошибки). Допустим, у нас есть текущие значения весови мы хотим совершить шаг SGD по мини-батчу. Мы должны сделать следующее: Совершить forward propagation, вычислив и запомнив все промежуточные представления. Вычислить все градиенты с помощью backward propagation. С помощью полученных градиентов совершить шаг SGD. Проиллюстрируем алгоритм на примере двухслойной нейронной сети со скалярным output. Для простоты опустим свободные члены в линейных слоях. Итого матрица, как и Итого, как и Схематически это можно представить следующим образом: Если вы не уследили за вычислениями в предыдущем примере, давайте более подробно разберём его чуть более конкретную версию (для) Рассмотрим двуслойную нейронную сеть для классификации. Мы уже встречали её ранее при рассмотрении линейно неразделимой выборки. Предсказания получаются следующим образом: Пустьи— текущее приближение матриц весов. Мы хотим совершить шаг по градиенту функции потерь, и для этого мы должны вычислить её градиенты поив точке. Прежде всего мы совершаем forward propagation, в ходе которого мы должны запомнить все промежуточные представления:,,,. Они понадобятся нам дальше. Для полученных предсказаний вычисляется значение функции потерь: Дальше мы шаг за шагом будем находить производные по переменным из всё более глубоких слоёв. Градиентпо предсказаниям имеет видгде, напомним,(обратите внимание на то, чтоитут именно те, из которых мы делаем градиентный шаг). Следующий слой — поэлементное взятие. Как мы помним, при переходе через него градиент поэлементно умножается на производную, в которую подставлено предыдущее промежуточное представление:Аналогичным образом Следующий слой — снова взятие. Наконец, последний слой — это умножениена. Тут мы дифференцируем только по: Итоговые формулы для градиентов получились страшноватыми, но они были получены друг из друга итеративно с помощью очень простых операций: матричного и поэлементного умножения, в которые порой подставлялись значения заранее вычисленных промежуточных представлений.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метод обратного распространения ошибки",
    "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
    "section_title": "Автоматизация и autograd",
    "text": "Итак, чтобы нейросеть обучалась, достаточно для любого слояс параметрамиуметь: превращатьв(градиент по выходу в градиент по входу); считать градиент по его параметрам. При этом слою совершенно не надо знать, что происходит вокруг. То есть слой действительно может быть запрограммирован как отдельная сущность, умеющая внутри себя делать forward propagation и backward propagation, после чего слои механически, как кубики в конструкторе, собираются в большую сеть, которая сможет работать как одно целое. Более того, во многих случаях авторы библиотек для глубинного обучения уже о вас позаботились и создали средства дляавтоматического дифференцирования выражений(autograd). Поэтому, программируя нейросеть, вы почти всегда можете думать только о forward-проходе, прямом преобразовании данных, предоставив библиотеке дифференцировать всё самостоятельно. Это делает код нейросетей весьма понятным и выразительным (да, в реальности он тоже бывает большим и страшным, но сравните на досуге код какой-нибудь разухабистой нейросети и код градиентного бустинга на решающих деревьях и почувствуйте разницу).",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метод обратного распространения ошибки",
    "url": "https://education.yandex.ru/handbook/ml/article/metod-obratnogo-rasprostraneniya-oshibki",
    "section_title": "Но это лишь начало",
    "text": "Метод обратного распространения ошибки позволяет удобно посчитать градиенты, но дальше с ними что-то надо делать, и старый добрый SGD едва ли справится с обучением современной сетки. Так что же делать? О некоторых приёмах мы расскажем в следующем параграфе.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метрики классификации и регрессии",
    "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
    "section_title": "Выбор метрик в реальных задачах",
    "text": "Возможно, вы уже участвовали в соревнованиях по анализу данных. На таких соревнованияхметрику(критерий качества модели) организатор выбирает за вас, и она, как правило, довольно понятным образом связана с результатами предсказаний. Но на практике всё бывает намного сложнее. Например, мы хотим: решить, сколько коробок с бананами нужно завтра привезти в конкретный магазин — чтобы предложение соответствовало спросу, и не пришлось выбрасывать излишки; увеличить счастье пользователя от работы с сервисом, чтобы он стал лояльным и приносил стабильный прогнозируемый доход; решить, нужно ли направить человека на дополнительное обследование. В каждом конкретном случае может возникать целая иерархия метрик. Представим, например, что речь идёт о стриминговом музыкальном сервисе, пользователей которого мы решили порадовать сгенерированными самодельной нейросетью треками — не защищёнными авторским правом, а потому совершенно бесплатными. Иерархия метрик могла бы иметь такой вид: Самый верхний уровень: будущий доход сервиса — невозможно измерить в моменте, сложным образом зависит от совокупности всех наших усилий; Медианная длина сессии, возможно, служащая оценкой радости пользователей, которая, как мы надеемся, повлияет на их желание продолжать платить за подписку — её нам придётся измерять в продакшене, ведь нас интересует реакция настоящих пользователей на новшество; Доля удовлетворённых качеством сгенерированной музыки асессоров, на которых мы потестируем её до того, как выставить на суд пользователей; Функция потерь, на которую мы будем обучать генеративную сеть. На этом примере мы можем заметить сразу несколько общих закономерностей. Во-первых, метрики бываютofflineиonline(оффлайновымиионлайновыми). Online-метрики вычисляются по данным, собираемым с работающей системы (например, медианная длина сессии). Offline-метрики могут быть измерены до введения модели в эксплуатацию, например, по историческим данным или с привлечением специальных людей, асессоров. Последнее часто применяется, когда метрика — это реакция живого человека: скажем, так поступают поисковые компании, которые предлагают людям оценить качество ранжирования экспериментальной системы ещё до того, как рядовые пользователи увидят эти результаты в обычном порядке. На самом же нижнем этаже иерархии лежат оптимизируемые в ходе обучения функции потерь. В данном разделе нас будут интересовать offline-метрики, которые могут быть измерены без привлечения людей.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метрики классификации и регрессии",
    "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
    "section_title": "Функция потерьметрика качества",
    "text": "Как мы узнали ранее, методы обучения реализуют разные подходы к обучению: обучение на основе прироста информации (как в деревьях решений); обучение на основе сходства (как в методах ближайших соседей); обучение на основе вероятностной модели данных (например, максимизацией правдоподобия); обучение на основе ошибок (минимизация эмпирического риска). И в рамках обучения на основе минимизации ошибок мы уже отвечали на вопрос: как можно штрафовать модель за предсказание на обучающем объекте. Во время сведения задачи о построении решающего правила к задаче численной оптимизации, мы вводили понятие функции потерь и, обычно, объявляли целевой функцией сумму потерь от предсказаний на всех объектах обучающей выборки. Важно понимать разницу между функцией потерь и метрикой качества. Её можно сформулировать следующим образом: Функция потерь возникает в тот момент, когда мы сводим задачу построения модели к задаче оптимизации. Обычно требуется, чтобы она обладала хорошими свойствами (например, дифференцируемостью). Метрика — внешний, объективный критерий качества, обычно зависящий не от параметров модели, а только от предсказанных меток. В некоторых случаях метрика может совпадать с функцией потерь. Например, в задаче регрессии MSE играют роль как функции потерь, так и метрики. Но, скажем, в задаче бинарной классификации они почти всегда различаются: в качестве функции потерь может выступать кросс-энтропия, а в качестве метрики —число верно угаданных меток(accuracy). Отметим, что в последнем примере у них различные аргументы: на вход кросс-энтропии нужно подавать логиты, а на вход accuracy — предсказанные метки (то есть по сути argmax логитов).",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метрики классификации и регрессии",
    "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
    "section_title": "Бинарная классификация: метки классов",
    "text": "Перейдём к обзору метрик и начнём с самой простой разновидности классификации — бинарной, а затем постепенно будем наращивать сложность. Напомним постановку задачи бинарной классификации: нам нужно по обучающей выборке, гдепостроить модель, которая по объектупредсказывает метку класса. Первый критерий качества, который приходит в голову, —accuracy, то есть доля объектов, для которых мы правильно предсказали класс: Или же сопряженная ей метрика —доля ошибочных классификаций(error rate): Познакомившись чуть внимательнее с этой метрикой, можно заметить, что у неё есть несколько недостатков: она не учитывает дисбаланс классов. Например, в задаче диагностики редких заболеваний классификатор, предсказывающий всем пациентам отсутствие болезни будет иметь достаточно высокую accuracy просто потому, что больных людей в выборке намного меньше; она также не учитывает цену ошибки на объектах разных классов. Для примера снова можно привести задачу медицинской диагностики: если ошибочный положительный диагноз для здорового больного обернётся лишь ещё одним обследованием, то ошибочно отрицательный вердикт может повлечь роковые последствия. Исторически задача бинарной классификации — это задача об обнаружении чего-то редкого в большом потоке объектов, например, поиск человека, больного туберкулёзом, по флюорографии. Или задача признания пятна на экране приёмника радиолокационной станции бомбардировщиком, представляющем угрозу охраняемому объекту (в противовес стае гусей). Поэтому класс, который представляет для нас интерес, называется «положительным», а оставшийся — «отрицательным». Заметим, что для каждого объекта в выборке возможно 4 ситуации: мы предсказалиположительнуюметку иугадали. Будет относить такие объекты кtrue positive(TP) группе. True — потому что предсказали мы правильно, а positive — потому что предсказали положительную метку; мы предсказалиположительнуюметку, ноошиблисьв своём предсказании —false positive(FP). False, потому что предсказание было неправильным; мы предсказалиотрицательнуюметку иугадали—true negative(TN); и наконец, мы предсказалиотрицательнуюметку, ноошиблись—false negative(FN).Для удобства все эти 4 числа изображают в виде таблицы, которую называютconfusion matrix(матрицей ошибок): Не волнуйтесь, если первое время эти обозначения будут сводить вас с ума (будем откровенны, даже профи со стажем в них порой путаются), однако логика за ними достаточно простая: первая часть названия группы показывает угадали ли мы с классом, а вторая — какой класс мы предсказали. Пример Попробуем воспользоваться введёнными метриками в боевом примере: сравним работу нескольких моделей классификации наBreast cancer wisconsin (diagnostic) dataset. Объекты выборки — фотографии биопсии грудных опухолей. С их помощью было сформировано признаковое описание, которое заключается в характеристиках ядер клеток (таких как радиус ядра, его текстура, симметричность). Положительным классом в такой постановке будут злокачественные опухоли, а отрицательным — доброкачественные. Модель 1. Константное предсказание Решение задачи начнём с самого простого классификатора, который выдаёт на каждом объекте константное предсказание — самый часто встречающийся класс. Скопировать код1fromsklearn.datasets2importload_breast_cancer3the_data = load_breast_cancer()45# 0 — «доброкачественный»6# 1 — «злокачественный»7relabeled_target =1- the_data[\"target\"]89fromsklearn.model_selectionimporttrain_test_split10X = the_data[\"data\"]11y = relabeled_target12X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)1314fromsklearn.dummyimportDummyClassifier15dc_mf = DummyClassifier(strategy=\"most_frequent\")16dc_mf.fit(X_train, y_train)1718fromsklearn.metricsimportconfusion_matrix19y_true = y_test y_pred = dc_mf.predict(X_test)20dc_mf_tn, dc_mf_fp, dc_mf_fn, dc_mf_tp = confusion_matrix(y_true, y_pred, labels = [0,1]).ravel() Обучающие данные таковы, что наш dummy-классификатор все объекты записывает в отрицательный класс, то есть признаёт все опухоли доброкачественными. Такой наивный подход позволяет нам получить минимальный штраф за FP (действительно, нельзя ошибиться в предсказании, если положительный класс вообще не предсказывается), но и максимальный штраф за FN (в эту группу попадут все злокачественные опухоли). Модель 2. Случайный лес. Настало время воспользоваться всем арсеналом моделей машинного обучения, и начнём мы со случайного леса. Скопировать код1fromsklearn.ensembleimportRandomForestClassifier2rfc = RandomForestClassifier()3rfc.fit(X_train, y_train)4y_true = y_test5y_pred = rfc.predict(X_test)6rfc_tn, rfc_fp, rfc_fn, rfc_tp = confusion_matrix(y_true, y_pred, labels = [0,1]).ravel() Можно сказать, что этот классификатор чему-то научился, так как главная диагональ матрицы стала содержать все объекты из отложенной выборки, за исключением 4 + 1 = 5 объектов (сравните с 0 + 53 объектами dummy-классификатора, все опухоли объявляющего доброкачественными). Отметим, что вычисляя долю недиагональных элементов, мы приходим к метрикеerror rate, о которой мы говорили в самом начале: тогда как доля объектов, попавших на главную диагональ — это как раз таки accuracy: Модель 3. Метод опорных векторов. Давайте построим еще один классификатор на основе линейного метода опорных векторов. Важно: Не забудьте привести признаки к единому масштабу, иначе численный алгоритм не сойдется к решению и мы получим гораздо более плохо работающее решающее правило. Попробуйте проделать это упражнение. Скопировать код1fromsklearn.svmimportLinearSVC2fromsklearn.preprocessingimportStandardScaler3ss = StandardScaler() ss.fit(X_train)4scaled_linsvc = LinearSVC(C=0.01,random_state=42)5scaled_linsvc.fit(ss.transform(X_train), y_train)6y_true = y_test7y_pred = scaled_linsvc.predict(ss.transform(X_test))8tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels = [0,1]).ravel() Сравним результаты Легко заметить, что каждая из двух моделей лучше классификатора-пустышки, однако давайте попробуем сравнить их между собой. С точки зренияerror rateмодели практически одинаковы: 5/143 для леса против 4/143 для SVM. Посмотрим на структуру ошибок чуть более внимательно: лес — (FP = 4, FN = 1), SVM — (FP = 1, FN = 3). Какая из моделей предпочтительнее? Замечание: Мы сравниваем несколько классификаторов на основании их предсказаний на отложенной выборке. Насколько ошибки данных классификаторов зависят от разбиения исходного набора данных? Иногда в процессе оценки качества мы будем получать модели, чьи показатели эффективности будут статистически неразличимыми. Пусть мы учли предыдущее замечание и эти модели действительно статистически значимо ошибаются в разную сторону. Мы встретились с очевидной вещью: на матрицах нет отношения порядка. Когда мы сравнивали dummy-классификатор и случайный лес с помощью Accuracy, мы всю сложную структуру ошибок свели к одному числу, так как на вещественных числах отношение порядка есть. Сводить оценку модели к одному числу очень удобно, однако не стоит забывать, что у вашей модели есть много аспектов качества. Что же всё-таки важнее уменьшить: FP или FN? Вернёмся к задаче: FP — доля доброкачественных опухолей, которым ошибочно присваивается метка злокачественной; FN — доля злокачественных опухолей, которые классификатор пропускает. В такой постановке становится понятно, что при сравнении выиграет модель с меньшим FN (то есть лес в нашем примере), ведь каждая не обнаруженная опухоль может стоить человеческой жизни. Рассмотрим теперь другую задачу: по данным о погоде предсказать, будет ли успешным запуск спутника. FN в такой постановке — это ошибочное предсказание неуспеха, то есть не более, чем упущенный шанс (если вас, конечно не уволят за срыв сроков). С FP всё серьёзней: если вы предскажете удачный запуск спутника, а на деле он потерпит крушение из-за погодных условий, то ваши потери будут в разы существеннее. Итак, из примеров мы видим, что в текущем виде введенная намидоля ошибочных классификацийне даст нам возможности учесть неравную важность FP и FN. Поэтому введем две новые метрики: точность и полноту. Accuracy - это метрика, которая характеризует качество модели, агрегированное по всем классам. Это полезно, когда классы для нас имеют одинаковое значение. В случае, если это не так, accuracy может быть обманчивой. Рассмотрим ситуацию, когда положительный класс это событие редкое. Возьмем в качестве примера поисковую систему - в нашем хранилище хранятся миллиарды документов, а релевантных к конкретному поисковому запросу на несколько порядков меньше. Пусть мы хотим решить задачу бинарной классификации «документ d релевантен по запросу q». Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что, и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называетсяточностью (precision) Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называетсяполнотой (recall) Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит названиеF1-меры (F1-measure). Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоватьсямерой:",
    "source_type": null,
    "useful_links": [
      {
        "text": "Breast cancer wisconsin (diagnostic) dataset",
        "url": "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)"
      }
    ]
  },
  {
    "document_title": "Метрики классификации и регрессии",
    "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
    "section_title": "Бинарная классификация: вероятности классов",
    "text": "Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемыекалибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные предсказания и разное качество на отложенной выборке. Так, чем ниже порог отсечения, тем больше объектов модель будет относить к положительному классу. Как в этом случае оценить качество модели? Пусть мы хотим учитывать ошибки на объектах обоих классов. При уменьшении порога отсечения мы будем находить (правильно предсказывать) всё большее число положительных объектов, но также и неправильно предсказывать положительную метку на всё большем числе отрицательных объектов. Естественным кажется ввести две метрикиTPRиFPR: TPR(true positive rate) — это полнота, доля положительных объектов, правильно предсказанных положительными: FPR(false positive rate) — это доля отрицательных объектов, неправильно предсказанных положительными: Обе эти величины растут при уменьшении порога. Кривая в осях TPR/FPR, которая получается при варьировании порога, исторически называетсяROC-кривой(receiver operating characteristics curve, сокращённоROC curve). Следующийинтерактивный графикпоможет вам понять поведение ROC-кривой. Желтая и синяя кривые показывают распределение предсказаний классификатора на объектах положительного и отрицательного классов соответственно. То есть значения на оси X (на графике с двумя гауссианами) мы получаем из классификатора. Если классификатор идеальный, — две кривые разделимы по оси X, — то на правом графике мы получаем ROC-кривую (0,0)->(0,1)->(1,1), площадь под которой равна 1. Если классификатор случайный (предсказывает одинаковые метки положительным и отрицательным объектам), то мы получаем ROC-кривую (0,0)->(1,1), площадь под которой равна 0.5. Поэкспериментируйте с разными вариантами распределения предсказаний по классам и посмотрите, как меняется ROC-кривая. Чем лучше классификатор разделяет два класса, тем больше площадь (area under curve) под ROC-кривой — и мы можем использовать её в качестве метрики. Эта метрика называетсяAUCи она работает благодаря следующему свойству ROC-кривой: AUCравен доле пар объектов вида (объект класса 1, объект класса 0), которые алгоритм верно упорядочил, то есть предсказание классификатора на первом объекте больше: Чтобы детальнее разобраться, почему это так, советуем вам обратиться кматериалам А.Г.Дьяконова. В каких случаях лучше отдать предпочтение этой метрике? Рассмотрим следующую задачу: некоторый сотовый оператор хочет научиться предсказывать, будет ли клиент пользоваться его услугами через месяц. На первый взгляд кажется, что задача сводится к бинарной классификации с метками 1, если клиент останется с компанией и— иначе. Однако если копнуть глубже в процессы компании, то окажется, что такие метки практически бесполезны. Компании скорее интересно упорядочить клиентов по вероятности прекращения обслуживания и в зависимости от этого применять разные варианты удержания: кому-то прислать скидочный купон от партнёра, кому-то предложить скидку на следующий месяц, а кому-то и новый тариф на особых условиях. Таким образом, в любой задаче, где нам важна не метка сама по себе, а правильный порядок на объектах, имеет смысл применять AUC. Утверждение выше может вызывать у вас желание использовать AUC в качестве метрики в задачах ранжирования, но мы призываем вас быть аккуратными. Будем постепенно уменьшать порог бинаризации. При этом полнота будет расти отдо, так как будет увеличиваться количество объектов, которым мы приписываем положительный класс (а количество объектов, на самом деле относящихся к положительному классу, очевидно, меняться не будет). Про точность же нельзя сказать ничего определённого, но мы понимаем, что скорее всего она будет выше при более высоком пороге отсечения (мы оставим только объекты, в которых модель «уверена» больше всего). Варьируя порог и пересчитывая значения Precision и Recall на каждом пороге, мы получим некоторую кривую примерно следующего вида: Рассмотрим среднее значение точности (оно равно площади под кривой точность-полнота): Получим показатель эффективности, который называетсяaverage precision. Как в случае матрицы ошибок мы переходили к скалярным показателям эффективности, так и в случае с кривой точность-полнота мы охарактеризовали ее в виде числа.",
    "source_type": null,
    "useful_links": [
      {
        "text": "калибровкой классификатора",
        "url": "https://academy.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti"
      },
      {
        "text": "интерактивный график",
        "url": "https://yastatic.net/s3/academy/ml/roc_auc/roc.html"
      },
      {
        "text": "материалам А.Г.Дьяконова",
        "url": "https://dyakonov.org/2017/07/28/auc-roc-%D0%BF%D0%BB%D0%BE%D1%89%D0%B0%D0%B4%D1%8C-%D0%BF%D0%BE%D0%B4-%D0%BA%D1%80%D0%B8%D0%B2%D0%BE%D0%B9-%D0%BE%D1%88%D0%B8%D0%B1%D0%BE%D0%BA/"
      }
    ]
  },
  {
    "document_title": "Метрики классификации и регрессии",
    "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
    "section_title": "Многоклассовая классификация",
    "text": "Если классов становится больше двух, расчёт метрик усложняется. Если задача классификации наклассов ставится какзадач об отделении классаот остальных (), то для каждой из них можно посчитать свою матрицу ошибок. Затем есть два варианта получения итогового значения метрики изматриц ошибок: Усредняем элементы матрицы ошибок (TP, FP, TN, FN) между бинарными классификаторами, например. Затем по одной усреднённой матрице ошибок считаем Precision, Recall, F-меру. Это называютмикроусреднением. Считаем Precision, Recall для каждого классификатора отдельно, а потом усредняем. Это называютмакроусреднением. Порядок усреднения влияет на результат в случае дисбаланса классов. Показатели TP, FP, FN — это счётчики объектов. Пусть некоторый класс обладает маленькой мощностью (обозначим её). Тогда значения TP и FN при классификации этого класса против остальных будут не больше, то есть тоже маленькие. Про FP мы ничего уверенно сказать не можем, но скорее всего при дисбалансе классов классификатор не будет предсказывать редкий класс слишком часто, потому что есть большая вероятность ошибиться. Так что FP тоже мало. Поэтому усреднение первым способом сделает вклад маленького класса в общую метрику незаметным. А при усреднении вторым способом среднее считается уже для нормированных величин, так что вклад каждого класса будет одинаковым. Рассмотрим пример. Пусть есть датасет из объектов трёх цветов: желтого, зелёного и синего. Желтого и зелёного цветов почти поровну — 21 и 20 объектов соответственно, а синих объектов всего 4. Модель по очереди для каждого цвета пытается отделить объекты этого цвета от объектов оставшихся двух цветов. Результаты классификации проиллюстрированы матрицей ошибок. Модель «покрасила» в жёлтый 25 объектов, 20 из которых были действительно жёлтыми (левый столбец матрицы). В синий был «покрашен» только один объект, который на самом деле жёлтый (средний столбец матрицы). В зелёный — 19 объектов, все на самом деле зелёные (правый столбец матрицы). Посчитаем Precision классификации двумя способами: С помощью микроусреднения получаем С помощью макроусреднения получаем Видим, что макроусреднение лучше отражает тот факт, что синий цвет, которого в датасете было совсем мало, модель практически игнорирует.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метрики классификации и регрессии",
    "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
    "section_title": "Как оптимизировать метрики классификации?",
    "text": "Пусть мы выбрали, что метрика качества алгоритма будет. Тогда мы хотим обучить модель так, чтобына валидационной выборке была минимальная/максимальная. Лучший способ добиться минимизации метрики— оптимизировать её напрямую, то есть выбрать в качестве функции потерь ту же. К сожалению, это не всегда возможно. Рассмотрим, как оптимизировать метрики иначе. Метрики precision и recall невозможно оптимизировать напрямую, потому что эти метрики нельзя рассчитать на одном объекте, а затем усреднить. Они зависят от того, какими были правильная метка класса и ответ алгоритма на всех объектах. Чтобы понять, как оптимизировать precision, recall, рассмотрим, как расчитать эти метрики на отложенной выборке.Пусть модель обучена на стандартную для классификации функцию потерь (LogLoss). Для получения меток класса специалист по машинному обучению сначала применяет на объектах модель и получает вещественные предсказания модели (). Затем предсказания бинаризуются по порогу, выбранному специалистом: если предсказание на объекте больше порога, то метка класса 1 (или «положительная»), если меньше — 0 (или «отрицательная»). Рассмотрим, что будет с метриками precision, recall в крайних положениях порога. Пусть порог равен нулю Тогда всем объектам будет присвоена положительная метка. Следовательно, все объекты будут либо TP, либо FP, потому что отрицательных предсказаний нет,, где— размер выборки. Также все объекты, у которых метка на самом деле 1, попадут в TP. По формуле точностьравна среднему таргету в выборке. А полнотаравна единице. Пусть теперь порог равен единице Тогда ни один объект не будет назван положительным,. Все объекты с меткой класса 1 попадут в FN. Если есть хотя бы один такой объект, то есть, будет верна формула. То есть при пороге единица, полнота равна нулю. Теперь посмотрим на точность. Формула для Precision состоит только из счётчиков положительных ответов модели (TP, FP). При единичном пороге они оба равны нулю,то есть при единичном пороге точность неопределена. Пусть мы отступили чуть-чуть назад по порогу, чтобы хотя бы несколько объектов были названы моделью положительными. Скорее всего это будут самые «простые» объекты, которые модель распознает хорошо, потому что её предсказание близко к единице. В этомпредположении. Тогда точностьбудет близка к единице. Изменяя порог, между крайними положениями, получим графики Precision и Recall, которые выглядят как-то так: Recall меняется от единицы до нуля, а Precision от среднего тагрета до какого-то другого значения (нет гарантий, что график монотонный). Итого оптимизация precision и recall происходит так: Модель обучается на стандартную функцию потерь (например, LogLoss). Используя вещественные предсказания на валидационной выборке, перебирая разные пороги от 0 до 1, получаем графики метрик в зависимости от порога. Выбираем нужное сочетание точности и полноты. Пусть теперь мы хотим максимизировать метрикуAUC. Стандартный метод оптимизации, градиентный спуск, предполагает, что функция потерь дифференцируема. AUC этим качеством не обладает, то есть мы не можем оптимизировать её напрямую. Поэтому для метрики AUC приходится изменять оптимизационную задачу. Метрика AUC считает долю верно упорядоченных пар. Значит от исходной выборки можно перейти к выборке упорядоченных пар объектов. На этой выборке ставится задача классификации: метка класса 1 соответствует правильно упорядоченной паре, 0 — неправильно. Новой метрикой становится accuracy — доля правильно классифицированных объектов, то есть доля правильно упорядоченных пар. Оптимизировать accuracy можно по той же схеме, что и precision, recall: обучаем модель на LogLoss и предсказываем вероятности положительной метки у объекта выборки, считаем accuracy для разных порогов по вероятности и выбираем понравившийся.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метрики классификации и регрессии",
    "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
    "section_title": "Регрессия",
    "text": "В задачах регрессии целевая метка у нас имеет потенциально бесконечное число значений. И природа этих значений, обычно, связана с каким-то процессом измерений: величина температуры в определенный момент времени на метеостанции количество прочтений статьи на сайте количество проданных бананов в конкретном магазине, сети магазинов или стране дебит добывающей скважины на нефтегазовом месторождении за месяц и т.п. Мы видим, что иногда метка это целое число, а иногда произвольное вещественное число. Обычно случаи целочисленных меток моделируют так, словно это просто обычное вещественное число. При таком подходе может оказаться так, что модель A лучше модели B по некоторой метрике, но при этом предсказания у модели A могут быть не целыми. Если в бизнес-задаче ожидается именно целочисленный ответ, то и оценивать нужно огрубление. Общая рекомендация такова: оценивайте весь каскад решающих правил: и те «внутренние», которые вы получаете в результате обучения, и те «итоговые», которые вы отдаёте бизнес-заказчику. Например, вы можете быть удовлетворены, что стали ошибаться не во втором, а только в третьем знаке после запятой при предсказании погоды. Но сами погодные данные измеряются с точностью до десятых долей градуса, а пользователь и вовсе может интересоваться лишь целым числом градусов. Итак, напомним постановку задачи регрессии: нам нужно по обучающей выборке, гдепостроить модель f(x). Величинуназывают ошибкой на объекте i или регрессионным остатком. Весь набор ошибок на отложенной выборке может служить аналогом матрицы ошибок из задачи классификации. А именно, когда мы рассматриваем две разные модели, то, глядя на то, как и на каких объектах они ошиблись, мы можем прийти к выводу, что для решения бизнес-задачи нам выгоднее взять ту или иную модель. И, аналогично со случаем бинарной классификации, мы можем начать строить агрегаты от вектора ошибок, получая тем самым разные метрики. MSE — одна из самых популярных метрик в задаче регрессии. Она уже знакома вам, так как применяется в качестве функции потерь (или входит в ее состав) во многих ранее рассмотренных методах. Иногда для того, чтобы показатель эффективности MSE имел размерность исходных данных, из него извлекают квадратный корень и получают показатель эффективности RMSE. MSE неограничен сверху, и может быть нелегко понять, насколько «хорошим» или «плохим» является то или иное его значение. Чтобы появились какие-то ориентиры, делают следующее: Берут наилучшее константное предсказание с точки зрения MSE — среднее арифметическое меток. При этом чтобы не было подглядывания в test, среднее нужно вычислять по обучающей выборке Рассматривают в качестве показателя ошибки:У идеального решающего правиларавен, у наилучшего константного предсказания он равенна обучающей выборке. Можно заметить, чтопоказывает, какая доля дисперсии таргетов (знаменатель) объяснена моделью. MSE квадратично штрафует за большие ошибки на объектах. Мы уже видели проявление этого при обучении моделей методом минимизации квадратичных ошибок — там это проявлялось в том, что модель старалась хорошо подстроиться под выбросы. Пусть теперь мы хотим использовать MSE для оценки наших регрессионных моделей. Если большие ошибки для нас действительно неприемлемы, то квадратичный штраф за них — очень полезное свойство (и его даже можно усиливать, повышая степень, в которую мы возводим ошибку на объекте). Однако если в наших тестовых данных присутствуют выбросы, то нам будет сложно объективно сравнить модели между собой: ошибки на выбросах будет маскировать различия в ошибках на основном множестве объектов. Таким образом, если мы будем сравнивать две модели при помощи MSE, у нас будет выигрывать та модель, у которой меньше ошибка на объектах-выбросах, а это, скорее всего, не то, чего требует от нас наша бизнес-задача. Использовать RMSE для сравнения моделей на выборках с большим количеством выбросов может быть неудобно. В таких случаях прибегают к также знакомой вам в качестве функции потери метрикеMAE(mean absolute error): И MSE и MAE считаются как сумма абсолютных ошибок на объектах. Рассмотрим следующую задачу: мы хотим спрогнозировать спрос товаров на следующий месяц. Пусть у нас есть два продукта: продукт A продаётся в количестве 100 штук, а продукт В в количестве 10 штук. И пусть базовая модель предсказывает количество продаж продукта A как 98 штук, а продукта B как 8 штук. Ошибки на этих объектах добавляют 4 штрафных единицы в MAE. И есть 2 модели-кандидата на улучшение. Первая предсказывает товар А 99 штук, а товар B 8 штук. Вторая предсказывает товар А 98 штук, а товар B 9 штук. Обе модели улучшают MAE базовой модели на 1 единицу. Однако, с точки зрения бизнес-заказчика вторая модель может оказаться предпочтительнее, так как предсказание продажи редких товаров может быть приоритетнее. Один из способов учесть такое требование — рассматривать не абсолютную, а относительную ошибку на объектах. Когда речь заходит об относительных ошибках, сразу возникает вопрос: что мы будем ставить в знаменатель? В метрикеMAPE(mean absolute percentage error) в знаменатель помещают целевое значение: С особым случаем, когда в знаменателе оказывается, обычно поступают «инженерным» способом: или выдают за непредсказаниена таком объекте большой, но фиксированный штраф, или пытаются застраховаться от подобного на уровне формулы и переходят к метрикеSMAPE(symmetric mean absolute percentage error): Если же предсказывается ноль, штраф считаем нулевым. Таким переходом от абсолютных ошибок на объекте к относительным мы сделали объекты в тестовой выборке равнозначными: даже если мы делаем абсурдно большое предсказание, на фоне которого истинная метка теряется, мы получаем штраф за этот объект порядка 1 в случае MAPE и 2 в случае SMAPE. Как и любая другая метрика, MAPE имеет свои границы применимости: например, она плохо справляется с прогнозом спроса на товары с прерывистыми продажами. Рассмотрим такой пример: Среднее MAPE — 36.7%, что не очень отражает реальную ситуацию, ведь два дня мы предсказывали с хорошей точностью. В таких ситуациях помогаетWAPE(weighted average percentage error): Если мы предсказываем идеально, то WAPE = 0, если все предсказания отдаём нулевыми, то WAPE = 1. В нашем примере получим WAPE = 5.9% Альтернативный способ уйти от абсолютных ошибок к относительным предлагает метрикаRMSLE(root mean squared logarithmic error): где нормировочная константавводится искусственно, чтобы не брать логарифм от нуля. Также по построению видно, что метрика пригодна лишь для неотрицательных меток. Все вышеописанные метрики легко допускают введение весов для объектов. Если мы из каких-то соображений можем определить стоимость ошибки на объекте, можно брать эту величину в качестве веса. Например, в задаче предсказания спроса в качестве веса можно использовать стоимость объекта. Еще одним способом охарактеризовать качество модели в задаче регрессии является доля предсказаний с абсолютными ошибками больше заданного порога: Например, можно считать, что прогноз погоды сбылся, если ошибка предсказания составила меньше 1/2/3 градусов. Тогда рассматриваемая метрика покажет, в какой доле случаев прогноз не сбылся.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метрики классификации и регрессии",
    "url": "https://education.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii",
    "section_title": "Как оптимизировать метрики регрессии?",
    "text": "Пусть мы выбрали, что метрика качества алгоритма будет. Тогда мы хотим обучить модель так, чтобы F на валидационной выборке была минимальная/максимальная. Аналогично задачам классификации лучший способ добиться минимизации метрики— выбрать в качестве функции потерь ту же. К счастью, основные метрики для регрессии: MSE, RMSE, MAE можно оптимизировать напрямую. С формальной точки зрения MAE не дифференцируема, так как там присутствует модуль, чья производная не определена в нуле. На практике для этого выколотого случая в коде можно возвращать ноль. Для оптимизации MAPE придётся изменять оптимизационную задачу. Оптимизацию MAPE можно представить как оптимизацию MAE, где объектам выборки присвоен вес.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Variational Autoencoder (VAE)",
    "url": "https://education.yandex.ru/handbook/ml/article/variational-autoencoder-(vae)",
    "section_title": "Постановка задачи",
    "text": "Давайте представим себе, что нам нужно нарисовать лошадь. Как бы мы это сделали? Наверное, сначала наметили бы общий силуэт лошади, её размер и позу, а затем стали бы добавлять детали: гриву, хвост, копыта, выбирать окраску шерсти и так далее. Кажется, что в процессе обучения рисованию мы учимся выделять для себя основной набор каких-тофакторов, наиболее важных для генерации нового изображения: общий силуэт, размер, цвет и тому подобное, а во время рисования уже просто подставляем какие-тозначенияфакторов. При этом одинаковые сочетания одних и тех же факторов могут привести к разным картинкам — ведь нарисовать что-то два раза абсолютно одинаково вы, скорее всего, не сможете. Попробуем формализовать описанный выше процесс. Пусть у нас есть датасетв многомерном пространстве исходных данных, — объектов, которые мы желаем генерировать, — и пространствоскрытых (латентных) переменныхменьшей размерности, которыми кодируются скрытые факторы в данных. Тогда генеративный процесс состоит из двух последовательных стадий (см. картинку ниже): Семплированиеиз распределения(красное) Семплированиеиз распределения(синее) То есть, рассуждая в терминах рисования картинок с лошадками, мы сначала мысленно семплируем некоторое(размер, форму, цвет, ...), затем дорисовываем все необходимые детали, то есть семплируем из распределения, и в итоге надеемся, что получившееся будет напоминать лошадку. Таким образом, построить генеративную модель в нашем случае — значит уметь семплировать с помощью описанного двустадийного процесса объекты, близкие к объектам из обучающей выборки. Говоря более формально, нам бы хотелось, чтобы наша модель максимизировала правдоподобиеэлементов обучающего множествапри описанной процедуре генерации: Предположим, что совместное распределениепараметризовано некоторым параметроми выражается непрерывной пофункцией при каждых фиксированныхи: Тогда и мы можем записать следующую задачу оптимизации: Решив её, мы построим нашу генеративную модель. Замечание 1. После приведённой выше аналогии с обучением рисованию может ошибочно показаться, что в скрытые переменные всегда заложен некоторый хорошо интерпретируемый смысл. Но на практике это всё же не обязано быть так: те скрытые переменные, которые мы найдём, могут как иметь простую интерпретацию, так и не иметь. С помощью объяснений выше мы прежде всего хотели проиллюстрировать понятие «скрытые переменные». Замечание 2. Может показаться, чтонам откуда-то уже известно, и тогда не ясно, зачем все эти сложности с введением латентных переменных и интегралами. На самом деле, мы действительно можем построитьстатистическую оценкупо данными даже пытаться генерировать новые данные с помощью таких моделей (как, например, делаетсятут). Но у статистических методов есть разные ограничения, наиболее серьёзным из которых представляется проклятие размерности: чем больше измерений у ваших данных, тем больше разнообразных примеров вам нужно для построения адекватной оценки. О проклятии размерности мы поговорим чуть подробнее далее. Замечание 3. Также может возникать вопрос — а зачем вообще нужно вводить латентные переменные, моделировать совместное распределение, а целевое распределениеопределять как маргинализациюпо? Почему такой подход в принципе должен работать? Ответ состоит в том, что, даже имея относительно простые выражения дляи, можно описать достаточно сложное распределение, что достаточно наглядно проиллюстрировано в примере ниже.",
    "source_type": null,
    "useful_links": [
      {
        "text": "статистическую оценку",
        "url": "https://en.wikipedia.org/wiki/Density_estimation"
      },
      {
        "text": "тут",
        "url": "https://scikit-learn.org/stable/modules/density.html"
      }
    ]
  },
  {
    "document_title": "Variational Autoencoder (VAE)",
    "url": "https://education.yandex.ru/handbook/ml/article/variational-autoencoder-(vae)",
    "section_title": "Обучение VAE",
    "text": "Прежде чем пытаться решать задачу оптимизациидавайте подумаем, а как мы вообще могли бы посчитать такой интеграл? Первое, что приходит на ум, — попробовать получить его приближённое значение методом Монте-Карло: где в последнем переходе мы используем сэмплы. Однако, еслии— достаточно большое, мы столкнёмся спроклятием размерности— количество семплов, необходимых для того, чтобы хорошо покрыть, растёт экспоненциально с ростом: Есть ли способ как-то сократить число необходимых семплов для подсчёта? На самом деле, часто оказывается, что далеко не все возможныеотображаются в элементы, и вклад большинствав оценкупрактически нулевой. Это наводит на мысль, что для каждогонам может пригодиться знание распределениятаких, которые являются прообразами. Мы можем предположить, что распределениепараметризовано некоторым семейством параметров: Зная распределение, мы могли бы семлировать уже только из него, а не из всего, и, если распределениеокажется достаточно хорошим, число необходимых семплов значительно сократится. О том, как построить, мы поговорим позже. Сейчас стоит обратить внимание на то, что процессы семплирования из распределенийивзаимно обратны друг к другу: первое отображает элементы датасета в подмножество латентного пространства, то есть действует какэнкодер, а второе отображает латентные переменные в подмножество, то есть действует какдекодер: Так как оба эти распределения будут участвовать в обучении VAE, возникает аналогия между VAE имоделями-автоэнкодерами, имеющими похожую структуру. Сейчас у нас всё готово для того, чтобы записать общий вид функции потерь для обучения вариационного автоэнкодера. Напомним, что мы обучаем модель путём максимизации правдоподобияпо. Для удобства мы перейдём к логарифму правдоподобия: Оптимизировать напрямую это выражение тяжело из-за проклятия размерности, обсуждавшегося в прошлом разделе. Чтобы победить проклятие размерности, мы хотели бы заменить семплирование из априорного распределенияна семплирование из, для чего придётся осуществить некоторый трюк. Для любого, отличного от нуля для всех, мы можем выписать следующую цепочку равенств: Второе слагаемое в последнем равенстве —-дивергенция междуи, которая, как известно, неотрицательна: А первое слагаемое — это величина, именуемая в английской литературеevidence lower bound (ELBO): Первое слагаемое в последнем переходе обычно называютreconstruction loss, так как оно оценивает качество восстановления декодером объектаиз его латентного представления. А второе играет роль регуляризационного члена и подталкивает распределение, генерируемое энкодером, быть ближе к априорному распределению. Так как-дивергенция неотрицательна, ELBO является нижней границей для логарифма правдоподобия данных: Посмотрим повнимательнее на равенства, которые мы выписали. Функциюможно оптимизировать градиентным спуском (SGD), предварительно выбрав удобный вид для,и. Максимизируя, мы растим, тем самым улучшая нашу генеративную модель. Оптимизацию ELBO с помощью SGD мы будем подробно обсуждать в следующем разделе. Максимизируя, мы одновременно минимизируем. Распределениеоценивает, из какихмог бы быть сгенерирован объект, и заранее оно нам не известно. Но если мы выберем достаточно большую модель для, тов процессе оптимизации может очень сильно приблизиться к, и тогда мы будем напрямую оптимизировать. Заодно мы получаем приятный бонус: для оценки распределения прообразовмы сможем использоватьвместо невычислимого. То есть, которое мы при выводе формулы ввели в рассмотрение как произвольное распределение, действительно будет играть роль энкодера для модели. Важное свойство ELBO в том, что его можно оптимизировать градиентным спуском относительно параметрови. Если объекты датасетанезависимы и одинаково распределены, тозапишется как сумма (или среднее) значенийна объектах: Значенияи их градиентыв общем случае вычислить невозможно, однако можно получить их несмещённые оценки, что позволит нам использовать стохастический градиентный спуск. Оценку для градиента по параметрамполучить несложно: где в последней строчке. Однако оценку на градиент по параметрамполучить сложнее, ведь они также участвуют и в семплировании: В общем случае эта проблема не разрешима. Однако некоторые распределения позволяют применитьрепараметризацию (reparameterization trick): представить переменнуюкак обратимую дифференцируемую функцию от случайного шума, параметрови переменнной: Здесь распределениене зависит оти. Например, пусть. Тогдаможет иметь следующий вид: После такой замены мы сможем получить оценку на градиент по: где в последней строчке. Репараметризация хорошо иллюстрируется следующей картинкой: Здесь— функция потерь. Значенияна обеих схемах одинаковы, но на левой картинке градиенты порассчитать не получится, так как мы не можем дифференцировать по случайной переменной. Однако на правой картинке источник случайности перемещается во входные данные благодаря репараметризации, а градиенты вычисляются по детерминированным переменным. Таким образом, мы получили сетап, типичный для оптимизации с помощью SGD: там мы приближаем градиент функции потерь по случайным батчам входных данных, а здесь роль случайных батчей играют одновременно батчи из переменныхи случайных переменных. Кроме нормального распределения, есть довольного много примеров распределений, допускающих репараметризацию. Их можно найтипо ссылкев разделе \"The reparameterization trick\". Однако большая часть реализаций VAE используют именно нормальное распределение. В итоге примерный алгоритм обучения VAE такой: Скопировать код1dataset = np.array(...)2epsilon = RandomDistribution(...)34# Энкодер q_phi(z|x) — нейронная сеть с параметрами phi5encoder = Encoder()67# Декодер p_theta(x|z) — нейронная сеть с параметрами theta8decoder = Decoder()910for step in range(max_steps):11# Семплируем батч исходных данных и случайного шума12batch_x = sample_batch(dataset)13batch_noise = sample_batch(epsilon)1415# Считаем параметры распределения q(z | x) с помощью энкодера16latent_distribution_parameters = encoder(batch_x)1718# Делаем репараметризацию (семплируем из q(z | x))19z = reparameterize(latent_distribution_parameters, batch_noise)2021# Декодер отдаёт параметры выходного распределения22output_distribution_parameters = decoder(z)2324# Вычисляем ELBO и обновляем параметры моделей25L = -ELBO(26latent_distribution_parameters,27output_distribution_parameters,28batch_x29)30L.backward() Стоит подчеркнуть, что декодер выдаёт именно параметры выходного распределения, а не конкретный семпл из этого распределения. Например, если вы моделируете выходные изображения с помощью нормального распределения, то декодер на выходе предскажет некоторыеи, которые вместе с параметрами латентного распределения (выход энкодера) будут поданы в ELBO. Для генерации конкретной картинки на этапе инференса нужно будет либо честно провести семплирование из, либо, как часто делают, просто взять среднеев качестве выходного изображения. В общем случае конкретный способ проведения инференса зависит от вида используемого выходного распределения. Пришло время привести примеры конкретных,и, с которыми можно построить VAE. Для начала предположим, чтоможно положить равным стандартному нормальному распределению: Заметим, что в этом случае у априорного распределенияотсутствует зависимость от параметров. Распределениезависит от того, к какому распределению принадлежат ваши данные. Если ваши данные имеют непрерывное распределение, томожно задать, например, как гауссовское распределение: Вектор средних в этом примере определяется функциейс переменнымии, а матрица ковариаций определяется постоянной диагональной матрицей. Функциюможно задать с помощью нейронной сети с параметрами. При желании, матрицу ковариаций тоже можно задавать некоторой функцией и не ограничивать её вид только постоянными матрицами. Если же ваши данные дискретны, то может подойти категориальное распределение: в котором вектор вероятностей— выход нейросети после применения. Если у вас бинарные данные, вы можете использовать бернуллиевское распределение: где— выход нейронной сети после применения сигмоиды. Распределениеможет, в принципе, быть любым, но в самом простом случае оно имеет вид гауссовского распределения c диагональной матрицей ковариаций: Такое распределение позволяет, в частности, применить репараметризацию, обсуждавшуюся выше. Если выбратьдвумерным, то распределения, определямые, хорошо визуализируются: Вычислим его для приведённых выше распределений. Начнём с.-дивергенция между распределениямииравна: где— размерность этих распределений. Вывод этого соотношения можно найтиздесь. В нашем случае,и Тогда ELBO будет вычисляться как: где. Как было упомянуто вэтой статьеот авторов VAE в разделе 2.3, число семплированийможно положить равным единице при достаточно большом размере батча (например, 100). Если вы выберете биномиальное, то Если гауссовское, то Пример реализации обучения и применения VAE на датасете MNIST на Keras можно найтиздесь, а на PyTorch —здесь. Когда мы обучили VAE, мы сможем генерировать новые семплы, просто подаваяна вход декодеру: ![2](https://yastatic.net/s3/education-portal/media/vae_decoder_diagram_385be2e566_6c396a28e8.svg\"> Энкодер для генерации новых семплов не нужен. Однако нам может понадобиться оценитьдляиз тестового множества, чтобы понять, с какой вероятностью модель сможет сгенерировать. Для оценки интеграла нам нужно насемплировать некоторое количество, и если брать семплы из, то оценка может плохо сойтись. Но можно снова использовать ELBO как нижнюю границу дляи оценивать уже её, семплируя из распределения. Такая оценка сойдётся быстрее и даст примерное представление о том, насколько хорошо модель справляется с конкретным примером. Также интересно бывает взглянуть на то, как распределены коды обучающих примеров в латентном пространстве. Так, например, может выглядеть распределение латентных кодов цифр MNIST для обученного VAE в двумерном латентном пространстве: Разные типы цифр обозначены разными цветами (соответствие цифр и цветов показано на шкале сбоку). Здесь видно, что лучше всего модель различает нули и единицы, а восьмёрки и тройки — хуже всего. Стоит, конечно, отметить, что латентное пространство выбрано двумерным в целях визуализации, и при большей его размерности модель могла бы научиться различать цифры более качественно. Для двумерного латентного пространства есть ещё один интересный способ визуализировать структуру многообразия, выученного VAE. Можно взять равномерную сетку на единичном квадрате и отобразить её в латентное пространство, применив к ней функцию, обратную к CDF нормального распределения. Полученные семплы можно подать в декодер и посмотреть, какие картинки будут соответствовать узлам сетки: Здесь изображены примеры, сгенерированные для датасетов Frey Face и MNIST (оба доступны поссылке). Такая визуализация позволяет увидеть плавный переход латентных кодов одних объектов в коды других, а также взаимное расположение латентных кодов. Для MNIST снова видно, в частности, что коды нулей и единиц модель разнесла далеко друг от друга, а коды троек и восьмёрок очень близки. А ещё интересно наблюдать плавный переход от шестёрок к нулям и от семёрок к единицам. Для Frey Face видно, что весёлые лица расположены далеко от грустных, а по главной диагонали квадрата можно проследить плавный переход от серьёзного лица к улыбающемуся. Ещё интересно посмотреть на то, как меняется качество генерируемых цифр в зависимости от размерности латентного пространства (на картинках просто случайные семплы из модели): Заметный переход виден между размерностями 2 и 5, дальнейший рост размерности почти не оказывает значимого эффекта. Иногда мы можем захотеть сгенерировать не просто какой-то произвольный объект из датасета, а относящийся к конкретной группе или классу. Ранее мы выписывали уравнение для: Все распределения, участвующие в этом уравнении, мы можем сделать обусловленными по переменной: Переменнаяможет быть лейблом объектаили вообще произвольным тензором, как-то характеризующим. Вместо, единого для всехиз обучающей выборки, для каждого значениятеперь будет отдельное априорное распределение. Переменнаяможет принимать и дискретные, и непрерывные значения. Она может даже, например, быть половиной изображения, которую модели предлагается дополнить. На всякий случай подчеркнём, что обучение CVAE — это не то же самое, что обучение нескольких независимых VAE, так как веса CVAE общие для всех классов. На уровне имплементации это реализуется довольно просто: нужно всего лишь сконкатенировать входы энкодера и декодера с тензором, соответствующим. Еслиимеет категориальные значения, то бывает полезно предварительно закодировать их one-hot векторами. Алгоритм будет примерно таким: Скопировать код1dataset, labels = np.array(...), np.array(...)2epsilon = RandomDistribution(...)34# Энкодер q_phi(z|x) — нейронная сеть с параметрами phi5encoder = Encoder()67# Декодер p_theta(x|z) — нейронная сеть с параметрами theta8decoder = Decoder()910for step in range(max_steps):11# Семплируем батч исходных данных, лейблов и случайного шума12batch_x = sample_batch(dataset)13batch_y = sample_batch(labels)14batch_noise = sample_batch(epsilon)1516# Подаём в энкодер конкатенацию входных данных и лейблов17encoder_input = concatenate([batch_x, batch_y])1819# Считаем параметры распределения z с помощью энкодера20latent_distribution_parameters = encoder(encoder_input)21# Делаем репараметризацию22z = reparameterize(latent_distribution_parameters, batch_noise)2324# Конкатенируем полученный случайный вектор и лейблы25decoder_input = concatenate([z, batch_y])2627# Декодер отдаёт нам выходное изображение28output_distribution_parameters = decoder(decoder_input)2930# Вычисляем ELBO и обновляем параметры31L = -ELBO(32latent_distribution_parameters,33output_distribution_parameters,34batch_x35)36L.backward() Реализацию CVAE на PyTorch и Tensorflow можно найти, например,здесь. Если визуализировать распределение латентных кодов для цифр MNIST, полученных после обуславливания модели на класс цифры, то можно увидеть что-то такое: Мы видим непонятную смесь из точек вместо явных кластеров, которые выделяла обычная модель VAE. Однако дело тут в том, что, вместо того, чтобы пытаться размещать все цифры в одном пространстве, модель использует отдельное латентное пространстводля каждой цифры: На картинке справа — априорные распределения для цифр 6 и 7, а слева — визуализация структуры выученных многообразий для этих цифр, построенная так же, как аналогичная визуализация для VAE. Качество изображений каждой отдельной цифры заметно повышается: Видно, что вариабельность генерации цифр теперь тоже заметно выросла, и модель может имитировать написание цифр разными почерками.",
    "source_type": null,
    "useful_links": [
      {
        "text": "",
        "url": "#eq:main_problem"
      },
      {
        "text": "",
        "url": "#eq:main_problem"
      },
      {
        "text": "моделями-автоэнкодерами",
        "url": "https://en.wikipedia.org/wiki/Autoencoder#:~:text=Machine%20learninganddata%20mining.%20v.%20t.,network%20to%20ignore%20signal%20%E2%80%9Cnoise%E2%80%9D"
      },
      {
        "text": "по ссылке",
        "url": "https://arxiv.org/pdf/1312.6114.pdf"
      },
      {
        "text": "здесь",
        "url": "https://mr-easy.github.io/2020-04-16-kl-divergence-between-2-gaussian-distributions/"
      },
      {
        "text": "этой статье",
        "url": "https://arxiv.org/pdf/1312.6114.pdf"
      },
      {
        "text": "здесь",
        "url": "https://blog.keras.io/building-autoencoders-in-keras.html"
      },
      {
        "text": "здесь",
        "url": "https://github.com/pytorch/examples/blob/master/vae/main.py"
      },
      {
        "text": "https://yastatic.net/s3/education-portal/media/vae_decoder_diagram_385be2e566_6c396a28e8.svg",
        "url": "https://yastatic.net/s3/education-portal/media/vae_decoder_diagram_385be2e566_6c396a28e8.svg"
      },
      {
        "text": "ссылке",
        "url": "https://cs.nyu.edu/~roweis/data.html"
      },
      {
        "text": "здесь",
        "url": "https://github.com/wiseodd/generative-models/tree/master/VAE/conditional_vae"
      }
    ]
  },
  {
    "document_title": "Variational Autoencoder (VAE)",
    "url": "https://education.yandex.ru/handbook/ml/article/variational-autoencoder-(vae)",
    "section_title": "Обзор статей",
    "text": "Кроме стандратного описания работы VAE, приведём результаты нескольких недавних интересных работ, базирующихся на идее VAE. МоделиVQ-VAEиVQ-VAE-2интересны тем, что в них в качестве априорных распределений были задействованы дискретные распределения. В каких ситуациях дискретные распределения могут быть более применимы, чем непрерывные? Например, если мы имеем дело с токенам в задачах NLP или фонемами в обработке речи. Картинки также можно было бы кодировать некоторым набором из целых чисел: например, одно число могло бы кодировать тип объекта, другое — его цвет, третье — цвет фона и так далее: Кроме того, существуют довольно мощные алгоритмы (например,Трансформер), предназначенные для работы с дискретными данными. Выучивание хороших дискретных представлений даёт возможность эффективно использовать такие алгоритмы для, например, задачи генерации картинок. Авторы VQ-VAE вводят дискретное латентное пространство в видевещественных векторовразмерности. Векторы из этого пространства называютсякодовыми векторамииликодами. На рисунке ниже приведена примерная схема обучения предлагаемой модели. Энкодер принимает на вход картинкуи выдаёт на выходе тензор. На рисунке этот тензор имеет размерность: последняя размерность совпадает с длиной кодовых векторов, а— это пространственная размерность выхода CNN (для простоты мы здесь не пишем явно размерность батчей). Каждый извекторов изотображается в ближайший к нему по-расстоянию кодовый вектор. После такой процедуры тензорпереходит в тензор, состоящий изкодовых векторов. Декодер получает на вход тензори отображает его в исходную картинку. Для работы с речью и текстами авторы использовали двумерный тензорвместо трёхмерного. Выходное распределение энкодераопределено здесь следующим образом: Во время обучения в качестве априорного распределения в латентном пространстве используется равномерное распределение, поэтому слагаемоеоказывается постоянным и равным: В точках, где, предпоследнее выражение продолжается нулём по непрерывности. Таким образом, ELBO для таких распределений примет вид где— параметры декодера. При оптимизацииможно не учитывать. Отображение выхода энкодера в кодовые векторы не дифференцируемо, поэтому при обучении применяется следующий трюк: при обратном проходе градиент копируется напрямую из декодера в энкодер, пропуская при этом слой, отображающий выходы энкодера в кодовые векторы. Этот трюк очень близок к приёму, известному какstraight-through estimator, впервые предложенному в этойстатье(а его простое описание можно найтитут). Использование straight-through estimator, однако, не позволяет обучать сами кодовые векторы, так как по ним не будут вычисляться градиенты. Поэтому лосс для обучения модели складывается из трёх компонент: Здесьобозначает оператор остановки дифференцирования: через его аргумент не текут градиенты. В статье лосс записан несколько иначе: Эти обозначения кажутся несколько путающими по двум причинам: Буквав нижнем индексепризвана обозначить только то, что это выход энкодера, а не наличие связи между кодовыми векторамии параметрами энкодера. Но второе довольно легко для себя предположить. Вычитаниеобозначает вычитание не всех элементов словаря из соответствующей позиции тензора, а только лишь ближайшего соседа к элементуна этой позиции. То есть по факту вычитаниев этой записи равносильно вычитанию. Это не уточняется в статье, но можноувидетьв официальной реализации. Первое слагаемое — это ELBO с точностью до константы. Второе слагаемое отвечает за сдвиг кодовых векторов в сторону выходов энкодера. Чтобы не получилось так, что выходы энкодера всё время меняют кодовые векторы за счёт второй компоненты лосса, а сами на каждой итерации выдают векторы, далёкие от текущих кодовых векторов, добавляется третье слагаемое. Оно отвечает за то, чтобы энкодер стремился выдавать векторы, близкие к кодовым векторам, а его значимость регулируется с помощью коэффициента. Однако при обучении мы потеряли регуляризационное слагаемое, из-за чего распределение энкодера не было обязано приближать собой априорное распределение и осталось его узким подмножеством. Из-за этого с наибольшей вероятностью при семплировании из равномерного категориального распределения мы будем получать просто шумы вместо хороших картинок: Чтобы исправить эту проблему, авторы предлагают с помощью дополнительной модели выучить априорное распределениетех латентных переменных, которые модель научилась генерировать в процессе обучения. Поскольку любое кодовое представление можно вытянуть в последовательность, а самих кодов — конечное наперёд заданное число, то эта задача близка к задаче обучения языковой модели. Действительно, ведь там мы должны по последовательности предыдущих слов предложения предсказать следующее слово из доступного словаря, а в нашем случае — по входной последовательности дискретных латентных кодов предсказать следующий латентный код. Для картинок авторы предложили моделировать априорное распределение латентных кодов с помощью PixelCNN. Детали архитектуры и обучения этой модели можно найти в оригинальнойстатье, здесь мы опишем только общую идею. PixelCNN последовательно генерирует пиксели картинки, двигаясь из верхнего левого угла в правый нижний. Она проходит все ряды последовательно от верхнего до нижнего, а внутри каждого ряда движется слева направо: Для цветных картинок каналы (R, G, B) также моделируются последовательно: канал B при генерации зависит от R и G, а G — только от R. При предсказании значения каждого следующего пикселя модель использует значения уже сгенерированных соседей из некоторого окружающего квадрата. Чтобы модель не могла читать пиксели, идущие после текущего предсказываемого пикселя, используется специальная маска, пример которой изображён на правой части рисунка. В случае VQ-VAE обучение PixelCNN происходит не на пикселях, а на латентных кодах. Семплирование из выученного априорного распределения выглядит гораздо лучше, чем попытки семплировать из равномерного: Для аудио вместо PixelCNN авторами используетсяWaveNet. При обучении моделей априорных распределений есть возможность подавать метки классов, чтобы потом можно было семплировать из этих классов (принцип тот же, что и для CVAE). Результаты реконструкции картинок из ImageNet с помощью VQ-VAE выглядят довольно неплохо (под реконструкцией понимается выход полной модели, состоящей из энкодера и декодера): А так выглядят результаты семплирования из VQ-VAE с априорным распределением, выученным PixelCNN: Модель VQ-VAE-2 — это расширение VQ-VAE. Она показывает значительный скачок по качеству генерируемых изображений: Впечатляет то, что на картинке именно результат семплирования из выученного моделью распределения, а не результат реконструкции. Первое основное отличие модели VQ-VAE от VQ-VAE-2 — использование иерархических латентных переменных: Прежде чем перейти к описанию архитектуры, хочется сделать небольшой дисклеймер: когда в тексте далее будет говориться «тензор размера», то будет иметься в виду, что тензор имеет шейп, где первая размерность соответствует батчам, а последняя — каналам. На картинке показан пример двухуровневой архитектуры (хотя уровней может быть и больше). Каждому уровню соответствуют свои энкодер, декодер и набор кодовых векторов (общей размерностидля всех уровней). Обозначим нижний и верхний энкодеры каки, а декодеры — каки. принимает на вход трёхканальную картинку размерапикселей, отображает её в тензор размераи передаёт на вход.выдаёт тензор размера, который затем отображается в тензор из кодовых векторов(квантизуется) передаётся на вход, затем выходыиконкатенируются и квантизуются в иконкатенируются и передаются на вход, который отображает их в исходную картинку Для обучения модели используется почти такой же лосс, как для VQ-VAE. Для VQ-VAE он имел вид: Для VQ-VAE-2 первое и третье слагаемые сохраняют свой вид, а второе слагаемое заменяется на обновление кодовых векторовс помощью экспоненциального скользящего среднего. Пусть— выход энкодера на шаге, выпрямленный в двумерный тензор, последняя размерность которого равна размерностикодовых векторов. Пусть— множество извекторов, для которых на шагеближайшим оказался кодовый вектор. Тогда обновлениена шагепроисходит по следующим формулам: Здесь— некоторый вещественный параметр. Так же, как и для VQ-VAE, априорное распределение для VQ-VAE-2 выучивается отдельно уже после обучения основной модели, но в случае VQ-VAE-2 оно имеет иерархическую структуру. На картинке изображён пример такого распределения для двухуровневой архитектуры: Для каждого уровня обучается отдельная модель PixelCNN: одна — на кодовых векторах первого уровня, вторая — на кодовых векторах первого и второго уровней. Обе модели также принимают на вход метку класса, изображение из которого нужно насемплировать. Семплирование из финальной модели происходит так: семплируются векторыиз верхнего распределения из нижнего распределения семплируются векторыпри условии векторов декодер принимает на вход векторыии выдаёт финальную картинку Результаты семплирования из двухуровневой модели VQ-VAE-2, обученной на ImageNet: А это — результаты семплирования из трёхуровневой модели VQ-VAE-2, обучавшейся наFFHQ: Одна из недавних работ, связанных с VAE, — этоDALL-Eот OpenAI. Они обучили модель с 12 миллиардами параметров, генерирующую картинки по их текстовому описанию. Для обучения авторами был собран датасет, состоящий из 250 миллионов пар картинок и их описаний. Вот примеры работы этой модели: Вблог-постеOpenAI, посвящённом DALL-E, есть возможность самостоятельно составлять текстовые описания из некоторого ограниченного словаря и смотреть на результаты. Осторожно, это затягивает 😃 DALL-E идейно основывается на результатах VQ-VAE: сначала выучиваются кодовые векторы для картинок, а затем обучается Трансформер, моделирующий совместное априорное распределение текстов и кодовых векторов. Подробнее о трансформерах мырассказывалив главе 6.3 этого хендбука. В DALL-E задействована архитектура, основанная на декодер-части исходной архитектуры Трансформера, поэтому стоит такжепочитатьпро модель GPT-2, работающую аналогичным образом. Обучение проходит в две стадии: Сначала обучается дискретизованный VAE (dVAE) c энкодером для сжатия RGB-картинок размерав тензор изкодовых векторов. Эта стадия обучения очень напоминает VQ-VAE, но вместо добавления в лосс дополнительных слагаемых для кодовых векторов авторы DALL-E используютрелаксацию Гумбеля— трюк, позволяющий проводить честное дифференцирование по параметрам энкодера. Об обучении dVAE мы будем говорить подробнее далее. Затем обучается Трансформер (точнее, только декодер-часть исходной архитектуры Трансформера), задача которого — выучить совместное распределение картинок и их текстовых описаний. Он принимает на вход конкатенацию из эмбеддингов текстовых токенов и кодовых векторов картинок и учится для каждой входной последовательности предсказывать её продолжение. О некоторых деталях обучения Трансформера также будет рассказано далее. Инференс обученной модели происходит так: эмбеддинги текстового описания картинки подаются на вход Трансформеру, и он авторегрессионно предсказывает кодовые векторы картинки, соответствующей этому описанию, а затем полученные кодовые векторы пропускаются через декодер dVAE. Обучение dVAE происходит путём максимизации ELBO для картиноки их дискретных латентных представлений: гдеи— параметры энкодера и декодера дискретизованного VAE, a— равномерное категориальное распределение над кодовыми векторами. Здесь можно заметить дополнительный коэффициент, который в стандартном VAE всегда равен 1. Однако авторы DALL-E ввели дополнительный параметр, опираясь на результатыстатьио-VAE. Но, в отличие от исходной статьи, в их экспериментах значениепостепенно понижается в ходе обучения. Энкодер dVAE отображает картинки размерав тензорс шейпом, где— число кодовых векторов. То есть каждой изпозиций энкодер сопоставляет категориальное распределение надкодовыми векторами, параметризованное выходными логитами. Для получения тензораиз кодовых векторов можно было бы сначала применитьк распределениям на каждой изпозиций, а затем сопоставить каждой позиции кодовый вектор, номеру которого соответствует максимальная вероятность (взятьдля этой позиции). Однако операцияне дифференцируема, и, к тому же, в концепции VAE на вход декодеру должен пойти семпл из распределения, предсказываемого энкодером, а взятиена каждой позиции не является семплированием из предсказанного распределения. Поэтому нам потребуется применение некоторых трюков, которые позволят нам одновременно: аппроксимировать семплирование из сделать семплирование дифференцируемым Первый трюк известен в англоязычной литературе как Gumbel-Max Trick. Представим, что у нас есть логиты-выходы сетки, и мы хотим с их помощью получить семпл из категориального распределения, то есть стохастически предсказать класс. Для этого мы обычно применяем к логитам, чтобы получить вероятности: а затем из получившегося категориального распределениясемплируем класс. Оказывается, этим двум шагам будет эквивалентна следующая процедура: насемплировать числаиз стандартного распределенияГумбеля, прибавить к каждому из логитовсемпл, выбрать класс, такой что. О том, почему это действительно так, можно почитатьздесь. Однако сам по себе Gumbel-Max Trick нам не поможет — ведь операция так и не стала дифференцируемой. Поэтому придётся использовать ещё один трюк, предложенный практически одновременно в двух статьях (перваяивторая) и названный Gumbel-Softmax в одной из них. Чтобы описать этот трюк, отметим, что результат операции— это индекс некоторого класса. Такой индекс можно описать one-hot кодированием, то есть вектором длиной, в котором все элементы равны нулю, кроме-го, который равен единице. Gumbel-Softmax состоит в том, чтобы вместо взятияна последнем этапе Gumbel-Max Trick делать следующее: вычислить,, — аппроксимацию one-hot при помощис температурой сложить кодовые векторыс весами: выдать векторв качестве латентного вектора для данной позиции На самом деле авторы DALL-E не уточняли, как выходной векторагрегируется из кодовых векторов и, но такой подход применён вреализацииDALL-E на PyTorch. Присемплирование из распределениястремится к, и в процессе обучения dVAE авторы постепенно уменьшали значение. На следующей картинке слева — просто Gumbel-Max Trick, а справа — дифференцируемый вариант Gumbel-Max Trick: Таким образом, для обучения кодовых векторов для dVAE не требуется дополнительных слагаемых в лоссе относительно ELBO, а также копирования градиентов из декодера в энкодер (как было в VQ-VAE). Кроме того, стоит отметить, чтов данном случае не вырождается в константу, а действительно действует как регурялизатор, заставляя категориальное распределение, параметризованное логитами энкодера, быть ближе к равномерному распределению над кодовыми векторами. Ещё один трюк в обучении dVAE касается выходного распределения. Авторы DALL-E подметили проблему, возникающую при часто встречающемся выборе лапласовского и гауссовского распределений в качестве: оба они определены на всей вещественной прямой, в то время как пиксели принимают значения из ограниченного интервала. Таким образом, часть плотности при моделировании «теряется», оказываясь вне возможных границ значений пикселей. Чтобы исправить эту проблему, авторы предлагают использовать распределение, которое они назвали “Logit-Laplace”. Его плотность определена на интервалеи выражается следующей формулой: Эта плотность соответствует случайной переменной, полученной применением сигмоиды к распределённой по Лапласу случайной переменной. Выражение для распределения Logit-Laplace можно получить по стандартной формуле для плотности случайной величины, полученной применением монотонной дифференцируемой функции к другой случайной величине (см. формулу, например,тут). Логарифм этой плотности подставляется в ELBO вместо. Декодер на выходе выдаёт 6 тензоров: первые три соответствуютдля RGB-каналов, оставшиеся три соответствуют, и эти 6 тензоров используются для подсчёта лосса. При подаче в энкодер значения картинок нормируются функцией: Этим авторы добиваются того, чтобы декодер моделировал значения из, что позволяет нивелировать вычислительные проблемы, связанные с делением нав формуле плотности. Во время инференса реконструкциякартинкивычисляется по формуле: где— первые три тензора из выхода декодера. Выходы, соответствующие, при этом не используются. На втором этапе авторы фиксируют параметрыии моделируют совместное распределение картинок и их текстовых описаний с помощьюSparse Transformerс 12 миллиардами параметров. На вход он получает конкатенацию из текстового описания картинки и её кодовых векторов. Картинка представляется 1024 кодовыми векторами, получаемыми из энкодера, причём при семплировании кодовых последовательностей используется обычныйбез добавления шума из распределения Гумбеля. Текстовое описание токенизируется с помощью процедуры BPE (см. раздел про BPEздесь), и каждому токену ставится в соответствие представляющий его вектор из вещественных чисел (эмбеддинг). Для представления текста используется не более 256 токенов, а размер используемого словаря — 16 384 токена. Задача Трансформера во время обучения — для каждого начального отрезка входной последовательности предсказать следующий за ним токен. Это может быть как текстовый токен, так и кодовый вектор картинки. Поскольку кодовые векторы картинок всегда идут за текстовыми токенами, при генерации кодовых векторов attention-механизм учитывает также и все предыдущие текстовые токены. Кроме того, маска attention для кодовых векторов учитывает, что исходно они расположены не линейно друг за другом, а на прямоугольной сетке. В статье приводится несколько вариантов геометрических паттернов, которые использовались для attention-маски на кодовых векторах. В качестве лосса используется взвешенная сумма кросс-энтропии для текстовых токенов и кросс-энтропии для кодовых векторов картинок c весамиисоответственно (больший приоритет отдаётся генерации картнок, отсюда и больший вес для лосса). Конечно, огромный Трансформер обучить крайне непросто, и очень существенная часть статьи посвящена трюкам, которые авторы применили для обучения такой большой модели. На этапе инференса в модель подаются токены текстового описания картинки, и на их основании модель авторегрессионно предсказывает кодовые векторы: Кодовые векторы картинки подаются в декодер dVAE, который отображает их в финальную картинку: Для повышения качества предсказания авторы сначала генерируют 512 картинок для каждого текстового описания, а затем выбирают лучшую картинку из предсказанных. Разные наборы кодовых векторов для одного и того же текста можно получить, например, случайно выбирая на каждом шаге генерации какой-то кодовый вектор согласно предсказанному Трансформером распределению. Ранжирование полученных 512 картинок осуществляется с помощьюCLIP— большой нейросети, обучавшейся в режиме без учителя на большом количестве данных моделировать совместное распределение картинок и текстов.",
    "source_type": null,
    "useful_links": [
      {
        "text": "VQ-VAE",
        "url": "https://arxiv.org/pdf/1711.00937v2.pdf"
      },
      {
        "text": "VQ-VAE-2",
        "url": "https://arxiv.org/pdf/1906.00446.pdf"
      },
      {
        "text": "Трансформер",
        "url": "https://arxiv.org/abs/1706.03762"
      },
      {
        "text": "статье",
        "url": "https://arxiv.org/pdf/1308.3432.pdf"
      },
      {
        "text": "тут",
        "url": "https://www.hassanaskary.com/python/pytorch/deep%20learning/2020/09/19/intuitive-explanation-of-straight-through-estimators.html"
      },
      {
        "text": "увидеть",
        "url": "https://github.com/deepmind/sonnet/blob/v2/sonnet/src/nets/vqvae.py#L113"
      },
      {
        "text": "статье",
        "url": "https://arxiv.org/pdf/1606.05328v2.pdf"
      },
      {
        "text": "WaveNet",
        "url": "https://deepmind.com/blog/article/wavenet-generative-model-raw-audio"
      },
      {
        "text": "FFHQ",
        "url": "https://paperswithcode.com/dataset/ffhq"
      },
      {
        "text": "DALL-E",
        "url": "https://arxiv.org/pdf/2102.12092.pdf"
      },
      {
        "text": "блог-посте",
        "url": "https://openai.com/blog/dall-e/"
      },
      {
        "text": "рассказывали",
        "url": "https://education.yandex.ru/handbook/ml/article/transformery"
      },
      {
        "text": "почитать",
        "url": "https://jalammar.github.io/illustrated-gpt2/"
      },
      {
        "text": "статьи",
        "url": "https://arxiv.org/pdf/1904.10509.pdf"
      },
      {
        "text": "Гумбеля",
        "url": "https://en.wikipedia.org/wiki/Gumbel_distribution"
      },
      {
        "text": "здесь",
        "url": "https://lips.cs.princeton.edu/the-gumbel-max-trick-for-discrete-distributions/"
      },
      {
        "text": "первая",
        "url": "https://arxiv.org/pdf/1611.01144.pdf"
      },
      {
        "text": "вторая",
        "url": "https://arxiv.org/pdf/1611.00712v3.pdf"
      },
      {
        "text": "реализации",
        "url": "https://github.com/lucidrains/DALLE-pytorch/tree/main/dalle_pytorch"
      },
      {
        "text": "тут",
        "url": "https://en.wikipedia.org/wiki/Probability_density_function"
      },
      {
        "text": "Sparse Transformer",
        "url": "https://openai.com/blog/sparse-transformer/"
      },
      {
        "text": "здесь",
        "url": "https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html"
      },
      {
        "text": "CLIP",
        "url": "https://openai.com/blog/clip/"
      }
    ]
  },
  {
    "document_title": "Variational Autoencoder (VAE)",
    "url": "https://education.yandex.ru/handbook/ml/article/variational-autoencoder-(vae)",
    "section_title": "Заключение",
    "text": "Итак, в этом параграфе мы поговорили о том, как устроен VAE в классическом смысле, — с непрерывным распределением латентных переменных, а также поговорили о работах, основанных на идеях использования дискретных распределений для VAE. Конечно, различные модификации VAE не исчерпываются только лишь отказом от непрерывных латентных переменных в пользу дискретных. Есть множество других возможных направлений для улучшения модели: использование иерархических латентных распределений (которые мы, кстати, видели в контексте VQ-VAE-2), использование функций потерь, отличающихся от ELBO, выбор различных форм латентных пространств, применение adversarial-обучения и многое другое. Хороший список различных статей, посвящённых модификациям VAE, можно найтиздесь. Из недавних работ, связанных с применением иерархических распределений, интересной кажетсяNVAE— семплы из модели выглядят весьма впечатляюще. Про неё есть хорошийвидеообзорот Yannic Kilcher. На этом мы завершаем рассказ о VAE. Будем надеяться, что он дал вам общее представление и об исходных идеях, из которых выросла модель VAE, и о наиболее интересных последних результатах, связанных с ней. А в следующем параграфе мы поговорим о генеративно-состязательных сетях.",
    "source_type": null,
    "useful_links": [
      {
        "text": "здесь",
        "url": "https://jmtomczak.github.io/blog/4/4_VAE.html#There-are-many,-many-more!"
      },
      {
        "text": "NVAE",
        "url": "https://arxiv.org/pdf/2007.03898.pdf"
      },
      {
        "text": "видеообзор",
        "url": "https://www.youtube.com/watch?v=x6T1zMSE4Ts"
      }
    ]
  },
  {
    "document_title": "Implicit bias",
    "url": "https://education.yandex.ru/handbook/ml/article/implicit-bias",
    "section_title": "Случай линейных сетей",
    "text": "Каков implicit bias нейронных сетей? Сходится ли градиентный спуск в решение наименьшей нормы и если да, то о какой норме идёт речь? Частичный ответ на этот вопрос удаётся получить для линейных сетей. Следуя работеExact solutions to the nonlinear dynamics of learning in deep linear neural networks, рассмотрим линейную сеть с одним скрытым слоем: гдеи– матрицы. Поставим задачу многомерной (метка– вектор) регрессии с квадратичной функцией потерь: Шаг градиентного спуска выглядит следующим образом: где точка надозначает производную по времени (то есть по). Это нелинейная система матричных дифференциальных уравнений второго порядка; чтобы проинтегрировать её аналитически, нам придётся сделать ряд предположений. Определим ковариационную матрицу входови матрицу ковариации меток со входами. Предположим, что данные декоррелированы:; этого можно добиться, заменив входына. Что касается матрицы ковариации меток со входами, рассмотрим её сингулярное разложение: Назовёмсилой моды с индексомковариации между метками и входами. Сделаем замену координат: В новых координатах градиентный спуск принимает вид: Пустьи. Тогда в терминах векторови Получилась система векторных дифференциальных уравнений порядка, всё ещё нелинейная. К счастью, при определённом предположении об инициализации эта система распадается нанезависимых систем порядка. Предположим, что существует ортогональная матрица, такая что при всехимеет место равенство и для некоторых скалярных величини. Нетрудно заметить, что в этом случае при всехи в любой момент времениимеемидля некоторых скалярных величини. Тогда для различныхвыражения выше становятся независимыми друг от друга: Теперь это система нелинейных дифференциальных уравнений второго порядка. Еслив начальный момент, то это верно и в любой момент времени. Тогда система выше превращается в одно уравнение первого порядка. В самом деле, обозначив, получаем: Это уравнение задаёт следующую динамику градиентного спуска для функции потерь(её глобальный минимум – это). Перед тем, как интегрировать уравнение (1), напомним, как изперейти обратно к исходными. Имеем для: Аналогично для: Теперь проинтегрируем уравнение (1) в предположении, чтоидля выбранного: Рассмотрим время, необходимое, чтобы выучить фиксированную долю силы данной моды, где, стартуя из точки из окрестности нуля. Оно равняется Видим, что чем сильнее мода (то есть чем больше), тем быстрее она сходится. Рассмотрим две моды с силамии, такие что. Насколько вторая (более слабая) мода выучится к моменту, когда первая уже выучится на долю? Из уравнения выше имеем: Подставляяи, получаем: Поскольку, это выражение стремится к минус бесконечности при, из чего следует, чтостремится к нулю. Это означает, что если веса в инициализации лежат в окрестности нуля, то к моменту, когда данная мода выучивается на любую фиксированную долю, более слабые моды не успевают выучиться вообще. Таким образом, в любой момент времениматрицаявляется наилучшим малоранговым приближением заданного ранга матрицы корреляций, причём чем больше, тем больше ранг. Можно сказать, чтоградиентный спуск с фиксированным числом шагов «предпочитает» решения малого ранга. В выводе выше, мы использовали ряд предположений, в частности, что вектора, образующие матрицу, ортогональны в инициализации. Эмпирически те же выводы оказываются верными и без этого предположения, см. графики в оригинальной работеExact solutions to the nonlinear dynamics of learning in deep linear neural networks. Можно ли их обосновать строго математически? В работахTowards resolving the implicit bias of gradient descent for matrix factorizationиDeep Linear Networks Dynamicsдоказывается, что самая сильная мода выучивается в первую очередь. Тем не менее, на момент написания этого текста остаётся недоказанным, что все моды выучиваются последовательно от сильных к слабым. К сожалению, implicit bias градиентного спуска для нелинейных сетей пока остаётся почти неизученным.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
        "url": "https://arxiv.org/pdf/1312.6120.pdf"
      },
      {
        "text": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
        "url": "https://arxiv.org/pdf/1312.6120.pdf"
      },
      {
        "text": "Towards resolving the implicit bias of gradient descent for matrix factorization",
        "url": "https://arxiv.org/pdf/2012.09839.pdf"
      },
      {
        "text": "Deep Linear Networks Dynamics",
        "url": "https://arxiv.org/pdf/2106.15933v1.pdf"
      }
    ]
  },
  {
    "document_title": "PAC-байесовские оценки риска",
    "url": "https://education.yandex.ru/handbook/ml/article/pac-bajesovskie-ocenki-riska",
    "section_title": "Применение пак-байесовских оценок к детерминированным алгоритмам обучения",
    "text": "Выше были рассмотрены две PAC-байесовские оценки: одна для не более, чем счётного множества моделей, другая – для произвольного. За возможность использования несчётных классов моделей мы заплатили тем, что алгоритм обучения должен быть недетерминированным (для детерминированных алгоритмов KL-дивергенция в Теореме Макаллестера может вырождаться в бесконечность; например, это так, если априорное распределение гауссово). Чаще всего класс моделейвсё-таки несчетён: например, если это класс всех сетей фиксированной архитектуры, то он индексируется весами, которых несчётное множество. При этом, хотя используемый алгоритм обучения и в самом деле недетерминирован (стохастический градиентный спуск зависит от случайного выбора батчей и от инициализации весов) и теорема Макаллестера выполняется, финальное распределение моделей очень сложно охарактеризовать, и из-за этого непонятно, как считать KL-дивергенцию. Предположим, что алгоритм обучения всё-таки детерминирован; этого можно добиться, зафиксировав сид генератора случайных чисел при обучении. Как получить осмысленную PAC-байесовскую оценку для детерминированного алгоритма на несчётном множестве моделей? Мы рассмотримдва способа. Первый способ – добавить известный шум в финальную модель, выданную детерминированным алгоритмом. Так, для нейронных сетей, результатом работы алгоритма обучения является набор весов. Если добавить в этот набор гауссовский шум, а также в качестве априорного распределения взять гауссовское, то KL-дивергенцию в теореме Макаллестера можно будет посчитать аналитически. Дисперсию шума в апостериорном распределении тоже можно обучить с помощью градиентного спуска одновременно с весами, тем самым минимизируя правую часть оценки из вышеупомянутой теоремы. Если в найденную модель удастся добавить шум так, чтобы KL-дивергенция значительно уменьшилась, но при этом риск на обучающей выборке не сильно вырос, то оценка на истинный риск получится хорошей. Это рассуждение связывает PAC-байесовские оценки и гипотезу о том, что «плоские» («широкие») минимумы хорошо обобщают. В самом деле, если минимум «плоский», то в модель из него можно добавить много шума, не испортив качество на обучении. Оценки, основанные на этом принципе, можно найти в работахComputing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training dataиA PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks. Второй способ состоит в том, чтобы взять дискретное кодированиеи применить дискретную PAC-байесовскую оценку к закодированной модели вместо оригинальной. Обозначим закодированную модельчерез. Следуя работеNon-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approach, возьмём априорное распределение с массой, убывающей с ростом длины кода: Здесь– длина кода модели,– некоторое вероятностное распределение на, а– нормализующая константа. Тогда KL-дивергенция примет следующий вид: Для того, чтобы KL-дивергенция выше была как можно меньше, необходимо, чтобы наш алгоритм обучения на реалистичных данных сходился в модели с маленькой длиной кода. Для этого будем применять наше кодирование не к оригинальной модели, а к сжатой с помощью некоторого алгоритма сжатия. Здесь мы предполагаем, что модели, к которым сходится наш алгоритм обучения, можно сжать с малыми потерями до моделей с малой длиной кода. Другими словами, мы опираемся на предположение, что обученные модели в некоторым смысле «простые». Если модель параметризована весами, типичный алгоритм сжатия выдаст набор, где – позиции ненулевых весов; – «словарь» весов; ,– квантизованные значения весов. Выход алгоритма будет выглядеть как, если, иначе. Тогда наивное 32-битное кодирование даст следующую длину: В работеNon-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approachописанный выше способ применяется к модели MobileNet (свёрточной сети, сконструированной специально для мобильных устройств), обученной на наборе данных ImageNet, и получают верхнюю оценку на истинный риск, равную(риск случайного угадывания –). Хотя такой результат и выглядит очень скромным, но это первая осмысленная оценка обобщающей способности реально используемой нейронной сети на реалистичном наборе данных.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data",
        "url": "https://arxiv.org/pdf/1703.11008.pdf"
      },
      {
        "text": "A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks",
        "url": "https://arxiv.org/pdf/1707.09564.pdf"
      },
      {
        "text": "Non-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approach",
        "url": "https://arxiv.org/pdf/1804.05862.pdf"
      },
      {
        "text": "Non-vacuous Generalization Bounds at the ImageNet Scale: a PAC-Bayesian Compression Approach",
        "url": "https://arxiv.org/pdf/1804.05862.pdf"
      }
    ]
  },
  {
    "document_title": "Языковые модели",
    "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
    "section_title": "Что такое языковые модели?",
    "text": "Говоря простым языком, языковые модели — это алгоритмы, способные продолжать тексты. Если чуть усложнить, то этовероятностные алгоритмы, и к ним сразу можно задать эмпирический критерий качества: хорошая модель даёт разумные продолжения данных ей текстов. Давайте разберём пример выше. Модель высчитывает вероятность возможных продолжений текста и предлагает их нам. Слово «фрукт» — наименее разумное продолжение нашей фразы, в то время как слово «наука» — наиболее разумное. И действительно, это часть определения машинного обучения, которое мы давали в начале этого учебника. Таким образом, нам осталось лишь научить алгоритм моделировать эти вероятности и максимизировать их для разумных предложений. Но как это сделать? По ходу развития языковых моделей подходы менялись, мы расскажем о каждом из них в хронологическом порядке. Начнём с краткого экскурса в историю — поговорим о статистических моделях, рекуррентных нейронных сетях и трансформерах. А затем перейдём к современным — GPT-1, GPT-2, GPT-3, InstructGPT, ChatGPT и LLaMa.",
    "source_type": null,
    "useful_links": [
      {
        "text": "вероятностные алгоритмы",
        "url": "https://ru.wikipedia.org/wiki/%D0%92%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%BD%D1%8B%D0%B9_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC"
      }
    ]
  },
  {
    "document_title": "Языковые модели",
    "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
    "section_title": "Развитие языковых моделей",
    "text": "Идея модели лежит на поверхности, много где применяется в самых разных вариациях даже в ХХ веке, поэтому сложно назвать авторов или точную дату создания. Однако этот метод популярен до сих пор — используется в клавиатурах смартфонов для исправления опечаток и быстрого набора текстов через Т9. Теперь подробнее о методе. Напомним вероятностную формулировку цепей Маркова в общем виде: Если представить, что— это слово, а набор этих омега — это предложение, то по формуле становится возможным посчитать вероятность предложенияС практической точки зрения всё чуть сложнее, ведь распределение слов в реальном языке (какое, с какими и как часто встречается), вообще говоря, неизвестно. Его принято аппроксимировать на основекорпуса текстов(например, всего интернета) — в этом случае считаются совстречаемости слов друг с другом, и по ним считаются вероятности. В условной вероятности число переменных, от которых зависит распределение следующего слова, называется контекстом. Например, в выражениидлина контекста равна. На практике же редко считают вероятности с контекстом больше трёх, на это есть несколько причин: Сложность в подсчёте и хранении каждого возможного уникального контекста длины. Если корпус текстов состоит изразличных слов, то стоимость хранения счётчиков встречаемости для выбранной длины контекста равна, что очень много при больших. Большой контекст реже встречается. То есть слова «яблоку», «негде» и «упасть» поодиночке встречаются чаще, чем их комбинация «яблоку негде упасть». Отсюда достаточность статистик падает с ростом длины контекста. В учебном примере предлагается ограничиться шириной контекста размера 1: Интересно, что такой подход достаточно популярен до сих пор. Например, он используется в умных клавиатурах, чтобы подсказать следующее слово. Достоинства статистических моделей: Простота имплементации. Высокая скорость работы алгоритма. Низкая вычислительная стоимость обучения и инференса. Недостатки статистических моделей: Не сможет сгенерировать слова, которые не шли подряд в обучающем корпусе. Очень маленький контекст. Длинные последовательности равновероятны ≈ нулю (в цепях Маркова для длинных последовательностей много множителей меньше нуля, поэтому их произведение уже практически равно нулю для любых множителей). Отсюда алгоритм не может выдавать разумные продолжения большой длины. Языковые модели, да и вообще все модели, которые оперируют текстом, используют понятие токена. Токен — это единица текста, которую понимают алгоритмы. В примере выше токен — это отдельное слово(этот подход называетсямешком слов), однако текст можно разбивать на токены и иначе. Раньше предложение разбивалось на слова по пробелам, знакам препинания, исключались стоп-слова и так далее (назовем этоCountVectorizer). Но у этого подхода возникали две проблемы с разными словоформами. Они: Либо обозначались разными токенами, что не совсем верно, ведь слово-то одно и то же. И получалось, что похожим смыслом обладало сразу несколько токенов. Либо приводились к начальной форме — и в итоге терялся падеж, время, число. Современные токенизаторы построены на алгоритме BPE (Byte Pair Encoding; об устройстве BPE более подробно можно прочитать вучебнике Лены Войта). Решение требует фиксации определённого числа токенов. Как только это сделано, в словарь добавляются все символы из текста, ищутся самые частые их сочетания и снова добавляются. Этот процесс продолжается до тех пор, пока число токенов не станет равно заданному значению. Токенизатор SentencePiece в определённом смысле совершеннее, чем BPE, — он наследует логику Unigram- и BPE-токенизаторов, иначе работает с пробелами (добавляет_перед соответствующим токеном) и не построен на логике разбиения слов по разделителям. Поэтому, в отличие от BPE, он способен работать с такими языками, как японский или китайский. Подробнее о его устройстве можно прочитатьздесь. Появились после статистических моделей, подробнее о хронологииздесь. Рекуррентные нейронные сети концептуально можно описать формулой, где: — некоторая модель; — внутреннее состояние модели на момент времени; — токен, который сейчас обрабатывается. Тогда следующий токенполучается так: Подробно об устройстве RNN мы рассказываем в параграфеНейросети для работы с последовательностями. Здесь же коротко отметим, что существуют различные модификации рекуррентных сетей, которые усложняют структуру алгоритма, даже добавляют механизм внимания Attention. Если коротко, то он позволяет лучше оценивать взаимосвязи токенов в тексте. Все они в разной степени помогают модели усваивать более длинные и сложные последовательности токенов. Достоинства RNN: Высокая скорость инференса и сравнительно низкая стоимость. Более качественный текст, чем у моделей на статистиках. Теоретически понимает контекст в сотни слов (а с Attention ещё больше). Точно учитывает весь контекст документа. Недостатки RNN: Невозможность параллельного обучения на многих устройствах, отсюда не получится просто так обучить большую RNN. Модель «хорошо помнит» лишь несколько последних токенов контекста (без Attention). Проблемы с обучением (exploading/vanishing gradients).",
    "source_type": null,
    "useful_links": [
      {
        "text": "мешком слов",
        "url": "https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%88%D0%BE%D0%BA_%D1%81%D0%BB%D0%BE%D0%B2"
      },
      {
        "text": "CountVectorizer",
        "url": "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
      },
      {
        "text": "учебнике Лены Войта",
        "url": "https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html#bpe"
      },
      {
        "text": "здесь",
        "url": "https://arxiv.org/pdf/1808.06226.pdf"
      },
      {
        "text": "здесь",
        "url": "https://ru.wikipedia.org/wiki/%D0%A0%D0%B5%D0%BA%D1%83%D1%80%D1%80%D0%B5%D0%BD%D1%82%D0%BD%D0%B0%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D1%81%D0%B5%D1%82%D1%8C"
      },
      {
        "text": "Нейросети для работы с последовательностями",
        "url": "https://academy.yandex.ru/handbook/ml/article/nejroseti-dlya-raboty-s-posledovatelnostyami"
      }
    ]
  },
  {
    "document_title": "Языковые модели",
    "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
    "section_title": "Трансформеры",
    "text": "Более подробно трансформеры и их устройство описаны в параграфеТрансформеры. Последней и наиболее успешной с точки зрения качества оказалась архитектура трансформеров. Она состоит из двух частей: encoder (на изображении слева) и decoder (на изображении справа). Изначально был популярен подход обучать части отдельно. Так на базе encoder-блоков были построеныBERT-модели. Идея обучения звучит несложно: давайте из входного текста замаскируем токеномMASK15% имеющихся токенов и обучим модель угадывать, какие именно токены были скрыты. Тогда, если модель обучится это делать, она сможет очень хорошо понимать текст. Таким образом, энкодеры обладают следующими особенностями: Анализируют входной текст и связи между токенами. Выделяют важные токены для определённой задачи. Ничего не генерируют. На базе декодеров сделаны GPT-модели. Они обучаются предсказывать следующий токен на основе предыдущих. На инференсе, когда очередной токен сгенерирован, он добавляется в контекст, и уже на основе него выбирается новый токен. Таким образом модель: генерирует токен за токеном. смотрит на весь контекст, архитектурно, нет забывания токенов. имеет возможность (как и BERT-модели) обучаться параллельно. обладает достаточно высокой вычислительной стоимостью инференса.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Трансформеры",
        "url": "https://academy.yandex.ru/handbook/ml/article/transformery"
      },
      {
        "text": "BERT-модели",
        "url": "https://en.wikipedia.org/wiki/BERT_(language_model)"
      },
      {
        "text": "MASK",
        "url": "https://academy.yandex.ru/handbook/ml/article/transformery"
      }
    ]
  },
  {
    "document_title": "Языковые модели",
    "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
    "section_title": "Современные подходы",
    "text": "Начнём немного издалека, с моделей GPT-1 и GPT-2. Первая была обучена в 2018 году на 7000 книг и имела размер контекста в 512 токенов. И она сразу получилась довольно сильной: после дообучения на специализированные задачи (бенчмарки) показывала на них лучшее на то время качество. Так, в задачах CoLA (бенчмарк классификационный, в нём надо определить грамматическую корректность предложения) результат вырос до 45,4 против прежнего результата в 35,0 у RNN. А вGLUE— с 72,8 до 68,9. Вторая модель была обучена в 2019 году. Она состояла из рекордных для того времени 1,5 млрд параметров (то есть была в ~10 раз больше первой), имела контекст в 1024 токена и была обучена на 40 ГБ текстовых данных. GPT-2 снова побеждала предыдущие подходы, включая GPT-1, на многихбенчмарках. По сравнению с первой версией модели у второй произошел качественный рост: теперь она могла генерировать разумные тексты — а не только предложения. Правда, не всегда и не с первой попытки. GPT-3 стала революцией с точки зрения качества и размеров. В 2020 году была получена модель размером в 175 млрд параметров, она обучалась на 570 ГБ текстовых данных с контекстом в 2048 токенов. Модельмогларешать целый спектр задач, включая перевод, суммаризацию и ответы на вопросы, с качеством, близким к человеческому уровню, а также отличалась высокой способностью генерировать креативный контент. Демонстрацию работы модели лучше посмотреть вэтой статьена 28 странице и далее. Модель демонстрировала действительно впечатляющие результаты: собрав обучающие данные, можно было с высоким качеством решить практически любую текстовую задачу. Однако для применения таких решений остаётся проблема со стоимостью их обучения. Для обучения GPT-2 авторы использовали 16 GPU (иначе говоря — графических процессоров, видеокарт), а для GPT-3 уже 3200. Для дообучения модели под определенную задачу, конечно, понадобится меньше ресурсов, но всё равно достаточно много. Что с этим делать? Использовать подводки.",
    "source_type": null,
    "useful_links": [
      {
        "text": "GLUE",
        "url": "https://gluebenchmark.com"
      },
      {
        "text": "бенчмарках",
        "url": "https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"
      },
      {
        "text": "могла",
        "url": "https://arxiv.org/abs/2005.14165"
      },
      {
        "text": "этой статье",
        "url": "https://arxiv.org/pdf/2005.14165.pdf"
      }
    ]
  },
  {
    "document_title": "Языковые модели",
    "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
    "section_title": "Подводки",
    "text": "Оказывается, что обучать большие языковые модели решать определённые задачи не всегда нужно (как мы говорили ранее, это ресурсоёмко): можно составитьfew-shotподводку. Подводка — словесное описание поставленной задачи, составленное определенным образом. Представим, что мы хотим осуществить перевод с английского на французский. Для обучения нам необходимо было бы составить пары, где— слово на английском, а— на французском. Сделаем иначе — опишем задание на естественном языке: Здесь на английском языке сформулировано задание и предлагается слово «cheese» перевести на французский. Назовем такую конструкциюzero-shot-примером. Такой запрос GPT-3, возможно, поймёт, но работать будет плохо. Давайте увеличим количество примеров в подводке и назовем эту конструкциюone-shot: Или больше, и это будетfew-shot: При этом приёме не тратятся ресурсы на обучение модели, она лишь смотрит на контекст и генерирует продолжение. Оказывается, этого достаточно, чтобы сравняться с downstream-обучением. Продемонстрируем преимущество такого подхода на двух бенчмарках. TriviaQA — вопросно-ответный бенчмарк, составленный на основе Википедии. Он помогает оценивать знания модели и ее ответы на вопросы. Lambada — оценивает меморизацию длинного контекста модели. Чем выше скор, тем лучше модель на обоих бенчмарках. Графики выше демонстрируют несколько особенностей: Few-shotпозволяет получать качество, сравнимое с дообучением на определённом датасете, и стремится к человеческому качеству. С ростом числа обучаемых параметров модели растет её качество. На правом графикеfew-shot-примеры начинают работать лучшеzero-shot-примеров лишь с некоторого размера модели. Это говорит о том, что модель начинает демонстрировать «умные» свойства лишь начиная с некоторого размера. Few-shotдействительно полезен и помогает получать от модели нужный результат без обучения, но всё же недостаточно хорошо. Предположим, мы хотим узнать у модели, как приготовить любимое блюдо. Пусть это будет лазанья: Можно заметить, что запрос к модели можно задать по-разному, но ответ ожидается обычно какой-то конкретный. Авторыэтой статьизаметили, что сама по себе конструкцияfew-shot-примера не приводит к стабильному результату. Качество решения задачи очень зависит от: Текстового описания задачи. Числа примеров в подводке. Порядка, в котором примеры следуют друг за другом в подводке. Формате составленияfew-shot. Чтобы улучшить качество решения задачи, авторы предлагают осуществлять калибровку подводок. В статье они заметили, что модели смещены относительно подводок, то есть переформулировка запроса ведёт к смещению в ответе модели, а также к росту разброса ответов. Например, модели задают вопрос и её задача — ответить «да» или «нет». Еслиfew-shotсостоит из четырёх примеров и они идут в порядке «да», «да», «нет», «нет», то, вероятнее всего, дальше модель ответит «нет» на любой вход, просто потому что слово «нет» встречалось последним. Калибровать модель предлагается с помощью выученного линейного преобразования: В этом преобразовании: и— обучаемые; — вероятности на выходе модели; — откалиброванные вероятности; Обучающие данные собираются так: Для различных задач собираем подводки и добавляем нейтральное слово N/A. В этом примере несмещённая модель должна давать с вероятностью 50% ответ «positive» или «negative». Чтобы добиться такого распределения ответов у смещённой модели, представим: Также всеfew-shot-примеры стандартизуются в специальный формат вопрос — ответ, как на картинке выше. Этот метод (синий график) по сравнению со стандартнымиfew-shot-примерами (красный график) помог повысить качество и уменьшить разброс результата. Таким образом, оптимизировав всего 4 параметра, авторы существенно улучшили итоговый результат. Качество работы модели зависит от подводки, иfew-shotпросто один из способов её построения. Эксперименты показывают, что грамотный подбор промта позволяет экономить на обучении и решать задачи с высоким качеством. Проблема в обучении больших моделей — нехватка оперативной памяти на GPU, поэтому не будем оптимизировать все параметры модели. Пусть необходимо решить задачу, к ней имеется обучающее множество вида. Введём дополнительные токены, которых не было в словаре:— и будем добавлять в каждый текст из X согласно какому-то правилу. Правило может быть таким: имеем 20 спецтокенов, добавим токены 1–10 в начало строки, а 11–20 в конец. Тогда, можно «заморозить» все параметры в модели, кроме этих токенов, и сэкономить на обучении. Если токенов 100 и каждый из них имеет размерность в 1024, то необходимооптимизироватьлишь 100 тысяч параметров вместо 175 млрд в случае обучения всей модели. Получается, что можно оптимизировать подводку, или, другими словами, находить наиболее оптимальный промт, который лучше прочих решает поставленную задачу. Языковые модели призваны решать самый широкий спектр текстовых задач — вопросно-ответные, суммаризацию, диалоговость, перевод и многие другие. Получается, что модель должна после некого обучения (подбора подводки или оптимизации вообще всех параметров под каждую задачу) решать каждую из них на высоком уровне. Однако модель обычно учится на текстах из интернета, книгах и других доступных ресурcах. И формат задачи, который обычно требуется от модели, не соответствует тому, что алгоритм привык видеть на обучении. К этому стоит добавить, что среди веб-документов просьба что-то сократить или определить тональность документа встречается не очень часто. Исправить этот недостаток призваны подходы по генерализации языковых моделей:FLANиT0. Инструкции даются на естественном языке и для подготовки качественного обучающего множества предлагается произвести следующие действия: Каждой отдельной задаче (будь то перевод, написание отзывов или суммаризация) пишется по несколько различных подводок, отражающих смысл задания. Итоговый датасет составляется из отдельных задач, все строчки датасета перемешиваются случайным образом. Авторы стараются собрать как можно более разнообразные задачи в обучающее множество. Две картинки сверху демонстрируют FLAN- и T0- подходы по созданию датасета, а картинка снизу — рост усреднённого качества модели после обучения на смеси. Таким образом с некоторого размера модели наблюдается повышение метрик качества при дальнейших дообучениях генерализованной модели на отложенных задачах. Предыдущий подход со смесью датасетов помогает решать многие задачи в среднем заметно лучше. Однако есть задачи, где качество результатов модели всё ещё низкое. Например, предложить эффективный код, решающий некую алгоритмическую задачу, найти минимум некоторой аналитической функции потерь, посчитать производную фукнции в точке и так далее. Такие вопросы требуют рассуждения, которое модель не может просто так провести из-за своей архитектуры. Выход — составить подводки в стилеChain-of-Thought (CoT): CoT-подводка состоит из трёх обязательных элементов: Формулировки задачи на естественном языке. Подробного пошагового решения. Ответа на задачу. Формирование такого промта, особенно наfew-shot, заставляет модель рассуждать, как можно правильно решить задачу. Авторыэтой статьисравнили на двух математических бенчмарках способность модели решать сложные задачи. MultiArith — проверяет умение решать простые арифметически задачки. GSM8K — более сложные. Результаты демонстрируют, что наличиеCoTв подводке увеличивает способность решать математические задачки у больших языковых моделей.",
    "source_type": null,
    "useful_links": [
      {
        "text": "этой статьи",
        "url": "https://arxiv.org/pdf/2102.09690.pdf"
      },
      {
        "text": "оптимизировать",
        "url": "https://aclanthology.org/2021.emnlp-main.243.pdf"
      },
      {
        "text": "FLAN",
        "url": "https://arxiv.org/abs/2109.01652"
      },
      {
        "text": "T0",
        "url": "https://arxiv.org/pdf/2110.08207.pdf"
      },
      {
        "text": "этой статьи",
        "url": "https://arxiv.org/pdf/2201.11903.pdf"
      }
    ]
  },
  {
    "document_title": "Языковые модели",
    "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
    "section_title": "InstructGPT",
    "text": "Наконец, обсудив, как готовить обучающие данные, перейдем к прародителю ChatGPT. Инструкционная модель — это та, которая обучена отвечать на пользовательские запросы в режимеzero-shot(а вообще, иfew-shot, и любой человекочитаемый формат) с высоким качеством. InstructGPT — это модель, и она интересна с точки зрения выработки концепции обучения всех инструкционных моделей (InstructGPT, ChatGPT, GPT-4 и других). С некоторыми нюансами обучение состоит из четырех этапов: Подготовка качественного претрейна. Языковая модель должна содержать в себе как можно больше знаний о мире, чтобы иметь возможность в последующем решать произвольные задачи с высоким качеством. На этом этапе необходимо озаботиться наибольшим разнообразием, чистотой и полнотой обучающих данных. Подробнее об этом мы поговорим в последнем разделе этого параграфа. SFT (supervised finetuning) — обучение модели следовать инструкциям. Этот пункт мы подробно обсудили в предыдущей части параграфа (T0, FLAN, CoT). На этом этапе важно составить грамотный инструкционный датасет, где инструкция содержит произвольные запросы к модели, а ответ на неё — подробный текст, которым будущий пользователь будет доволен. Грамотный сбор таких данных довольно дорогостоящий процесс, но от него напрямую зависит, каким образом модель будет взаимодействовать с пользователем. Обучение reward-модели. Каждый ответ алгоритма можно оценить с точки зрения вежливости, подробности или персонажности. Персонажность позволяет модели считать себя, например, капитаном Джеком Воробьем и общаться на пиратском говоре. Также есть менее формализуемые критерии качества ответов, их даже сложно описать словами. Например, что в основном людям ответ 1 нравится больше чем ответ 2.Reward-модель агрегирует эти кртитерии в число — меру качества. Чем оно выше, тем качественнее ответ модели. Для выравнивания поведения модели обычно важно уметь оценивать тысячи текстов, а вручную это делать дорого и долго, поэтому обучается специальная модель-оценщик. Про то, как обучать reward-модель, будет рассказано далее. Этап Reinforcement Learning (RL). На нём языковая модель обучается генерировать такие ответы, которые имели бы наивысшую оценку относительно reward-модели. Про то, как делать RL, будет рассказано далее.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Языковые модели",
    "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
    "section_title": "ChatGPT",
    "text": "Одна из самых нашумевших языковых моделей в мире наследует логику обучения Instruct GPT. Основные отличия от последней заключаются в: Диалоговости. Модель обучена работать с диалогами, держать их в контексте и помнить историю того, что требовал пользователь. Обучение производится посредством сбора/написания диалоговых данных. Размере и качестве инструкционного датасета. Том, что больше внимания уделено разметке и обучению reward-модели и этапу с RL. К сожалению, OpenAI не предоставили детали обучения ChatGPT, а предложили лишь общий ход действий. Также неизвестны архитектурные параметры модели.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Языковые модели",
    "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
    "section_title": "Как обучить свою LLM?",
    "text": "Обсудим детально на примере доступных в open-source моделей семейства LLaMA. В качестве примера возьмём самую свежую архитектуру трансформеров на первую половину 2023 года —LLaMa, а также способы превращать её в чатовую модель, проводить Alignment на примереLLaMa-2. Вторая модель архитектурно не отличается от первой (кроме увеличенного контекста до 4096 токенов), поэтому содержание статей можно объединить в один рассказ. Для обучения с нуля качественной языковой модели необходимы: мощный кластер на сотни видеокарт, на котором можно производить параллельное обучение модели. Больше GPU — больше модель можно обучить и быстрее по времени обучения; терабайты текстовых данных для тренировки на них; архитектура, которая лучшим образом может моделировать язык. Поговорим подробнее о двух последних пунктах. Текстовые данные Текстовые данные можно брать из открытых источников, таких как CommonCrawl, C4, Taiga и прочее. Важно обеспечить: чистоту данных — например, убрать html-тэги, устранить дублирование текстов; полноту — чтобы модель одинаково хорошо решала математические задачи, писала код или сочиняла стихотворения, текстов соответствующих доменов должно быть в достатке в обучающем корпусе; разнообразие данных. Существуют эмпирические законы обученности модели, но здесь остановимся на числе пройденных за обучение токенов. В LLaMa-моделях это значение варьируется от 1T до 2Т. Ниже приведены основные параметры по числу размерности внутренних эмбедингов, числу голов Attention, слоёв и параметров обучения разных моделей: Архитектура У LLaMa-моделей предлагается целый ряд архитектурных изменений. Так как в учебнике рассматривался лишь базовая архитектура трансформеров, то опишем, что в ней необходимо изменить, чтобы получить LLaMa-модель. Pre-нормализация. ПустьТогда нелинейное преобразование в общем виде выглядит так: И LayerNorm можно описать следующими формулами: В свою очередь экспериментально RMSNorm демонстрирует лучшие результаты в сравнении с LayerNorm и высчитывается так: SwiGLU-активация используется вместо ReLU.— значок поэлементного умножения матриц. Роторные эмбединги. Информацию о том, в каком порядке следуют токены внутри модели, хранят в себе позиционные эмбединги. Они могут быть абсолютными (кодирование синусами и косинусами, как описано в параграфе отрансформерах) или относительными (кодируется расстояние между каждой парой токенов).Роторные эмбединги позволяют вычислять относительную связь между парой токенов на этапе вычисления Attention, также они выигрывают по сравнению с относительными в совместимости kernel-ов. То есть, одно из понятных не технических отличий их от других — вычисление позиционной информации на каждом слое модели при подсчёте Attention, а не только перед первым слоем. Это позволяет на каждом слое явно обрабатывать информацию об относительном расположении токенов. Роторные эмбединги показывают лучшее качество на многих задачах и являются стандартом для обучения языковых моделей. Подробнее о них можно почитать вэтой статье. Существуют также техники ускорения обучения моделей и оптимизации использования памяти, но с этим предлагаем читателям ознакомиться самостоятельно. Второй этап обучения инструкционных языковых моделей требует множество инструкций. Рецепт как их готовить был подробно описан всередине этого параграфа. Снова проговорим, что для написания инструкций или сбора датасета необходимо, чтобы инструкции были: разнообразными; качественными; имели одинаковый формат, чтобы чатовая модель могла обучиться диалоговости (где вопрос пользователя, где ее ответ); информативными; подробными; Chain-of-Thought (CoT),few-shotи так далее. Третий этап в создании инструкционных моделей. Есть несколько способов собрать датасет для обучения reward-модели. Он должен содержать тексты и метки к ним. Если меток много (например, в случае балльной оценки), можно использовать разновидностиранжирующих лоссов.Разберем способ обучения модели на бинарную оценку. Пусть модели подается на вход инструкция. Поменяв температуру, способ сэмплирования или использовав разные чек-пойнты модели, возможно получить два разнообразных ответаи. Не ограничивая общность, предположим, что, согласно некоторым предпочтениям, асессоры или пользователи установили, что первый ответ лучше второго. Проделаем эту операцию много раз и получим обучающее множество, состоящее из. Тогда reward-модель можно обучать минимизацией следующей функции потерь: Где: — reward-модель с обучаемыми параметрами тета; — некий margin, который определяет, насколько сильно модель должна отделять хороший и плохой ответы друг от друга. На четвёртом этапе, этапе выравнивания модели, можно воспользоваться разными алгоритмами. LLaMa-2 Chat была обучена последовательно сначала на Rejection Sampling fine-tuning (RL «для бедных») и Proximal Policy Optimization (PPO). Rejection Sampling fine-tuning. Этот подход основан на довольно простой стратегии. Пусть имеется инструкция. Сгенерируем для неёответов и выберем тот, который получает наивысшую оценку у reward-модели. График ниже демонстрирует, что чем больше, тем больше reward-score у лучшего ответа. Собрав парыинструкция — лучший ответ, можно обучить на них языковую модель и провести таким образом выравнивание поведения модели. Proximal Policy Optimization. Для лучшего понимания происходящего советуем прочесть параграф, посвященныйRL. Основная задача, как обычно, следовать некой политике, которая лучшим образом отражает human feedback. Политика — наша итоговая модель, value-функция оценивает средний reward в текущем состоянии (обычно это та же самая модель с линейным слоем поверх). Формализуем термины из RL для задачи выравнивания языковой модели: Политика— обучаемая языковая модель. Value-функция— обычно та же самая модель с линейным слоем поверх, оценивает средний reward, если действовать из состояниясогласно политике. — состояние в момент времени. Это весь контекст-токенов, которые модель успела сгенерировать к текущему моменту. — действие из текущего состояния в момент времени. Обозначает следующий токен, который будет сгенерирован. — траектория, т. е. тройки, — это состояния генерируемого токена и награды за него Сразу можно сделать вывод, что в языковых моделях, Также, в RL символомобозначается вся последовательность токенов, то есть на практике сюда можно подставлять количество сгенерированных токенов. Инициализируем— начальные веса политики и value-функции Для Соберем коллекцию траекторий, следуя политике. Посчитаем. Эта формула отражает разницу между финальной наградой за выбранное действиев текущем состояниии средней финальной наградой, которую можно было бы получить в этом состоянии. Вообще говоря, с помощью метода Generalized Advantage Estimation (GAE) её можно аппроксимировать следующим выражением: Обновляем веса политики согласно одному из лоссов PPO. Например, используем такой: С помощью MSE лосса оптимизируем значение value-функции:",
    "source_type": null,
    "useful_links": [
      {
        "text": "LLaMa",
        "url": "https://arxiv.org/pdf/2302.13971.pdf"
      },
      {
        "text": "LLaMa-2",
        "url": "https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/"
      },
      {
        "text": "трансформерах",
        "url": "https://academy.yandex.ru/handbook/ml/article/transformery"
      },
      {
        "text": "этой статье",
        "url": "https://arxiv.org/pdf/2104.09864v4.pdf"
      },
      {
        "text": "середине этого параграфа",
        "url": "https://academy.yandex.ru/handbook/ml/article/yazykovye-modeli#podvodki"
      },
      {
        "text": "ранжирующих лоссов.",
        "url": "https://gombru.github.io/2019/04/03/ranking_loss/"
      },
      {
        "text": "RL",
        "url": "https://academy.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem"
      },
      {
        "text": "GAE",
        "url": "https://arxiv.org/abs/1907.00456"
      }
    ]
  },
  {
    "document_title": "Языковые модели",
    "url": "https://education.yandex.ru/handbook/ml/article/yazykovye-modeli",
    "section_title": "Итог",
    "text": "Мы с вами обсудили, как развивались языковые модели, какие приёмы и техники необходимы для успешного обучения инструкционных моделей. Также на примере архитектуры LLaMa разобрали, как самостоятельно обучить языковые модели с нуля.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Регуляризация в онлайн-обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii",
    "section_title": "Идея неразложения регуляризаторов в субградиентную оценку",
    "text": "Вспомним вывод linearized FTRL. В ходе линеаризации мы заменяли все функциина их субградиентную оценку в точке. Для регуляризованного функционалаполучалась бы такая оценка: где черезмы обозначили для краткости субградиентв точке. Теперь субградиентную оценку можно подставить в метод FTRL: Идея неразложения состоит в следующем: заменим на субградиентную оценку только, а регуляризатор будем подбирать так, чтобы задача FTRL решалась аналитически. Интуитивно, оценка должна быть точнее оценки а значит, и метод оптимизации будет точнее и эффективнее. Эта идея очень важна для построения регуляризованных алгоритмов онлайн-обучения. Давайте выпишем, как будут выглядеть с учётом этой идеи регуляризованные алгоритмы. Composite Objective FTRL Online Mirror Descent, Proximal Gradient Descent, (F)ISTA Напомним, что три названия в заголовке соответствуют трём способам восприятия этой формулы: Online Mirror Descent — метод онлайн-обучения; Proximal Gradient Descent — метод (стохастической) батч-оптимизации. В стохастическом случае он неотличим от Mirror Descent; (F)ISTA — по сути, это название аналитического решения указанного уравнения для-регуляризации. В этом подразделе мы будем проводить рассуждения на примере-регуляритора. для других регуляризаторов выкладки будут аналогичными. Выпишем Proximal (он же Mirror) Gradient Descent с-регуляризацией: Необходимым условием минимума явняется равенство нулю градиента (а в данном случае субградиента) всего выражения: где- субградиент регуляризаторав точке. Отсюда получаем Если же переписать формулы в духе FTRL, мы получим Получился метод, который оптимизирует-регуляризатор в явном виде только на текущей итерации, а для остальных использует субоптимальные субградиентные оценки. Заметим, что тем же выражением можно ограничить сверху и функционал: Мы получили метод FTRL с incremental— более сильным и стабильным вариантом регуляризации, чем Mirror Descent. Подробнее его анализом мы займемся в параграфе про продвинутую-регуляризацию.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Регуляризация в онлайн-обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii",
    "section_title": "-регуляризация",
    "text": "Предположим, что мы хотим обучить модель минимального размера и при этом как можно лучшего качества. В этом нам поможет отбор параметров. А именно, давайте постараемся оставить только те из них, которые оказывают наиболее влияние на лосс. Определение. Будем называть параметрразреженным, если он не используется (пропускается) при предсказании некоторых. «Некоторых» может означать как десятую часть, так ипрогнозов, главное — что такие объекты просто есть. Частым мы будем называть параметр, у которого частота пропусков низкая (например,пропусков), а редким — тот, у которого она высокая (второй случай). Пример. Рассмотрим модель разреженной линейной регрессии. Обычно она применяется в ситуациях, когда элементы вектора признаков— этоили(например, «встретилось ли-е слово в-м документе»), причем на практике доля единиц обычно бывает очень маленькой. Поэтому существенная часть параметровпри прогнозе на шагебудет умножаться на нули и, таким образом, не будет использоваться. Обратите внимание: как правило, в литературе по онлайн-обучению говорят о разреженныхпараметрах, а не признаках. Впрочем, подавляющее большинство моделей на разреженных признаках устроены так, что каждому такому признаку сопоставляется некий набор параметров, поэтому определения «разреженный признак» и «разреженные параметры» взаимозаменяемы. В линейной модели, как в примере выше, каждому признакусопоставляется параметр. В более сложных моделях признакуможет сопоставляться вектор параметров— эмбеддинг этого признака. Давайте теперь поймём, что означает фраза «признак влияет на лосс». Оказывать влияние можно двумя способами: Качеством. Если параметрредкий, но очень хорошо прогнозирует свой небольшой набор объектов, его стоит оставить. За счет того, что мы оставим достаточное количество таких параметров, мы можем покрыть большое число объектов. Такие параметры называютсяmemorization parameters(они как будто запоминают «свои» объекты). Количеством. Если параметрчасто встречается, то он в любом случае должен остаться в модели и помогать с суммарным качеством прогноза. Убирать мы хотим только слабые и редкие параметры. Таких, как правило, больше. Обратите внимание: мы не хотим убиратьслабые, но часто встречающиеся параметры. Тому есть две причины: Места они много не занимают, а количества данных в large scale задачах достаточно, чтобы правильно выучить эти параметры. Они будут вносить свой, пусть и небольшой, вклад в общее качество; Частые параметры хорошо запоминают среднее поведение на всех данных, а разреженные — поведение на конкретных объектах. Если наша цель — оставить как можно меньше параметров, то выгоднее хорошо выучить среднее поведение на всех данных, а отклонения от среднего запомнить с помощью memorization parameters. Если в модели есть только супер-разреженные параметры, то из-за огромной вариативности в их возможных комбинациях в данных каждому параметру придется доучивать среднее поведение. Подробнее на этой проблеме мы остановимся в конце параграфа. В обучении разреженных моделей все параметры, на которые накладывается-регуляризация, инициализируются нулями. С точки зрения здравого смысла такая инициализация довольно естественна, однако есть и более формальное обоснование; Если параметры инициализируются нулями, то мы по мере обучения смотрим на градиенты этих параметров и в зависимости от градиентов принимаем решение, нужен нам параметр для прогноза или не нужен. Все параметры стартуют в равных условиях, и модель понемногу выходит из состояния «абсолютная разреженность», выучивая что-то содержательное. Если же параметры инициализируются случайно, то нам надо сначала доучить все параметры до какого-то более или менее разумного значения, а потом уже пытаться понять, нужен ли он нам. Момент, когда модель начинает эффективно разреживаться, тем самым очень сильно отдалается. Напомним формулировку задачи: Решение можно выписать в явном виде. Для этого введём следующие обозначения: будет аккумулировать сумму градиентов,, будет аккумулировать сумму поэлементных квадратов градиентов,, — это learning rate. Следующие формулы выписаны отдельно для каждой координаты. В них— индекс параметра модели,— номер итерации. Вывод этих формул хорошо расписан вконспекте курса Д. А. Кропотова. При регуляризаторев оптимизируемом функционале стоят коэффициенты, которые могут как-то зависеть от. Обычно рассматривают три вида зависимости: Fixed:. Squared incremental: Linear incremental: Их также можно комбинировать, получая коэффициенты регуляризации Напомним, что все весамы инициализируем нулями. По формуламиз нуля на шагевыводятся веса, для которых Таким образом,начальное условие выхода параметров из нуляимеет вид Попробуем понять физический смысл этого неравенства. Напоминание. Говорят, что функцияимеетлипшиц-непрерывныйградиент с константой, если Предположим, что это выполняется (ниже мы покажем, что это не слишком обременительное ограничение). Тогда, подставив в качестветочку оптимума функции(не путайте с глобальнымиз regret!), мы получим Это означает, что для достаточно хорошей функциинорма градиента является оценкой снизу на расстояние до точки оптимума в пространстве параметров. Чем больше норма градиента, тем дальше мы от оптимальных параметров. Вернемся к выражению. Здесь мы имеем дело (а) отдельно с каждой из координат и (б) с нормой суммы градиентов (а не с суммой норм). Хорошая новость: утверждение выше верно и для функций одной переменной, то есть, грубо говоря, показывает, насколько мы далеки от оптимума по-й координате. Знакговорит о том, в какую сторону мы будем сдвигаться по-й координатена-м шаге. Если сдвиги были в основном в одну сторону, тобудет больше, а если они всё время в разную сторону, то отдельные слагаемые могут скомпенсировать друг друга, иможет быть малым. Отметим ещё, что абсолютная величина компонентына первых итерациях может отражать прогнозирующую силу параметра: в самом деле, неверное значение важного для предсказания параметра может вести к большим ошибкам, что будет давать большие градиенты. Посмотрим теперь, как будет вести себя разреженная модель в зависимости от вида. Условие выходаиз нуля принимает вид что равносильно Ограничение на среднее значение компоненты градиента означает, что для выхода из нуля параметрдолжен иметь определённую прогнозирующую силу. Это противоречит нашему требованию о том, чтобы частые маломощные параметры все равно присутствовали в модели и выучивали среднее поведение. Обратите внимание. Выше мы показали, что проксимальный градиентный спуск с обычным в некотором смысле эквивалентен Composite-Objective FTRL с инкрементальным. Таким образом, обычная-регуляризация в классическом градиентном спуске эквивалентна именно инкрементальному, который, как мы выяснили, субоптимален. Ниже мы рассмотрим специфический для FTRL вариант-регуляризации, который лишен этих недостатков. Это самый мощный и полезный на практике режим. Здесь мы не нормируем на(то есть не берём среднее), и это означает, что выйти из нуля может и слабый, но частый параметр, который за много итераций накопит достаточно большую сумму частных производных. Свойства фильтрации с фиксированным регуляризатором в точности совпадают с продуктовыми требованиями: Редкий параметр с мощной прогнозирующей силой на старте будет иметь большие по модулю градиенты одного знака, и он выйдет из нуля; Редкий параметр с малой прогнозной силой не выйдет из нуля; Частые параметры в любом случае выйдут из нуля. Вэтой статьебыло теоретически обосновано, что если параметр частый, но нерелевантный и абсолютно шумный, то дисперсиябудет иметь асимптотику. Из этого следует, что, если сделать регуляризацию порядка, мы лишим такой случайный шум почти любых шансов выйти из нуля. К сожалению, ни в игрушечных примерах вроде Avazu, ни в продакшен задачах улучшений качества прогноза или степени разреживания модели без потери качества достичь не удалось. Возможно, вам повезет больше. Рассмотрим две линейных модели в которых все параметрыразреженные. Давайте считать, что в первой модели есть константный (и совсем даже не разреженный) признак, которому и соответствует параметр. Теперь в каждой из моделей наложим нарегуляризациюи сравним, что получится: В моделипараметрамнужно запомнить «отклонение» от среднего; В моделипараметрамнужно запомнить абсолютное значение предсказания. Нетрудно понятно, что при наличии bias нормы градиентов в первой модели в среднем будут намного меньше, потому что мы на каждом шаге оптимизации будем стартовать с точки, которая в среднем ближе к точке оптимума (bias и есть наше среднее). Поэтому меньше весов смогут преодолеть порог по модулю суммы градиентов и выйти из нуля. Таким образом, несмотря на одинаковый оптимум без регуляризации, при введении-регуляризации модель с bias будет обладать более хорошим соотношением разреженность/качество прогноза. Эта логика легко обобщается на более сложные случаи, когда вместо bias у нас есть неразреженные контентные признаки. Вывод такой: модели, в которых есть только очень разреженные параметры, обладают гораздо худшим соотношением разреженность/качество, чем модели, в которых есть и контентные, и разреженные параметры. Убедиться в этих эффектах мы сможем в разделе с практикой на линейных моделях.",
    "source_type": null,
    "useful_links": [
      {
        "text": "конспекте курса Д. А. Кропотова",
        "url": "http://www.machinelearning.ru/wiki/images/5/5b/MOMO12_sparse_methods.pdf"
      },
      {
        "text": "этой статье",
        "url": "http://www.opt-ml.org/papers/OPT2016_paper_24.pdf"
      }
    ]
  },
  {
    "document_title": "Регуляризация в онлайн-обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii",
    "section_title": "регуляризация",
    "text": "Рассмотрим обыкновенный SGD. Weight decayсостоит во введение штрафа на размер текущих весов: Внимательные читатели уже заметили, что в случае с SGD это эквивалентно введению-регуляризации. Давайте разберёмся, как это сделать правильно. Попробуем заменитьна и запустить любой адаптивный метод, например, AdaGrad. Если мы беспечно заменим на градиентную оценку всю функцию(забыв, что с регуляризатором этого делать не стоит), то алгоритм примет вид где В этих формулах нехороши две вещи: Коэффициентыинетривиальным образом взаимодействуют. Это крайне неудобно при переборе гиперпараметров: изменение learning rateдолжно влечь за собой переподбор коэффициента регуляризациипо полной сетке; В квадратах градиентов мы хотим видеть только адаптивность к кривизне самой функции, но теперь там ещё добавка. Эта проблема была впервые замечена вDecoupled weight decay regularization. Авторы также рассматривали влияние на momentum, к этому мы вернёмся в параграфе про AdamW. Авторы статьи предлагают модифицировать метод AdaGrad следующим образом: Сразу отметим сходство с исходными формулами weight decay — его и добивались авторы. Легко видеть, что формула описывает обыкновенный покоординатный градиентный спуск с некоторым линеаризованным-регуляризатором. Давайте «проинтегрируем» это выражение обратно до аргминимума, из которого бы получились такие формулы обновления весов: Получается, что decoupled weight decay — это адаптивный-centered регуляризатор. Его можно усовершенствовать, вспомним наше важное правило не заменять регуляризатор на субградиентную оценку. Перейдём к задаче Она отличается от предыдущей заменойна. Её решение имеет вид Поскольку мы меньше огрубляем оптимизируемый функционал, обучение может стать немного стабильнее. Обратите внимание, что в оптимизационной задаче у нас теперь стоит не просто, а. Теперь посмотрим, как decoupled weight decay будте работать с Composite-Objective FTRL. Линеаризованная задача имеет вид: Перепишем её: Нетрудно показать, что решение имеет вид Дляможно написать и явную формулу:. Замечание. Чтобы оценить Regret такого метода, мы не сможем механически воспользоваться оценкой для AdaGrad: ведь она базированась на оценке на Regret, выведенной либо для целиком Proximal, либо для целиком Centered-регуляризаторов. Composite objective из теоремы 10 тут не годится, так как Centered регуляризатор в этом случае не поедет в оценку норм градиентов, а мы в текущем представлении рассматриваем Proximal и Centered как равноправные члены. Интуитивно, мы должны применить Lemma 7 к обоим регуляризаторам и получить точно такую же оценку с такой же двойственной нормой (напомним, что centered и proximal регуляризаторы имеют одинаковую двойственную норму). Двойственная норма такая же ->формулы оптимального метода AdaGrad будут такие же. Мы оставляем это читателям в качестве упражнения.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Decoupled weight decay regularization",
        "url": "https://arxiv.org/pdf/1711.05101.pdf"
      }
    ]
  },
  {
    "document_title": "Регуляризация в онлайн-обучении",
    "url": "https://education.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii",
    "section_title": ": проекция на выпуклое множество",
    "text": "Напоминание: множествоназываетсявыпуклым, если Проекцией на это множество называют функцию Докажем, что— выпуклый регуляризатор. Для этого нам нужно проверить неравенство Единственный шанс, когда это может быть нарушено — это,,. Это значит, что, а, что противоречит выпуклости. Вернемся к формулам FTRL. Здесь ситуация сильно проще — от накидывания любых последовательностейна регуляризатор ничего не изменится, так что его всегда оставляют просто as is Аналитические решения для каждого виданужно искать отдельно. Примерно все решения получаются путем выносаиз оптимизируемого функционала и превращения его в ограничение, после чего можно применить метод множителей Лагранжа. Решим аналитически задачу проекции на шар Функция Лагранжа будет иметь вид а её градиент равен где- вектор, а— поэлементное умножение векторов. Приравнивая к нулю градиент, получаем где мы, как обычно, обозначили. Проанализируем условие дополняющей нежесткости. Если, то решениеуже находится внутри шара и имеет вид При практической реализации мы просто сначала посчитаем это выражение и проверим, не попадаем ли мы в шар. Если попадаем — отлично, если нет — то дальше говорим, чтои решаем продолжаем решение Теперь подставим это ви получим Получаем, что если мы находимся внутри шара, то мы действуем согласно обыкновенному adaptive алгоритму со всеми хорошими свойствами, иначе — проекция побеждает. Аналогичнорегуляризации, здесь тоже есть различия между lazy и greedy представлением этого регуляризатора. Однако, в классических DL задачах эти методы встречаются не слишком часто и здесь сложно привести какой-нибудь значимый успех, который мог бы улучшить качество в важной задача. Навскидку мы можем вспомнить разве что Adversatial White-Box learning, в котором можно было бы это попробовать.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
    "section_title": "Почему модели линейные?",
    "text": "Представьте, что у вас есть множество объектов, а вы хотели бы каждому объекту сопоставить какое-то значение. К примеру, у вас есть набор операций по банковской карте, а вы бы хотели, понять, какие из этих операций сделали мошенники. Если вы разделите все операции на два класса и нулём обозначите законные действия, а единицей мошеннические, то у вас получится простейшая задача классификации. Представьте другую ситуацию: у вас есть данные геологоразведки, по которым вы хотели бы оценить перспективы разных месторождений. В данном случае по набору геологических данных ваша модель будет, к примеру, оценивать потенциальную годовую доходность шахты. Это пример задачи регрессии. Числа, которым мы хотим сопоставить объекты из нашего множества иногда называют таргетами (от английскогоtarget). Таким образом, задачи классификации и регрессии можно сформулировать как поиск отображения из множества объектовв множество возможных таргетов. Математически задачи можно описать так: классификация:, где– номера классов, регрессия:. Очевидно, что просто сопоставить какие-то объекты каким-то числам — дело довольно бессмысленное. Мы же хотим быстро обнаруживать мошенников или принимать решение, где строить шахту. Значит нам нужен какой-то критерий качества. Мы бы хотели найти такое отображение, которое лучше всего приближает истинное соответствие между объектами и таргетами. Что значит «лучше всего» – вопрос сложный. Мы к нему будем много раз возвращаться. Однако, есть более простой вопрос: среди каких отображений мы будем искать самое лучшее? Возможных отображений может быть много, но мы можем упростить себе задачу и договориться, что хотим искать решение только в каком-то заранее заданном параметризированном семействе функций. Весь этот параграф будет посвящен самому простому такому семейству — линейным функциям вида где– целевая переменная (таргет),– вектор, соответствующий объекту выборки (вектор признаков), а– параметры модели. Признаки ещё называютфичами(от английскогоfeatures). Векторчасто называют вектором весов, так как на предсказание модели можно смотреть как на взвешенную сумму признаков объекта, а число– свободным коэффициентом, илисдвигом(bias). Более компактно линейную модель можно записать в виде Теперь, когда мы выбрали семейство функций, в котором будем искать решение, задача стала существенно проще. Мы теперь ищем не какое-то абстрактное отображение, а конкретный вектор. Замечание. Чтобы применять линейную модель, нужно, чтобы каждый объект уже был представлен вектором численных признаков. Конечно, просто текст или граф в линейную модель не положить, придётся сначала придумать для него численные фичи. Модель называют линейной, если она является линейной по этим численным признакам. Разберёмся, как будет работать такая модель в случае, если. То есть у наших объектов есть ровно один численный признак, по которому они отличаются. Теперь наша линейная модель будет выглядеть совсем просто:. Для задачи регрессии мы теперь пытаемся приблизить значение игрек какой-то линейной функцией от переменной икс. А что будет значить линейность для задачи классификации? Давайте вспомним про пример с поиском мошеннических транзакций по картам. Допустим, нам известна ровно одна численная переменная — объём транзакции. Для бинарной классификации транзакций на законные и потенциально мошеннические мы будем искать так называемоеразделяющее правило: там, где значение функции положительно, мы будем предсказывать один класс, где отрицательно – другой. В нашем примере простейшим правилом будет какое-то пороговое значение объёма транзакций, после которого есть смысл пометить транзакцию как подозрительную. В случае более высоких размерностей вместо прямой будет гиперплоскость с аналогичным смыслом. Вопрос на подумать. Если вы посмотрите содержание учебника, то не найдёте в нём ни «полиномиальных» моделей, ни каких-нибудь «логарифмических», хотя, казалось бы, зависимости бывают довольно сложными. Почему так? Вопрос на подумать. А как быть, если одна из фичей являетсякатегориальной, то есть принимает значения из (обычно конечного числа) значений, не являющихся числами? Например, это может быть время года, уровень образования, марка машины и так далее. Как правило, с такими значениями невозможно производить арифметические операции или же результаты их применения не имеют смысла. Помимо простоты, у линейных моделей есть несколько других достоинств. К примеру, мы можем достаточно легко судить, как влияют на результат те или иные признаки. Скажем, если весположителен, то с ростом-го признака таргет в случае регрессии будет увеличиваться, а в случае классификации наш выбор будет сдвигаться в пользу одного из классов. Значение весов тоже имеет прозрачную интерпретацию: чем весбольше, тем «важнее»-й признак для итогового предсказания. То есть, если вы построили линейную модель, вы неплохо можете объяснить заказчику те или иные её результаты. Это качество моделей называютинтерпретируемостью. Оно особенно ценится в индустриальных задачах, цена ошибки в которых высока. Если от работы вашей модели может зависеть жизнь человека, то очень важно понимать, как модель принимает те или иные решения и какими принципами руководствуется. При этом не все методы машинного обучения хорошо интерпретируемы, к примеру, поведение искусственных нейронных сетей или градиентного бустинга интерпретировать довольно сложно. В то же время слепо доверять весам линейных моделей тоже не стоит по целому ряду причин: Линейные модели всё-таки довольно узкий класс функций, они неплохо работают для небольших датасетов и простых задач. Однако, если вы решаете линейной моделью более сложную задачу, то вам, скорее всего, придётся выдумывать дополнительные признаки, являющиеся сложными функциями от исходных. Поиск таких дополнительных признаков называетсяfeature engineering, технически он устроен примерно так, как мы описали в вопросе про \"полиномиальные модели\". Вот только поиском таких искусственных фичей можно сильно увлечься, так что осмысленность интерпретации будет сильно зависеть от здравого смысла эксперта, строившего модель. Если между признаками есть приближённая линейная зависимость, коэффициенты в линейной модели могут совершенно потерять физический смысл (об этой проблеме и о том, как с ней бороться, мы поговорим дальше, когда будем обсуждать регуляризацию). Особенно осторожно стоит верить в утверждения вида «этот коэффициент маленький, значит, этот признак не важен». Во-первых, всё зависит от масштаба признака: вдруг коэффициент мал, чтобы скомпенсировать его. Во-вторых, зависимость действительно может быть слабой, но кто знает, в какой ситуации она окажется важна. Такие решения принимаются на основе данных, например, путём проверки статистического критерия (об этом мы коротко упомянем в разделе про вероятностные модели). Конкретные значения весов могут меняться в зависимости от обучающей выборки, хотя с ростом её размера они будут потихоньку сходиться к весам «наилучшей» линейной модели, которую можно было бы построить по всем-всем-всем данным на свете. Обсудив немного общие свойства линейных моделей, перейдём к тому, как их всё-таки обучать. Сначала разберёмся с регрессией, а затем настанет черёд классификации.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
    "section_title": "Линейная регрессия и метод наименьших квадратов (МНК)",
    "text": "Мы начнём с использования линейных моделей для решения задачи регрессии. Простейшим примером постановки задачи линейной регрессии являетсяметод наименьших квадратов(Ordinary least squares). Пусть у нас задан датасет, где– вектор значений целевой переменной, а– матрица объекты-признаки, в которой-я строка – это вектор признаков-го объекта выборки. Мы хотим моделировать зависимостьоткак линейную функцию со свободным членом. Общий вид такой функции изввыглядит следующим образом: Свободный членчасто опускают, потому что такого же результата можно добиться, добавив ко всемпризнак, тождественно равный единице; тогда роль свободного члена будет играть соответствующий ему вес: Поскольку это сильно упрощает запись, в дальнейшем мы будем считать, что это уже сделано и зависимость имеет вид просто. Мы хотим, чтобы на нашем датасете (то есть на парахиз обучающей выборки) функциякак можно лучше приближала нашу зависимость. Для того, чтобы чётко сформулировать задачу, нам осталось только одно: на математическом языке выразить желание «приблизитьк». Говоря простым языком, мы должны научиться измерять качество модели и минимизировать её ошибку, как-то меняя обучаемые параметры. В нашем примере обучаемые параметры — это веса. Функция, оценивающая то, как часто модель ошибается, традиционно называетсяфункцией потерь,функционалом качестваили простолоссом(loss function). Важно, чтобы её было легко оптимизировать: скажем, гладкая функция потерь – это хорошо, а кусочно постоянная – просто ужасно. Функции потерь бывают разными. От их выбора зависит то, насколько задачу в дальнейшем легко решать, и то, в каком смысле у нас получится приблизить предсказание модели к целевым значениям. Интуитивно понятно, что для нашей текущей задачи нам нужно взять вектори вектор предсказаний модели и как-то сравнить, насколько они похожи. Так как эти вектора «живут» в одном векторном пространстве, расстояние между ними вполне может быть функцией потерь. Более того, положительная непрерывная функция от этого расстояния тоже подойдёт в качестве функции потерь. При этом способов задать расстояние между векторами тоже довольно много. От всего этого разнообразия глаза разбегаются, но мы обязательно поговорим про это позже. Сейчас давайте в качестве лосса возьмём квадрат-нормы вектора разницы предсказаний модели и. Во-первых, как мы увидим дальше, так задачу будет нетрудно решить, а во-вторых, у этого лосса есть ещё несколько дополнительных свойств: -норма разницы – это евклидово расстояниемежду вектором таргетов и вектором ответов модели, то есть мы их приближаем в смысле самого простого и понятного «расстояния». Как мы увидим в разделе про вероятностные модели, с точки зрения статистики это соответствует гипотезе о том, что наши данные состоят из линейного «сигнала» и нормально распределенного «шума». Так вот, наша функция потерь выглядит так: Такой функционал ошибки не очень хорош для сравнения поведения моделей на выборках разного размера. Представьте, что вы хотите понять, насколько качество модели на тестовой выборке изобъектов хуже, чем на обучающей изобъектов. Вы измерили-норму ошибки и получили в одном случае, а в другом. Эти числа не очень интерпретируемы. Гораздо лучше посмотреть на среднеквадратичное отклонение По этой метрике на тестовой выборке получаем, а на обучающей. Функция потерьназываетсяMean Squared Error,MSEилисреднеквадратическим отклонением. Разница с-нормой чисто косметическая, на алгоритм решения задачи она не влияет: В самом широком смысле, функции работают с объектами множеств: берут какой-то входящий объект из одного множества и выдают на выходе соответствующий ему объект из другого. Если мы имеем дело с отображением, которое на вход принимает функции, а на выходе выдаёт число, то такое отображение называютфункционалом. Если вы посмотрите на нашу функцию потерь, то увидите, что это именно функционал. Для каждой конкретной линейной функции, которую задают веса, мы получаем число, которое оценивает, насколько точно эта функция приближает наши значения. Чем меньше это число, тем точнее наше решение, значит для того, чтобы найти лучшую модель, этот функционал нам надо минимизировать по: Эту задачу можно решать разными способами. В этом параграфе мы сначала решим эту задачу аналитически, а потом приближенно. Сравнение двух этих решений позволит нам проиллюстрировать преимущества того подхода, которому посвящена эта книга. На наш взгляд, это самый простой способ \"на пальцах\" показать суть машинного обучения. Точку минимума можно найти разными способами. Если вам интересно аналитическое решение, вы можете найти его в параграфе про матричные дифференцирования (раздел «Примеры вычисления производных сложных функций»). Здесь же мы воспользуемся геометрическим подходом. Пусть– столбцы матрицы, то есть столбцы признаков. Тогда и задачу регрессии можно сформулировать следующим образом:найти линейную комбинацию столбцов, которая наилучшим способом приближает столбецпо евклидовой норме – то естьнайтипроекциювекторана подпространство, образованное векторами. Разложим, где– та самая проекция, а– ортогональная составляющая, то есть. Как это можно выразить в матричном виде? Оказывается, очень просто: В самом деле, каждый элемент столбца– это скалярное произведение строки(=столбца= одного из) на. Из уравненияуже очень легко выразить: Вопрос на подуматьДля вычислениянам приходится обращать (квадратную) матрицу, что возможно, только если она невырождена. Что это значит с точки зрения анализа данных? Почему мы верим, что это выполняется во всех разумных ситуациях? Вычислительная сложность аналитического решения —, где— длина выборки,— число признаков у одного объекта. Слагаемоеотвечает за сложность перемножения матрици, а слагаемое— за сложность обращения их произведения. Перемножать матрицыине стоит. Гораздо лучше сначала умножитьна, а затем полученный вектор на: так будет быстрее и, кроме того, не нужно будет хранить матрицу. Вычисление можно ускорить, используя продвинутые алгоритмы перемножения матриц или итерационные методы поиска обратной матрицы. Заметим, что для получения ответа нам нужно обратить матрицу. Это создает множество проблем: Основная проблема в обращении матрицы — это то, что вычислительно обращать большие матрицы дело сложное, а мы бы хотели работать с датасетами, в которых у нас могут быть миллионы точек, Матрица, хотя почти всегда обратима в разумных задачах машинного обучения, зачастую плохо обусловлена. Особенно если признаков много, между ними может появляться приближённая линейная зависимость, которую мы можем упустить на этапе формулировки задачи. В подобных случаях погрешность нахождениябудет зависеть от квадратачисла обусловленностиматрицы, что очень плохо. Это делает полученное таким образом решение численно неустойчивым: малые возмущениямогут приводить к катастрофическим изменениям. Полностью вылечить проблемы мы не сможем, но никто и не обязывает нас останавливаться на «точном» решении (которое всё равно никогда не будет вполне точным). Поэтому ниже мы познакомим вас с совершенно другим методом. Минимизируемый функционал является гладким и выпуклым, а это значит, что можно эффективно искать точку его минимума с помощью итеративных градиентных методов. Более подробно вы можете прочитать о них в разделе про методы оптимизации, а здесь мы лишь коротко расскажем об одном самом базовом подходе. Как известно, градиент функции в точке направлен в сторону её наискорейшего роста, а антиградиент (противоположный градиенту вектор) в сторону наискорейшего убывания. То есть имея какое-то приближение оптимального значения параметра, мы можем его улучшить, посчитав градиент функции потерь в точке и немного сдвинув вектор весов в направлении антиградиента: где– это параметр алгоритма («темп обучения»), который контролирует величину шага в направлении антиградиента. Описанный алгоритм называетсяградиентным спуском. Посмотрим, как будет выглядеть градиентный спуск для функции потерь. Градиент квадрата евклидовой нормы мы уже считали; соответственно, Следовательно, стартовав из какого-то начального приближения, мы можем итеративно уменьшать значение функции, пока не сойдёмся (по крайней мере в теории) к минимуму (вообще говоря, локальному, но в данном случае глобальному). Алгоритм градиентного спуска Скопировать код1w = random_normal()# можно пробовать и другие виды инициализации2repeat S times:# другой вариант: while abs(err) >tolerance3f = X.dot(w)# посчитать предсказание4err = f - y# посчитать ошибку5grad =2* X.T.dot(err) / N# посчитать градиент6w -= alpha * grad# обновить веса С теоретическими результатами о скорости и гарантиях сходимости градиентного спуска вы можете познакомиться в параграфе прометоды оптимизации. Мы позволим себе лишь несколько общих замечаний: Поскольку задача выпуклая, выбор начальной точки влияет на скорость сходимости, но не настолько сильно, чтобы на практике нельзя было стартовать всегда из нуля или из любой другой приятной вам точки; Число обусловленности матрицысущественно влияет на скорость сходимости градиентного спуска: чем более вытянуты эллипсоиды уровня функции потерь, тем хуже; Темп обучениятоже сильно влияет на поведение градиентного спуска; вообще говоря, он является гиперпараметром алгоритма, и его, возможно, придётся подбирать отдельно. Другими гиперпараметрами являются максимальное число итерацийи/или порог tolerance. Вычислительная сложность градиентного спуска –, где, как и выше,– длина выборки,– число признаков у одного объекта. Сравните с оценкойдля «наивного» вычисления аналитического решения. Сложность по памяти –на хранение выборки. В памяти мы держим и выборку, и градиент, но в большинстве реалистичных сценариев доминирует выборка. На каждом шаге градиентного спуска нам требуется выполнить потенциально дорогую операцию вычисления градиента по всей выборке (сложность). Возникает идея заменить градиент его оценкой на подвыборке (в английской литературе такую подвыборку обычно именуютbatchилиmini-batch; в русской разговорной терминологии тоже часто встречается словобатчилимини-батч). А именно, если функция потерь имеет вид суммы по отдельным парам объект-таргет а градиент, соответственно, записывается в виде то предлагается брать оценку для некоторого подмножества этих пар. Обратите внимание на множителииперед суммами. Почему они нужны? Полный градиентможно воспринимать как среднее градиентов по всем объектам, то есть как оценку матожидания; тогда, конечно, оценка матожидания по меньшей подвыборке тоже будет иметь вид среднего градиентов по объектам этой подвыборки. Как делить выборку на батчи? Ясно, что можно было бы случайным образом сэмплировать их из полного датасета, но даже если использовать быстрый алгоритм вроде резервуарного сэмплирования, сложность этой операции не самая оптимальная. Поэтому используют линейный проход по выборке (которую перед этим лучше всё-таки случайным образом перемешать). Давайте введём ещё один параметр нашего алгоритма: размер батча, который мы обозначим. Теперь наочередных примерах вычислим градиент и обновим веса модели. При этом вместо количества шагов алгоритма обычно задают количествоэпох. Это ещё один гиперпараметр. Одна эпоха – это один полный проход нашего сэмплера по выборке. Заметим, что если выборка очень большая, а модель компактная, то даже первый проход бывает можно не заканчивать. Алгоритм: Скопировать код1w = normal(0,1)2repeat E times:3fori = B, i <= n, i += B4X_batch = X[i-B : i]5y_batch = y[i-B : i]6f = X_batch.dot(w)# посчитать предсказание7err = f - y_batch# посчитать ошибку8grad =2* X_batch.T.dot(err) / B# посчитать градиент9w -= alpha * grad10 Сложность по времени –. На первый взгляд, она такая же, как и у обычного градиентного спуска, но заметим, что мы сделали враз больше шагов, то есть веса модели претерпели намного больше обновлений. Сложность по памяти можно довести до: ведь теперь всю выборку не надо держать в памяти, а достаточно загружать лишь текущий батч (а остальная выборка может лежать на диске, что удобно, так как в реальности задачи, в которых выборка целиком не влезает в оперативную память, встречаются сплошь и рядом). Заметим, впрочем, что при этом лучше бывзять побольше: ведь чтение с диска – намного более затратная по времени операция, чем чтение из оперативной памяти. В целом, разницу между алгоритмами можно представлять как-то так: Шаги стохастического градиентного спуска заметно более шумные, но считать их получается значительно быстрее. В итоге они тоже сходятся к оптимальному значению из-за того, что матожидание оценки градиента на батче равно самому градиенту. По крайней мере, сходимость можно получить при хорошо подобранных коэффициентах темпа обучения в случае выпуклого функционала качества. Подробнее мы об этом поговорим впараграфе про оптимизацию. Для сложных моделей и лоссов стохастический градиентный спуск может сходиться плохо или застревать в локальных минимумах, поэтому придумано множество его улучшений. О некоторых из них также рассказано впараграфе про оптимизацию. Существует определённая терминологическая путаница, иногда стохастическим градиентным спуском называют версию алгоритма, в которой размер батча равен единице (то есть максимально шумная и быстрая версия алгоритма), а версии с бОльшим размером батча называютbatch gradient descent. В книгах, которые, возможно, старше вас, такая процедура иногда ещё называется incremental gradient descent. Это не очень принципиально, но вы будьте готовы, если что. Вопрос на подумать. Вообще говоря, если объём данных не слишком велик и позволяет это сделать, объекты лучше случайным образом перемешивать перед тем, как подавать их в алгоритм стохастического градиентного спуска. Как вам кажется, почему? Также можно использовать различные стратегии отбора объектов. Например, чаще брать объекты, на которых ошибка больше. Какие ещё стратегии вы могли бы придумать? После прочтения этой главы у вас может сложиться ощущение, что приближённые способы решения ML задач и градиентные методы – это одно и тоже, но вы будете правы в этом только на 98%. В принципе, существуют и другие способы численно решать эти задачи, но в общем случае они работают гораздо хуже, чем градиентный спуск, и не обладают таким хорошим теоретическим обоснованием. Мы не будем рассказывать про них подробно, но можете на досуге почитать, скажем, про Stepwise regression, Orthogonal matching pursuit или LARS. У LARS, кстати, есть довольно интересное свойство: он может эффективно работать на выборках, в которых число признаков больше числа примеров. С алгоритмом LARS вы можете познакомиться впараграфе про оптимизацию.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Примеры вычисления производных сложных функций",
        "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie#primery-vychisleniya-proizvodnyh-slozhnyh-funkczij"
      },
      {
        "text": "числа обусловленности",
        "url": "https://ru.wikipedia.org/wiki/%D0%A7%D0%B8%D1%81%D0%BB%D0%BE_%D0%BE%D0%B1%D1%83%D1%81%D0%BB%D0%BE%D0%B2%D0%BB%D0%B5%D0%BD%D0%BD%D0%BE%D1%81%D1%82%D0%B8"
      },
      {
        "text": "методы оптимизации",
        "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning"
      },
      {
        "text": "параграфе про оптимизацию",
        "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning"
      },
      {
        "text": "параграфе про оптимизацию",
        "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning"
      },
      {
        "text": "параграфе про оптимизацию",
        "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning"
      }
    ]
  },
  {
    "document_title": "Линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
    "section_title": "Регуляризация",
    "text": "Всегда ли решение задачи регрессии единственно? Вообще говоря, нет. Так, если в выборке два признака будут линейно зависимы (и следовательно, ранг матрицы будет меньше), то гарантировано найдётся такой вектор весовчто. В этом случае, если какой-тоявляется решением оптимизационной задачи, то итоже является решением для любого. То есть решение не только не обязано быть уникальным, так ещё может быть сколь угодно большим по модулю. Это создаёт вычислительные трудности. Малые погрешности признаков сильно возрастают при предсказании ответа, а в градиентном спуске накапливается погрешность из-за операций со слишком большими числами. Конечно, в жизни редко бывает так, что признаки строго линейно зависимы, а вот быть приближённо линейно зависимыми они вполне могут быть. Такая ситуация называетсямультиколлинеарностью. В этом случае у нас, всё равно, возникают проблемы, близкие к описанным выше. Дело в том, чтодля вектора, состоящего из коэффициентов приближённой линейной зависимости, и, соответственно,, то есть матрицаснова будет близка к вырожденной. Как и любая симметричная матрица, она диагонализуется в некотором ортонормированном базисе, и некоторые из собственных значенийблизки к нулю. Если векторв выражениибудет близким к соответствующему собственному вектору, то он будет умножаться на, что опять же приведёт к появлению уочень больших по модулю компонент (при этомещё и будет вычислен с большой погрешностью из-за деления на маленькое число). И, конечно же, все ошибки и весь шум, которые имелись в матрице, при вычислениибудут умножаться на эти большие и неточные числа и возрастать во много-много раз, что приведёт к проблемам, от которых нас не спасёт никакое сингулярное разложение. Важно ещё отметить, что в случае, когда несколько признаков линейно зависимы, весапри них теряют физический смысл. Может даже оказаться, что вес признака, с ростом которого таргет, казалось бы, должен увеличиваться, станет отрицательным. Это делает модель не только неточной, но и принципиально не интерпретируемой. Вообще, неадекватность знаков или величины весов – хорошее указание на мультиколлинеарность. Для того, чтобы справиться с этой проблемой, задачу обычнорегуляризуют, то есть добавляют к ней дополнительное ограничение на вектор весов. Это ограничение можно, как и исходный лосс, задавать по-разному, но, как правило, ничего сложнее, чем- и-нормы, не требуется. Вместо исходной задачи теперь предлагается решить такую: – это очередной параметр, а– это один из двух вариантов: или Добавканазываетсярегуляризационным членомилирегуляризатором, а число–коэффициентом регуляризации. Коэффициентявляется гиперпараметром модели и достаточно сильно влияет на качество итогового решения. Его подбирают по логарифмической шкале (скажем, от1e-2до1e+2), используя для сравнения моделей с разными значениямидополнительную валидационную выборку. При этом качество модели с подобранным коэффициентом регуляризации уже проверяют на тестовой выборке, чтобы исключить переобучение. Более подробно о том, как нужно подбирать гиперпараметры, вы можете почитать всоответствующем параграфе. Отдельно надо договориться о том, что вес, соответствующий отступу от начала координат (то есть признаку из всех единичек), мы регуляризовать не будем, потому что это не имеет смысла: если даже все значенияравномерно велики, это не должно портить качество обучения. Обычно это не отображают в формулах, но если придираться к деталям, то стоило бы написать сумму по всем весам, кроме: В случае-регуляризации решение задачи изменяется не очень сильно. Например, продифференцировав новый лосс по, легко получить, что «точное» решение имеет вид: Отметим, что за этой формулой стоит и понятная численная интуиция: раз матрицаблизка к вырожденной, то обращать её сродни самоубийству. Мы лучше слегка исказим её добавкой, которая увеличит все собственные значения на, отодвинув их от нуля. Да, аналитическое решение перестаёт быть «точным», но за счёт снижения численных проблем мы получим более качественное решение, чем при использовании «точной» формулы. В свою очередь, градиент функции потерь по весам теперь выглядит так: Подставив этот градиент в алгоритм стохастического градиентного спуска, мы получаем обновлённую версию приближенного алгоритма, отличающуюся от старой только наличием дополнительного слагаемого. Вопрос на подумать. Рассмотрим стохастический градиентный спуск для-регуляризованной линейной регрессии с батчами размера. Выберите правильный вариант шага SGD: (а); (б); (в). Вопрос на подумать. Распишите процедуру стохастического градиентного спуска для-регуляризованной линейной регрессии. Как вам кажется, почему никого не волнует, что функция потерь, строго говоря, не дифференцируема? Отметим, что- и-регуляризацию можно определять для любой функции потерь(и не только в задаче регрессии, а и, например, в задаче классификации тоже). Новая функция потерь будет соответственно равна или -регуляризация работает прекрасно и используется в большинстве случаев, но есть одна полезная особенность-регуляризации: её применение приводит к тому, что у признаков, которые не оказывают большого влияния на ответ, вес в результате оптимизации получается равным. Это позволяет удобным образом удалять признаки, слабо влияющие на таргет. Кроме того, это даёт возможность автоматически избавляться от признаков, которые участвуют в соотношениях приближённой линейной зависимости, соответственно, спасает от проблем, связанных с мультиколлинеарностью, о которых мы писали выше. Не очень строгим, но довольно интуитивным образом это можно объяснить так: В точке оптимума линии уровня регуляризационного члена касаются линий уровня основного лосса, потому что, во-первых, и те, и другие выпуклые, а во-вторых, если они пересекаются трансверсально, то существует более оптимальная точка: Линии уровня-нормы – это-мерные октаэдры. Точки их касания с линиями уровня лосса, скорее всего, лежат на грани размерности, меньшей, то есть как раз в области, где часть координат равна нулю: Заметим, что данное построение говорит о том, как выглядит оптимальное решение задачи, но ничего не говорит о способе, которым это решение можно найти. На самом деле, найти такой оптимум непросто: умеры довольно плохая производная. Однако, способы есть. Можете на досуге прочитать, например,вот эту статьюо том, как работало предсказание CTR в google в 2012 году. Там этой теме посвящается довольно много места. Кроме того, рекомендуем посмотреть про проксимальные методы в разделе этой книги про оптимизацию в ML. Заметим также, что вообще-то оптимизация любой нормы, приведёт к появлению разреженных векторов весов, просто если cещё хоть как-то можно работать, то с остальными всё будет ещё сложнее.",
    "source_type": null,
    "useful_links": [
      {
        "text": "соответствующем параграфе",
        "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov"
      },
      {
        "text": "вот эту статью",
        "url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41159.pdf"
      }
    ]
  },
  {
    "document_title": "Линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
    "section_title": "Другие лоссы",
    "text": "Стохастический градиентный спуск можно очевидным образом обобщить для решения задачи линейной регрессии с любой другой функцией потерь, не только квадратичной: ведь всё, что нам нужно от неё, – это чтобы у функции потерь был градиент. На практике это делают редко, но тем не менее рассмотрим ещё пару вариантов. Mean absolute error, абсолютная ошибка, появляется при замененормы в MSE на: Можно заметить, что в MAE по сравнению с MSE существенно меньший вклад в ошибку будут вносить примеры, сильно удалённые от ответов модели. Дело тут в том, что в MAE мы считаем модуль расстояния, а не квадрат, соответственно, вклад больших ошибок в MSE получается существенно больше. Такая функция потерь уместна в случаях, когда вы пытаетесь обучить регрессию на данных с большим количеством выбросов в таргете. Иначе на эту разницу можно посмотреть так: MSE приближает матожидание условного распределения, а MAE – медиану. Mean absolute percentage error, относительная ошибка. Часто используется в задачах прогнозирования (например, погоды, загруженности дорог, кассовых сборов фильмов, цен), когда ответы могут быть различными по порядку величины, и при этом мы бы хотели верно угадать порядок, то есть мы не хотим штрафовать модель за предсказание 2000 вместо 1000 в разы сильней, чем за предсказание 2 вместо 1. Вопрос на подумать. Кроме описанных выше в задаче линейной регрессии можно использовать и другие функции потерь, например,Huber loss: Числоявляется гиперпараметром. Сложная формула принужна, чтобы функциябыла непрерывной. Попробуйте объяснить, зачем может быть нужна такая функция потерь.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
    "section_title": "Линейная классификация",
    "text": "Теперь давайте поговорим про задачу классификации. Для начала будем говорить про бинарную классификацию на два класса. Обобщить эту задачу до задачи классификации наклассов не составит большого труда. Пусть теперь наши таргетыкодируют принадлежность к положительному или отрицательному классу, то есть принадлежность множеству(в этом параграфе договоримся именно так обозначать классы, хотя в жизни вам будут нередко встречаться и метки), а– по-прежнему векторы из. Мы хотим обучить линейную модель так, чтобы плоскость, которую она задаёт, как можно лучше отделяла объекты одного класса от другого. В идеальной ситуации найдётся плоскость, которая разделит классы: положительный окажется с одной стороны от неё, а отрицательный с другой. Выборка, для которой это возможно, называетсялинейно разделимой. Увы, в реальной жизни такое встречается крайне редко. Как обучить линейную модель классификации, нам ещё предстоит понять, но уже ясно, что итоговое предсказание можно будет вычислить по формуле Сконструируем теперь функционал ошибки так, чтобы он вышеперечисленными проблемами не обладал. Мы хотим минимизировать число ошибок классификатора, то есть Домножим обе части наи немного упростим Величинаназываетсяотступом(margin) классификатора. Такая фунция потерь называетсяmisclassification loss. Легко видеть, что отступ положителен, когда, то есть класс угадан верно; при этом чем больше отступ, тем больше расстояние отдо разделяющей гиперплоскости, то есть «уверенность классификатора»; отступ отрицателен, когда, то есть класс угадан неверно; при этом чем больше по модулю отступ, тем более сокрушительно ошибается классификатор. От каждого из отступов мы вычисляем функцию Она кусочно-постоянная, и из-за этого всю сумму невозможно оптимизировать градиентными методами: ведь её производная равна нулю во всех точках, где она существует. Но мы можем мажорировать её какой-нибудь более гладкой функцией, и тогда задачу можно будет решить. Функции можно использовать разные, у них свои достоинства и недостатки, давайте рассмотрим несколько примеров: Вопрос на подумать. Допустим, мы как-то обучили классификатор, и подавляющее большинство отступов оказались отрицательными. Правда ли нас постигла катастрофа? Вопрос на подумать. Предположим, что у нас есть два классификатора с примерно одинаковыми и достаточно приемлемыми значениями интересующей нас метрики. При этом одна почти всегда выдаёт предсказания с большими по модулю отступами, а вторая – с относительно маленькими. Верно ли, что первая модель лучше, чем вторая? Реализуем простейшую идею: давайте считать отступы только на неправильно классифицированных объектах и учитывать их не бинарно, а линейно, пропорционально их размеру. Получается такая функция: Давайте запишем такой лосс с-регуляризацией: Найдём градиент: Имея аналитическую формулу для градиента, мы теперь можем так же, как и раньше, применить стохастический градиентный спуск, и задача будет решена. Данная функция потерь впервые была предложена для перцептрона Розенблатта, первой вычислительной модели нейросети, которая в итоге привела к появлению глубокого обучения. Она решает задачу линейной классификации, но у неё есть одна особенность: её решение не единственно и сильно зависит от начальных параметров. Например, все изображённые ниже классификаторы имеют одинаковый нулевой лосс: Для таких случаев, как на картинке выше, возникает логичное желание не только найти разделяющую прямую, но и постараться провести её на одинаковом удалении от обоих классов, то есть максимизировать минимальный отступ: Это можно сделать, слегка поменяв функцию ошибки, а именно положив её равной: Почему же добавленная единичка приводит к желаемому результату? Интуитивно это можно объяснить так: объекты, которые проклассифицированы правильно, но не очень \"уверенно\" (то есть), продолжают вносить свой вклад в градиент и пытаются \"отодвинуть\" от себя разделяющую плоскость как можно дальше. К данному выводу можно прийти и чуть более строго; для этого надо совершенно по-другому взглянуть на выражение, которое мы минимизируем. Поможет вот эта картинка: Если мы максимизируем минимальный отступ, то надо максимизировать, то есть ширину полосы при условии того, что большинство объектов лежат с правильной стороны, что эквивалентно решению нашей исходной задачи: Отметим, что первое слагаемое у нас обратно пропорционально ширине полосы, но мы и максимизацию заменили на минимизацию, так что тут всё в порядке. Второе слагаемое – это штраф за то, что некоторые объекты неправильно расположены относительно разделительной полосы. В конце концов, никто нам не обещал, что классы наши линейно разделимы и можно провести оптимальную плоскость вообще без ошибок. Итоговое положение плоскости задаётся всего несколькими обучающими примерами. Это ближайшие к плоскости правильно классифицированные объекты, которые называютопорными векторамиилиsupport vectors. Весь метод, соответственно, зовётся методомопорных векторов, илиsupport vector machine, или сокращённоSVM. Начиная с шестидесятых годов это был сильнейший из известных методов машинного обучения. В девяностые его сменили методы, основанные на деревьях решений, которые, в свою очередь, недавно передали «пальму первенства» нейросетям. Почему же SVM был столь популярен? Из-за небольшого количества параметров и доказуемой оптимальности. Сейчас для нас нормально выбирать специальный алгоритм под задачу и подбирать оптимальные гиперпараметры для этого алгоритма перебором, а когда-то трава была зеленее, а компьютеры медленнее, и такой роскоши у людей не было. Поэтому им нужны были модели, которые гарантированно неплохо работали бы в любой ситуации. Такой моделью и был SVM. Другие замечательные свойства SVM: существование уникального решения и доказуемо минимальная склонность к переобучению среди всех популярных классов линейных классификаторов. Кроме того, несложная модификация алгоритма, ядровый SVM, позволяет проводить нелинейные разделяющие поверхности. Строгий вывод постановки задачи SVM можно прочитатьтутилив лекции К.В. Воронцова. В этом параграфе мы будем обозначать классы нулём и единицей. Ещё один интересный метод появляется из желания посмотреть на классификацию как на задачу предсказания вероятностей. Хороший пример – предсказание кликов в интернете (например, в рекламе и поиске). Наличие клика в обучающем логе не означает, что, если повторить полностью условия эксперимента, пользователь обязательно кликнет по объекту опять. Скорее у объектов есть какая-то \"кликабельность\", то есть истинная вероятность клика по данному объекту. Клик на каждом обучающем примере является реализацией этой случайной величины, и мы считаем, что в пределе в каждой точке отношение положительных и отрицательных примеров должно сходиться к этой вероятности. Проблема состоит в том, что вероятность, по определению, величина от 0 до 1, а простого способа обучить линейную модель так, чтобы это ограничение соблюдалось, нет. Из этой ситуации можно выйти так: научить линейную модель правильно предсказывать какой-то объект, связанный с вероятностью, но с диапазоном значений, и преобразовать ответы модели в вероятность. Таким объектом являетсяlogitилиlog odds– логарифм отношения вероятности положительного события к отрицательному. Если ответом нашей модели является, то искомую вероятность посчитать не трудно: Функция в правой части называетсясигмоидойи обозначается Таким образом, Как теперь научиться оптимизироватьтак, чтобы модель как можно лучше предсказывала логиты? Нужно применить метод максимума правдоподобия для распределения Бернулли. Это самое простое распределение, которое возникает, к примеру, при бросках монетки, которая орлом выпадает с вероятностью. У нас только событием будет не орёл, а то, что пользователь кликнул на объект с такой вероятностью. Если хотите больше подробностей, почитайте про распределение Бернулли в теоретическом минимуме. Правдоподобие позволяет понять, насколько вероятно получить данные значения таргетапри данныхи весах. Оно имеет вид и для распределения Бернулли его можно выписать следующим образом: где– это вероятность, посчитанная из ответов модели. Оптимизировать произведение неудобно, хочется иметь дело с суммой, так что мы перейдём к логарифмическому правдоподобию и подставим формулу для вероятности, которую мы получили выше: Если заметить, что то выражение можно переписать проще: Нас интересует, для которого правдоподобие максимально. Чтобы получить функцию потерь, которую мы будемминимизировать, умножим его на минус один: В отличие от линейной регрессии, для логистической нет явной формулы решения. Деваться некуда, будем использовать градиентный спуск. К счастью, градиент устроен очень просто: Предсказание модели будет вычисляться, как мы договаривались, следующим образом: Это вероятность положительного класса, а как от неё перейти к предсказанию самого класса? В других методах нам достаточно было посчитать знак предсказания, но теперь все наши предсказания положительные и находятся в диапазоне от 0 до 1. Что же делать? Интуитивным и не совсем (и даже совсем не) правильным является ответ «взять порог 0.5». Более корректным будет подобрать этот порог отдельно, для уже построенной регрессии минимизируя нужную вам метрику на отложенной тестовой выборке. Например, сделать так, чтобы доля положительных и отрицательных классов примерно совпадала с реальной. Отдельно заметим, что метод называется логистическойрегрессией, а не логистическойклассификациейименно потому, что предсказываем мы не классы, а вещественные числа – логиты. Вопрос на подумать. Проверьте, что, если метки классов – это, а неи, то функцию потерь для логистической регрессии можно записать в более компактном виде: Вопрос на подумать. Правда ли разделяющая поверхность модели логистической регрессии является гиперплоскостью? Вопрос на подумать. Допустим, что матрица объекты-признакиимеет полный ранг по столбцам (то есть все её столбцы линейно независимы). Верно ли, что решение задачи восстановления логистической регрессии единственно? Вопрос на подумать. На картинке ниже представлены результаты работы на одном и том же датасете трёх моделей логистической регрессии с разными коэффициентами-регуляризации: Наверху показаны предсказанные вероятности положительного класса, внизу – вид разделяющей поверхности. Как вам кажется, какие картинки соответствуют самому большому коэффициенту регуляризации, а какие – самому маленькому? Почему?",
    "source_type": null,
    "useful_links": [
      {
        "text": "тут",
        "url": "https://www.mit.edu/~9.520/spring08/Classes/class05.pdf"
      },
      {
        "text": "в лекции К.В. Воронцова",
        "url": "http://machinelearning.ru/wiki/images/archive/a/a0/20150316112120!Voron-ML-Lin-SVM.pdf"
      }
    ]
  },
  {
    "document_title": "Линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
    "section_title": "Многоклассовая классификация",
    "text": "В этом разделе мы будем следовать изложениюиз лекций Евгения Соколова. Пусть каждый объект нашей выборки относится к одному изклассов:. Чтобы предсказывать эти классы с помощью линейных моделей, нам придётся свести задачу многоклассовой классификации к набору бинарных, которые мы уже хорошо умеем решать. Мы разберём два самых популярных способа это сделать – one-vs-all и all-vs-all, а проиллюстрировать их нам поможет вот такой игрушечный датасет Обучимлинейных классификаторов, выдающих оценки принадлежности классамсоответственно. В случае с линейными моделями эти классификаторы будут иметь вид Классификатор с номеромбудем обучать по выборке; иными словами, мы учим классификатор отличать-й класс от всех остальных. Логично, чтобы итоговый классификатор выдавал класс, соответствующий самому уверенному из бинарных алгоритмов. Уверенность можно в каком-то смысле измерить с помощью значений линейных функций: Давайте посмотрим, что даст этот подход применительно к нашему датасету. Обучим три линейных модели, отличающих один класс от остальных: Теперь сравним значения линейных функций и для каждой точки выберем тот класс, которому соответствует большее значение, то есть самый «уверенный» классификатор: Хочется сказать, что самый маленький класс «обидели». Проблема данного подхода заключается в том, что каждый из классификаторовобучается на своей выборке, и значения линейных функцийили, проще говоря, \"выходы\" классификаторов могут иметь разные масштабы. Из-за этого сравнивать их будет неправильно. Нормировать вектора весов, чтобы они выдавали ответы в одной и той же шкале, не всегда может быть разумным решением: так, в случае с SVM веса перестанут являться решением задачи, поскольку нормировка изменит норму весов. Обучимклассификаторов,,. Например, в случае с линейными моделями эти модели будут иметь вид Классификаторбудем настраивать по подвыборке, содержащей только объекты классови. Соответственно, классификаторбудет выдавать для любого объекта либо класс, либо класс. Проиллюстрируем это для нашей выборки: Чтобы классифицировать новый объект, подадим его на вход каждого из построенных бинарных классификаторов. Каждый из них проголосует за свой класс; в качестве ответа выберем тот класс, за который наберется больше всего голосов: Для нашего датасета получается следующая картинка: Обратите внимание на серый треугольник на стыке областей. Это точки, для которых голоса разделились (в данном случае каждый классификатор выдал какой-то свой класс, то есть у каждого класса было по одному голосу). Для этих точек нет явного способа выдать обоснованное предсказание. Некоторые методы бинарной классификации можно напрямую обобщить на случай многих классов. Выясним, как это можно проделать с логистической регрессией. В логистической регрессии для двух классов мы строили линейную модель а затем переводили её прогноз в вероятность с помощью сигмоидной функции. Допустим, что мы теперь решаем многоклассовую задачу и построилилинейных моделей каждая из которых даёт оценку принадлежности объекта одному из классов. Как преобразовать вектор оценокв вероятности? Для этого можно воспользоваться оператором, который производит «нормировку» вектора: В этом случае вероятность-го класса будет выражаться как Обучать эти веса предлагается с помощью метода максимального правдоподобия: так же, как и в случае с двухклассовой логистической регрессией:",
    "source_type": null,
    "useful_links": [
      {
        "text": "из лекций Евгения Соколова",
        "url": "https://github.com/esokolov/ml-course-hse/blob/master/2020-fall/lecture-notes/lecture06-linclass.pdf"
      }
    ]
  },
  {
    "document_title": "Линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
    "section_title": "Масштабируемость линейных моделей",
    "text": "Мы уже обсуждали, что SGD позволяет обучению хорошо масштабироваться по числу объектов, так как мы можем не загружать их целиком в оперативную память. А что делать, если признаков очень много, или мы не знаем заранее, сколько их будет? Такое может быть актуально, например, в следующих ситуациях: Классификация текстов: мы можем представить текст в формате «мешка слов», то есть неупорядоченного набора слов, встретившихся в данном тексте, и обучить на нём, например, определение тональности отзыва в интернете. Наличие каждого слова из языка в тексте у нас будет кодироваться отдельной фичой. Тогда размерность каждого элемента обучающей выборки будет порядка нескольких сотен тысяч. В задаче предсказания кликов по рекламе можно получить выборку любой размерности, например, так: в качестве фичи закодируем индикатор того, что пользователь X побывал на веб-странице Y. Суммарная размерность тогда будет порядка. Кроме того, всё время появляются новые пользователи и веб-страницы, так что на этапе применения нас ждут сюрпризы. Есть несколько хаков, которые позволяют бороться с такими проблемами: Несмотря на то, что полная размерность объекта в выборке огромна, количество ненулевых элементов в нём невелико. Значит, можно использовать разреженное кодирование, то есть вместо плотного вектора хранить словарь, в котором будут перечислены индексы и значения ненулевых элементов вектора. Даже хранить все веса не обязательно! Можно хранить их в хэш-таблице и вычислять индекс по формулеhash(feature) % tablesize. Хэш может вычисляться прямо от слова или id пользователя. Таким образом, несколько фичей будут иметь общий вес, который тем не менее обучится оптимальным образом. Такой подход называетсяhashing trick. Ясно, что сжатие вектора весов приводит к потерям в качестве, но, как правило, ценой совсем небольших потерь можно сжать этот вектор на много порядков. Примером открытой библиотеки, в которой реализованы эти возможности, являетсяvowpal wabbit. Если при решении задачи ставки столь высоки, что мы не можем разменивать качество на сжатие вектора весов, а признаков всё-таки очень много, то задачу можно решать распределённо, храня все признаки в шардированной хеш-таблице Кружки здесь означают отдельные сервера. Жёлтые загружают данные, а серые хранят части модели. Для обучения жёлтый кружок запрашивает у серого нужные ему для предсказания веса, считает градиент и отправляет его обратно, где тот потом применяется. Схема обладает бесконечной масштабируемостью, но задач, где это оправдано, не очень много.",
    "source_type": null,
    "useful_links": [
      {
        "text": "vowpal wabbit",
        "url": "https://vowpalwabbit.org/"
      }
    ]
  },
  {
    "document_title": "Линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/linear-models",
    "section_title": "Подытожим",
    "text": "На линейную модель можно смотреть как на однослойную нейросеть, поэтому многие методы, которые были изначально разработаны для них, сейчас переиспользуются в задачах глубокого обучения, а базовые подходы к регрессии, классификации и оптимизации вообще выглядят абсолютно так же. Так что несмотря на то, что в целом линейные модели на сегодня применяются редко, то, из чего они состоят и как строятся, знать очень и очень полезно. Надеемся также, что главным итогом прочтения этого параграфа для вас будет осознание того, что решение любой ML-задачи состоит из выбора функции потерь, параметризованного класса моделей и способа оптимизации. В следующих параграфах мы познакомимся с другими моделями и оптимизаторами, но эти базовые принципы не изменятся. Теперь предлагаем вам потренировать изученный материал на практике. Скачайтеноутбукс лабораторной работой. В нём вы найдете описания заданий и дополнительные материалы. Задания из лабораторной прикреплены к этому параграфу в виде задач в системе Яндекс Контест. Чтобы проверить себя, отправляйте решения по соответствующим задачам в систему. Успехов в практике!",
    "source_type": null,
    "useful_links": [
      {
        "text": "ноутбук",
        "url": "https://yastatic.net/s3/ml-handbook/admin/autohw_linear_models_dabd6b0378.ipynb?updated_at=2024-03-07T13:21:15.517Z"
      }
    ]
  },
  {
    "document_title": "Нейросети для работы с последовательностями",
    "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-raboty-s-posledovatelnostyami",
    "section_title": "Word Embeddings",
    "text": "Перед тем, как рассказать об архитектурах, которые часто используются для работы с текстами, надо разобраться, каким образом можно кодировать текстовые данные: ведь нужно их превратить во что-то векторное, прежде чем подавать на вход нейросети. К векторизации текстов есть два базовых подхода: векторизовать текст целиком, превращая его в один вектор; векторизовать отдельные структурные единицы, превращая текст в последовательность векторов. Первые, статистические подходы к векторизации следовали первому подходу и рассматривали текст как неупорядоченный набор («мешок») токенов (обычно токенами являются слова). Тем самым, тексты «Я не люблю ML» и «Я люблю не ML» получали одинаковые векторизации, то есть по ходу терялась существенная информация. Поэтому мы лишь коротко упомянем о них. Обратимся теперь к другому подходу и подумаем, как сопоставить векторы (эмбеддинги) словам. Допустим, что у нас одно и то же слово будет представлено одним и тем же вектором во всех текстах и в любых позициях. Как заключить в векторе его смысл, содержающуюся в нём информацию? Ответ предвосхищает одну из основных идей обучения представлений: нужно использоватьконтекст. Если, читая книгу на иностранном языке, вы встречаете незнакомое слово, вы нередко можете угадать его значение по контексту, что оно значит. Можно сказать, что смысл слова — это те слова, которые встречаются с ним рядом. Одним из воплощений такого подхода является Word2vec. Впервые он был предложен Т.Миколовым в 2013 году встатьеEfficient Estimation of Word Representations in Vector Space. Для обучения авторы предложили две стратегии: Skip-gram и CBOW (Сontinuous bag-of-words): В архитектуре CBOW модель учится предсказывать данное (центральное) слово по контексту (например, по двум словам перед данным и двум словам после него). В архитектуре Skip-gram модель учится по слову предсказывать контекст (например, каждого из двух соседей слева и справа); Авторы предложили для каждого словаобучать два эмбеддинга:и, первое из которых используется, когдаявляется центральным, а второе — когда оно рассматривается, как часть контекста. В модели CBOW при фиксированном контекстевычисляются логиты после чего «вероятности» всевозможных словбыть центральным словом для контекставычисляются как. Модель учится с помощью SGD на кросс-энтропию полученного распределения с истинным рапределением центральных слов. В модели Skip-gram по данному центральному словудля каждой позиции контекстанезависимо предсказывается распределение вероятностей. В качестве функции потерь выступает сумма кросс-энтропий распределений слов контекста с их истинными распределениями. Размерность эмбеддинга в каждой из архитектур — это гиперпараметр и подбирается эмпирически. В оригинальнойстатьепредлагается взять размерность эмбеддинга 300. Полученные представления центральных слов могут дальше использоваться в качестве эмбеддингов слов, которые сохраняют семантическую связь слов друг с другом. Мы не будем здесь останавливаться подробно на деталях работы Word2vec и его современных модификациях и предложим читателю обратиться к соответствующей лекции вучебникеЛены Войта по NLP. А мы лишь продемонстрируем, что он работает. Примеры. Возьмём несколько слов и посмотрим, как выглядят топ-10 слов, ближайших к ним в пространстве эмбеддингов (обученных на одном из датасетов Quora Questions с помощью word2vec): quantum: electrodynamics, computation, relativity, theory, equations, theoretical, particle, mathematical, mechanics, physics; personality: personalities, traits, character, persona, temperament, demeanor, narcissistic, trait, antisocial, charisma; triangle: triangles, equilateral, isosceles, rectangle, circle, choke (догадаетесь, почему?), quadrilateral, hypotenuse, bordered, polygon; art: arts, museum, paintings, painting, gallery, sculpture, photography, contemporary, exhibition, artist. Вопрос на подумать. В реальных текстах наверняка будут опечатки, странные слова и другие подобные неприятности. Word2vec же учится для фиксированного словаря. Что делать, если на этапе применения вам попадается неизвестное слово? Да и вообще, хорошо ли учить вложения для редких слов или слов с нетривиальными опечатками, которые, может быть, только раз встретятся в тексте? Вопрос на подумать. В некоторых случаях всё же полезно уметь строить эмбеддинги не отдельных слов, а текстов (например, для поиска похожих документов). Можете ли вы, вдохновившись идеей word2vec, придумать более тонкий способ сделать это, чем BoW или TF-IDF?",
    "source_type": null,
    "useful_links": [
      {
        "text": "статье",
        "url": "https://arxiv.org/abs/1301.3781"
      },
      {
        "text": "статье",
        "url": "https://arxiv.org/abs/1301.3781"
      },
      {
        "text": "учебнике",
        "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html"
      }
    ]
  },
  {
    "document_title": "Нейросети для работы с последовательностями",
    "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-raboty-s-posledovatelnostyami",
    "section_title": "Рекуррентные нейронные сети",
    "text": "Итак, мы представили текст в виде последовательности векторов, соответствующих словам или их кусочкам. Как с ней работать? Один из вариантов мы уже рассматривали: можно посмотреть на последовательность извекторов размерностикак на «изображение»с«каналами», после чего использовать уже знакомые нам свёрточные нейросети, только с одномерными свёртками вместо двумерных. В каких-то случаях это действительно будет работать, но всё же есть несколько сомнительных моментов: Хотя изображения тоже могут быть разного размера, всё же в датасете редко попадаются рядом картинкии, а среди, скажем, отзывов на ресторан могут попадаться как труды, сопоставимые по размеру с «Войной и миром», так и безликие «Да, вроде норм». И если обработать слишком длинное предложение нам поможет (с потерей информации, конечно) global pooling, слишком короткое может что-нибудь поломать, особенно если мы забываем про паддинг. Слегка философское соображение. Изображение однородно, в нём нет предпочтительных направлений, тогда как текст пишется и читается последовательно. Нам может показаться, что это стоит использовать: при обработке очередного токена обращаться к предыдущим, как к его контексту. В последнем соображении уже непосредственно видна идея рекуррентных нейронных сетей (recurrent networks, RNN): Давайте разберёмся, что тут происходит. Чтобы хранить информацию о предыдущих токенах, мы вводим понятие внутренней памяти илискрытого состояния(hidden state, векторы). В простейшем случае оно выражается одним вектором фиксированной размерности. На каждом (дискретном) шаге в сеть подаются данные (например, эмбеддинг токена), при этом происходит обновление скрытого состояния. Пример: после чего по скрытому состоянию предсказывается выходной сигнал, к примеру, следующим образом: Обратите внимание, что весаодинаковы на всех итерациях, то есть вы можете представлять себе, что очередныеиподаются на вход одного и того же слоя, зацикленного на себе. Рекуррентную сеть можно обучать на ошибку, равную суммарному отклонению по всем выходных сигналамнашей сети. Вопрос на подумать. Как инициализировать весамы, наверное, понимаем (про это можно почитать впараграфепро тонкости обучения нейросетей). А как инициализировать начальное скрытое состояние? Можно ли инициализировать его нулём? Нетрудно представить себе и нейросеть с несколькими рекуррентными слоями: первый слой RNN будет принимать на вход исходную последовательность, вторая RNN — выходы первой сети, третья — выходы второй и т.д. Такие сети называют глубокими рекуррентными сетями. Вот пример схему глубокой рекуррентной сети: Вы, наверное, заметили, что описанная выше архитектура RNN решает синхронизованную версию задачи many-to-many. Её, впрочем, легко переделать для решения задачи many-to-one: достаточно убрать все выходы, кроме последнего: Стандартная RNN учитывает только предыдущий контекст. Но ведь слово в предложении связано не только с предыдущими, но и с последующими словами. В таких случаях имеет смысл использовать двунаправленную рекуррентную сеть (bidirectional RNN, BRNN). Как следует из названия, в bidirectional RNN есть две рекуррентных подсети: прямая (forward, токены в нее подаются от первого к последнему) и обратная (backward, токены подаются в обраттном порядке). Вот пример такой архитектуры: Конечно, формула дляможет быть и другой. Например, выходы обеих рекуррентных сетей могут агрегироваться путем усреднения, или суммирования, или любым другим способом. Обратите внимание, что двунаправленная рекуррентная сеть работает с входом фиксированного размера, и по-прежнему не может решать не синхронизованный вариант задачи many-to-many. Backward RNN должна точно знать, где заканчивается входная последовательность, чтобы начать её обрабатывать с конца. Зато такая архитектура может помочь в решении задачи определения именованных сущностей или частей речи, использоваться в качестве энкодера в машинном переводе и так далее. При всех неоспоримых плюсах описанной выше глубокой рекуррентной архитектуры, на практике обычно используется её модифицированный вариант, который позволяет бороться с проблемой затухания или зашкаливания (взрыва) градиентов. Давайте разберёмся подробнее, почему она возникает. Рассмотрим функцию потерь, измеряющую отклонение предсказанного-го выхода от истинного (напомним, что архитектура many-to-many обучается на, а архитектура many-to-one — на). Выходзависит от скрытого состояния, а то, в свою очередь, от всех. Обновление градиента при переходе через преобразованиеимеет, как мы хорошо знаем, вид То есть в ходе вычислениямыраз будем умножать на. Если уесть собственные значения, по модулю большие, и нам не посчастливится попадать в их окрестность, градиент будет стремиться к бесконечности («взрываться»). Такие градиенты делают обучение нестабильным, а в крайнем случае значения весов могут стать настолько большими, что произойдет численное переполнение, и значения весов перестанут обновляться. Если же уесть маленькие собственные значения, градиент может затухать. В любом случае, эти проблемы делают получение информации от далеких по времени состояний затруднительным. Теоретические выкладки о том, почему RNN без модификаций не могут достаточно хорошо учитывать долговременные зависимости, появились ещё в 90х. Их можно прочесть встатьеY.Bengio, 1994 илидиссертацииJosef Hochreiter, 1991. Но как бороться с этой проблемой? Простым инженерным решением являетсяgradient clipping. Эта техника устанавливает максимально возможное значение градиента и заменяет все значения выше выбранного порога на это значение. При обратном распространении ошибки пробрасывается «ограниченный» градиент: где— гиперпараметр, подбираемый порог. Но сам по себеgradient clippingэто довольно грубый инструмент. Поэтому были придуманы сложные модификации рекуррентных сетей, позволяющие им выучивать длинные зависимости. Вдохновение при написании этого параграфа черпалось изстатьив блоге исследователя Кристофера Олаха, из него же взяты иллюстрации. Сеть с долговременной и кратковременной памятью (Long short term memory, LSTM) частично решает проблему исчезновения или зашкаливания градиентов в процессе обучения рекуррентных сетей методом обратного распространения ошибки. Эта архитектура былапредложенаHochreiter &Schmidhuber в 1997 году. LSTM построена таким образом, чтобы учитывать долговременные зависимости.Рассмотрим подробнее архитектуру LSTM. Все рекуррентные сети можно представить в виде цепочки из повторяющихся блоков. В RNN таким блоком обычно является один линейный слой с гиперболическим тангенсом в качестве функции активации. В LSTM повторяющийся блок имеет более сложную структуру, состоящую не из одного, а из четырех слоев. Кроме скрытого состояния, в LSTM появляется понятие состояния блока (cell state,). Cell stateбудет играть роль внутренней, закрытой информации LSTM-блока, тогда как скрытое состояниетеперь становится передаваемым наружу (не только в следующий блок, но и на следующий слой или выход всей сети) значением. LSTM может добавлять или удалять определенную информацию из cell state с помощью специальных механизмов, которые называютсяgates(ворота или вентили в русскоязычной литературе). Рассмотрим этот механизм подробнее. Основное назначение вентиля — контролировать количество проходящей через него информации. Для этого матрица, проходящая по каналу, который контролирует вентиль, поточечно умножается на выражение вида Сигмоида выдает значение отдо. Оно означает, какая доля информации сможет пройти через вентиль. Рассмотрим типы гейтов в том порядке, в каком они применяются в LSTM. Forget gate(вентиль забывания). Он позволяет на основе предыдущего скрытого состоянияи нового входаопределить, какую долю информации из(состояния предыдущего блока) стоит пропустить дальше, а какую забыть. Долясохраняемой информации извычисляется следующим образом: Дальшепоэлементно умножается на. Следующий шаг — определить, что нового мы внесём в cell state. Для этого у нас есть отличная кандидатура — уже привычное: Но мы не уверены, что вся эта информация достаточно релевантна и достойна переноса в cell state, и хотим взять лишь некоторую её долю. Какую именно — поможет узнать наш следующий персонаж. Input gate(вентиль входного состояния). Вычислим и умножим почленно на, чтобы получить информацию, которая поступит в cell state оти. А именно, новое состояние cell state будет равно: где— это поэлементное умножение. Первое слагаемое отвечает за «забывание» нерелевантной информации из, а второе — за привнесение новой, релевантной. Как мы уже отмечали, роль выходного вектора LSTM-блока будет играть. Он вычисляется по cell state с помощью последнего вентиля. Output gate(вентиль выходного состояния). Он отвечает на вопрос о том, сколько информации из cell state следует отдавать на выход из LSTM-блока. Доля вычисляется следующим образом: Теперь пропускаем cell state через гиперболический тангенс, чтобы значения были в диапазоне отдо, и умножаем полученный вектор на o_n, чтобы отфильтровать информацию из cell state, которую нужно подать на выход: Описанная архитектура выглядит несколько сложно. Кроме того, вычисление четырех различных типов гейтов может быть вычислительно невыгодным. Поэтому были разработаны различные вариации LSTM, одна из самых популярных (Gated Recurrent Unit, GRU) освещена ниже. Gated Recurrent Unit был предложен встатьеCho et al. в 2014 году. GRU объединяет input gate и forget gate в одинupdate gate, также устраняет разделение внутренней информации блока на hidden и cell state. Вот общий вид GRU-блока: Внимательно посмотрев на структуру LSTM, можно заметить, что функции forget gate и input gate похожи. Первый механизм определяет, какие значениянадо забыть, а второй — какие значения нового векторанужно использовать для обновления старого cell state. Давайте объединим эти функции воедино: грубо говоря, будем забывать только те значения, которые собираемся обновить. Такую роль в GRU выполняет update gate (): Новый тип гейта, который появляется в GRU —reset gate(). Он определяет, какую долю информации изс прошлого шага надо «сбросить», инициализировать заново. Теперь мы вычисляем потенциальное обновление для скрытого состояния и, наконец, решаем, что из старого забыть, а что из нового добавить: В итоге GRU имеет меньше параметров, чем LSTM (в GRU нет output gate) и при прочих равных, быстрее учится. GRU и LSTM показывают сопоставимое качество на многих задачах, включая генерацию музыки, распознавание речи, многие задачи обработки естественного языка. Модификации RNN, которые помогают лучше моделировать долгосрочные зависимости (LSTM, GRU) — важная веха развития нейросетей в NLP. Следующий большой этап в развитии — механизм внимания — мы рассмотрим чуть ниже.",
    "source_type": null,
    "useful_links": [
      {
        "text": "параграфе",
        "url": "https://academy.yandex.ru/handbook/ml/article/tonkosti-obucheniya"
      },
      {
        "text": "статье",
        "url": "http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf"
      },
      {
        "text": "диссертации",
        "url": "http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf"
      },
      {
        "text": "статьи",
        "url": "https://colah.github.io/posts/2015-08-Understanding-LSTMs"
      },
      {
        "text": "предложена",
        "url": "http://www.bioinf.jku.at/publications/older/2604.pdf"
      },
      {
        "text": "статье",
        "url": "https://arxiv.org/pdf/1406.1078v3.pdf"
      }
    ]
  },
  {
    "document_title": "Нейросети для работы с последовательностями",
    "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-raboty-s-posledovatelnostyami",
    "section_title": "Seq2seq",
    "text": "Вы, должно быть обратили внимание, что мы пока не касались задач, связанных с порождением последовательностей (синхронизованный варианты many-to-many не в счёт). Действительно: имевшиеся у нас пока инструменты не позволяли генерировать последовательности произвольной длины. Но как тогда переводить с одного языка на другой? Ведь мы не знаем, какой должна быть длина перевода фразы, да и однозначного соответствия между словами исходного предложения и его перевода обычно нет. Естественным решением для задачи sequence-to-sequence (seq2seq) является использование архитектурыэнкодер-декодер, состоящей из кодировщика (энкодера) для кодирования информации об исходной последовательности вконтекстном векторе(context vector) и декодировщика (декодера) для превращения закодированной энкодером информации в новую последовательность. Очевидным выбором на роль энкодера и декодера являются рекуррентные сети, например, LSTM. Простейшая архитектура будет иметь вид: Рассмотрим подробнее энкодер и декодер. Энкодер читает входное предложение токен за токеном и обрабатывает их с помощью блоков рекуррентной сети. Hidden state последнего блока становится контекстным вектором. Часто энкодер читает предложение в обратном порядке. Это делается для того, чтобы последний токен, который видит энкодер, совпал (или примерно совпал) с первыми токенами, которые будет генерировать декодер. Таким образом, декодеру проще начать процесс воссоздания предложения. Несколько первых правильных токенов сильно упрощают процесс дальнейшей генерации. Архитектура декодера аналогична энкодеру. При этом каждый блок декодера должен учитывать токены, сгенерированные к текущему моменту, и также информацию о предложении на исходном языке. Вектор скрытого состояния в нулевом блоке декодера () инициализируется с помощью контекстного вектора. Таким образом, декодер получит сжатое представление исходного предложения. Предложение генерируется следующим образом: в первый блок подаем метку начала последовательности (например, -токен, begin of sentence), на выходе первого блока получаем первый токен новой последовательности, и затем подаем его на вход следующего блока декодера. Повторяем аналогичную процедуру до тех пор, пока не сгенерируется метка конца последовательности (например, , end of sentence) или не будет достигнута максимально возможная длина предложения. Таким образом, декодер работает в режиме языковой модели, генерируя предложение токен за токеном и учитывая предыдущий контекст. Разумеется, энкодер может быть и более сложным. Например, можно использовать многослойную двунаправленную сеть, лишь бы выходом её был один вектор контекста. С декодером сложнее: он должен порождать слова по одному, в одном направлении. Далее мы очень коротко остановимся на нетривиальных моментах обучения и применения такой модели. В предыдущих разделах мы не останавливались подробно на том, что происходит с выходами, но сейчас всё-таки попробуем разобраться. Если мы решаем задачу машинного перевода, то на очередном этапе декодер выдаёт нам условное распределение на словах (или каких-то subword unit, например, BPE), из которого мы будем выбирать самое вероятное словои подавать его на вход следующего блока. Но эта, жадная, стратегия может и подвести. Легко представить себе ситуацию, в которой самое вероятное на данный момент слово приведёт дальше к менее вероятной подпоследовательности: Чтобы справиться с этим, на этапе применения модели используютbeam search. В каждый момент времени мы поддерживаем некоторое количествосамых вероятных гипотез, на-м шаге пытаясь продолжать все сохранённые, а из продолжений выбирая топ-по метрике Числонет смысла делать большим (это и вычислительно будет тяжко, и может привести к более плохим результатам), можете брать в пределах. Как уже было сказано выше, на каждом шаге декодер предсказывает распределение вероятностей. Вся модель учится на сумму по всемкросс-энтропиям этих распределений с истинными. Одна из сложностей такого обучения состоит в том, что единожды ошибившись и предсказав неправильныйвместо истинного, модель скорее всего и следующие токены предскажет неверно, а это сделает всё дальнейшее обучение малополезным: ведь мы будем учить декодер предсказывать правильное продолжение неправильного начала. Одним из способов борьбы с этим являетсяteacher forcing. Суть его в том, что на этапе обучения мы подаём на вход декодера не предсказанный им на предыдущем этапе токен, а истинный: У нас остался лишь один неразобранный тип задач: one-to-many. К счастью, чтобы с ним справиться, ничего нового не нужно: достаточно уже знакомой модели энкодер-декодер, лишь с корректировкой энкодера. Рассмотрим для примера задачу генерации подписей к изображениям (image captioning). Если мы уже умеем как-то превращать картинки в векторы, то эти векторы мы можем напрямую подавать в декодер в качестве векторов контекста: Более подробно о том, как строить векторизации для изображений, вы узнаете в параграфе прообучение представлений. А если у вас есть все данные мира, то вы можете в качестве энкодера взять свёрточную нейросеть и обучать её вместе с декодером end-to-end:",
    "source_type": null,
    "useful_links": [
      {
        "text": "обучение представлений",
        "url": "https://academy.yandex.ru/handbook/ml/article/obuchenie-predstavlenij"
      }
    ]
  },
  {
    "document_title": "Нейросети для работы с последовательностями",
    "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-raboty-s-posledovatelnostyami",
    "section_title": "Механизм внимания (attention)",
    "text": "Как человек переводит предложения с одного языка на другой? Обычно переводчик уделяет особое внимание слову, которое записывает в данный момент. Хочется сообщить аналогичную интуицию нейронным сетям. Рассмотрим, как можно реализовать такой механизм на примере машинного перевода. Внимательно посмотрим на seq2seq модель для машинного перевода. Вся информация о предложении на исходном языке заключена в контекстном векторе, но разные слова в предложении могут иметь разную смысловую значимость и следовательно, должны учитываться с разными весами. Кроме того, при генерации разных частей перевода следует обращать внимание на разные части исходного предложения. Например, первое слово переведенной фразы нередко связано с первыми словами в предложении, поданном на вход энкодеру, а порой одно слово перевода передаёт смысл нескольких слов, разбросанных по исходному предложению (вдруг кто-нибудь сталкивался с отделяемыми приставками в немецком?). Механизм внимания(attention) реализует эту интуицию путем предоставления декодеру информации обо всех токенах исходного предложения на каждом шаге генерации. Рассмотрим классическую модель внимания, предложенную Bahdanau et al. в 2014 году. Обозначим скрытые состояния энкодера, а скрытые состояния декодера. Важно отметить, что, это контекстный вектор. На каждом шаге декодера будем считатьattention scores, умножаяна вектор скрытого состояния каждого блока энкодера. Таким образом, получаемзначений, указывающих, насколько каждый из токенов c номерамииз исходного предложения важен для генерации токенаиз перевода: (здесьи, как обычно, являются строками, так что— скаляр). Теперь превращаем эти значения в attention distribution, применив к ним softmax: Используемв качестве весов для нахождения окончательного вектора внимания: Теперь в декодере на шаге i вместо вектора скрытого состояниябудем использовать вектор-- конкатенацию скрытого состояния блока и соответствующего attention вектора. Таким образом, на каждом шаге декодер получает информацию о важности всех токенов входного предложения. Данная схема вычисления attention представлена на следующем рисунке. Существует много разных видов механизмов внимания, например: Базовый dot-product, рассмотренный ранее: Мультипликативный:, где— обучаемая матрица весов. MLP:, где,— обучаемые матрицы весов,— обучаемый вектор весов Важной особенностью механизма внимания является то, что его веса несут в себе информацию о связях слов в двух языках, участвующих в переводе. Визуализировав веса механизма внимания, получаем таблицу взаимосвязей между словами: Весьма логично, что словоdogsтеснее всего связано со словомсобак, а словуоченьсоответствуют целых два слова:veryиmuch.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Нейросети для работы с последовательностями",
    "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-raboty-s-posledovatelnostyami",
    "section_title": "Self-attention",
    "text": "В предыдущем разделе мы обсуждали применение механизма внимания во время работы декодера, но оказывается, что и энкодеру это может быть полезно. Механизм внутреннего внимания(self-attention) используется, чтобы посмотреть на другие слова во входной последовательности во время кодирования конкретного слова. Изначально этот механизм был представлен встатьеAttention is all you need как элемент архитектуры «трансформер» (Transformer). Эффективность трансформера демонстировалась на примере задачи машинного перевода. Сейчас трансформеры и self-attention обрели огромную популярность и используются не только в NLP, но и в других областях (например, в компьютерном зрении:Vision Transformer,Video Transformer,Multimodal Transformer for Video Retrievalи так далее). Более подробный обзор архитектуры Трансформер оставимкурсуЛены Войта по NLP, а пока остановимся на механизме внутреннего внимания. Пусть на вход нейросети пришли два предложения «Мама мыла раму. Она держала в руках тряпку». Местоимение «она» относится к маме или к раме? Для человека это очень простой вопрос, но для модели машинного обучения — нет. Self-attention помогает выучить взаимосвязи между токенами в последовательности, моделируя «смысл» других релевантных слов в последовательности при обработке текущего токена. Что происходит внутри self-attention-модуля? Для начала, из входного вектора (например, эмбеддинга каждого токена) формируются три вектора: Query (запрос), Key (ключ) и Value (значение). Они получаются с помощью умножения входного вектора на матрицы,и, веса которых учатся вместе со всеми остальными параметрами модели с помощью обратного распространения ошибки. Выделение этих трех абстракций нужно, чтобы разграничить эмбеддинги, задающие «направление» внимания (query, key) и смысловую часть токена (value). Вектор query задает модальность «начальной точки» механизма внутреннего внимания (от какого токена направлено внимание), вектор key — модальность «конечной точки» (к какому токену направлено внимание). Таким образом, один и тот же токен может выступать как «начальной», так и «конечной» точкой направления внимания: self-attention вычисляется между всеми токенами в выбранном фрагменте текста. Процесс происходит так: по очереди фиксируется каждый токен (становится query) и просчитывается степень его связанности со всеми оставшимися токенами. Для этого поочередно key-вектора всех токенов скалярно умножаются на query-вектор текущего токена. Полученные числа будут показывать, насколько важны остальные токены при кодировании query токена в конкретной позиции. Дальше полученные числа надо нормализовать и пропустить через софтмакс, чтобы получить распределение. Затем подсчитывается взвешенная сумма value векторов,где в качестве весов используются полученные на предыдущем шаге вероятности. Полученный вектор и будет выходом слоя внутреннего внимания для одного токена. Изложенную выше схему вычисления self-attention вектора для одного токена можно представить простой схемой: На практике self-attention не вычисляется для каждого токена по отдельности, вместо этого используются матричные вычисления. Например, вместо вычисления query, key и value векторов для каждого токена, настакаем эмбеддинги входных токенов в матрицуи посчитаем матрицы,и. Затем происходит повторение описанных в предыдущем абзаце шагов, только для матриц. Посчитаем итоговую матрицу, подав матрицы Q, K и V в формулу: В оригинальнойстатьеVaswani et al., 2017 в качестве нормализующей константы выбрали число 8 (квадратный корень размерности key-векторов). Нормализация приводила к более стабильным градиентам в процессе обучения. Интересно, что обычно используют параллельно несколько self-attention блоков. Такая схема называется multi-head self-attention. Вычисление self-attention происходит несколько раз с разными матрицами весов, затем полученные матрицы конкатенируются и умножаются на еще одну матрицу весов(см. схему). Это позволяет разным self-attention головам фокусироваться на разных взаимосвязях, например, одна голова может отвечать за признаковые описания, другая за действия, третья за отношения «объект-субъект». Разные головы могут вычисляться параллельно, при этом входная матрица эмбеддингов отображается в разные подпространства представлений, что значительно обогащает возможности внутреннего внимания моделировать взаимосвязи между словами. В виде формулы вычисление multihead self-attention можно представить так: ,где Есть много реализаций self-attention (PyTorch, TensorFlow). Также советуем ознакомиться сjupyter-ноутбукомот Гарвардской NLP-группы, в котором представлена реализация архитектуры «трансформер» с подробными объяснениями. Еще один отличный источник, позволяющий подробнее разобраться с self-attention и трансформером, - этостатьяJay Alammar под названием «Illustrated Transformer».",
    "source_type": null,
    "useful_links": [
      {
        "text": "статье",
        "url": "https://arxiv.org/abs/1706.03762"
      },
      {
        "text": "Vision Transformer",
        "url": "https://arxiv.org/pdf/2010.11929.pdf"
      },
      {
        "text": "Video Transformer",
        "url": "https://arxiv.org/pdf/1906.02634.pdf"
      },
      {
        "text": "Multimodal Transformer for Video Retrieval",
        "url": "https://arxiv.org/pdf/2007.10639.pdf"
      },
      {
        "text": "курсу",
        "url": "https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html"
      },
      {
        "text": "статье",
        "url": "https://arxiv.org/pdf/1706.03762.pdf"
      },
      {
        "text": "PyTorch",
        "url": "https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html"
      },
      {
        "text": "jupyter-ноутбуком",
        "url": "http://nlp.seas.harvard.edu/2018/04/03/attention.html"
      },
      {
        "text": "статья",
        "url": "https://jalammar.github.io/illustrated-transformer/"
      }
    ]
  },
  {
    "document_title": "Нейросети для работы с последовательностями",
    "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-raboty-s-posledovatelnostyami",
    "section_title": "Особенности работы с текстами",
    "text": "Перед тем, как применять описанные выше архитектуры (или даже использовать простые подходы, вроде TF-IDF или word2vec), нужно разобраться, как делать предобработку текстов. Первым делом надо научиться представлять связный текст в виде последовательности. Для начала имеет смысл разбить текст на предложения, а дальше уже на слова или символьные n-граммы. Этот процесс называется токенизацией. Можно делать токенизацию вручную, например, с помощью регулярных выражений, или воспользоваться готовыми методами из библиотеки NLTK. Представим, что мы получили упорядоченный список слов, из которых состоит текст. Но это еще не все. Обычно тексты содержат разные грамматические формы одного и того же слова. Привести все словоформы к начальной форме можно с помощью лемматизации. Лемматизация - это алгоритм приведения слова к его начальной форме с использованием морфологическего анализа и знаний об особенностях конкретного языка. Пример работы лемматизатора:«собаки, собака, с собакой, собаками ->собака» Другой способ приведения всех словоформ к одной форме - это стемминг. Стемминг — это более грубый процесс на основе эвристик, который действует без знания контекста, словарей и морфологии. Стеммер не поймет, что слова с чередованием имеют один и тот же корень (только если прописать в явном виде такую эвристику) или что слова «есть», «буду» и «был» - это формы глагола «быть». Стемминг - менее аккуратный процесс по сравнению с лемматизацией, зато гораздо более быстрый. Еще один важный этап предобработки текстов - это удаление стоп-слов. Стоп-словами называют междометия, союзы, предлоги, артикли, в общем все слова, которые будут вносить шум в работу алгоритма машинного обучения. Иногда дополнительно убирают слова общей лексики, оставляя только специфические термины. Универсального списка слов не существует, но для начала можно использовать список стоп-слов из библиотеки NLTK. Аугментации данных часто используются, чтобы увеличить количество данных в обучающей выборке, а также повысить обобщаемость модели. И если для компьютерного зрения аугментации относительно простые и могут выполняться на лету (масштабирование, обрезка, вращение, добавление шума и т.д.), то для текстов в виду грамматической структуры, синтаксиса и особенностей языка все не так просто. Аугментации текста менее «автоматические», в идеале нужно понимать смысл фразы и иметь под рукой отлично работающий механизм перефразирования. Рассмотрим несколько популярных способов аугментации текстовых данных: Обратный перевод. Переводим исходный текст на какой-то язык, и затем переводим его обратно. Это помогает сохранить контекст, но при этом получить синонимичную формулировку. Замены слова на синонимичное/близкое по смыслу. Для этого можно использовать словари синонимов либо искать близкое слово в пространстве эмбеддингов, минимизируя расстояние между соответствующими векторами. В качестве таких эмбеддингов можно взять привычный word2vec,fasttextили контекстуализированные эмбеддинги на основе претренированных моделей (BERT,ELMO,GPT-2/GPT-3и так далее). Вставка синонима слова в случайное место в предложении. Замена сокращения на полное наименование и обратно. Для английского языка этот способ более актуален, чем для русского. Случайная вставка/удаление/замена/перемена местами слов в предложении. Случайная перестановка местами предложений. Случайное изменение букв на произвольные/ближайшие на клавиатуре, добавление/исправление орфографических и пунктуационных ошибок, изменение регистра. MixUpдля текстов. В задаче классификации смешиваем признаковые описания двух объектов и с такими же весами смешиваем их метки классов, получаем новый объект с признакамии меткой класса: Для текстов признаковые описания можно смешивать на уровне слов (выбирать ближайшее слово в пространстве word embeddings) или на уровне предложений. Еще один вариант: сэмплировать слова из двух разных текстов с вероятностямии.9. Аугментации с использованием синтаксического дерева предложения.10. Генерация текста языковыми моделями. Например, генерация текста с помощью упоминавшейся ранее модели GPT-3. Подробнее про некоторые методы аугментации текстов можно почитать встатьеEasy Data Augmentation (EDA). Многие из описанных выше и в статье методов реализованы в библиотекеNLPAug, использование которой сильно упрощает задачу аугментации текстовых данных на практике.",
    "source_type": null,
    "useful_links": [
      {
        "text": "fasttext",
        "url": "https://fasttext.cc/"
      },
      {
        "text": "BERT",
        "url": "https://arxiv.org/abs/1810.04805"
      },
      {
        "text": "ELMO",
        "url": "https://arxiv.org/abs/1802.05365"
      },
      {
        "text": "GPT-2",
        "url": "https://openai.com/blog/gpt-2-1-5b-release/"
      },
      {
        "text": "GPT-3",
        "url": "https://arxiv.org/abs/2005.14165"
      },
      {
        "text": "MixUp",
        "url": "https://arxiv.org/abs/1905.08941"
      },
      {
        "text": "статье",
        "url": "https://arxiv.org/abs/1901.11196"
      },
      {
        "text": "NLPAug",
        "url": "https://github.com/makcedward/nlpaug"
      }
    ]
  },
  {
    "document_title": "Вероятностные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnye-raspredeleniya",
    "section_title": "Вероятностное пространство",
    "text": "В учебниках вероятность традиционно поставляется в комплекте свероятностным пространством. Не увлекаясь чрезмерным формализмом, можно сказать, что для задания вероятностного пространства нужны: непустое множество, называемое пространствомэлементарных событий(исходов); алгебрамножеств— набор подмножеств, замкнутый относительно дополнений, объединений и пересечений; каждый элементназываетсясобытием; вероятностная мера, приписывающая каждому событиюнекоторуювероятность. К вероятностному пространствупредъявляются следующие требования: (невозможноесобытие),(достоверноесобытие); ; , еслии(аддитивность). Упражнение. Докажите, чтои, если. Аддитивность вероятности легко обобщается по индукции до свойстваконечной аддитивности: если событияпопарно несовместны, то Множествочасто называютносителем; говорят также, что вероятностная мера (масса)сосредоточена, илираспределена, на носителе. В зависимости от типа носителяраспределения делятся на два типа:дискретныеинепрерывные.",
    "source_type": null,
    "useful_links": [
      {
        "text": "вероятностным пространством",
        "url": "https://ru.wikipedia.org/wiki/%D0%92%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%BD%D0%BE%D0%B5_%D0%BF%D1%80%D0%BE%D1%81%D1%82%D1%80%D0%B0%D0%BD%D1%81%D1%82%D0%B2%D0%BE"
      },
      {
        "text": "алгебра",
        "url": "https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%B5%D0%B1%D1%80%D0%B0_%D0%BC%D0%BD%D0%BE%D0%B6%D0%B5%D1%81%D1%82%D0%B2"
      }
    ]
  },
  {
    "document_title": "Вероятностные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnye-raspredeleniya",
    "section_title": "Дискретные распределения",
    "text": "Вероятность на не более чем счётном пространстве элементарных событийзадаётся просто приписыванием неотрицательного числакаждому элементарному исходус условием. Для произвольного событияполагают. Набор чиселназывают такжераспределением вероятностейна множестве. В англоязычной литературе распространён терминprobability mass function(сокращённоpmf). Зачастую в результате эксперимента нас интересуют не вероятности событий сами по себе, а значения некоторой связанной с нимислучайной величины, принимающей числовые значения. Например: сумма очков, выпавших при броске двух кубиков; число метеоритов диаметром более одного метра, падающих на Землю в течение года; ежедневный доход от показа рекламных объявлений в интернете. На каждом элементарном исходеслучайная величинапринимает некоторое числовое значение. Иными словами, случайная величина — это функция, принимающая значениес вероятностью; еёматематическое ожидание(среднее) идисперсия(среднеквадратичное отклонение) вычисляются по формулам соответственно. Корень из дисперсииназваютстандартным отклонениемслучайной величины. Стандартное отклонение и дисперсия показывают, насколько далеко значения случайной величины могут отклоняться от среднего значения. Стандартное отклонение хорошо тем, что, в отличие от дисперсии, измеряется в тех же единицах, что и сама случайная величина. Так называется распределение вероятностней на множестве, у которого,. Тогда, и мы получили формулу из классического подхода к вероятности, при котором вероятность события равна отношению числа благоприятных исходов к общему их количеству. Равномерным распределением моделируются различные игровые ситуации: подбрасывание симметричной монеты (,); подбрасывание кубика (,); вращение рулетки в казино (для европейской,для американской). Упражнение.У европейской рулетки почёрных и красных секторов и один сектор «зеро». Игрок ставит €10 на чёрное. В случае успеха казино выплачивает ему ещё €10, в противном случае забирает ставку. Чему равно математическое ожидание, дисперсия и стандартное отклонение выигрыша? Вопрос на подумать. Бывают ли равномерные распределения в пространствах со счётным носителем? Равномерные распределения преимущественно встречаются в разного сорта играх. В более жизненных ситациях случайность обычно распределена отнюдь не равномерно. Так называется очень простое распределение всего лишь с двумя исходами: Бернуллиевскаяслучайная величина— это просто индикаторная функция успешного события:, если случился «успех»,, если нас постигла «неудача». Несложные вычисления показывают, что Если, то снова получается равномерное распределение с двумя исходами. Прибернуллиевская случайная величина моделирует подбрасывание несимметричной монеты. В машинном обучении часто встречается задача бинарной классификации, и разбиение на классы обычно кодируется с помощью, например: диагностика болезни (болен —, здоров —); оценка кредитоспособности клиента (одобрить кредит —, отказать); предсказание поведения пользователя (кликнет на рекламу —, пропустит —). В этих примерах вероятности классов явно не равны, поэтому несимметричное распределение Бернулли — типичная ситуация в реальных задачах. Биномиальное распределениеимеет сумма независимых бернуллиевских случайных величин:, если. Другими словами, случайная величинаравна количеству успехов внезависимых испытаниях Бернулли с вероятностью успеха. Случайная величинапринимает значения отдо, и Отметим, что согласнобиному Ньютона поэтому числадействительно представляют собой распределение вероятностей, называемое такжебиномиальным. Если, то Пример. Каждый день рекламу компании А поисковой выдаче Яндекса видят ровночеловек. Вчераиз них кликнули на рекламу. Для прогнозирования объемов продаж компании А хочется знать, с какой вероятностью не менее 50 людей кликнут на ее рекламу сегодня. Если моделировать наличие или отсутствие клика бернуллиевской случайной величиной, то общее количество кликов за день моделируется случайной величинойс параметрамии. Тогда с помощью вычислительной техники получаем, что Отметим, что параметрв предыдущем примере нам, строго говоря, не был известен, и вместо него мы использовали частотную оценку. Это распределение имеет счётный носитель. Случайная величинаимеетпуассоновское распределениес параметром,, если Известное разложение экспоненты в ряд Тейлорапозволяет заключить, что вероятности распределения Пуассона действительно суммируются в единицу. Этот же ряд позволяет вычислить, что Пуассоновская случайная величина моделирует число редких событий, происходящих в течение фиксированного промежутка времени: если события наступают со средней скоростью, то Иногда приходится рассматривать биномиальное распределениес большим числом попытоки вероятностью успехас условием. Оказывается, что вне зависимости оттакое распределение быстро стабилизируется, сходясь к пуассоновскому распределению с параметром. Точнее говоря, справедлива следующая теорема. Теорема (Пуассон). Пустьи. Тогда Пример. Известно, что на поисковой выдаче яндекса на рекламу компании А кликает в среднем примерно 50 пользоваталей в день. Количество показов достаточно большое и может меняться изо дня в день. Требуется оценить вероятность того, что сегодня будет совершено не менее 50 кликов по рекламным объявлениям. Распределение количества кликов снова будем моделировать биномиальным распределением. На этот раз числонам неизвестно, но сказано, что оно велико и(вспомним, что, если). Поэтому можно воспользоваться теоремой Пуассона и заменить биномиальное распределение пуассоновским с параметром. Тогда искомая вероятность равна что практически совпадает ответом, полученным с помощью биномиального распределения при. Пусть монетка с вероятностью «успеха»подбрасывается до тех пор, пока впервые не случится «успех». Случайная величина, равная общему количеству попыток на этом пути, имеетгеометрическоераспределение, т.е. По формуле геометрической прогрессии находим, что поэтому с нормировкой тут всё в порядке. Чем меньше, тем больше геометрическое распределение похоже на равномерное, что подтверждают и формулы для среднего и дисперсии: Пример. По оценкам за предыдущие дни пользователь нажимает на рекламу с вероятностью. Сегодня компания B планирует показать очень важное рекламное объявление и требует от Яндекса, чтобы с вероятностью не менеена него кликнули хотя бы раз. Скольким различным людям следует показать это объявление? Здесь мы имеем дело с геометрическим распределением с вероятностью «успеха» (клика): именно так распределена случайная величина, равная количеству показов объявления до первого клика по нему. Следовательно, Эта вероятность должна быть не меньше, т. е.. Отсюда находим, что. Таким образом, рекламу надо показать как минимумраз. Пример. Известно, что партия издеталей содержитбракованных. Какова вероятность того, что среди выбранных наугаддеталей окажется ровнобракованных? Всего естьспособов выборадеталей из партии. Число вариантов выбратьдеталей избракованных ииздеталей без дефектов равно. По классическому определению вероятности получаем, что искомая вероятность равна Такое распределение называетсягипергеометрическим. Равенство следует изтождества Вандермонда. Если случайная величинаимеет гипергеометрическое распределение с параметрами,,, то Гипергеометрическое распределение является аналогом биномиального, при котором моделируется выбор без возвращения с вероятностью успеха.",
    "source_type": null,
    "useful_links": [
      {
        "text": "биному Ньютона",
        "url": "https://ru.wikipedia.org/wiki/%D0%91%D0%B8%D0%BD%D0%BE%D0%BC_%D0%9D%D1%8C%D1%8E%D1%82%D0%BE%D0%BD%D0%B0"
      },
      {
        "text": "тождества Вандермонда",
        "url": "https://ru.wikipedia.org/wiki/%D0%A2%D0%BE%D0%B6%D0%B4%D0%B5%D1%81%D1%82%D0%B2%D0%BE_%D0%92%D0%B0%D0%BD%D0%B4%D0%B5%D1%80%D0%BC%D0%BE%D0%BD%D0%B4%D0%B0"
      }
    ]
  },
  {
    "document_title": "Вероятностные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnye-raspredeleniya",
    "section_title": "Непрерывные распределения",
    "text": "Вероятностная модель с конечным или счётным носителем не подходит в тех случаях, когда результатом эксперимента удобно считать произвольное действительное число, например, распределение людей по росту или по весу. Для этого требуется пересмотреть подход к построению пространства элементарных событий: ведь множество действительных чиселконтинуально, и поэтому вероятность события не получится определить как сумму вероятностей всех составляющих исходов, коих тоже может оказаться континуум. Приходится искать другие способы задания вероятности. Наиболее часто встречающийся на практике класс непрерывных распределений на числовой прямой задаётся с помощью неотрицательной интегрируемой функцииплотности(probability density function,pdf)со свойством Вероятность событияопределяется как при условии, что этот интеграл имеет смысл. В частности, Замечание. Связь между вероятностью и плотностью распределения весьма напоминает связь между массой и физической плотностью. Когда плотность объекта всюду одинакова, то масса равна плотности, умноженной на объём. Если же объект неоднороден, то плотность становится функцией, сопоставляющей каждой точке некое число (что-то вроде предела отношения массы малого шарика вокруг этой точки к объёму шарика). Тогда масса любого куска объекта может быть вычислена, как интеграл функции плотности по объёму этого куска. С плотностью вероятностиавтоматически связана случайная величина, для которой. Функцияназывается плотностью случайной величины, и обозначается также как. Иногда используется запись. Среднее и дисперсия случайной величинывычисляются по формулам Равномерноераспределение на отрезке, которое часто обозначают, имеет постоянную плотность на этом отрезке: Если, то Вопрос на подумать. Можно ли задать равномерное распределения на неограниченном промежутке, например, наили на? Аналогичным образом вводится равномерное распределение в многомерном пространстве: если множествоимеет объём, то плотность равномерно распределённой наслучайной величинызадаётся как. Если, то и мы получили формулугеометрической вероятности. Случайная величинаимеетнормальное(гауссовское) распределение, если её плотность равна Параметры нормального распределенияпредставляют собой его среднее и дисперсию: Параметротвечает за выраженность «колокола» плотности нормального распределения: при«колокол» приобретает очертания резко выраженного пика, то есть практически вся вероятностная масса сосретдоточена в малой окрестности точки; при«колокол», наоборот, размывается, и распределение становится больше похоже на равномерное. Гауссиана, у которойи, называетсястандартным нормальным распределением. Иногда бывает полезно тесно связанное с гауссовскимлогнормальноераспределение.Случайная величинаимеет логнормальное распределение,, если. Плотность логнормальной случайной величины равна а её среднее и дисперсию можно вычислить по формулам Плотностьпоказательного(экспоненциального) распределениясосредоточена на лучеи имеет параметр:,. Если, то Плотность показательного распределения является убывающей функцией на, а параметротвечает за скорость этого убывания: приубывание очень медленное, и распределение больше похоже на равномерное; при, наоборот, вся вероятностная масса сосредоточена около точки. Показательное распределение моделирует временные интервалы между случайными событиями, наступающими с постоянной скоростью, например: время ожидания автобуса на остановке; время между телефонными звонками в колл-центре; время до выхода из строя вычислительного узла в дата-центре. Гамма-распределениес положительными параметрамииимеет плотность где—гамма-функция Эйлера. Пригамма-распределение превращается в показательное с параметром. Среднее и дисперсия случайной величины, имеющей гамма-распределение с параметрамии, равны Плотностьбета-распределенияс параметрамиравна где—бета-функция Эйлера. Бета-распределение имеет следующее статистическое приложение. Выберем случайным образом точки, и упорядочим их по возрастанию. Получим набор значений Оказывается, что случайная величина, называемая-й порядковой статистикой, имеет бета распределение с параметрамии: При проверке статистических гипотез бывает полезнораспределение Стьюдента(t-distribution) сстепенями свободы, плотность которого равна где— гамма-функция Эйлера. Распределение Стьюдента похоже на стандартное нормальное распределение; более того, прионо превращается в. Однако при малых значенияхраспределение Стьюдента имеет гораздо более тяжёлые «хвосты»: например, приего дисперсия бесконечна, а прита же участь постигает и математическое ожидание (всё из-за расходимости соответствующих интегралов). В остальных случаях еслиимеет распределение Стьюдента сстепенями свободы. Плотностьраспределения Лапласас параметрамиравна Такое распределение иногда обозначают. Если, то Прираспределение Лапласа представляет собой экспоненциальное распределение, плотность которого симметрично отражена на отрицательную полуось: если, то. Распределение Лапласа похоже на нормальное и отличается от него немного более тяжёлыми «хвостами» и тем, что его плотность теряет гладкость в нуле.",
    "source_type": null,
    "useful_links": [
      {
        "text": "гамма-функция Эйлера",
        "url": "https://ru.wikipedia.org/wiki/%D0%93%D0%B0%D0%BC%D0%BC%D0%B0-%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F"
      },
      {
        "text": "бета-функция Эйлера",
        "url": "https://ru.wikipedia.org/wiki/%D0%91%D0%B5%D1%82%D0%B0-%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F"
      }
    ]
  },
  {
    "document_title": "Вероятностные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnye-raspredeleniya",
    "section_title": "Характеристики случайных величин",
    "text": "Если, то-й моментслучайной величиныравен. В зависимости от типа случайной величины моменты вычисляются по-разному: , еслипринимает дискретные значения; , еслиимеет плотность. Первый момент— это в точности математическое ожидание (среднее) случайной величины. Дисперсию тоже можно выразить через моменты: Не у всех случайных величин есть конечные среднее и дисперсия. Например,распределение Коши(оно жераспределение Стьюдентас одной степенью свободы) имеет плотность, и если мы попытаемся вычислить первые два момента, то получим расходящиеся интегралы Упражнение. Приведите пример дискретной случайной величины с бесконечным средним. Если, то. (линейность). Если, то(монотонность). . Если случайные величиныинезависимы, то. Если, то(неравенство Маркова). Если функциявыпукла вниз, то(неравенство Йенсена). Law of the unconscious statistician (LOTUS) Если случайная величинаполучена применением некоторой детерминированной функцией из случайной величины,, то , еслидискретна; , еслинепрерывна. Ковариацияслучайных величиниопределяется по формуле В частности,. На практике часто применяюткоэффициент корреляции, который получается нормированием ковариации: Коэффициент корреляции всегда принимает значения из отрезка. Если, то случайные величиныиназываютнекоррелированными. Свойства дисперсии и ковариации , причём. ,. ,. . Если случайные величиныинезависимы, тои. (неравенство Чебышева). Случайная величинаявляется числовой функцией, заданной на пространстве элементарных событий; однако, больший интерес обычно представляет порождаемое ею распределение вероятностей. В дискретном случае достаточно задать вероятности отдельных значений; для непрерывных же случайных величин на помощь приходят функция распределения и функция плотности. Функцией распределения(cumulative distribution function,cdf) случайной величиныназывается функция Свойства функции распределения: ,; функциянеубывающая; функциянепрерывна справа:; . Любая дискретная случайная величина имеет ступенчатую функцию распределения. К примеру, вот как выглядит график функциидля: Если непрерывная случайная величинаимеет непрерывную плотность, то откуда следует, что. В типичных случаях непрерывная случайная величина имеет гладкую возрастающую функцию распределения с двумя горизонтальными асимптотами. Вот примеры графиков функций распределения гауссовских случайных величин: Математическое ожидание — не единственная числовая метрика, с помощью которой можно пытаться охарактеризовать, чему равно в среднем значение случайной величины.Медианаразбивает вероятностную массу распределения на две равные части. Если случайная величинаимеет плотность, то её медианаопределяется из условия В терминах функции распределения это означает, что, или. В непрерывном случае функция распределениястрого возрастает, поэтому уравнениеимеет единственное решение. Для дискретных случайных величин это может быть не так, и поэтому в общем случае медиану определяют как число, удовлетворяющее условиям Например, если, то, и поэтому любое числоявляется медианой симметричного бернуллиевского распределения. Бесконечное количество медиан будет у всякой дискретной случайной величины, для которойна целом промежутке. Модараспределения максимизирует его pmf или pdf: Мод у распределения может быть больше одной; самое вырожденное в этом смысле распределение — равномерное, каждая точка носителя является его модой. Если плотность случайной величины имеет единственную точку максимума, то она и является модой. Например: , если; , если; мода t-распределения Стьюдента также равна нулю. Все такие распределенияунимодальны. Если плотностьимеет два или более максимума, то случайная величинаназываетсябимодальнойилимультимодальной. Для симметричных распределений вроде нормального математическое ожидание, медиана и мода совпадают, однако, в общем случае это три различные меры типичного среднего значения случайной величины. Смысл каждой из этой мер наглядно демострирует следующая иллюстрация: Упражнение. Найдите среднее, медиану и моду экспоненциального распределения с параметроми сравните их между собой. У внимательного читателя (отягощённого математическим образованием впридачу) может возникнуть вопрос: а все ли случайные величины относятся к дискретным или непрерывным? В буквально такой постановке ответ, конечно, отрицательный, поскольку можно получить гибридную случайную величину, сложив дискретную и непрерывную. Но, может быть, всякая случайная величина равна сумме непрерывной и дискретной компонент? В терминах функций распределения этот вопрос можно переформулировать так: верно ли, что всякая монотонная функцияможет быть представлена в виде, где— неубывающая ступенчатая функция (функция скачков), а — гладкая возрастающая функция, полученная интегрированием плотности?",
    "source_type": null,
    "useful_links": [
      {
        "text": "распределение Стьюдента",
        "url": "#%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5-%D1%81%D1%82%D1%8C%D1%8E%D0%B4%D0%B5%D0%BD%D1%82%D0%B0"
      }
    ]
  },
  {
    "document_title": "Решающие деревья",
    "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
    "section_title": "Определение решающего дерева",
    "text": "Разобравшись с приведёнными выше примерами, мы можем дать определение решающего дерева. Пусть задано бинарное дерево, в котором: каждой внутренней вершинеприписан предикат; каждой листовой вершинеприписан прогноз, где— область значений целевой переменной (в случае классификации листу может быть также приписан вектор вероятностей классов). В ходе предсказания осуществляется проход по этому дереву к некоторому листу. Для каждого объекта выборкидвижение начинается из корня. В очередной внутренней вершинепроход продолжится вправо, если, и влево, если. Проход продолжается до момента, пока не будет достигнут некоторый лист, и ответом алгоритма на объектесчитается прогноз, приписанный этому листу. Вообще, предикатможет иметь, произвольную структуру, но на практике чаще используют просто сравнение с порогомпо какому-то-му признаку: При проходе через узел дерева с данным предикатом объекты будут отправлены в правое поддерево, если значение-го признака у них меньше либо равно, и в левое — если больше. В дальнейшем рассказе мы будем по умолчанию использовать именно такие предикаты. Из структуры дерева решений следует несколько интересных свойств: выученная функция — кусочно-постоянная, из-за чего производная равна нулю везде, где задана. Следовательно, о градиентных методах при поиске оптимального решения можно забыть; дерево решений (в отличие от, например, линейной модели) не сможет экстраполировать зависимости за границы области значений обучающей выборки; дерево решений способно идеально приблизить обучающую выборку и ничего не выучить (то есть такой классификатор будет обладать низкой обобщающей способностью): для этого достаточно построить такое дерево, в каждый лист которого будет попадать только один объект. Следовательно, при обучении нам надо не просто приближать обучающую выборку как можно лучше, но и стремиться оставлять дерево как можно более простым, чтобы результат обладал хорошей обобщающей способностью.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Решающие деревья",
    "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
    "section_title": "Почему построение оптимального решающего дерева — сложная задача?",
    "text": "Пусть, как обычно, у нас задан датасет, где— вектор таргетов, а— матрица признаков, в которой-я строка — это вектор признаков-го объекта выборки. Пусть у нас также задана функция потерь, которую мы бы хотели минимизировать. Наша задача — построить решающее дерево, наилучшим образом предсказывающее целевую зависимость. Однако, как уже было замечено выше, оптимизировать структуру дерева с помощью градиентного спуска не представляется возможным. Как ещё можно было бы решить эту задачу? Давайте начнём с простого — научимся строитьрешающие пни, то есть решающие деревья глубины 1. Как и раньше, мы будем рассматривать только самые простые предикаты: Ясно, что задачу можно решить полным перебором: существует не болеепредикатов такого вида. Действительно, индекс(номер признака) пробегает значения отдо, а всего значений порога, при которых меняется значение предиката, может быть не более: Решение, которое мы ищем, будет иметь вид: Для каждого из предикатовнам нужно посчитать значение функции потерь на всей выборке, что, в свою очередь, тоже занимает.Следовательно, полный алгоритм выглядит так: Скопировать код1min_loss = inf2optimal_border =None34forjinrange(D):5fortinX[:, j]:# Можно брать сами значения признаков в качестве порогов6loss = calculate_loss(t, j, X, y)7ifloss <min_loss:8min_loss, optimal_border = loss, (j, t) Сложность алгоритма —. Это не заоблачная сложность, хотя, конечно, не идеальная. Но это была схема возможного алгоритма поиска оптимального дерева высоты 1. Как обобщить алгоритм для дерева произвольной глубины? Мы можем сделать наш алгоритм поиска решающего пня рекурсивным и в теле цикла вызывать исходную функцию для всех возможных разбиений. Как мы упоминали выше, так можно построить дерево, идеально запоминающее всю выборку, однако на тестовых данных такой алгоритм вряд ли покажет высокое качество. Можно поставить другую задачу: построить оптимальное с точки зрения качества на обучающей выборке дерево минимальной глубины (чтобы снизить переобучение). Проблема в том, что поиск такого дерева —NP-полнаязадача, то есть человечеству пока неизвестны способы решить её за полиномиальное время. Как быть? Идеального ответа на этот вопрос нет, но до некоторой степени ситуацию можно улучшить двумя не исключающими друг друга способами: Разрешить себе искать не оптимальное решение, а просто достаточно хорошее. Начать можно с того, чтобы строить дерево с помощьюжадного алгоритма, то есть не искать всю структуру сразу, а строить дерево этаж за этажом. Тогда в каждой внутренней вершине дерева будет решаться задача, схожая с задачей построения решающего пня. Для того чтобы этот подход хоть как-то работал, его придётся прокачать внушительным набором эвристик. Заняться оптимизацией с точки зрения computer science — наивную версию алгоритма (перебор наборов возможных предикатов и порогов) можно ускорить и асимптотически, и в константу раз. Эти две идеи мы и будем обсуждать в дальнейшем. Сначала попытаемся подробно разобраться с первой — как использовать жадный алгоритм.",
    "source_type": null,
    "useful_links": [
      {
        "text": "NP-полная",
        "url": "https://people.csail.mit.edu/rivest/pubs/HR76.pdf"
      }
    ]
  },
  {
    "document_title": "Решающие деревья",
    "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
    "section_title": "Жадный алгоритм построения решающего дерева",
    "text": "Пусть— исходное множество объектов обучающей выборки, а— множество объектов, попавших в текущий лист (в самом начале). Тогда жадный алгоритм можно верхнеуровнево описать следующим образом: Создаём вершину. Если выполненкритерий остановки, то останавливаемся, объявляем эту вершину листом и ставим ей в соответствие ответ, после чего возвращаем её. Иначе: находим предикат (иногда ещё говорятсплит), который определит наилучшее разбиение текущего множества объектовна две подвыборкии, максимизируякритерий ветвления. Дляирекурсивно повторим процедуру. Данный алгоритм содержит в себе несколько вспомогательных функций, которые надо выбрать так, чтобы итоговое дерево было способно минимизировать:, вычисляющая ответ для листа по попавшим в него объектам из обучающей выборки, может быть, например: в случае задачи классификации — меткой самого частого класса или оценкой дискретного распределения вероятностей классов для объектов, попавших в этот лист; в случае задачи регрессии — средним, медианой или другой статистикой; простой моделью. К примеру, листы в дереве, задающем регрессию, могут быть линейными функциями или синусоидами, обученными на данных, попавших в лист. Впрочем, везде ниже мы будем предполагать, что в каждом листе просто предсказывается константа. Критерий остановки— функция, которая решает, нужно ли продолжать ветвление или пора остановиться. Это может быть какое-то тривиальное правило: например, остановиться только в тот момент, когда объекты в листе получились достаточно однородными и/или их не слишком много. Более детально мы поговорим о критериях остановки в параграфе про регуляризацию деревьев. Критерий ветвления— пожалуй, самая интересная компонента алгоритма. Это функция, измеряющая, насколько хорош предлагаемый сплит. Чаще всего эта функция оценивает, насколько улучшится некоторая финальная метрика качества дерева в случае, если получившиеся два листа будут терминальными, по сравнению с ситуацией, когда сама исходная вершина — это лист. Выбирается такой сплит, который даёт наиболее существенное улучшение. Впрочем, есть и другие подходы. При этом строгой теории, которая бы связывала оптимальность выбора разных вариантов этих функций и разных метрик классификации и регрессии, в общем случае не существует. Однако есть набор интуитивных и хорошо себя зарекомендовавших соображений, с которыми мы вас сейчас познакомим. Давайте теперь по очереди посмотрим на популярные постановки задач ML и под каждую подберём свой критерий. Ответы дерева будем кодировать так:— для ответов регрессии и меток класса. Для случаев, когда надо ответить дискретным распределением на классах,будет вектором вероятностей: Предположим также, что задана некоторая функция потерь. О том, что это может быть за функция, мы поговорим ниже. В момент, когда мы ищем оптимальный сплит, мы можем вычислить для объектов изтот константный таргет, которые предсказало бы дерево, будь текущая вершина терминальной, и связанное с ними значение исходного функционала качества. А именно — константадолжна минимизировать среднее значение функции потерь: Оптимальное значение этой величины обычно называютинформативностью, илиimpurity. Чем она ниже, тем лучше объекты в листе можно приблизить константным значением. Похожим образом можно определить информативность решающего пня. Пусть, как и выше,— множество объектов, попавших в левую вершину, а— в правую; пусть такжеи— константы, которые предсказываются в этих вершинах. Тогда функция потерь для всего пня в целом будет равна Вопрос на подумать. Как информативность решающего пня связана с информативностью его двух листьев? Теперь для того чтобы принять решение о разделении, мы можем сравнить значение информативности для исходного листа и для получившегося после разделения решающего пня. Разность информативности исходной вершины и решающего пня равна Для симметрии её принято умножить на; тогда получится следующий критерий ветвления: Получившаяся величина неотрицательна: ведь, разделив объекты на две кучки и подобрав ответ для каждой, мы точно не сделаем хуже. Кроме того, она тем больше, чем лучше предлагаемый сплит. Теперь посмотрим, какими будут критерии ветвления для типичных задач. Посмотрим на простой пример — регрессию с минимизацией среднеквадратичной ошибки: Информативность листа будет выглядеть следующим образом: Как мы уже знаем, оптимальным предсказанием константного классификатора для задачи минимизации MSE является среднее значение, то есть Подставив в формулу информативности сплита, получаем: То есть при жадной минимизации MSE информативность — это оценка дисперсии таргетов для объектов, попавших в лист. Получается очень стройная картинка: оценка значения в каждом листе — это среднее, а выбирать сплиты надо так, чтобы сумма дисперсий в листьях была как можно меньше. Случай средней абсолютной ошибки так же прост: в листе надо предсказывать медиану, ведь именно медиана таргетов для обучающих примеров минимизирует MAE констатного предсказателя (мы это обсуждали в параграфе пролинейные модели). В качестве информативности выступает абсолютное отклонение от медианы: Пусть в нашей задачеклассов, а— доля объектов классав текущей вершине: Допустим, мы заботимся о доле верно угаданных классов, то есть функция потерь — это индикатор ошибки: Пусть также предсказание модели в листе — один какой-то класс. Информативность для такой функции потерь выглядит так: Ясно, что оптимальным предсказанием в листе будет наиболее частотный класс, а выражение для информативности упростится следующим образом: Если же мы собрались предсказывать вероятностное распределение классов, то к этому вопросу можно подойти так же, как мы поступали при выводе логистической регрессии: через максимизацию логарифма правдоподобия (= минимизацию минус логарифма) распределения Бернулли. А именно, пусть в вершине дерева предсказывается фиксированное распределение(не зависящее от), тогда правдоподобие имеет вид откуда То, что оценка вероятностей в листе, минимизирующая, должна быть равна, то есть доле попавших в лист объектов этого класса, до некоторой степени очевидно, но это можно вывести и строго. Подставляя векторв выражение выше, мы в качестве информативности получим энтропию распределения классов: Пусть предсказание модели — это распределение вероятностей классов. Вместо логарифма правдоподобия в качестве критерия можно выбрать, например,метрику Бриера(за которой стоит всего лишь идея посчитать MSE от вероятностей). Тогда информативность получится равной Можно показать, что оптимальное значение этой метрики, как и в случае энтропии, достигается на векторе, состоящем из выборочных оценок частот классов,. Если подставитьв выражение выше и упростить его, получитсякритерий Джини: Критерий Джини допускает и следующую интерпретацию:равно математическому ожиданию числа неправильно классифицированных объектов в случае, если мы будем приписывать им случайные метки из дискретного распределения, заданного вероятностями. Казалось бы, мы вывели критерии информативности для всех популярных задач, и они довольно логично следуют из их постановок, но получилось ли у нас обмануть NP-полноту и научиться строить оптимальные деревья легко и быстро? Конечно, нет. Простейший пример — решение задачи XOR с помощью жадного алгоритма и любого критерия, который мы построили выше: Вне зависимости от того, что вы оптимизируете, жадный алгоритм не даст оптимального решения задачи XOR. Но этим примером проблемы не исчерпываются. Скажем, бывают ситуации, когда оптимальное с точки зрения выбранной метрики дерево вы получите с критерием ветвления, построенным по другой метрике (например, MSE-критерий для MAE-задачи или Джини для misclassification error).",
    "source_type": null,
    "useful_links": [
      {
        "text": "линейные модели",
        "url": "https://education.yandex.ru/handbook/ml/article/linear-models"
      },
      {
        "text": "метрику Бриера",
        "url": "https://en.wikipedia.org/wiki/Brier_score#:~:text=The%20Brier%20Score%20is%20a,as%20applied%20to%20predicted%20probabilities"
      }
    ]
  },
  {
    "document_title": "Решающие деревья",
    "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
    "section_title": "Особенности данных",
    "text": "На первый взгляд, деревья прекрасно могут работать с категориальными переменными. А именно, если признакпринимает значения из множества, то при очередном разбиении мы можем рассматривать по этому признаку произвольные сплиты вида(предикат будет иметь вид). Это очень логично и естественно, но проблема в том, что при большиху нас будетсплитов, и перебирать их будет слишком долго. Было бы здорово уметь каким-то образомупорядочиватьзначения, чтобы работать с ними так же, как с обычными числами: разделяя на значения, «не превосходящие» и «большие» определённого порога. Оказывается, что для некоторых задач такое упорядочение можно построить вполне естественным образом. Так, для задачи бинарной классификации значенияможно упорядочить по неубыванию доли объектов класса 1 с, после чего работать с ними, как со значениями вещественного признака. Показано, что в случае, если мы выбираем таким образом сплит, оптимальный с точки зрения энтропийного критерия или критерия Джини, то он будет оптимальным среди всехсплитов. Для задачи регрессии с функцией потерь MSE значенияможно упорядочивать по среднему значению таргета на подмножестве. Полученный таким образом сплит тоже будет оптимальным. Одна из приятных особенностей деревьев — это способность обрабатывать пропуски в данных. Разберёмся, что при этом происходит на этапе обучения и на этапе применения дерева. Пусть у нас есть некоторый признак, значение которого пропущено у некоторых объектов. Как обычно, обозначим черезмножество объектов, пришедших в рассматриваемую вершину, а через— подмножество, состоящее из объектов с пропущенным значением. В момент выбора сплитов по этому признаку мы будем просто игнорировать объекты из, а когда сплит выбран, мы отправим их в оба поддерева. При этом логично присвоить им веса:для левого поддерева идля правого. Веса будут учитываться как коэффициенты прив формуле информативности. Вопрос на подумать. Во всех критериях ветвления участвуют мощности множеств,и. Нужно ли уменьшение размера выборки учитывать в формулах для информативности? Если нужно, то как? Теперь рассмотрим этап применения дерева. Допустим, в вершину, где сплит идёт по-му признаку, пришёл объектс пропущенным значением этого признака. Предлагается отправить его в каждую из дальнейших веток и получить по ним предсказанияи. Эти предсказания мы усредним с весамии(которые мы запомнили в ходе обучения): Для задачи регрессии это сразу даст нам таргет, а в задаче бинарной классификации — оценку вероятности класса 1. Замечание. Если речь идёт о категориальном признаке, может оказаться хорошей идеей ввести дополнительное значение «пропущено» для категориального признака и дальше работать с пропусками, как с обычным значением. Особенно это актуально в ситуациях, когда пропуски имеют системный характер и их наличие несёт в себе определённую информацию.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Решающие деревья",
    "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
    "section_title": "Методы регуляризации решающих деревьев",
    "text": "Мы уже упоминали выше, что деревья легко переобучаются и процесс ветвления надо в какой-то момент останавливать. Для этого есть разные критерии, обычно используются все сразу: ограничение по максимальной глубине дерева; ограничение на минимальное количество объектов в листе; ограничение на максимальное количество листьев в дереве; требование, чтобы функционал качествапри делении текущей подвыборки на две улучшался не менее чем напроцентов. Делать это можно на разных этапах работы алгоритма, что не меняет сути, но имеет разные устоявшиеся названия: можно проверять критерии прямо во время построения дерева, такой способ называетсяpre-pruningилиearly stopping; а можно построить дерево жадно без ограничений, а затем провестистрижку(pruning), то есть удалить некоторые вершины из дерева так, чтобы итоговое качество упало не сильно, но дерево начало подходить под условия регуляризации. При этом качество стоит измерять на отдельной, отложенной выборке.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Решающие деревья",
    "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
    "section_title": "Алгоритмические трюки",
    "text": "Теперь временно снимем шапочку ML-аналитика, наденем шапочку разработчика и специалиста по computer science и посмотрим, как можно сделать полученный алгоритм более вычислительно эффективным. В базовом алгоритме мы в каждой вершине дерева для всех возможных значений сплитов вычисляем информативность. Если в вершину пришлообъектов, то мы рассматриваемсплитов и для каждого тратимопераций на подсчёт информативности. Отметим, что в разных вершинах, находящихся в нашем дереве на одном уровне, оказываются разные объекты, то есть сумма этихпо всем вершинам заданного уровня не превосходит, а значит, выбор сплитов во всех вершинах уровня потребуетопераций. Таким образом, общая сложность построения дерева —(где— высота дерева), и доминирует в ней перебор всех возможных предикатов на каждом уровне построения дерева. Посмотрим, что с этим можно сделать. Постараемся оптимизировать процесс выбора сплита в одной конкретной вершине. Вместо того чтобы рассматривать всевозможных сплитов, для каждого тратяна вычисление информативности, можно использовать одномерную динамику. Для этого заметим, что если отсортировать объекты по какому-то признаку, то, проходя по отсортированному массиву, можно одновременно и перебирать все значения предикатов, и поддерживать все необходимые статистики для пересчёта значений информативности задля каждого следующего варианта сплита (против изначальных). Давайте разберём, как это работает, на примере построения дерева для MSE. Чтобы оценить информативность для листа, нам нужно знать несколько вещей: дисперсию и среднее значение таргета в текущем листе; дисперсию и среднее значение таргета в обоих потомках для каждого потенциального значения сплита. Дисперсию и среднее текущего листа легко посчитать за. С дисперсией и средним для всех значений сплитов чуть сложнее, но помогут следующие оценки математического ожидания и дисперсии: Следовательно, нам достаточно для каждого потенциального значения сплита знать количество элементов в правом и левом поддеревьях, их сумму и сумму их квадратов. Впрочем, всё это необходимо знать только для одной из половинок сплита, а для второй это можно получить, вычитая значения для первой из полных сумм. Это можно сделать за один проход по массиву, просто накапливая значения частичных сумм. Если в вершину дерева пришлообъектов, сложность построения одного сплита складывается изсортировок каждая пои одного линейного прохода с динамикой, всего, что лучше исходного. Итоговая сложность алгоритма построения дерева —(где– высота дерева) противв наивной его версии. Какие именно статистики накапливать (средние, медианы, частоты), зависит от критерия, который вы используете. Если бы мощность множества значений признаков была ограничена какой-то разумной константой, то сортировку в предыдущем способе можно было бы заменитьсортировкой подсчётоми за счёт этого существенно ускорить алгоритм: ведь сложность такой сортировки —. Чтобы провернуть это с любой выборкой, мы можем искусственно дискретизировать значения всех признаков. Это приведёт к локально менее оптимальным значениям сплитов, но, учитывая, что наш алгоритм и без этого был весьма приблизительным, это не ухудшит ничего драматически, а вот ускорение получается очень неплохое. Самый популярный и простой способ дискретизации основан на частотах значений признаков: отрезок между максимальным и минимальным значением признака разбивается наподотрезков, длины которых выбираются так, чтобы в каждый попадало примерно равное число обучающих примеров. После чего значения признака заменяются на номера отрезков, на которые они попали. Аналогичная процедура проводится для всех признаков выборки. Полная сложность предобработки —— сортировка задля каждого изпризнаков. Теперь в процедуре динамического алгоритма поиска оптимального сплита нам надо перебирать не всеобъектов выборки, а всего лишьподготовленных заранее границ подотрезков. Частичные суммы статистик тоже придётся поддерживать не для исходного массива данных, а для списка извозможных сплитов. А для того чтобы делать это эффективно, необходим объект, называемыйгистограммой: упорядоченный словарь, сопоставляющий каждому значению дискретизированного признака сумму необходимой статистики от таргета на отрезке [B[i-1], B[i]]. Финальный вид алгоритма таков: Дискретизируем каждый из признаков назначений. Сложность. Создаём корневую вершинуroot. Вызываемbuild_tree_recursive(root, data). Функцияbuild_tree_recursiveвыглядит следующим образом: Проверяем, не пора ли остановиться. Если пора — считаем значение в листе. Теперь мы снова используем динамический алгоритм, но объекты будем сортировать не по исходным значениям признаков, а по их дискретизированным версиям, упорядочивая их с помощью сортировки подсчётом (для вершины, в которую попалообъектов, сложность будет равнапротивв стандартной динамике). Находим оптимальный сплит за. Делим данные, запускаем процедуру рекурсивно для обоих поддеревьев. Общая сложность: Если вам действительно хочется построитьоптимальное(или хотя бы очень близкое к оптимальному) дерево, то на сегодня для решения этой проблемы не нужно придумывать кучу эвристик самостоятельно, а можно воспользоваться специальными солверами, которые решают NP-полные задачи приближённо, но всё-таки почти точно. Так что единственной (и вполне решаемой) проблемой будет представить исходную задачу в понятном для солвера виде. По ссылке —примерпостроения оптимального дерева с помощью решения задачи целочисленного программирования.",
    "source_type": null,
    "useful_links": [
      {
        "text": "сортировкой подсчётом",
        "url": "https://ru.wikipedia.org/wiki/%D0%A1%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%BA%D0%B0_%D0%BF%D0%BE%D0%B4%D1%81%D1%87%D1%91%D1%82%D0%BE%D0%BC"
      },
      {
        "text": "пример",
        "url": "https://arxiv.org/abs/1907.02211"
      }
    ]
  },
  {
    "document_title": "Решающие деревья",
    "url": "https://education.yandex.ru/handbook/ml/article/reshayushchiye-derevya",
    "section_title": "Историческая справка",
    "text": "Как вы, может быть, уже заметили, решающие деревья — это одна большая эвристика для решения NP-полной задачи, практически лишённая какой-либо стройной теоретической подоплёки. В 1970–1990-e годы интерес к ним был весьма велик как в индустрии, где был полезен хорошо интерпретируемый классификатор, так и в науке, где учёные интересовались способами приближённого решения NP-полных задач. В связи с этим сложилось много хорошо работающих наборов эвристик, у которых даже были имена: например,ID3был первой реализацией дерева, минимизирующего энтропию, аCART— первым деревом для регрессии. Некоторые из них были запатентованы и распространялись коммерчески. На сегодня это всё потеряло актуальность в связи с тем, что существуют хорошо написанные библиотеки (например,sklearn, в которой реализована оптимизированная версия CART).",
    "source_type": null,
    "useful_links": [
      {
        "text": "ID3",
        "url": "https://en.wikipedia.org/wiki/ID3_algorithm"
      },
      {
        "text": "CART",
        "url": "https://en.wikipedia.org/wiki/Predictive_analytics#Classification_and_regression_trees_.28CART.29"
      },
      {
        "text": "sklearn",
        "url": "https://scikit-learn.org/stable/modules/tree.html"
      }
    ]
  },
  {
    "document_title": "Обобщённые линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/obobshyonnye-linejnye-modeli",
    "section_title": "Мотивация",
    "text": "До сих пор мы рассматривали в основном модели вида с шумомиз того или иного распределения. Но у этих моделей: шум не зависит от; может принимать любые значения. А что, если мы захотим предсказывать время ожидания доставки? Казалось бы, чем дольше время потенциального ожидания, тем больше его дисперсия. А как корректно предсказывать таргет, который принимает только целые значения? Один из подходов мы обсудим в этом параграфе. Грубо говоря, вместо того, чтобы прибавлять один и тот же шум, мы зафиксируем семейство распределений, в котором изменяемым параметром будет зависящее отматематическое ожидание. Вот как могут выглядеть такие модели для случаев, еслинормальное с фиксированной дисперсией, экспоненциальное или пуассоновское соответственно: Как видим, такой подход позволяет получать и модели с меняющейся дисперсией шума, и модели с целочисленным таргетом.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обобщённые линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/obobshyonnye-linejnye-modeli",
    "section_title": "Определение",
    "text": "Мы рассмотрим достаточно широкий класс моделей —обобщённые линейные модели(generalized linear models,GLM). К ним относятся, в частности, линейная и логистическая регрессии. В итоге мы научимся подбирать подходящую регрессионную модель для самых разных типов данных. Вспомним, что вероятностную модель линейной регрессии можно записать как а вероятностную модель логистической регрессии — как где— распределение Бернулли с параметром, а. Итак, чем в этих терминах отличаются вероятностные модели линейной и логистической регрессии? Во первых, параметризованное семейство распределений для, а именно,в случае линейной регрессии ив случае логистической. Во-вторых, в обоих случаях математическое ожидание условного распределенияявляется функцией от. На это можно посмотреть и по-другому: для каждой из задач выбрана функциятакая, что. Эта функция называетсяфункцией связи(link function). В случае линейной регрессии. В самом деле,. В случае логистической регрессии. Давайте это тоже проверим. В модели логистической регрессии условное распределение— это распределение Бернулли с вероятностью успеха, и этой же вероятности равно его математическое ожидание. Следовательно,. Обобщая, можно сказать, что, если данные таковы, чтоне является линейной функцией от, мы линеаризуемс помощью функции связи. Замечание:Вообще говоря, нормальное распределение определяется не только своим математическим ожиданием, но и стандартным отклонением. То есть, в отличие от логистической регрессии, модель линейной регрессии не позволяет для данногооценить все параметры распределения, и дисперсию приходится фиксировать изначально. К счастью, выбор её значения в нормальном распределении не влияет ни на оптимальный вектор весов, ни на итоговые предсказания, которые выдаёт обученная модель. Продолжим. Задав эти две составляющие — параметризованное семейство распределений и функцию связи — мы получим обобщённую линейную модель (GLM). Для нового объектаона выдаст предсказание, а выбор класса распределенийпотребуется нам для подбора весов. В принципе, можно выбрать любой класс распределенийи любую монотонную функцию связи, получив некоторую вероятностную модель. Однако обычно для упрощения поиска оптимальных весовв GLM предполагают, чтопринадлежит одному из достаточно простых семейств экспоненциального класса.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обобщённые линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/obobshyonnye-linejnye-modeli",
    "section_title": "Что даёт нам принадлежность экспоненциальному классу?",
    "text": "В контексте GLM обычно рассматривают подкласс экспоненциального класса, состоящий из семейств, представимых в виде гдеи— скалярные параметры, причём— нечто фиксированное, обычно дисперсия, которая чаще всего полагается равной, а значенияпараметризуют распределения из семейства. Нетрудно переписать плотность в более привычном для нас виде, чтобы стало очевидно, что это семейство действительно из экспоненциального класса: Действительно, если вспомнить, что— это константа, а не параметр, то получается очень похоже на В частности, мы видим, чтосостоит из единственной компоненты, равной. По доказанной в предыдущем разделе лемме имеем тогда, что математическое ожиданиетакой случайной величины равно До сих пор мы рассуждали о распределениибезв условии. Что будет, если его добавить? Параметрмы договорились сохранять постоянным, тогда отдолжен зависеть единственный оставшийся параметр. Самый естественный в нашей ситуации вариант — это положить. В GLM мы вводили функцию, для которой, то есть. Но ведь матожиданиеравно, то есть. Это позволяет нам однозначно определить функцию связи. Такая функция связи называетсяканонической функцией связи(canonical link function).",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обобщённые линейные модели",
    "url": "https://education.yandex.ru/handbook/ml/article/obobshyonnye-linejnye-modeli",
    "section_title": "Примеры",
    "text": "Поговорим немного о том, как на практике подбирать, чтобы по классу распределенийопределить каноническую функцию связи. Чтобы разобраться, рассмотрим несколько примеров. Пример 1. Пусть мы решили применить к данным линейную регрессию. Тогда Обозначим для краткостии будем рассматривать. Мы уже знаем, что семейство нормальных распределений относится к экспоненциальному классу, но давайте выразим эту плотность в описанном выше более частном виде: В формуле экспоненциального семейства распределений единственная часть, не зависящая от, — это функция. Поскольку, функциятакже не должна зависеть от. Так что внутри экспоненты выделим в качестве функциивсё, что не зависит от: Эта формула уже похожа на формулу экспоненциального семейства распределений и видно, что,(коэффициент при),,. Каноническая функция связи является обратной к, то есть, как мы и привыкли. Пример 2. Проделаем то же самое, но теперь для распределения Бернулли. Пример 3. Хорошо, про линейную и логистическую регрессию мы и так знали. Давайте попробуем решить с помощью GLM новую задачу. Пусть мы хотим по каким-то признакампредсказать количество «лайков», которое пользователи поставят посту в социальной сети за первые 10 минут после публикации. Конечно, можно использовать для этого линейную регрессию. Однако предположение линейной регрессии, что, в данном случае странное по нескольким причинам. Во-первых, количество лайков заведомо не может быть отрицательным, а нормальное распределение всегда будет допускать ненулевую вероятность отрицательного значения. Во-вторых, количество лайков — всегда целое число. В-третьих, у распределения количества лайков, скорее всего,положительный коэффициент асимметрии(skewness). То есть, если модель предсказывает, что под постом будет 100 лайков, мы скорее можем ожидать, что под ним окажется 200 лайков, чем 0. Нормальное распределение симметрично и не может описать такие данные. С другой стороны, если мы предположим, что в первые 10 минут после публикации есть какая-то постоянная частота (своя для каждого поста, зависящая от), с которой пользователи ставят лайк, мы получим, что количество лайков имеет распределение Пуассона. Распределение Пуассона не имеет описанных выше проблем: Но какая будет каноническая функция связи, если мы считаем, что? Аналогично первому и второму примерам: Откуда,,, Значит, эта модель (она называетсяпуассоновская регрессия), будет предсказывать с помощью формулы. Вопрос на подумать. В каких ситуациях была бы полезной функция связиcomplementary log-log link(cloglog)",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Кластеризация",
    "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
    "section_title": "Задача кластеризации",
    "text": "В задаче классификации мы имели дело с восстановлением отображения из множества объектов в конечный набор меток классов. При этом классы были зафиксированы заранее, то есть мы с самого начала примерно понимали, какого рода объекты должны относиться к каждому из них, и мы располагали обучающей выборкой с примерами объектов и классов, к которым они относятся. В задаче кластеризации мы тоже разбиваем объекты на конечное множество классов, но у нас нет ни обучающей выборки, ни понимания, какой будет природа этих классов. То, что модель кластеризации какие-то объекты сочла «похожими», отнеся к одному классу, будет новой информацией, «открытием», сделанным этой моделью. Обучающей выборки у нас также не будет: ведь мы не знаем заранее, что за классы получатся (а иногда и сколько их будет). Таким образом,кластеризация— это задача обучения без учителя. Из-за общего сходства постановок задач в литературе кластеризацию иногда называютunsupervised classification. Методы кластеризации часто применяют, когда фактически нужно решить задачу классификации, но обучающую выборку собрать затруднительно (дорого или долго). При этом валидационную выборку для оценки результатов кластеризации собрать значительно проще, так как для неё требуется меньше примеров. При этом стоит помнить, что точность работы supervised-методов значительно выше. Поэтому, если обучающую выборку всё-таки можно собрать, лучше решать задачу классификации, чем задачу кластеризации.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Кластеризация",
    "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
    "section_title": "Примеры задач кластеризации",
    "text": "Хороший пример применения методов кластеризации — анализ геоданных. В мобильных приложениях, собирающих геоданные пользователей, часто требуется понять, где именно пользователь находился. GPS-координаты известны с некоторой погрешностью, пользователь тоже обычно двигается, поэтому вместо точного положения часто приходится иметь дело с роем точек. Положение усугубляется, когда мы пытаемся анализировать поведение сразу тысяч людей в какой-то локации — например, определить, в каких точках люди чаще всего садятся в такси у аэропорта. Может показаться, что достаточно посмотреть на данные — и мы увидим в точности нужные нам кластеры. Изображение ниже показывает, как может выглядеть ситуация всего для нескольких пользователей: согласно данным GPS, такси подбирают пассажиров и внутри здания аэропорта, и на взлётной полосе, и там, где это происходит на самом деле: Подобная задача решалась в Яндекс.Такси при разработке пикап-пойнтов (наиболее удобных точек вызова такси, подсвечиваемых в приложении). Координаты точек заказа кластеризовались таким образом, чтобы кластер соответствовал какому-то одному, удобному для пользователя месту, и центры кластеров использовались как кандидаты в пикап-пойнты. Те кандидаты, которые удовлетворяли простым фильтрам (например, не попадали в здание или в воду), использовались в приложении. При этом не обходилось и без вручную проставленных пикап-пойнтов: например, такое решение использовалось в окрестностях аэропортов. Другой пример кластеризации геоданных, который всегда рядом с нами, — это интерфейсы для просмотра фотографий в вашем смартфоне. Почти наверняка вы можете просмотреть их в привязке к местам, где они были сделаны, и по мере масштабирования карты вы будете видеть разное количество кластеров фотографий. Кстати, если говорить об интерфейсах, то есть и другой интересный пример: если нужно подстроить цветовую схему вашего интерфейса под выбираемое пользователем изображение (например, фоновую картинку), достаточно кластеризовать цвета из пользовательского изображения, используя RGB-представление (или любое другое) как признаки цвета, и воспользоваться для оформления цветами, соответствующими центрам кластеров.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Кластеризация",
    "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
    "section_title": "Простейшие методы кластеризации с помощью графов",
    "text": "Можно приводить примеры не только про геоаналитику, однако тема геоданных поможет нам придумать пару наиболее простых и наглядных методов кластеризации. Представим, что перед нами рой геокоординат и нам нужно предложить по этим данным пикап-пойнты для такси. Разберём пару очевидных методов. Логично попробовать объединить точки, которые находятся друг от друга на расстоянии двух-трёх метров, а потом просто выбрать наиболее популярные места. Для этого давайте построим на известных нам точках граф: точки, расстояние между которыми в пределах трёх метров, мы соединим рёбрами. Выделим в этом графе компоненты связности, они и будут нашими кластерами. У этого способа есть пара очевидных недостатков. Во-первых, может найтись сколько угодно длинная цепочка точек, в которой соседние отстоят друг от друга на пару метров, — и вся она попадёт в одну компоненту связности. В итоге наша отсечка по трём метрам имеет очень опосредованное отношение к диаметру кластеров, а сами кластеры будут получаться значительно больше, чем нам хотелось бы. Во-вторых (и с первой проблемой это тоже связано), непонятно, как мы выбираем максимальное расстояние, при котором соединяем точки ребром. В данной задаче ещё можно предъявить хоть какую-то логику, а вот если бы мы кластеризовали не геометки, а что-то многомерное, например электронные письма по их тематике, придумать отсечку было бы уже сложнее. Если наша цель — не только решить практическую задачу, но и придумать достаточно общий метод кластеризации, понятно, что нам хочется понимать, как подбирать параметры этого метода (в данном случае условие добавления рёбер в граф). Эти соображения могут привести нас к другому решению. Вместо того чтобы проводить рёбра в графе, давайте их удалять. Построимминимальное остовное дерево, считая расстояния между точками весами рёбер. Тогда, удаливрёбер с наибольшим весом, мы получимкомпоненту связности, которые, как и в прошлом подходе, будем считать кластерами. Различие в том, что теперь нам нужно задавать не расстояние, при котором проводится ребро, а количество кластеров. С одной стороны, если мы решаем задачу расчёта пикап-пойнтов в какой-то конкретной локации (аэропорт, торговый центр, жилой дом), нам может быть понятно, сколько примерно пикап-пойнтов мы хотим получить. С другой стороны, даже без локального рассмотрения можно просто сделать достаточно много кластеров, чтобы было из чего выбирать, но при этом достаточно мало, чтобы в каждый кластер попадало репрезентативное количество точек. Аналогичная логика будет справедлива и во многих других задачах кластеризации: количество кластеров — достаточно общий и достаточно хорошо интерпретируемый параметр, чтобы настраивать его вручную, поэтому во многих методах кластеризации количество кластеров выступает как гиперпараметр. Далее будем рассматривать некоторую обобщённую задачу кластеризации без привязки к нашему примеру с анализом геоданных. Мы приведём три наиболее популярных метода кластеризации — k-средних, иерархическую кластеризацию и DBSCAN, а затем рассмотрим вопросы оценки качества кластеризации.",
    "source_type": null,
    "useful_links": [
      {
        "text": "минимальное остовное дерево",
        "url": "https://ru.wikipedia.org/wiki/%D0%9C%D0%B8%D0%BD%D0%B8%D0%BC%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B5_%D0%BE%D1%81%D1%82%D0%BE%D0%B2%D0%BD%D0%BE%D0%B5_%D0%B4%D0%B5%D1%80%D0%B5%D0%B2%D0%BE"
      }
    ]
  },
  {
    "document_title": "Кластеризация",
    "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
    "section_title": "Метод K средних",
    "text": "Пожалуй, один из наиболее популярных методов кластеризации — это метод K-средних (K-means). Основная идея метода — итеративное повторение двух шагов: распределение объектов выборки по кластерам; пересчёт центров кластеров. В начале работы алгоритма выбираютсяслучайных центров в пространстве признаков. Каждый объект выборки относят к тому кластеру, к центру которого объект оказался ближе. Далее центры кластеров пересчитывают как среднее арифметическое векторов признаков всех вошедших в этот кластер объектов (то есть центр масс кластера). Как только мы обновили центры кластеров, объекты заново перераспределяются по ним, а затем можно снова уточнить положение центров. Процесс продолжается до тех пор, пока центры кластеров не перестанут меняться. Первый вопрос при выборе начального положения центров — как, выбирая центры из некоторого случайного распределения, не попасть в область пространства признаков, где нет точек выборки. Базовое решение — просто выбрать в качестве центров какие-то из объектов выборки. Вторая потенциальная проблема — кучное размещение центров. В этом случае их начальное положение с большой вероятностью окажется далёким от итогового положения центров кластеров. Например, для таких изначальных положений центров мы получим неправильную кластеризацию. Чтобы бороться с этим явлением, выгодно брать максимально удаленные друг от друга центры. На практике работает следующая эвристика: первый центр выбираем случайно из равномерного распределения на точках выборки; каждый следующий центр выбираем из случайного распределения на объектах выборки, в котором вероятность выбрать объект пропорциональна квадрату расстояния от него до ближайшего к нему центра кластера.Модификация K-means, использующая эту эвристику для выбора начальных приближений, называется K-means++. Так как работа метода K-средних состоит из последовательного повторения до сходимости двух шагов, обоснованность применения различных метрик (расстояний между точками, а не метрик качества 😃 или функций близости связана с тем, «ломают» они какой-либо из этих шагов или нет. Первый шаг с отнесением объектов к ближайшим центрам не зависит от вида метрики. Второй шаг предполагает пересчёт центров как среднего арифметического входящих в кластер точек, и вот здесь будет подвох: к оптимальности выбора центров в среднем арифметическом приводит именно евклидова метрика (подробнее в разделе «Что оптимизирует K-means»). Однако на практике никто не мешает использовать метод и без должного обоснования, поэтому можно экспериментировать с любыми расстояниями, с той лишь оговоркой, что не будет никаких теоретических гарантий, что метод сработает. Наиболее распространённая альтернатива евклидовой метрике — это косинусная мера близости векторов (она особенно популярна в задачах анализа текстов): При её использовании стоит не забывать, что косинусная мера — это функция близости, а не расстояние, так что чем больше её значения, тем ближе друг к другу векторы. Несложно заметить, что, если считатьи размерность пространства признаков константами, оба шага алгоритма работают за, где n — количество объектов обучающей выборки. Отсюда возникает идея ускорения работы алгоритма. В mini-batch K-means мы не считаем шаги сразу на всей выборке, а на каждой итерации выбираем случайную подвыборку (мини-батч) и работаем на ней. В случае когда исходная выборка очень велика, переход к пакетной обработке не приводит к большой потере качества, зато значительно ускоряет работу алгоритма. С другой стороны, вычисление расстояний и средних делается за, где— размерность пространства признаков, так что другая идея ускорения K-means — это предварительно понизить размерность пространства признаков (с помощью PCA или эмбеддингов). Особенно удачно эта идея работает в задачах кластеризации текстов, когда K-means применяют на эмбеддингах слов: получается выиграть не только в скорости работы, но и в интерпретируемости результатов кластеризации. Кстати, сам алгоритм кластеризации тоже можно использовать как метод понижения размерности. Если вы решаете задачу обучения с учителем и пространство признаков очень разнообразно (то есть обучающая выборка не даёт вам достаточно статистики при столь большом числе признаков), можно выполнить кластеризацию объектов выборки на 500 или 1000 кластеров и оперировать попаданием объектов в какой-то кластер как признаком. Такой подход называетсяквантизацией пространства признаков(feature space quantization) и часто помогает на практике, когда нужно огрубить признаки, добавить им интерпретируемости или же, наоборот, обезличить. Хрестоматийный пример такого использования кластеризации — метод bag of visual words, расширяющий bag of words из анализа текстов на работу с изображениями. Идея метода в том, чтобы строить признаковое описание изображений на основе входящих в него фрагментов: так, изображения с лицами будут содержать фрагменты с носом, глазами, ртом, а изображения с машинами — колёса, зеркала, двери. Но проблема здесь в том, что нарезать такие фрагменты из обучающей выборки и искать точные совпадения в новых примерах изображений, которые нужно классифицировать, — безнадёжная затея. В жизни фрагменты изображений не повторяются в других изображениях с попиксельной точностью. Решение этой проблемы оказалось возможным при помощи алгоритмов кластеризации (исторически использовался именно K-means): фрагменты изображений из обучающей выборки кластеризовали на 100–1000 кластеров («визуальных слов»), а проходясь по новым изображениям, также нарезали их на фрагменты и относили к одному из этих кластеров. В итоге как новые изображения, так и изображения из обучающей выборки можно было описать количеством вхождений в них фрагментов из различных кластеров («визуальных слов»), так же как в анализе текстов описывают текст количеством вхождений в него слов из словаря. В таком признаковом пространстве уже можно было успешно обучать модели машинного обучения. Сейчас выделение «визуальных слов» в задаче классификации изображений происходит автоматически: с одной стороны, задачи компьютерного зрения теперь решаются нейросетями, но с другой стороны — если мы визуализируем отдельные слои этих нейросетей, станет понятно, что их логика работы во многом похожа на описанную выше. При этом идея квантизации признаков не утратила своей актуальности. Вот лишь несколько современных примеров её применения: Если вам необходимо дать возможность заказчику (например, внешней компании) анализировать используемые вами признаки — отсутствие провалов в данных и какие-то другие общие показатели, но нельзя отдавать признаки как есть (например, из-за законодательства, регулирующего передачу пользовательских данных), возможное решение — это агрегировать признаки по кластерам. Та же цель может быть отчасти достигнута, если перейти к самим кластерам как к признакам, чтобы скрыть исходные признаки. Переход к кластерам может быть сделан не с целью что-то скрыть, а наоборот, с целью повысить интерпретируемость: исходные сырые данные часто не вполне понятны бизнесу, но позволяют построить маркетинговые сегменты по различным коммерческим интересам пользователей, из-за чего становится удобно показывать принадлежность к этим сегментам как исходные признаки, не вдаваясь в детали о том, на каких данных эти сегменты построены. Для ускорения поиска похожих объектов в пространстве признаков вы также можете проводить поиск внутри того же кластера и соседних кластеров, так что за счёт «огрублённого» вида признаков какие-то процессы можно ещё и ускорить. Проговорим на интуитивном уровне, какую оптимизационную задачу решает K-means. Оба шага алгоритма работают на уменьшение среднего квадрата евклидова расстояния от объектов до центров их кластеров: На шаге отнесения объектов к одному из кластеров мы выбираем кластер с ближайшим центроидом, то есть минимизируем каждое слагаемое в: все потенциально большие слагаемые мы зануляем, а оставляем ненулевыми только наименьшие из возможных (при условии фиксирования центров кластеров). На шаге пересчёта центров кластеров мы выбираем центр таким образом, чтобы при фиксированном наборе объектов, относящихся к кластеру, для всехминимизировать выражение, стоящее под суммой по: Здесь уже становится принципиально, что мы определяем квадрат расстояния как квадрат разности векторов, так как именно отсюда при дифференцировании пои записи необходимого условия экстремума получается, что центры кластеров нужно пересчитывать как средние арифметические, принадлежащих кластеру. Этих соображений, конечно, недостаточно, чтобы утверждать, что мы найдём минимум. Более того, гарантии того, что мы найдём глобальный минимум, вообще говоря, нет. Однако, потратив чуть больше усилий, можно доказать, что процесс сойдётся в один из локальных минимумов. Также можно справедливо заметить, что, так как любой центр кластера — это среднее арифметическое входящих в кластер объектов, на выборке фиксированного размера есть лишь конечное множество потенциальных центров кластеров. Если предположить, что в ходе работы K-means не зацикливается, отсюда следует, что рано или поздно центры кластеров не изменятся на следующем шаге и алгоритм сойдётся. При этом фактическая сходимость, конечно же, происходит задолго до полного перебора всех возможных центров кластеров.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Кластеризация",
    "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
    "section_title": "Иерархическая агломеративная кластеризация",
    "text": "Другой классический метод кластеризации — этоиерархическая кластеризация. Иногда дополнительно уточняют:иерархическая агломеративная кластеризация. Название указывает сразу на два обстоятельства. Во-первых, есть деление алгоритмов кластеризации наагломеративные(agglomerative) идивизивные, илидивизионные(divisive). Агломеративные алгоритмы начинают с небольших кластеров (обычно с кластеров, состоящих из одного объекта) и постепенно объединяют их в кластеры побольше. Дивизивные начинают с больших кластеров (обычно – с одного единственного кластера) и постепенно делят на кластеры поменьше. Во-вторых, кластеризация бывает, по аналогии с оргструктурой в организациях, плоской (когда все кластеры равноправны и находятся на одном уровне кластеризации) и иерархической (когда кластеры бывают вложены друг в друга и образуют древовидную структуру). В случае иерархической агломеративной кластеризации мы действительно будем начинать с кластеров из одного объекта, постепенно объединяя их, а уже последовательность этих объединений даст структуру вложенности кластеров. Даже если в итоге мы будем использовать кластеры с одного уровня, не углубляясь ни в какую вложенность, кластеризация всё равно называется иерархической, так как иерархия естественным образом возникает в процессе работы алгоритма. Сам алгоритм выглядит предельно просто: Создаём столько кластеров, сколько у нас объектов в выборке, каждый объект — в своём отдельном кластере. Повторяем итеративно слияние двух ближайших кластеров, пока не выполнится критерий останова. Как измерить расстояние между кластерами из одного объекта? Нужно просто взять расстояние между этими объектами. Остаётся вопрос, как обобщить расстояние между объектами до расстояния между кластерами (если в них более одного объекта). Традиционные решения — брать среднее расстояние между объектами кластеров, минимальное расстояние или максимальное. Если обозначить кластерыи, расстояние между ними в этом случае можем вычислять по одной из формул: Используемая формула расстояния между кластерами — один из гиперпараметров алгоритма. Кроме приведённых стандартных вариантов бывают и более экзотичные, например расстояние Уорда (Ward distance). В наиболее общем виде способы задания расстояния между кластерами даются формулой Ланса — Уильямса (Lance — Williams; более подробно вы можете почитать вэтой статье). Сами же расстояния между объектами можно задавать любой метрикой, как евклидовой, так и манхэттенским расстоянием или, например, косинусной мерой (с той лишь поправкой, что это мера близости, а не расстояние). В качестве условия для завершения работы алгоритма можем выбрать либо получение нужного количества кластеров (количество кластеров может быть гиперпараметром алгоритма), либо выполнение эвристик на основе расстояния между объединяемыми кластерами (например, если расстояние сливаемых кластеров значительно выросло по сравнению с прошлой итерацией). На практике же обычно кластеризацию проводят вплоть до одного кластера, включающего в себя всю выборку, а затем анализируют получившуюся иерархическую структуру с помощью дендрограммы. По мере объединения кластеров, каждой итерации алгоритма соответствует пара объединяемых на этой итерации кластеров, а также расстояние между кластерами в момент слияния. Расстояния с ростом итерации будут только увеличиваться, поэтому возникает возможность построить следующую схему, называемуюдендрограммой: Здесь по горизонтали внизу отмечены объекты кластеризуемой выборки, под горизонтальной осью подписаны номера объектов, а их расположение вдоль оси продиктовано только эстетическими соображениями: нам удобно строить дендрограмму так, чтобы никакие дуги в ней не пересекались. По вертикали отложены расстояния между кластерами в момент слияния. Когда происходит объединение кластеров, состоящих из нескольких объектов, соответствующая этой итерации алгоритма дуга идёт не до конкретных объектов выборки, а до дуги другого кластера. Таким образом мы получаем наглядную визуализацию древовидной структуры процесса кластеризации. В частности, на дендрограмме мы можем визуально заметить, в какой момент происходит скачок расстояний между кластерами, и попытаться определить «естественное» количество кластеров в нашей задаче. На практике же это соображение, как правило, остаётся лишь красивой теорией, так как любую кластеризацию можно делать в разной степени «мелкой» и «естественного» количества кластеров в практических задачах часто не существует. В случае же если данные были получены таким образом, что в них действительно есть какое-то естественное количество кластеров, иерархическая кластеризация обычно справляется с определением числа кластеров по дендрограмме заметно хуже, чем DBSCAN. Именно алгоритму DBSCAN мы и посвятим следующий раздел.",
    "source_type": null,
    "useful_links": [
      {
        "text": "этой статье",
        "url": "https://arxiv.org/pdf/1105.0121.pdf"
      }
    ]
  },
  {
    "document_title": "Кластеризация",
    "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
    "section_title": "DBSCAN",
    "text": "АлгоритмDBSCAN(Density-based spatial clustering of applications with noise) развивает идею кластеризации с помощью выделения связных компонент. Прежде чем перейти к построению графа, введём понятие плотности объектов выборки в пространстве признаков. Плотность в DBSCAN определяется в окрестности каждого объекта выборкикак количество других точек выборки в шаре. Кроме радиусаокрестности в качестве гиперпараметра алгоритма задается порогпо количеству точек в окрестности. Далее все объекты выборки делятся на три типа:внутренние / основные точки(core points),граничные(border points) ишумовые точки(noise points). К основным относятся точки, в окрестности которых большеобъектов выборки. К граничным — точки, в окрестности которых есть основные, но общее количество точек в окрестности меньше. Шумовыми называют точки, в окрестности которых нет основных точек и в целом содержится менееобъектов выборки. Алгоритм кластеризации выглядит следующим образом: Шумовые точки убираются из рассмотрения и не приписываются ни к какому кластеру. Основные точки, у которых есть общая окрестность, соединяются ребром. В полученном графе выделяются компоненты связности. Каждая граничная точка относится к тому кластеру, в который попала ближайшая к ней основная точка. Удобство DBSCAN заключается в том, что он сам определяет количество кластеров (по модулю задания других гиперпараметров —и), а также в том, что метод успешно справляется даже с достаточно сложными формами кластеров. Кластеры могут иметь вид протяжённых лент или быть вложенными друг в друга как концентрические гиперсферы. На изображении ниже показан пример выделения кластеров достаточно сложной формы с помощью DBSCAN: DBSCAN — один из самых сильных алгоритмов кластеризации, но работает он, как правило, заметно дольше, чем mini-batch K-means, к тому же весьма чувствителен к размерности пространства признаков, поэтому используется на практике DBSCAN только тогда, когда успевает отрабатывать за приемлемое время.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Кластеризация",
    "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
    "section_title": "Какой метод кластеризации выбирать?",
    "text": "Если сравнивать частоту использования K-means, иерархической кластеризации и DBSCAN, то на первом месте, бесспорно, будет K-means, а второе место будут делить иерархический подход и DBSCAN. Иерархическая кластеризация — более известный и простой в понимании метод, чем DBSCAN, но довольно редко отрабатывающий качественно. Частая проблема иерархической кластеризации — раннее образование одного гигантского кластера и ряда очень небольших, что приводит к сильной несбалансированности количества объектов в итоговых кластерах. В то же время DBSCAN — менее широко известный подход, но, когда его можно применить, качество, как правило, получается выше, чем в K-means или иерархической кластеризации.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Кластеризация",
    "url": "https://education.yandex.ru/handbook/ml/article/klasterizaciya",
    "section_title": "Оценка качества кластеризации",
    "text": "Далее приведём список основных метрик качества кластеризации и обсудим некоторые особенности их применения. Смысл среднего внутрикластерного расстояния максимально соответствует названию: Сумма расстояний между точками из одного и того же кластера делится на количество пар точек, принадлежащих к одному кластеру. В приведённой выше формуле пары видавключены в рассмотрение, чтобы избежать неопределённостив случае, когда в каждом кластере ровно по одному объекту. Однако иногда записывают суммы по, просто доопределяяв описанном случае нулём. Решая задачу кластеризации, мы хотим по возможности получать как можно более кучные кластеры, то есть минимизировать. В случае если у кластеров есть центры, часто рассматривается аналогичная метрика — средний квадрат внутрикластерного расстояния: Аналогично среднему внутрикластерному расстоянию вводится среднее межкластерное: Среднее межкластерное расстояние, напротив, нужно максимизировать, то есть имеет смысл выделять в разные кластеры наиболее удалённые друг от друга объекты. Для измерения следующих метрик (гомогенности, полноты и V-меры) нам уже потребуется разметка выборки. Будем обозначать кластеры, к которым наш алгоритм кластеризации относит каждый объект, буквами, а классы, к которым объекты отнесены разметкой, — буквами. Разумный вопрос при наличии разметки — зачем нам решать задачу кластеризации, если с разметкой можно поставить задачу как задачу классификации. Это и правда хороший вопрос в том случае, если размеченных данных достаточно много для обучения классификатора. На практике же часто встречаются ситуации, когда данных достаточно для оценки качества кластеризации, но всё ещё не хватает для использования методов обучения с учителем. Пусть— общее количество объектов в выборке,— количество объектов в кластере номер,— количество объектов в классе номер, а— количество объектов из классав кластере. Рассмотрим следующие величины: Несложно заметить, что эти величины соответствуют формуле энтропии и условной энтропии для мультиномиальных распределений,исоответственно. Гомогенность кластеризации определяется следующим выражением: Отношениепоказывает, во сколько раз энтропия изменяется за счёт того, что мы считаем известной принадлежность объектов к выделенным нашим алгоритмом кластерам. Худший случай — когда отношение оказывается равным единице (энтропия не изменилась, условная энтропия совпала с обычной), лучший — когда каждый кластер содержит элементы только одного класса и номер кластера, таким образом, точно определяет номер класса (в этом случае). Тривиальный способ максимизировать гомогенность кластеризации — выделить каждый объект выборки в отдельный кластер. Полнота задаётся аналогично гомогенности, с той лишь разницей, что вводится величина, симметричная: Полнота равна единице, когда все объекты класса всегда оказываются в одном кластере. Тривиальный способ максимизировать полноту кластеризации — объединить всю выборку в один кластер. Гомогенностьиполнотакластеризации – это в некотором смысле аналоги точности и полноты классификации. Аналог F-меры для задачи кластеризации тоже есть, он называется V-мерой и связан с гомогенностью и полнотой той же формулой, что и F-мера с точностью и полнотой: В частности,по аналогии с-мерой в классификации (не путать со средним межкластерным расстоянием, которое мы тоже обозначаливыше) будет просто средним гармоническим гомогенности и полноты: V-мера комбинирует в себе гомогенность и полноту таким образом, чтобы максимизация итоговой метрики не приводила к тривиальным решениям. Ещё одна метрика кластеризации, на этот раз уже не требующая разметки, этокоэффициент силуэта(silhouette coefficient). Изначально коэффициент определяется для каждого объекта выборки, а метрика для результатов кластеризации всей выборки вводится как средний коэффициент силуэта для всех объектов выборки. Чтобы ввести коэффициент силуэта, нам потребуются две вспомогательные величины. Первая,, — это среднее расстояние междуи объектами того же кластера. Вторая,, — это среднее расстояние междуи объектами следующего ближайшего кластера. Коэффициент силуэта вводится следующим образом: В идеальном случае объекты «родного» кластерадолжны быть ближе к, чем объекты соседнего кластера, то есть. Однако это неравенство выполняется далеко не всегда. Если «родной» кластер, например, имеет форму очень протяжённой ленты или просто большой размер, а недалеко отесть кластер поменьше, может оказаться, что. Таким образом, если мы посмотрим на разность, она может оказаться как положительной, так и отрицательной, но в идеальном сценарии всё же следует ожидать положительное значение. Сам же коэффициентпринимает значения от –1 до +1 и максимизируется, когда кластеры кучные и хорошо отделены друг от друга. Коэффициент силуэта особенно полезен (по сравнению с другими приведёнными метриками) тем, что одновременно и не требует разметки, и позволяет подбирать количество кластеров. См. подробнеев примере из документации scikit-learn. Подводя итог в теме метрик качества в задаче кластеризации, отметим, что есть несколько разных сценариев использования этих метрик. Если вы уже определились с количеством кластеров, можно оптимизировать среднее внутрикластерное или среднее межкластерное расстояние. Если у вас ещё и есть разметка — гомогенность и полноту. V-мера за счёт сочетания гомогенности и полноты в целом позволяет выполнять и подбор количества кластеров. Однако разметка, с одной стороны, есть далеко не всегда, а с другой стороны, в задаче кластеризации часто очень субъективна. Сложность кластеризации в том, что на одной и той же выборке нас вполне могут устроить сразу несколько различных вариантов кластеризации, то есть задача поставлена некорректно и имеет более одного решения. Формализовать, какие решения нас устроят, на практике довольно сложно, поэтому сама по себе задача кластеризации решается не слишком хорошо. Если разметки нет и число кластеров не фиксировано, лучшая метрика на практике — коэффициент силуэта. Исключение — ситуация, когда результат кластеризации используется далее для решения некоторой задачи обучения с учителем (как было в примере классификации изображений с помощью visual bag of words). В этом случае можно абстрагироваться от качества кластеризации и выбирать такой алгоритм кластеризации и такие его гиперпараметры, которые позволят лучше всего решить итоговую задачу.",
    "source_type": null,
    "useful_links": [
      {
        "text": "в примере из документации scikit-learn",
        "url": "https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html"
      }
    ]
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Модель скользящего среднего MA()",
    "text": "Модель скользящего среднего порядкаили просто MA() предполагает следующую зависимость данных: где— стационарный ряд со средним, а— гауссовский белый шум, то естьи независимы. По сути наш рядвыражается через сумму некоторого фиксированного среднего, значения белого шума в текущий момент времении не болеепредыдущих значений белого шума, домноженных на некоторые коэффициенты, которые являются параметрами модели. Рассмотрим некоторые свойства модели MA(). Как уже было упомянуто выше, рядбудет являтьcя стационарным со средним. Найдем также. Воспользовавшись свойством независимости для, можем заключить, что Посчитаем автоковариационную функцию для ряда, то есть найдем значение. Легко понять, что если, то= 0, т.к.независимы. Если же, то тогда Записав более компактно, можем получить: где. Из посчитанных значений для дисперсии и ковариационной функции, можете попробовать получить выражение и для автокорреляционной функции. Ее особенностью будет как раз равенство нулю на лаге, превосходящим. Посмотрим на визуализацию:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Модель авторегрессии AR()",
    "text": "Модель авторегрессии для временного ряда можно записать следующим образом: где— стационарный ряд, а— гауссовский белый шум, то естьи независимы. Отметим, что, вообще говоря, для стационарности нужны некоторые условия на коэффициенты. По сути наш рядвыражается через сумму некоторого фиксированного числа, значения белого шума в текущий момент времении не болеепредыдущих значений этого же ряда, домноженных на некоторые коэффициенты, которые являются параметрами модели. Другими словами, модель AR() — это модельдля которой Таргет:— значение ряда в момент времени Признаки:— значения ряда в предыдущие моменты времени Введем— оператор сдвига, обладающий следующими свойствами: применениек ряду дает предыдущее значение этого же ряда: применениек белому шуму дает предыдущее значение шума: применениек константе — это константа: Операториногда называют такжелаговымоператором. Можно рассматривать функции от оператора сдвига, например, кратное применение оператора:или. Для записей некоторых моделей временных рядов будет удобно использовать лаговый многочлен: Обратным к операторуназывают оператортакой, что: Так, например, дляможно заключить, что: Рассмотрим модель AR(): С помощью оператора сдвига ее можно представить в следующем виде: где— характеристический полином. Сформулируем пару важных утверждений: Любой стационарный (в широком смысле) процесс представим в виде, то есть в виде модели скользящего среднего с неограниченным количеством слагаемых (конечное или бесконечное число). Этот результат так же известен кактеорема Волдао декомпозиции временного ряда. Модельзадает стационарный временной рядвсе комплексные корнилежат вне единичного круга. Приведем пояснение второго утверждения. В самом деле, пусть— все его комплексные корни (их ровнос учетом кратности), тогда справедливо представление: Тогда при представлении временного ряда в виде и дальнейшего его разложения на простые дроби возникнут слагаемые вида Если при этомлежит внутри единичного круга или на его границе, то соответствующий ряд будет расходящимся. На самом деле, случаймы в дальнейшем учтем. В качестве примера рассмотрим подробнее модель.Зависимость имеет вид, где. Для данного ряда можно выписать следующие свойства: Уравнение, имеет корень. Тем самым,стационарен. Кроме того, чем меньше, тем предыдущее значение ряда вносит меньший вклад в текущее значение. Если ряд стационарен, то:. . Разберем первое равенство, остальные получаются аналогично. Возьмем математическое ожидание в уравнении ряда Поскольку ряд стационарен, то его математическое ожидание не меняется во времени, а для белого шума математическое ожидание равно нулю. Тем самым мы получаем уравнение на, откуда следует доказываемая формула. Таким образом, в зависимости от значениямы можем получить следующие результаты: Если, то— представление ряда в виде MA(). Если, то— это случайное блуждание. Если, то— экспоненциально растущий процесс. Посмотрим на визуализацию. В первом случае мы имеем модель, отрицательный коэффициент является следствием больших колебаний ряда. Во втором случае модель, большой положительный коэффициент делает ряд менее шумным. В третьем случае показано несколько рядов вида случайного блуждания, что соответствует случаю. В четвертом случае показан экспоненциальный процесс, на графике шум уже не заметен из-за масштаба. На немного вернемся к модели MA(). Чуть выше мы выяснили, что при некоторых условиях на коэффицентывременной ряд модели AR() будет стационарным, а значит имеет представление в виде MA(). На самом деле, модель скользящего среднего порядкатоже можно представить с помощью оператораследующим образом: где—характеристический многочлен. Для простоты изложения пусть. Важным при такой записи оказывается понятие обратимости, то есть представления в виде которое означает, что ряд можно представить в виде бесконечной авторегрессионной модели.Здесь, как и в рассуждениях выше, можно заключить, что временной рядобратим, если все комплексные корнилежат вне единичного круга.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Модель ARMA()",
    "text": "Модель ARMA() по сути является суммой моделейи, иначе говоря, модель есть сумма нескольких предыдущих значений ряда и нескольких предыдущих значений белого шума с некоторым коэффициентами. Эквивалентную запись ряда в терминах оператора сдвига можно получить, рассмотрев два многочлена или гдеи.Заметим, что во втором представлении константазаменена на. На самом деле, стационарность такого ряда будет определяться только его AR() компонентой, то есть значениями коэффициентов, так ряд в модели MA() всегда является стационарным.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Модель ARIMA()",
    "text": "Модель ARIMA() — это расширение моделей типа ARMA на нестационарные временные ряды, которые однако могут стать стационарным после применениея процедуры дифференцирования ряда. Модель ARIMA() для рядаопределяется как модель ARMA() для ряда разностей порядкаряда. Разность порядка 1:. Разность порядка 2:. Получаем формулу модели ARIMA: или То есть многочленимеетединичных корней.Тем самым такая модель позволяет учесть нестационарности, в частности, тренд. В качестве примера рассмотрим процесс случайного блуждания: где— белый шум. Как уже упомяналось ранее, такой ряд не является стационарным. Однако, если мы применим операцию дифференцирования, то можем перейти к новому, уже стационарном ряду, который можно записать в виде:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Частичная автокорреляция",
    "text": "Для модели скользящего среднего порядкамы выяснили, что значения автокорреляционной функции для такого ряда оказывается равной нулю после лага. Эта особенность позволяет использовать автокорреляционную функцию для определения порядка модели скользящего среднего. Возникает разумный вопрос, как оценить порядокдля модели AR()? Здесь оказывается полезным понятие частичной (частной) автокорреляционной функции. Частичная автокорреляция (PACF)— корреляция ряда с собой после снятия линеной зависимости от промежуточных значений ряда. Иначе говоря, мы хотим как-то учесть опосредованного влияние промежуточных значений ряда и оценить непосредственное влияниена. Чуть более формально частичную автокорреляцию можно записать следующим образом: где— линейная регрессия на: Пример для: где— МНК-оценка в модели. Можно показать, что значение частиной автокорреляции для модели авторегресии AR() будет ненулевой для лагови равняться нулю для лагов. Имеет место быть полная аналогия с автокорреляционной функцией и моделью MA(). Таким образом, исследование поведения автокорреляционной и частичной автокорреляционной функции может быть использовано для определения порядкамодели скользящего среднего и порядкамодели авторегрессии соответсвтенно.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Оценка коэффициентов в ARIMA",
    "text": "Пусть гиперпараметрыфиксированы.&tab;В предположении, что— гауссовский белый шум, в нашей модели мы можем выписать функцию правдоподобиягде— соместная плотность. Из-за того, чтоимеют нормальное распределение, она будет иметь разумный вид. Соответственно, в качестве оценок параметров берется оценка максимального правдоподобия. Для поиска начальных приближение для параметровивоспользуемся автокорреляционной и частичной автокорреляционной функцией. Начальное приближение: последний значимый пик у PACF. Начальное приближение: последний значимый пик у ACF. Далее обычно используется поиск по сетке вокруг подобранных значений, минимизируя информационный критерий: — критерий Акаике; — критерий Акаике (короткие ряды); — Байесовский информационный критерий или критерий Шварца, где— логарифм функции правдоподобия,— длина временного ряда. Приведем некоторый план при применению модели ARIMA для прогнозирования временных рядов. Анализ выбросов: замена нерелевантых выбросов наNAили усреднение по соседним элементам. Стабилизация дисперсии (преобразования). Дифференцирование, если ряд не стационарен. Выбор пилотныхипо PACF и ACF. Вокруг этих параметров подбираем оптим. модель по/. Пошаговое построение прогноза:— для:;— для:;— для:. Построение предсказательного интервала:— если остатки модели нормальны и гомоскедастичны (дисперсия постоянна), то строится теоретический предсказательный интервалгде— горизонт прогнозирования,— оценка на дисперсию шума,— коэф. для ряда при его представлении в виде бесконечного процесса скользящего среднего. И, имогут быть выражены через оценки на параметрыи.— иначе интервалы строятся с помощью бутстрепа.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Модели SARIMA и ARIMAX",
    "text": "Рассмотрим некоторые расширение модели ARIMA. Обобщение модели ARIMA на ряды с наличием сезонной составляющей назвается SARIMA. Пусть— известная сезонность ряда. Добавим в модель ARIMA() компоненты, отвечающие за значения в предыдущие сезоны. Тогда модель SARIMAможет быть записана следующим образом: где Параметр сезонного дифференцирования, а также параметрыподбираются из тех же соображений, что и для, но только с поправкой, что делается это с учетом сезонности. ARIMAX — обобщение модели ARIMA, которая учитывает некоторые экзогенные факторы. Пусть— ряд регрессоров,известный до начала прогноза. Простой вариант: Общий случай: Пример: Вышеуказанные модели можно объединить и получить SARIMAX: Проведем аналогию с линейной регрессией. Это линейная по признакам модель, в которой Отклик:— значение ряда в моменты времени Признаки:— значения ряда в предыдущие моменты времениЗначение ряда за предыдущие сезоныЗначения признаков в предыдущие моменты времениЗначения признаков в предыдущие сезоны — значения ряда в предыдущие моменты времени Значение ряда за предыдущие сезоны Значения признаков в предыдущие моменты времени Значения признаков в предыдущие сезоны Ошибка:сумма шума за предыдущие моменты времени и предыдущие сезоны.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обучение с подкреплением",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
    "section_title": "Постановка задачи",
    "text": "Теперь попробуем формализовать всю эту концепцию и познакомиться с местной терминологией. Задача обучения с подкреплением задаётсяМарковским Процессом Принятия Решений(Markov Decision Processили сокращённоMDP) это четвёрка, где: —пространство состояний(state space), множество состояний, в которых в каждый момент времени может находиться среда. —пространство действий(action space), множество вариантов, из которых нужно производить выбор на каждом шаге своего взаимодействия со средой. —функция переходов(transition function), которая задаёт изменение среды после того, как в состояниибыло выбрано действие. В общем случае функция переходов может быть стохастична, и тогда такая функция переходов моделируется распределением: с какой вероятностью в какое состояние перейдёт среда после выбора действияв состоянии. —функция награды(reward function), выдающая скалярную величину за выбор действияв состоянии. Это наш «обучающий сигнал». Традиционно субъект, взаимодействующий со средой и влияющий на неё, называется в обучении с подкреплениемагентом(agent). Агент руководствуется некоторым правилом, возможно, тоже стохастичным, как выбирать действия в зависимости от текущего состояния среды, которое называетсястратегией(policy; термин часто транслитерируют и говорятполитика) и моделируется распределением. Стратегия и будет нашим объектом поиска, поэтому, как и в классическом машинном обучении, мы ищем какую-то функцию. Взаимодействие со средой агента со стратегиеймоделируется так. Изначально среда находится в некотором состоянии. Агент сэмплирует действие из своей стратегии. Среда отвечает на это, сэмплируя своё следующее состояниеиз функции переходов, а также выдаёт агенту награду в размере. Процесс повторяется: агент снова сэмплирует, а среда отвечает генерациейи скалярной наградой. Так продолжается до бесконечности или пока среда не перейдёт в терминальное состояние, после попадания в которое взаимодействие прерывается, и сбор агентом награды заканчивается. Если в среде есть терминальные состояния, одна итерация взаимодействия от начального состояния до попадания в терминальное состояние называетсяэпизодом(episode). Цепочка генерируемых в ходе взаимодействия случайных величинназываетсятраекторией(trajectory).Примечание:функция награды тоже может быть стохастичной, и тогда награды за шаг тоже будут случайными величинами и частью траекторий, но без ограничения общности мы будем рассматривать детерминированные функции награды. Итак, фактически среда для нас — это управляемая марковская цепь: на каждом шаге мы выборомопределяем то распределение, из которого будет генерироваться следующее состояние. Мы предполагаем, во-первых, марковское свойство: что переход в следующее состояние определяется лишь текущим состоянием и не зависит от всей предыдущей истории: Во-вторых, мы предполагаем стационарность: функция переходовне зависит от времени, от того, сколько шагов прошло с начала взаимодействия. Это довольно реалистичные предположения: законы мира не изменяются со временем (стационарность), а состояние — описывает мир целиком (марковость). В этой модели взаимодействия есть только одно нереалистичное допущение:полная наблюдаемость(full observability), которая гласит, что агент в своей стратегиинаблюдает всё состояниеполностью и может выбирать действия, зная об окружающем мире абсолютно всё; в реальности нам же доступны лишь какие-то частичные наблюдения состояния. Такая более реалистичная ситуация моделируется вчастично наблюдаемых MDP(Partially observable MDP,PoMDP), но мы далее ограничимся полностью наблюдаемыми средами. Итак, мы научились на математическом языке моделировать среду, агента и их взаимодействие между собой. Осталось понять, чего же мы хотим. Во время взаимодействия на каждом шаге агенту приходит награда, однако, состояния и действияв рамках такой постановки — случайные величины. Один и тот же агент может в силу стохастики как внутренней (в силу случайности выбора действий в его стратегии), так и внешней (в силу стохастики в функции переходов) набирать очень разную суммарную наградув зависимости от везения. Мы скажем, что хотим научиться выбирать действия так, чтобы собиратьв среднемкак можно больше награды. Что значит в среднем, в среднем по чему? По всей стохастике, которая заложена в нашем процессе взаимодействия со средой. Каждая стратегиязадаёт распределение в пространстве траекторий — с какой вероятностью нам может встретится траектория: Вот по такому распределению мы и хотим взять среднее получаемой агентом награды. Записывают это обычно как-нибудь так: Здесь мат.ожидание по траекториям — это бесконечная цепочка вложенных мат.ожиданий: Вот такую конструкцию мы и хотим оптимизировать выбором стратегии. На практике, однако, вносят ещё одну маленькую корректировку. В средах, где взаимодействие может продолжаться бесконечно долго, агент может научиться набирать бесконечную награду, с чем могут быть связаны разные парадоксы (например, получать +1 на каждом втором шаге становится также хорошо, как получать +1 на каждом сотом шаге). Поэтому вводятдисконтирование(discounting) награды, которое гласит: тортик сейчас лучше, чем тот же самый тортик завтра. Награду, которую мы получим в будущем, агент будет дисконтировать на некоторое число, меньшее единицы. Тогда наш функционал примет такой вид: Заметим, что обучение с подкреплением - это в первую очередь задача оптимизации, оптимизации функционалов определённого вида. Если в классическом машинном обучении подбор функции потерь можно считать элементом инженерной части решения, то здесь функция награды задана нам готовая и определяет тот функционал, который мы хотим оптимизировать.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обучение с подкреплением",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
    "section_title": "Окей, и как такое решать?",
    "text": "Выглядит сложновато, но у человечества есть уже довольно много наработок, как подойти к этой на вид очень общей задаче, причём с основной идеей вы скорее всего уже сталкивались. Называется онадинамическим программированием. Дело в том, что мы оптимизируем не абы какой функционал, а среднюю дисконтированную кумулятивную награду. Чтобы придумать более эффективное решение, чем какой-нибудь подход, не использующий этот факт (например, эволюционные алгоритмы), нам нужно воспользоваться структурой поставленной задачи. Эта структура задана в формализме MDP и определении процесса взаимодействия агента со средой. Интуитивно она выражается так: вот мы сидим в некотором состояниии хотим выбрать действиекак можно оптимальнее. Мы знаем, что после выбора этого действия мы получим награду за этот шаг, среда перекинет нас в состояниеи, внимание, дальше нас ждётподзадача эквивалентной структуры: в точности та же задача выбора оптимального действия, только в другом состоянии. Действительно: когда мы будем принимать решение на следующем шаге, на прошлое мы повлиять уже не способны; стационарность означает, что законы, по которым ведёт себя среда, не поменялись, а марковость говорит, что история не влияет на дальнейший процесс нашего взаимодействия. Это наводит на мысль, что задача максимизации награды из текущего состояния тесно связана с задачей максимизации награды из следующего состояния, каким бы оно ни было. Чтобы сформулировать это на языке математики, вводятся «дополнительные переменные», вспомогательные величины, называемыеоценочными функциями. Познакомимся с одной такой оценочной функцией - оптимальной Q-функцией, которую будем обозначать. Скажем, что- это то, сколько максимально награды можно (в среднем) набрать после выбора действияиз состояния. Итак: Записьздесь означает, что мы садимся в состояние; выбираем действие, а затем продолжаем взаимодействие со средой при помощи стратегии, порождая таким образом траекторию. По определению, чтобы посчитать, нужно перебрать все стратегии, посмотреть, сколько каждая из них набирает награды после выбораиз состояния, и взять наилучшую стратегию. Поэтому эта оценочная функция называется оптимальной: она предполагает, что в будущем после выбора действияиз состоянияагент будет вести себя оптимально. Определение неконструктивное, конечно, поскольку в реальности мы так сделать не можем, зато обладает интересным свойством. Если мы каким-то чудом узнали, то мы знаем оптимальную стратегию. Действительно: представьте, что вы находитесь в состоянии, вам нужно сделать выбор из трёх действий, и вы знаете значения. Вы знаете, что если выберете первое действие, то в будущем сможете набрать не более чем, допустим,награды. При этом вы знаете, что существует какая-то стратегия, на которой достигается максимум в определении оптимальной Q-функции, то есть которая действительно позволяет набрать эти +3. Вы знаете, что если выберете второе действие, то в будущем сможете набрать, допустим,, а для третьего действия. Вопрос: так как нужно действовать? Интуиция подсказывает, что надо просто выбирать действие, что позволит набрать +10, ведь по определению больше набрать никак не получится. Значит, выбор в этом состоянии действияоптимален. Эта интуиция нас не обманывает, и принцип такого выбора называетсяпринципом оптимальности Беллмана. Выбор того действия, на котором достигается максимум по действиям Q-функции, называетсяжадным(greedy) по отношению к ней. Таким образом, принцип оптимальности Беллмана гласит:жадный выбор по отношению к оптимальной Q-функции оптимален: Примечание:если Q-функция достигает максимума на нескольких действиях, то можно выбирать любое из них. Заметим, что эта оптимальная стратегия детерминирована. Этот интересный факт означает, что нам, в общем-то, необязательно искать стохастичную стратегию. Наше рассуждение пока даже показывает, что мы можем просто пытаться найти, а дальше выводить из неё оптимальную стратегию, выбирая действие жадно. Но как искать? Тут на сцене и появляется наше наблюдение про структуру задачи. Оказывается,выражается через саму себя. Действительно: рассмотрим некоторую пару состояние-действие. С одной стороны, по определению, мы в будущем сможем при условии оптимального поведения получитьнаграды. С другой стороны, после того, как мы выберем действиев состоянии, мы получим награду за один шаг, вся дальнейшая награда будет дисконтирована на, среда ответит нам сэмплированием(на результат этого сэмплирования мы уже никак повлиять не можем и по этой стохастике нашу будущую награду надо будет усреднять), а затем в состояниимы, в предположении оптимальности поведения, выберем то действие, на котором достигается максимум. Другими словами, в дальнейшем после попадания вмы сможем получитьнаграды. А значит, верно следующее рекурсивное соотношение, называемоеуравнением оптимальности Беллмана для Q-функции: Мы получили систему уравнений, связывающую значенияс самой собой. Это нелинейная система уравнений, но оказывается, что она в некотором смысле «хорошая». У неё единственное решение - и, значит, решение этого уравнения можно считать эквивалентным определением, - и его можно искатьметодом простой итерации. Метод простой итерации решения систем уравнений позволяет улучшать своё текущее приближениерешения некоторого уравнения видаего подстановкой в правую часть. То есть: инициализируем произвольную функцию, которая будет приближать, затем итеративно будем подставлять её в правую часть уравнений оптимальности Беллмана и полученным значением обновлять наше приближение: Такая процедура в пределе приведёт нас к истинной, а значит и оптимальной стратегии. Кстати, когда вы в прошлом встречались с динамическим программированием, вы скорее всего неявно использовали именно эту идею, разве что часто в задачах для решения уравнений оптимальности Беллмана можно просто последовательно исключать неизвестные переменные; но метод простой итерации даёт более общую схему, применимую всегда. А сейчас для нас принципиально следующее: если у нас есть какое-то приближение, то вычисление правой части уравнения оптимальности Беллмана позволит получить приближение лучше.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обучение с подкреплением",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
    "section_title": "А где же метод проб и ошибок?",
    "text": "Решать методом простой итерации уравнения оптимальности Беллмана и таким образом получатьв реальности можно только при двух очень существенных ограничивающих условиях. Нужно, чтобы, во-первых, мы могли хранить как-то текущее приближениев памяти. Это возможно только если пространства состояний и действий конечные и не очень большие, то есть, например, в вашем MDP всего 10 состояний и 5 действий, тогда— это табличка 10x5. Но что, если вы хотите научиться играть в видеоигру, и состояние — это входное изображение? Тогда множество картинок, которые вам может показать видеоигра, сохранить в памяти уже не получится. Ну, допустим пока, что число состояний и число действий не очень большое, и мы всё-таки можем хранить таблицу в памяти, а позже мы снимем это ограничение, моделируяпри помощи нейросети. Во-вторых, нам необходимо уметь считать выражение, стоящее справа в уравнение оптимальности Беллмана: Мало того, что в сложных средах взять мат.ожидание по функции переходовв реальности мы не сможем, так ещё и обычно мы эту функцию переходов на самом деле не знаем. Представьте, что вы катаетесь на велосипеде: можете ли вы по текущему состоянию окружающего мира, например, положению всех атомов во вселенной, рассказать, с какими вероятностями в каком состоянии мир окажется в следующий момент времени? Это соображение также подсказывает, что было бы здорово, если б мы смогли решать задачу, избегая даже попыток выучить эту сложную функцию переходов. Что нам доступно? Мы можем взятькакую-нибудьстратегию(важный момент: мы должны сами выбрать какую) и повзаимодействовать ею со средой. «Попробовать решить задачу». Мы можем сгенерировать при помощицелую траекторию или даже сделать всего один шаг в среде. Таким образом мысоберём данные: допустим, мы были в состояниии сделали выбор действия, тогда мы узнаем, какую наградумы получаем за такой шаг и, самое главное, в какое состояниенас перевела среда. Полученный— сэмпл из функции переходов. Собранная так информация — четвёрка— называетсяпереходом(transition), и может быть как-то использована для оптимизации нашей стратегии. Можем ли мы, используя лишь переходы, то есть имея на руках лишь сэмплы, как-то пользоваться схемой динамического программирования? Что, если мы будем заменять значениене на которое мы не можем посчитать, а на его Монте Карло оценку: где— сэмпл из функции переходов из собранного нами опыта? В среднем-то такая замена верная. Такая Монте-Карло оценка правой части для заданного переходиканазываетсяБеллмановским таргетом, то есть «целевой переменной». Почему такое название — мы увидим чуть позже. Чтобы понять, как нам нужно действовать, рассмотрим какую-нибудь типичную ситуацию. Допустим, после выполнения действияиз некоторого состояниясреда награждает наси перекидывает нас с равными вероятностями то в состояние, для которого, то в состояние, для которого. Метод простой итерации говорит, что на очередной итерации нужно заменитьна, но в реальности мы встретимся лишь с одним исходом, и таргет — Монте-Карло оценка правой части уравнения оптимальности Беллмана — будет с вероятностью 0.5 равен, а с вероятностью 0.5 равен. Ясно, что нельзя просто взять и жёстко заменять наше текущее приближениена посчитанный Беллмановский таргет по некоторому одному переходу, поскольку нам могло повезти (мы увидели) или не повезти (мы увидели). Давайте вместо этого поступать также, как учат среднее по выборке: не сдвигать «жёстко» наше текущее приближение в значение очередного сэмпла, асмешиватьтекущее приближение с очередным сэмплом. То есть: берём переходик, и не заменяемна стохастичную оценку правой части уравнения оптимальности Беллмана, а только сдвигаемся в его сторону: Таким образом, мы проводимэкспоненциальное сглаживаниестарого приближенияи новой оценки правой части уравнения оптимальности Беллмана со свежим сэмплом. Выборздесь определяет, насколько сильно мы обращаем внимание на последние сэмплы, и имеет тот же физический смысл, что и learning rate. В среднем по стохастике (а стохастика в этой формуле обновления заложена в случайном) мы будем сдвигаться в сторону и значит применять этакий «зашумлённый» метод простой итерации. Итак, возникает следующая идея. Будем как-то взаимодействовать со средой и собирать переходики. Для каждого перехода будем обновлять одну ячейку нашей Q-таблицы размера число состояний на число действий по вышеуказанной формуле. Таким образом мы получим как бы «зашумлённый» метод простой итерации, где мы на каждом шаге обновляем только одну ячейку таблицы, и не заменяем жёстко значение на правую часть уравнений оптимальности, а лишь сдвигаемся по некоторому в среднем верному стохастичному направлению. Очень похоже на стохастическую оптимизацию вроде стохастического градиентного спуска, и поэтому гарантии сходимости выглядят схожим образом. Оказывается, такой алгоритм сходится к истинной, если для любой парымы в ходе всего процесса проводим бесконечное количество обновлений, а learning rate (гиперпараметр) в них ведёт себя как learning rate из условий сходимости стохастического градиентного спуска: Этот алгоритм, к которому мы уже практически пришли, называетсяQ-learning, «обучение оптимальной Q-функции». Нам, однако, осталось ответить на один вопрос: так как же нужно собирать данные, чтобы удовлетворить требованиям для сходимости? Как взаимодействовать со средой так, чтобы мы каждую ячейкуне прекращали обновлять?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обучение с подкреплением",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
    "section_title": "Дилемма Exploration-exploitation",
    "text": "Мы уже встречали дилемму exploration-exploitation (букв. «исследования-использования») в параграфе протюнинг гиперпараметров. Задача многоруких бандитов, которая там встретилась, на самом деле является частным случаем задачи обучения с подкреплением, в котором после первого выбора действия эпизод гарантированно завершается, и этот частный случай задачи часто используется для изучения этой дилеммы. Рассмотрим эту дилемму в нашем контексте. Допустим, на очередном шаге алгоритма у нас есть некоторое приближение. Приближение это, конечно, неточное, поскольку алгоритм, если и сходится к истинной оптимальной Q-функции, то на бесконечности. Как нужно взаимодействовать со средой? Если вы хотите набрать максимальную награду, наверное, стоит воспользоваться нашей теорией и заниматьсяexploitation-ом, выбирая действие жадно: Увы, такой выбор не факт что совпадёт с истинной оптимальной стратегией, а главное, он детерминирован. Это значит, что при взаимодействии этой стратегией со средой, многие парыникогда не будут встречаться просто потому, что мы никогда не выбираем действиев состоянии. А тогда мы, получается, рискуем больше никогда не обновить ячейкудля таких пар! Такие ситуации запросто могут привести к застреванию алгоритма. Мы хотели научиться кататься на велосипеде и получали +0.1 за каждый пройденный метр и -5 за каждое попадание в дерево. После первых проб и ошибок мы обнаружили, что катание на велосипеде приносит нам -5, поскольку мы очень скоро врезаемся в деревья и обновляли нашу аппроксимацию Q-функции сэмплами с негативной наградой; зато если мы не будем даже забираться на велосипед и просто займёмся ничего не деланьем, то мы сможем избежать деревьев и будем получать 0. Просто из-за того, что в нашей стратегии взаимодействия со средой никогда не встречались те, которые приводят к положительной награде, и жадная стратегия по отношению к нашей текущей аппроксимации Q-функции никогда не выбирает их. Поэтому нам нужно экспериментировать и пробовать новые варианты. Режимexploration-а предполагает, что мы взаимодействуем со средой при помощи какой-нибудьстохастичнойстратегии. Например, такой стратегией является случайная стратегия, выбирающая рандомные действия. Как ни странно, сбор опыта при помощи случайной стратегии позволяет побывать с ненулевой вероятностью во всех областях пространства состояний, и теоретически даже наш алгоритм обучения Q-функции будет сходится. Означает ли это, что exploration-а хватит, и на exploitation можно забить? В реальности мы понимаем, что добраться до самых интересных областей пространства состояний, где функция награда самая большая, не так-то просто, и случайная стратегия хоть и будет это делать с ненулевой вероятностью, но вероятность эта будет экспоненциально маленькая. А для сходимости нам нужно обновить ячейкидля этих интересных состояний бесконечно много раз, то есть нам придётся дожидаться необычайно редкого везения далеко не один раз. Куда разумнее использовать уже имеющиеся знания и при помощи жадной стратегии, которая уже что-то умеет, идти к этим интересным состояниям. Поэтому для решения дилеммы exploration-exploitation обычно берут нашу текущую жадную стратегию и что-нибудь с ней делают такое, чтобы она стала чуть-чуть случайной. Например, с вероятностьювыбирают случайное действие, а с вероятностью— жадное. Тогда мы чаще всё-таки и знаниями пользуемся, и любое действие с ненулевой вероятностью выбираем; такая стратегия называется-жадной, и она является самым простым способом как-то порешать эту дилемму. Давайте закрепим, что у нас получилось, в виде табличного алгоритма обучения с подкреплением под названием Q-learning: Проинициализироватьпроизвольным образом. Пронаблюдатьиз среды. Для: с вероятностьювыбрать действиеслучайно, иначе жадно: отправить действиев среду, получить награду за шаги следующее состояние. обновить одну ячейку таблицы:",
    "source_type": null,
    "useful_links": [
      {
        "text": "тюнинг гиперпараметров",
        "url": "https://academy.yandex.ru/handbook/ml/article/podbor-giperparametrov"
      }
    ]
  },
  {
    "document_title": "Обучение с подкреплением",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
    "section_title": "Добавим нейросеток",
    "text": "Наконец, чтобы перейти к алгоритмам, способным на обучение в сложных MDP со сложным пространством состояний, нужно объединять классическую теорию обучения с подкреплением с парадигмами глубокого обучения. Допустим, мы не можем позволить себе хранитькак таблицу в памяти, например, если мы играем в видеоигру и на вход нам подаются какие-нибудь изображения. Тогда мы можем обрабатывать любые имеющиеся у агента входные сигналы при помощи нейросетки. Для тех же видеоигр мы легко обработаем изображение экрана небольшой свёрточной сеточкой и выдадим для каждого возможного действиявещественный скаляр. Допустим также, что пространство действий всё ещё конечное и маленькое, чтобы мы могли для такой модели строить жадную стратегию, выбирать. Но как обучать такую нейросетку? Давайте ещё раз посмотрим на формулу обновления в Q-learning для одного переходика: Теория Q-learning-а подсказывала, что у процесса такого обучения Q-функции много общего с обычным стохастическим градиентным спуском. В таком виде формула подсказывает, что, видимо, — это стохастическая оценка какого-то градиента. Этот градиент сравнивает Беллмановский таргет с нашим текущим приближениеми чуть-чуть корректирует это значение, сдвигая в сторону таргета. Попробуем «заменить» в этой формуле Q-функцию с табличного представления на нейросетку. Рассмотрим такую задачу регрессии. Чтобы построить один прецедент для обучающей выборки, возьмём один имеющийся у нас переходик. Входом будет пара. Целевой переменной, таргетом, будет Беллмановский таргет его зависимость от параметровнашей нейронки мы далее будем игнорировать и будем «притворяться», что это и есть наш ground truth. Именно поэтому Монте-Карло оценка правой части уравнения оптимальности Беллмана и называют таргетом. Но важно помнить, что эта целевая переменная на самом деле «зашумлена»: в формуле используется взятый из перехода, который есть лишь сэмпл из функции переходов. На самом же деле мы хотели бы выучить среднее значение такой целевой переменной, и поэтому в качестве функции потерь мы возьмём MSE. Как будет выглядеть шаг стохастического градиентного спуска для решения этой задачи регрессии (для простоты — для одного прецедента)? Это практически в точности повторяет формулу Q-learning, которая гласит, что если таргетбольше, то нужно подстроить веса нашей модели так, чтобыстало чуть побольше, и наоборот. В среднем при такой оптимизации мы будем двигаться в сторону — в сторону правой части уравнения оптимальности Беллмана, то есть моделировать метод простой итерации для решения системы нелинейных уравнений. Единственное отличие такой задачи регрессии от тех, с которыми сталкивается традиционное глубокое обучение — то, что целевая переменнаязависит от нашей же собственной модели. Раньше целевые переменные были напрямую источником обучающего сигнала. Теперь же, когда мы хотим выучить будущую награду при условии оптимального поведения, мы не знаем этого истинного значения или даже её стохастичных оценок. Поэтому мы применяем идеюбутстрапирования(bootstrapping): берём награду за следующий шаг, и нечестно приближаем всю остальную награду нашей же текущей аппроксимацией. Да, за этим кроется идея метода простой итерации, но важно понимать, что такая целевая переменная лишь указывает направление для обучения, но не является истинным приближением будущих наград или даже их несмещённой оценкой. Поэтому говорят, что в этой задаче регрессии оченьсмещённые(biased) целевые переменные. На практике из-за этого возникает беда. Наша задача регрессии в таком виде меняется после каждого же шага. Если вдруг после очередного шага оптимизации и обновления весов нейросети наша модель начала выдавать какие-то немного неадекватные значения, они рискуют попасть в целевую переменную на следующем шаге, мы сделаем шаг обучения под неадекватные целевые переменные, модель станет ещё хуже, и так далее, начнётся цепная реакция. Алгоритмы, в которых целевая переменная вот так напрямую зависит от текущей же модели, из-за этого страшно нестабильны. Для стабилизации применяется трюк, называемыйтаргет-сетью(target network). Давайте сделаем так, чтобы у нас задача регрессии менялась не после каждого обновления весов нейросетки, а хотя бы раз, скажем, в 1000 шагов оптимизации. Для этого заведём полную копию нашей нейросети («таргет-сеть»), веса которой будем обозначать. Каждые 1000 шагов будем копировать веса из нашей модели в таргет-сеть, больше никак менятьне будем. Когда мы захотим для очередного переходапостроить таргет, мы воспользуемся не нашей свежей моделью, а таргет-сетью: Тогда правило, по которому строится целевая переменная, будет меняться раз в 1000 шагов, и мы 1000 шагов будем решать одну и ту же задачу регрессии. Такой процесс будет намного стабильнее.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обучение с подкреплением",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
    "section_title": "Experience Replay",
    "text": "Чтобы окончательно собрать алгоритмDeep Q-learning(обычно называемыйDQN,Deep Q-network), нам понадобится сделать последний шаг, связанный опять со сбором данных. Коли мы хотим обучать нейросетку, нам нужно для каждого обновления весов откуда-то взять целый мини-батч данных, то есть батч переходов, чтобы по нему усреднить оценку градиента. Однако, если мы возьмём среду, сделаем в нейшагов, то встреченные намипереходов будут очень похожи друг на друга: они все придут из одной и той же области пространства состояний. Обучение нейросетки на скоррелированных данных — плохая идея, поскольку такая модель быстро забудет, что она учила на прошлых итерациях. Бороться с этой проблемой можно двумя способами. Первый способ, доступный всегда, когда среда задана при помощи виртуального симулятора — запускпараллельных агентов. Запускается параллельнопроцессов взаимодействия агента со средой, и для того, чтобы собрать очередной мини-батч переходов для обучения, во всех экземплярах проводится по одному шагу взаимодействия, собирается по одному переходику. Такой мини-батч уже будет разнообразным. Более интересный второй способ. Давайте после очередного шага взаимодействия со средой мы не будем тут же использовать переходдля обновления модели, а запомним этот переход и положим его себе в коллекцию. Память со всеми встретившимися в ходе проб и ошибок переходаминазываетсяреплей буфером(replay bufferилиexperience replay). Теперь для того, чтобы обновить веса нашей сети, мы возьмём и случайно засэмплируем из равномерного распределения желаемое количество переходов из всей истории. Однако, использование реплей буфера возможно далеко не во всех алгоритмах обучения с подкреплением. Дело в том, что некоторые алгоритмы обучения с подкреплением требуют, чтобы данные для очередного шага обновления весов были сгенерированы именно текущей, самой свежей версией стратегии. Такие алгоритмы относят к классуon-policy: они могут улучшать стратегию только по данным из неё же самой («on policy»). Примером on-policy алгоритмов выступают, например, эволюционные алгоритмы. Как они устроены: например, можно завести популяцию стратегий, поиграть каждой со средой, отобрать лучшие и как-то породить новую популяцию (подробнее про одну из самых успешных схем в рамках такой идеи можно посмотретьздесь). Как бы ни была устроена эта схема, эволюционный алгоритм никак не может использовать данные из, например, старых, плохих стратегий, которые вели себя, скажем, не сильно лучше случайной стратегии. Поэтому неизбежно в эволюционном подходе нужно свежую популяцию отправлять в среду и собирать новые данные перед каждым следующим шагом. И вот важный момент: Deep Q-learning, как и обычный Q-learning, относится кoff-policyалгоритмам обучения с подкреплением. Совершенно неважно, какая стратегия, умная или не очень, старая или новая, породила переход, нам всё равно нужно решать уравнение оптимальности Беллмана в том числе и для этой парыи нам достаточно при построении таргета лишь чтобыбыл сэмплом из функции переходов (а она-то как раз одна вне зависимости от того, какая стратегия взаимодействует в среде). Поэтому обновлять модельмы можем по совершенно произвольному опыту, и, значит, мы в том числе можем использовать experience replay. В любом случае, даже в сложных средах, при взаимодействии со средой мы всё равно должны как-то разрешить дилемму exploration-exploitation, и пользоваться, например,-жадной стратегией исследования. Итак, алгоритм DQN выглядит так: Проинициализировать нейросеть. Проинициализировать таргет-сеть, положив. Пронаблюдатьиз среды. Для: с вероятностьювыбрать действиеслучайно, иначе жадно: отправить действиев среду, получить награду за шаги следующее состояние. добавить переходв реплей буфер. если в реплей буфере скопилось достаточное число переходиков, провести шаг обучения. Для этого сэмплируем мини-батч переходиковиз буфера. для каждого переходика считаем целевую переменную: сделать шаг градиентного спуска для обновления, минимизируя еслиделится на 1000, обновить таргет-сеть:. Алгоритм DQN не требует никаких handcrafted признаков или специфических настроек под заданную игру. Один и тот же алгоритм, с одними и теми же гиперпараметрами, можно запустить на любой из 57 игр древней консоли Atari (пример игры в Breakout) и получить какую-то стратегию. Для сравнения алгоритмов RL между собой результаты обычно усредняют по всем 57 играм Atari. Недавно алгоритм под названием Agent57, объединяющий довольно много модификаций и улучшений DQN и развивающий эту идею,смог победить человека сразу во всех этих 57 играх.",
    "source_type": null,
    "useful_links": [
      {
        "text": "здесь",
        "url": "https://openai.com/blog/evolution-strategies/"
      },
      {
        "text": "пример игры в Breakout",
        "url": "https://www.youtube.com/watch?v=TmPfTpjtdgg"
      },
      {
        "text": "смог победить человека сразу во всех этих 57 играх",
        "url": "https://deepmind.com/blog/article/Agent57-Outperforming-the-human-Atari-benchmark"
      }
    ]
  },
  {
    "document_title": "Обучение с подкреплением",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
    "section_title": "А если пространство действий непрерывно?",
    "text": "Всюду в DQN мы предполагали, что пространство действий дискретно и маленькое, чтобы мы могли считать жадную стратегиюи считать максимум в формуле целевой переменной. Если пространство действий непрерывно, и на каждом шаге от агента ожидается выбор нескольких вещественных чисел, то как это делать непонятно. Такая ситуация повсюду возникает в робототехнике. Там каждое сочленение робота можно, например, поворачивать вправо / влево, и такие действия проще описывать набором чисел в диапазоне [-1, 1], где -1 — крайне левое положение, +1 — крайне правое, и доступны любые промежуточные варианты. При этом дискретизация действий не вариант из-за экспоненциального взрыва числа вариантов и потери семантики действий. Нам, в общем-то, нужно в DQN только одну проблему решить: как-то научиться аргмаксимум по действиям брать. А давайте, коли мы не знаем, приблизим его другой нейросеткой. А то есть, заведём вторую нейросетьс параметрами, и будем учить её так, чтобы Как это сделать? Ну, будем на каждой итерации алгоритма брать батч состоянийиз нашего реплей буфера и будем учитьвыдавать такие действия, на которых наша Q-функция выдаёт большие скалярные значения: Причём, поскольку действия непрерывные, всё слева дифференцируемо и мы можем напрямую применять самый обычный backpropagation! Теперь когда на руках есть приближение, можно просто использовать его всюду, где нам нужны аргмаксимумы и максимумы от нашей Q-функции. Мы получилиActor-Criticсхему: у нас естьактёр,— детерминированная стратегия, икритик, который оценивает выбор действий актёром и предоставляет градиент для его улучшения. Актёр учится выбирать действия, которые больше всего нравятся критику, а критик учится регрессией с целевой переменной Эта прикольная рабочая эвристика позволяет придумать off-policy алгоритмы для непрерывных пространств действий; к такому подходу относятся такие алгоритмы, как DDPG, TD3 и SAC.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обучение с подкреплением",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
    "section_title": "Policy Gradient алгоритмы",
    "text": "В рассмотренных алгоритмах есть несколько приниципиальных ограничений, которые вытекают непосредственно из самой идеи подхода. Мы учимся с таргетов, заглядывающих всего на один шаг вперёд, использующих только; это чревато проблемой накапливающейся ошибки, поскольку если между выполнением действия и получением награды +1 проходит 100 шагов, нам нужно на сто шагов «распространять» полученный сигнал. Мы должны учитьвместо того, чтобы как-то напрямую («end-to-end») запомнить, какие действия в каких состояниях хорошие. Наконец, наша стратегия всегда детерминирована, когда для взаимодействия со средой во время сбора данных, например, нам позарез нужна была стохастичная, чтобы гарантированно обновлять Q-функцию для всех пар, и эту проблему пришлось закрывать костылями. Есть второй подход model-free алгоритмов RL, называемыйPolicy Gradient, который позволяет избежать вышеперечисленных недостатков за счёт on-policy режима работы. Идея выглядит так: давайте будем искать стратегию в классе стохастичных стратегий, то есть заведём нейросеть, моделирующуюнапрямую. Тогда наш функционал, который мы оптимизируем, дифференцируем по параметрам, и градиент равен: где- reward-to-go с шага, то есть награда, собранная в сыгранном эпизоде после шага: Эта формула говорит нам, что градиент нашего функционала — это тоже мат.ожидание по траекториям. А значит, мы можем попробовать посчитать какую-то оценку этого градиента, заменив мат.ожидание на Монте Карло оценку, и просто начать оптимизировать наш функционал самым обычным стохастическим градиентным спуском! А то есть: берём нашу стратегиюс текущими значениями параметров, играем эпизод (или несколько) в среде, то есть сэмплируем, и затем делаем шаг градиентного подъёма: Почему эта идея приводит к on-policy подходу? Для каждого шага градиентного шага нам обязательно нужно взятьс самыми свежими, с текущими весами, и никакая другая траектория, порождённая какой-то другой стратегией, нам не подойдёт. Поэтому для каждой итерации алгоритма нам придётся заново играть очередной эпизод со средой. Этоsample-inefficient: неэффективно по числу сэмплов, мы собираем слишком много данных и очень неэффективно с ними работаем. Policy Gradient алгоритмы пытаются по-разному бороться с этой неэффективностью, опять же обращаясь к теории оценочных функций и бутстрапированным оценкам, позволяющим предсказывать будущие награды, не доигрывая эпизоды целиком до конца. Большинство этих алгоритмов остаются в on-policy режиме и применимы в любых пространствах действий. К этим алгоритмам относятся такие алгоритмы, как Advantage Actor-Critic (A2C), Trust-Region Policy Optimization (TRPO) и Proximal Policy Optimization (PPO).",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обучение с подкреплением",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-s-podkrepleniem",
    "section_title": "Что там ещё?",
    "text": "Мы до сих пор разбиралиmodel-freeалгоритмы RL, которые обходились без знаний ои никак не пытались приближать это распределение. Однако, в каких-нибудь пятнашках функция переходов нам известна: мы знаем, в какое состояние перейдёт среда, если мы выберем некоторое действие в таком-то состоянии. Понятно, что эту информацию было бы здорово как-то использовать. Существует обширный классmodel-based, который либо предполагает, что функция переходов дана, либо мы учим её приближение, используяиз нашего опыта в качестве обучающей выборки. Алгоритм AlphaZero на основе этого подходапревзошёл человека в игру Го, которая считалась куда более сложной игрой, чем шахматы; причём этот алгоритм возможно запустить обучаться на любой игре:как на Го, так и на шахматах или сёги. Обучение с подкреплением стремится построить алгоритмы, способные обучаться решать любую задачу, представленную в формализме MDP. Как и обычные методы оптимизации, их можно использовать в виде чёрной коробочки из готовых библиотек, например,OpenAI Stable Baselines. Внутри таких коробочек будет, однако, довольно много гиперпараметров, которые пока не совсем понятно как настраивать под ту или иную практическую задачу. И хотя успехи Deep RL демонстрируют, что эти алгоритмы способны обучаться невероятно сложным задачам вродепобеды над людьми в Dota 2ив StarCraft II, они требуют для этого колоссального количества ресурсов. Поиск более эффективных процедур — открытая задача в Deep RL. В ШАДе есть курс Practical RL, на котором вы погрузитесь глубже в мир глубокого обучения с подкреплением, разберётесь в более продвинутых алгоритмах и попробуете пообучать нейронки решать разные задачки в разных средах.",
    "source_type": null,
    "useful_links": [
      {
        "text": "превзошёл человека в игру Го",
        "url": "https://www.youtube.com/watch?v=WXuK6gekU1Y&ab_channel=DeepMind"
      },
      {
        "text": "как на Го, так и на шахматах или сёги",
        "url": "https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go"
      },
      {
        "text": "OpenAI Stable Baselines",
        "url": "https://stable-baselines.readthedocs.io/en/master/"
      },
      {
        "text": "победы над людьми в Dota 2",
        "url": "https://openai.com/projects/five/"
      },
      {
        "text": "в StarCraft II",
        "url": "https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii"
      }
    ]
  },
  {
    "document_title": "Градиентный бустинг",
    "url": "https://education.yandex.ru/handbook/ml/article/gradientnyj-busting",
    "section_title": "Интуиция",
    "text": "Рассмотрим задачу регрессии с квадратичной функцией потерь: Для решения будем строить композицию избазовых алгоритмов: Если мы обучим единственное решающее дерево, то качество такой модели, скорее всего, будет низким. Однако мы знаем, на каких объектах построенное дерево давало точные предсказания, а на каких ошибалось. Попробуем использовать эту информацию и обучим ещё одну модель. Допустим, что предсказание первой модели на объектена 10 больше, чем необходимо (т.е.). Если бы мы могли обучить новую модель, которая набудет выдавать ответ, то сумма ответов этих двух моделей на объектев точности совпала бы с истинным значением: Другими словами, если вторая модель научится предсказывать разницу между реальным значением и ответом первой, то это позволит уменьшить ошибку композиции. В реальности вторая модель тоже не сможет обучиться идеально, поэтому обучим третью, которая будет «компенсировать» неточности первых двух. Будем продолжать так, пока не построим композицию изалгоритмов. Для объяснения метода градиентного бустинга полезно воспользоваться следующей аналогией. Бустинг можно представить как гольфиста, цель которого — загнать мяч в лунку с координатой. Положение мяча здесь – ответ композиции. Гольфист мог бы один раз ударить по мячу, не попасть в лунку и пойти домой, но настырность заставляет его продолжить. По счастью, ему не нужно начинать каждый раз с начальной позиции. Следующий удар гольфиста переводит мяч из текущего положенияв положение. Каждый следующий удар — это та поправка, которую вносит очередной базовый алгоритм в композицию. Если гольфист все делает правильно, то функция потерь будет уменьшаться: то есть мяч постепенно будет приближаться к лунке. Удары при этом делаются не хаотично. Гольфист оценивает текущее положение мяча относительно лунки и следующим ударом старается нивелировать те проблемы, которые он создал себе всеми предыдущими. Подбираясь к лунке, он будет бить всё аккуратнее и, возможно, даже возьмет другую клюшку, но точно не будет лупить так же, как из первоначальной позиции. В итоге комбинация всех ударов рано или поздно перенесет мяч в лунку. Подобно тому, как гольфист постепенно подводит мяч к цели, бустинг с каждым новым базовым алгоритмом всё больше приближает предсказание к истинному значению метки объекта. Рассмотрим теперь другую аналогию — разложение функции в ряд Тейлора. Из курса математического анализа известно, что (достаточно хорошую) бесконечно дифференцируемую функциюна интервалеможно представить в виде бесконечной суммы степенных функций: Одна, самая первая степенная функция в разложении, очень грубо приближает. Прибавляя к ней следующую, мы получим более точное приближение. Каждая следующая элементарная функция увеличивает точность приближения, но менее заметна в общей сумме. Если нам не требуется абсолютно точное разложение, вместо бесконечного ряда Тейлора мы можем ограничиться суммой его первыхэлементов. Таким образом, интересующую нас функцию мы с некоторой точностью представили в виде суммы «простых» функций. Перенесём эту идею на задачи машинного обучения. В машинном обучении мы пытаемся по выборкевосстановить неизвестную истинную зависимость. Прежде всего, мы выбираем подходящий алгоритм. Мы можем выбрать «сложный» алгоритм, который сразу хорошо выучит истинную зависимость. А можем обучить «простой», который выучит истинную зависимость посредственно. Затем мы добавим к нему ещё один такой простой алгоритм, чтобы уточнить предсказание первого алгоритма. Продолжая этот процесс, мы получим сумму простых алгоритмов, где первый алгоритм грубо приближает истинную зависимость, а каждый следующий делает приближение всё точнее.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Градиентный бустинг",
    "url": "https://education.yandex.ru/handbook/ml/article/gradientnyj-busting",
    "section_title": "Пример с задачей регрессии: формальное описание",
    "text": "Рассмотрим тот же пример с задачей регрессии и квадратичной функцией потерь: Для решения также будем строить композицию избазовых алгоритмов семейства: В качестве базовых алгоритмов выберем, как и условились в начале параграфа, семействорешающих деревьев некоторой фиксированной глубины. Используя известные нам методы построения решающих деревьев, обучим алгоритм, который наилучшим образом приближает целевую переменную: Построенный алгоритм, скорее всего, работает не идеально. Более того, если базовый алгоритм работает слишком хорошо на обучающей выборке, то высока вероятность переобучения: низкий уровень смещения, но высокий уровень разброса. Далее вычислим, насколько сильно отличаются предсказания этого дерева от истинных значений: Теперь мы хотим скорректироватьс помощью. В идеале так, чтобыидеально предсказывал величины, ведь в этом случае Найти совершенный алгоритм, скорее всего, не получится, но по крайней мере мы можем выбрать из семейства наилучшего представителя для такой задачи. Итак, второе решающее дерево будет обучаться предсказывать разности: Ожидается, что композиция из двух таких моделейстанет более качественно предсказывать целевую переменную. Далее рассуждения повторяются до построения всей композиции. На-ом шаге вычисляется разность между правильным ответом и текущим предсказанием композиции изалгоритмов: Затем-й алгоритм учится предсказывать эту разность: а композиция в целом обновляется по формуле Обучениебазовых алгоритмов завершает построение композиции.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Градиентный бустинг",
    "url": "https://education.yandex.ru/handbook/ml/article/gradientnyj-busting",
    "section_title": "Обобщение на другие функции потерь",
    "text": "Отметим теперь важное свойство функции потерь в рассмотренном выше примере с регрессией. Для этого посчитаем производную функции потерь по предсказаниюмодели для-го объекта: Видим, что разность, на которую обучается-й алгоритм, выражается через производную: Таким образом, для каждого объектаочередной алгоритм в бустинге обучается предсказывать антиградиент функции потерь по предсказанию моделив точкепредсказания текущей части композиции на объекте. Почему же это важно?Дело в том, что это наблюдение позволяет обобщить подход построения бустинга на произвольную дифференцируемую функцию потерь. Для этого мы заменяем обучение на разностьобучением на антиградиент функции потерь, где Вспомните аналогию с гольфистом: обучение композиции можно представить как перемещение предсказания из точкив точку. В конечном итоге мы ожидаем, что точкабудет располагаться как можно ближе к точке с истинными значениями. В случае квадратичной функции потерь интуиция вполне подкрепляется математикой. Изменится ли что-либо в наших действиях, если мы поменяем квадратичную функцию потерь на любую другую? С одной стороны, мы, как и прежде, можем двигаться в направлении уменьшения разности предсказания и истинного значения: любая функция потерь поощряет такие шаги для каждого отдельного объекта, ведь для любой адекватной функции потерь выполнено. Но мы можем посмотреть на задачу и с другой стороны: не с точки зрения уменьшения расстояния между вектором предсказаний и вектором истинных значений, а с точки зрения уменьшения значения функции потерь. Для наискорейшего уменьшения функции потерь нам необходимо шагнуть в сторону её антиградиента по вектору предсказаний текущей композиции, то есть как раз таки в сторону вектора. Это направление не обязано совпадать с шагом по направлению уменьшения разности предсказания и истинного значения. Например, может возникнуть гипотетическая ситуация, как на рисунке ниже: В изображённом примере рассматриваются два объектаи. Текущее предсказание для них —, а окружность определяет варианты следующего шага: первый вариант — пойти в направлении, как делалось ранее; второй — пойти в направлении антиградиента. Также показаны линии уровня значений функции потерь. Функция потерь в этом примере устроена таким образом, что, из-за чего шаг по антиградиенту оказывается более выгодным. Движение в сторону антиградиента более выгодно с точки зрения минимизации функции потерь — плюс оно также позволяет справляться с ситуациями, когда явно посчитать остаток (разницу между целевым значением и предсказанием) не представляется возможным. Один из таких примеров — задача ранжирования. В задаче ранжирования объекты в датасете разбиты на группы и требуется построить модель, по предсказаниям которой можно было бы «правильно» упорядочить документы в каждой группе (обычно по убыванию предсказания модели). Что значит упорядочить «правильно»?Это значит, что полученная по предсказаниям модели перестановка объектов в группе должна быть близка к идеальной по некоторой метрике. Как задается идеальная перестановка?Есть два способа: Первый способ — проставить каждому объекту число, по которому можно отсортировать объекты для получения идеальной перестановки. Это число можно рассматривать как таргет и обучать модель регрессии — в некоторых случаях это даже будет работать хорошо. Второй способ — задать набор пар объектов, которые обозначают их порядок относительно друг друга в идеальной перестановке. То есть параозначает, что объект с номеромдолжен стоять раньше в перестановке, чем объект с номером. Во втором способе таргетов у объектов нет, но дифференцируемая функция потерь есть — в библиотеке CatBoost она называется PairLogit и вычисляется по формуле: гдеи— это предсказания модели на объектахисоответственно. Градиент такой функции потерь посчитать можно, а разницу между предсказанием и истинным значением — нет. Попробуем записать наши интуитивные соображения более формально. Пусть– дифференцируемая функция потерь, а наш алгоритмпредставляет собой композицию базовых алгоритмов: Мы строим нашу композицию «жадно»: где вновь добавляемый базовый алгоритмобучается так, чтобы улучшить предсказания текущей композиции: Модельвыбирается так, чтобы минимизировать потери на обучающей выборке: Для построения базовых алгоритмов на следующих шагах рассмотрим разложение Тейлора функции потерьдо первого члена в окрестности точки: Избавившись от постоянных членов, мы получим следующую оптимизационную задачу: Поскольку суммируемое выражение — это скалярное произведение двух векторов, его значение минимизируют, пропорциональные значениям. Поэтому на каждой итерации базовые алгоритмыобучаются предсказывать значения антиградиента функции потерь по текущим предсказаниям композиции. Итак, использованная нами интуиция шага в сторону «уменьшения остатка» удивительным образом привела к оптимальным смещениям в случае квадратичной функции потерь, но для других функций потерь это не так: для них смещение происходит в сторону антиградиента. Получается, что в общем случае на каждой итерации базовые алгоритмы должны приближать значения антиградиента функции потерь. Однако есть частный случай, в котором в качестве таргета для базового алгоритма выгоднее использовать именно «остатки» — это касается функции потерь MAE. Её производная равна -1, 0 или +1. Приближая базовым алгоритмом антиградиент MAE, количество итераций до сходимости будет расти пропорционально масштабу таргета. То есть, если домножить целевое значение на 10, то потребуется в 10 раз больше итераций градиентного бустинга. Использование остатков в качестве таргета для базового алгоритма не имеет такой проблемы. Аналогичные рассуждения верны также для функции MAPE, в которой проблема с масштабом таргета может проявляться еще сильнее. При построении очередного базового алгоритмамы решаем задачу регрессии с таргетом, равным антиградиенту функции потерь исходной задачи на предсказании. Теоретически можно воспользоваться любым методом построения регрессионного дерева. Важно выбрать оценочную функцию, которая будет показывать, насколько текущая структура дерева хорошо приближает антиградиент. Её нужно будет использовать для построения критерия ветвления: где— значение функциив вершине,— значения в левом и правом сыновьяхпосле добавления предиката,— количество элементов, пришедших в вершину. Например, можно использовать следующие оценочные функции: где— предсказание дерева на объекте,— антиградиент, на который учится дерево,,. Функцияпредставляет собой среднеквадратичную ошибку, а функцияопределяет близость через косинусное расстояние между векторами предсказаний и антиградиентов. В итоге обучение базового алгоритма проходит в два шага: пофункции потерьвычисляется целевая переменная для обучения следующего базового алгоритма: строится регрессионное дерево на обучающей выборке, минимизирующее выбраннуюоценочную функцию. Поскольку для построения градиентного бустинга достаточно уметь считать градиент функции потерь по предсказаниям, с его помощью можно решать широкий спектр задач. В библиотеках градиентного бустинга даже реализована возможность создавать свои функции потерь: для этого достаточно уметь вычислять ее градиент, зная истинные значения и текущие предсказания для элементов обучающей выборки. Типичный градиентный бустинг имеет в составе несколько тысяч деревьев решений, которые необходимо строить последовательно. Построение решающего дерева на выборках типичного размера и современном железе, даже с учетом всех оптимизаций, требует небольшого, но всё-таки заметного времени (0.1-1c), которое для всего ансамбля превратится в десятки минут. Это не так быстро, как обучение линейных моделей, но всё-таки значительно быстрее, чем обучение типичных нейросетей. Обучение композиции с помощью градиентного бустинга может привести к переобучению, если базовые алгоритмы слишком сложные. Например, если сделать решающие деревья слишком глубокими (более 10 уровней), то при обучении бустинга ошибка на обучающей выборке даже при довольно скромномможет приблизиться к нулю, то есть предсказание будет почти идеальным, но на тестовой выборке всё будет плохо. Существует два решения этой проблемы. Во-первых, необходимо упростить базовую модель, уменьшив глубину дерева (либо примерив какие-либо ещё техники регуляризации). Во-вторых, мы можем ввести параметр, называемыйтемпом обучения(learning rate): Присутствие этого параметра означает, что каждый базовый алгоритм вносит относительно небольшой вклад во всю композицию: если расписать сумму целиком, она будет иметь вид Значение параметра обычно определяется эмпирически по входным данным. В библиотеке CatBoost темп обучения может быть выбран автоматически по набору данных. Для этого используется заранее обученная линейная модель, предсказывающая темп обучения по мета-параметрам выборки данных: числу объектов, числу признаков и другим. Темп обучения связан с количеством итераций градиентного бустинга. Чем меньше learning rate, тем больше итераций потребуется сделать для достижения того же качества на обучающей выборке. Отдельные деревья решений можно легко интерпретировать, просто визуализируя их структуру. Но в модели градиентного бустинга содержатся сотни деревьев, и поэтому её нелегко интерпретировать с помощью визуализации входящих в неё деревьев. При этом хотелось бы, как минимум, понимать, какие именно признаки в данных оказывают наибольшее влияние на предсказание композиции. Можно сделать следующее наблюдение: признаки из верхней части дерева влияют на окончательное предсказание для большей доли обучающих объектов, чем признаки, попавшие на более глубокие уровни. Таким образом, ожидаемая доля обучающих объектов, для которых происходило ветвление по данному признаку, может быть использована в качестве оценки его относительной важности для итогового предсказания. Усредняя полученные оценки важности признаков по всем решающим деревьям из ансамбля, можно уменьшить дисперсию такой оценки и использовать ее для отбора признаков. Этот метод известен какMDI(mean decrease in impurity). Существуют и другие методы оценки важности признаков для ансамблей: например, Permutation feature importance (см.описаниев sklearn) и множество разных подходов,предлагаемыхв библиотеке CatBoost. Все эти техники отбора признаков применимы также и для случайных лесов. Для общего развития имеет смысл посмотреть реализацию вsklearn, но на практике она весьма медленная и не такая уж умная. Хороших реализаций GBDT есть, как минимум, три:LightGBM,XGBoostиCatBoost. Исторически они отличались довольно сильно, но за последние годы успели скопировать друг у друга все хорошие идеи. Одно из основных отличий LightGBM, XGBoost и CatBoost — форма решающих деревьев. LightGBM строит деревья по принципу: «На каждом шаге делим вершину с наилучшим скором», а основным критерием остановки выступает максимально допустимое количество вершин в дереве. Это приводит к тому, что деревья получаются несимметричными, то есть поддеревья могут иметь разную глубину — например, левое поддерево может иметь глубину, а правое может разрастись до глубины. С одной стороны, это позволяет быстро подогнаться под обучающие данные. С другой — бесконтрольный рост дерева в глубину неизбежно ведет к переобучению, поэтому LightGBM позволяет помимо количества вершин ограничивать и максимальную глубину. Впрочем, это ограничение обычно все равно выше, чем для XGBoost и CatBoost. XGBoost строит деревья по принципу: «Строим дерево последовательно по уровням до достижения максимальной глубины». Отдельного ограничения на количество вершин нет, так как оно естественным образом получается из ограничения на глубину дерева. В XGBoost деревья «стремятся» быть симметричными по глубине, и в идеале получается полное бинарное дерево, если это не противоречит другим ограничениям (например, ограничению на минимальное количество объектов в листе). Такие деревья обычно являются более устойчивыми к переобучению. CatBoost строит деревья по принципу: «Все вершины одного уровня имеют одинаковый предикат». Одинаковые сплиты во всех вершинах одного уровня позволяют избавиться от ветвлений (конструкций if-else) в коде инференса модели с помощью битовых операций и получить более эффективный код, который в разы ускоряет применение модели, в особенности в случае применения на батчах. Кроме этого, такое ограничение на форму дерева выступает в качестве сильной регуляризации, что делает модель более устойчивой к переобучению. Основной критерий остановки, как и в случае XGBoost, — ограничение на глубину дерева. Однако, в отличие от XGBoost, в CatBoost всегда создаются полные бинарные деревья, несмотря на то, что в некоторые поддеревья может не попасть ни одного объекта из обучающей выборки. Если коротко — везде. Сегодня это один из двух главных подходов, которые используются на практике (второй — это нейронные сети, конечно). Формально градиентный бустинг слабее и менее гибок, чем сети, но выигрывает в простоте настройки темпа обучения и применения, размере и интерпретируемости модели. Во многих компаниях, так или иначе связанных с ML, он используется для всех задач, которые не связаны с однородными данными (картинками, текстами, и так далее). Типичный поисковый запрос в Яндексе, выбор отеля наBooking.comили сериала на вечер в Netflix задействует несколько десятков моделей GBDT. Впрочем, в будущем можно ожидать плавного исчезновения этого подхода, так как улучшение архитектур глубинного обучения и дальнейшее развитие железа нивелирует его преимущество по сравнению с нейросетями.",
    "source_type": null,
    "useful_links": [
      {
        "text": "описание",
        "url": "https://scikit-learn.org/stable/modules/permutation_importance.html#permutation-importance"
      },
      {
        "text": "предлагаемых",
        "url": "https://catboost.ai/en/docs/concepts/fstr"
      },
      {
        "text": "sklearn",
        "url": "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
      },
      {
        "text": "LightGBM",
        "url": "https://lightgbm.readthedocs.io/en/latest/"
      },
      {
        "text": "XGBoost",
        "url": "https://xgboost.readthedocs.io/en/latest/"
      },
      {
        "text": "CatBoost",
        "url": "https://catboost.ai/"
      },
      {
        "text": "Booking.com",
        "url": "http://Booking.com"
      }
    ]
  },
  {
    "document_title": "Градиентный бустинг",
    "url": "https://education.yandex.ru/handbook/ml/article/gradientnyj-busting",
    "section_title": "Почитать по теме",
    "text": "Серия блог-постово градиентном бустинге от Terence Parr and Jeremy Howard Раздел документацииsklearn с теоретическими выкладками для градиентного бустинга",
    "source_type": null,
    "useful_links": [
      {
        "text": "Серия блог-постов",
        "url": "https://explained.ai/gradient-boosting/"
      },
      {
        "text": "Раздел документации",
        "url": "https://scikit-learn.org/stable/modules/ensemble.html#mathematical-formulation"
      }
    ]
  },
  {
    "document_title": "Экспоненциальный класс распределений и принцип максимальной энтропии",
    "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
    "section_title": "Мотивация: метод моментов",
    "text": "Метод моментов — это ещё один способ, наряду с методом максимального правдоподобия, оценки параметров распределения по данным. Суть его в том, что мы выражаем через параметры распределения теоретические значения моментовнашей случайной величины, затем считаем их выборочные оценки, приравниваем их все друг к другу и, решая полученную систему, находим оценки параметров. Можно доказать, что полученные оценки являются состоятельными, хотя могут быть смещены. Пример 1. Оценим параметры нормального распределенияс помощью метода моментов. Теоретические моменты равны Запишем систему: Из неё очевидным образом находим Легко видеть, что полученные оценки совпадают с оценками максимального правдоподобия Пример 2. Оценим параметрлогнормального распределения при известном. Будет ли оценка совпадать с оценкой, полученной с помощью метода максимального правдоподобия? Теоретическое математическое ожидание равно, откуда мы сразу находим оценку. Теперь запишем логарифм правдоподобия: Дифференцируя пои приравнивая производную к нулю, получаем что вовсе не совпадает с оценкой выше. Несколько приукрасив ситуацию, можно сделать вывод, что первые два выборочных момента позволяют если не править миром, то уверенно восстанавливать параметры распределений. А теперь давайте представим, что мы посчиталии, а семейство распределений пока не выбрали. Как же совершить этот судьбоносный выбор? Давайте посмотрим на следующие три семейства и подумаем, в каком из них мы бы стали искать распределение, зная его истинные матожидание и дисперсию? Почему-то хочется сказать, что в первом. Почему? Второе не симметрично — но почему мы так думаем? Если мы выберем третье, то добавим дополнительную информацию как минимум о том, что у распределения конечный носитель. А с чего бы? У нас такой инфомации вроде бы нет. Общая идея такова: мы будем искать распределение, которое удовлетворяет только явно заданным нами ограничениям и не отражает никакого дополнительного знания о нём. Но чтобы эти нестрогие рассуждения превратить в формулы, придётся немного обогатить наш математический аппарат и научиться измерять количество информации.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Экспоненциальный класс распределений и принцип максимальной энтропии",
    "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
    "section_title": "Энтропия и дивергенция Кульбака-Лейблера",
    "text": "Измерять «знание» можно с помощьюэнтропии Шэннона. Она определяется как для дискретного распределения и для непрерывного. В классическом определении логарифм двоичный, хотя, конечно, варианты с разным основанием отличаются лишь умножением на константу. Неформально можно представлять, что энтропия показывает, насколько сложно предсказать значение случайной величины. Чуть более строго — сколько в среднем бит нужно потратить, чтобы передать информацию о её значении. Пример 1. Рассмотрим схему Бернулли с вероятностью успеха. Энтропия её результата равна Давайте посмотрим на график этой функции: Минимальное значение (нулевое) энтропия принимает при. В самом деле, для такого эксперимента мы всегда можем наверняка сказать, каков будет его исход; обращаясь к другой интерпретации — чтобы сообщить кому-то о результате эксперимента, достаточнобит (ведь получатель сообщения и так понимает, что вышло). Максимальное значение принимается в точке, что вполне соответствует тому, что припредсказать исход эксперимента сложнее всего. Пример 2. Энтропия нормального распределенияравна, и чем меньше дисперсия, тем меньше энтропия, что и логично: ведь когда дисперсия мала, значения сосредоточены возле матожидания, и они становятся менее «разнообразными». Энтропия тесно связана с другим важным понятием из теории информации —дивергенцией Кульбака-Лейблера. Она определяется длякак в непрерывном случае и точно так же, но только с суммой вместо интеграла в дискретном. Дивергенцию можно представить в виде разности: Вычитаемое — это энтропия, которая, как мы уже поняли, показывает, сколько в среднем бит требуется, чтобы закодировать значение случайной величины. Уменьшаемое похоже по виду, и можно показать, что оно говорит о том, сколько в среднем бит потребуется на кодирование случайной величины с плотностьюалгоритмом, оптимизированным для кодирования случайной величины. Иными словами, дивергенция Кульбака-Лейблера говорит о том, насколько увеличится средняя длина кодов для значений, если при настройке алгоритма кодирования вместоиспользовать. Более подробно вы можете почитать, например, вэтом посте. Дивергенция Кульбака-Лейблера в некотором роде играет роль расстояния между распределениями. В частности,, причём дивергенция равна нулю, только если распределения совпадают почти всюду. Но при этом она не является симметричной: вообще говоря,. Вопрос на подумать. Пусть— распределение, заданное на отрезке. Выразите энтропию через дивергенцию Кульбака-Лейблерас равномерным на отрезке распределением.",
    "source_type": null,
    "useful_links": [
      {
        "text": "этом посте",
        "url": "https://habr.com/ru/post/484756/"
      }
    ]
  },
  {
    "document_title": "Экспоненциальный класс распределений и принцип максимальной энтропии",
    "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
    "section_title": "Принцип максимальной энтропии",
    "text": "Теперь наконец мы готовы сформулировать, какие распределения мы хотим искать. Принцип максимальной энтропии. Среди всех распределений на заданном носителе, удовлетворяющих условиям, ...,, где— некоторые функции, мы хотим иметь дело с тем, которое имеет наибольшую энтропию. В самом деле, энтропия выражает нашу меру незнания о том, как ведёт себя распределение, и чем она больше — тем более «произвольное распределение», по крайней мере, в теории. Давайте рассмотрим несколько примеров, которые помогут ещё лучше понять, почему некоторые распределения так популярны: Пример 1. На конечном множественаибольшую энтропию имеет равномерное распределение (носитель — конечное множество изэлементов, других ограничений нет). Доказательство: Пусть,— некоторое распределение,— равномерное. Запишем их дивергенцию Кульбака-Лейблера: Так как дивергенция Кульбака-Лейблера всегда неотрицательна, получаем, что. При этом равенство возможно, только если распределения совпадают. Пример 2. Среди распределений, заданных на всей вещественной прямой и имеющих заданные матожиданиеи дисперсиюнаибольшую энтропию имеет нормальное распределение. Доказательство: Пусть— некоторое распределение,. Запишем их дивергенцию Кульбака-Лейблера: Так как дивергенция Кульбака-Лейблера всегда неотрицательна, получаем, что. При этом равенство возможно, только если распределенияисовпадают почти всюду, а с точки зрения теории вероятностей такие распределения различать не имеет смысла. Пример 3. Среди распределений, заданных на множестве положительных вещественных чисел и имеющих заданное матожиданиенаибольшую энтропию имеет показательное распределение с параметром(его плотность равна). Все хорошо знакомые нам распределения, не правда ли? Проблема в том, что они свалились на нас чудесным образом. Возникает вопрос, можно ли их было не угадать, а вывести как-нибудь? И как быть, если даны не эти конкретные, а какие-то другие ограничения? Оказывается, что при некоторых не очень обременительных ограничениях ответ можно записать с помощью распределений экспоненциального класса. Давайте же познакомимся с ними поближе.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Экспоненциальный класс распределений и принцип максимальной энтропии",
    "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
    "section_title": "Экспоненциальное семейство распределений",
    "text": "Говорят, что семейство распределений относится кэкспоненциальному классу, если оно может быть представлено в следующем виде: где— вектор вещественнозначных параметров (различные значения которых дают те или иные распределения из семейства),,— некоторая вектор-функция, и, разумеется, сумма или интеграл поравняется единице. Последнее, в частности, означает, что (или сумма в дискретном случае). Пример 1. Покажем, что нормальное распределение принадлежит экспоненциальному классу. Для этого мы должны представить привычную нам функцию плотности в виде Распишем Определим Если теперь всё-таки честно выразитьчерез(это мы оставляем в качестве лёгкого упражнения), то получится В данном случае функцияпросто равна единице. Пример 2. Покажем, что распределение Бернулли принадлежит экспоненциальному классу. Для этого попробуем преобразовать функцию вероятности (нижепринимает значенияили): Теперь мы можем положить,, и всё получится. Единственное, что смущает, — это то, что компоненты векторалинейно зависимы. Хотя это не является формальной проблемой, но всё же хочется с этим что-то сделать. Исправить это можно, если переписать и определить уже минимальное представление с,— мы ведь уже сталкивались с этим выражением, когда изучали логистическу регрессию, не так ли? Вопрос на подумать. Принадлежит ли к экспоненциальному классу семейство равномерных распределений на отрезках? Казалось бы, да: так как: В чём может быть подвох? Как мы увидели, к экспоненциальным семействам относятся как непрерывные, так и дискретные распределения. Вообще, к ним относится большая часть распределений, которыми Вам на практике может захотеться описать. В том числе: нормальное; распределение Пуассона; экспоненциальное; биномиальное, мультиномиальное (с фиксированным числом испытаний); геометрическое; -распределение; бета-распределение; гамма-распределение; распределение Дирихле. К экспоненциальным семействам не относятся, к примеру: равномерное распределение на отрезке; -распределение Стьюдента; распределение Коши; смесь нормальных распределений.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Экспоненциальный класс распределений и принцип максимальной энтропии",
    "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
    "section_title": "MLE для семейства из экспоненциального класса",
    "text": "Возможно, вас удивил странный и на первый взгляд не очень естественный вид. Но всё не просто так: оказывается, что оценка максимального правдоподобия параметров распределений из экспоненциального класса устроена очень интригующе. Запишем функцию правдоподобия выборки: Её логарифм равен Дифференцируя по, получаем Тут нам потребуется следующая Лемма. Доказательство: Как мы уже отмечали в прошлом пункте: Следовательно, Кстати, можно ещё доказать, что Приравниваяк нулю и применяя лемму, мы получаем, что Таким образом, теоретические матожидания всех компонентдолжны совпадать с их эмпирическими оценками, а метод максимального правдоподобия совпадает с методом моментов дляв качестве моментов. И в следующем пункте выяснится, что распределения из семейств, относящихся к экспоненциальному классу, это те самые распределения, которые имеют максимальную энтропию из тех, что имеют заданные моменты. **Пример.**Рассмотрим вновь логнормальное распределение: Как видим, логнормальное распределение тоже из экспоненциального класса. Вас может это удивить: ведь выше мы обсуждали, что для него метод моментов и метод максимального правдоподобия дают разные оценки. Но никакого подвоха тут нет: мы просто брали не те моменты. В данном случае,, их матожидания и надо брать; тогда для параметров, получаемых из MLE, должно выполняться Матожидания в левых частых мы должны выразить через параметры — и нам для этого совершенно не обязательно что-то интегрировать! В самом деле:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Экспоненциальный класс распределений и принцип максимальной энтропии",
    "url": "https://education.yandex.ru/handbook/ml/article/eksponencialnyj-klass-raspredelenij-i-princip-maksimalnoj-entropii",
    "section_title": "Теорема Купмана-Питмана-Дармуа",
    "text": "Теперь мы наконец готовы сформулировать одно из самых любопытных свойств семейств экспоненциального класса. В следующей теореме мы опустим некоторые не очень обременительные условия регулярности. Просто считайте, что для хороших дискретных и абсолютно непрерывных распределений, с которыми вы в основном и будете сталкиваться, это так. Теорема. Пусть— распределение, причём— вектор длиныидля некоторых фиксированных,. Тогда распределениеобладает наибольшей энтропией среди распределений с тем же носителем, для которых,. При этом оно — единственное с таким свойством: в том смысле, что любое другое распределение, обладающее этим свойством, совпадает с ним почти всюду. Рассмотрим несколько примеров: Пример 1. Среди распределений на множественеотрицательных целых чисел с заданным математическим ожиданиемнайдём распределение с максимальной энтропией. В данном случае у нас лишь одна функция, которая соответствует фиксации матожидания. Плотность будет вычисляться только в точках,и будет иметь вид В этой формуле уже безошибочно угадывается геометрическое распределение с. Параметрможно подобрать из соображений того, что математическое ожидание равно. Матожидание геометрического распределения равно, так что. Окончательно, Пример 2. Среди распределений на всей вещественной прямой с заданным математическим ожиданиемнайдём распределение с максимальной энтропией.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метрические методы",
    "url": "https://education.yandex.ru/handbook/ml/article/metricheskiye-metody",
    "section_title": "Метод k-ближайших соседей (KNN)",
    "text": "Представим, что мы проводим классификацию объектов на два класса — красный или жёлтый. Нам дана некоторая обучающая выборка и целевой объект (серый): Мы хотим определить, к какому классу относится серый объект. Интуитивно очевидно, что он должен быть жёлтым, потому что все его соседи жёлтые. Эта интуиция и отражает суть метода KNN — классифицировать целевой объект, исходя из того, какие классы у объектов, которые максимально похожи на него. Перейдём теперь к более формальному описанию алгоритма. Рассмотрим сначала задачу многоклассовой классификации, а регрессией займёмся позже. Пусть дана обучающая выборка, где. Пусть также задана некоторая симметричная по своим аргументам функция расстояния. Предположим, что требуется классифицировать новый объект. Для этого найдёмнаиболее близких кв смысле расстоянияобъектов обучающей выборки: Метку класса объектабудем обозначать. Класс нового объекта тогда естественным образом определим как наиболее часто встречающийся класс среди объектов из: Формула может показаться страшной, но на самом деле всё довольно просто: для каждой метки классаколичество соседейс такой меткой можно посчитать, просто просуммировав по всем соседям индикаторы событий, соответствующих тому, что метка соседа равна. Легко заметить, что этот алгоритм позволяет также оценивать вероятности классов. Для этого достаточно просто посчитать частоты классов соседей: Стоит, однако, понимать, что, хоть такая функция и удовлетворяет свойствам вероятности (она неотрицательна, аддитивна и ограничена единицей), это не более чем эвристика. Несмотря на то что формально фаза обучения отсутствует, алгоритм может легко переобучиться. Вы можете убедиться в этом сами, использовав маленькое количество соседей (например, одного или двух), — границы классов оказываются довольно сложными. Происходит это из-за того, что параметрами алгоритма можно считать всю обучающую выборку, довольно большую по размеру. Из-за этого алгоритму легко подстроиться под конкретные данные. Поссылкевы можете увидеть интерактивный пример работы алгоритма. Автор примера -Анастасия Чирикова. Может возникнуть закономерный вопрос, как же правильно выбрать функцию расстояния. В подавляющем большинстве случаев обычное евклидово расстояниебудет хорошим выбором. Однако в некоторых случаях другие функции будут подходить лучше, поэтому давайте разберём ещё несколько функций, наиболее используемых на практике. Часто используется в высокоразмерных пространствах из-за лучшей устойчивости к выбросам. Представим, что два объекта в 1000-размерном пространстве почти идентичны, но сильно отличаются по одному из признаков. Это почти наверняка свидетельствует о выбросе в этом признаке, и объекты, скорее всего, очень близки. Однако евклидово расстояние усилит различие в единственном признаке и сделает их более далёкими друг от друга. Этого недостатка лишена манхэттенская метрика — в ней вместо квадрата используется модуль. Является обобщением евклидовой () и манхэттенской () метрик. Эта метрика хороша тем, что не зависит от норм векторов. Такое поведение бывает полезно в некоторых задачах, например при поиске похожих документов. В качестве признаков там часто используются количества слов. При этом интуитивно кажется, что если в тексте использовать каждое слово в два раза больше, то тема этого текста поменяться не должна. Поэтому как раз в этом случае нам не важна норма вектор-признака, и в задачах, связанных с текстами, часто применяется именно косинусное расстояние. Его стоит использовать, если исследуемые объекты — это некоторые множества. Это полезно тем, что нет нужды придумывать векторные представления для этих множеств, чтобы использовать традиционные метрики. Вообще говоря, несмотря на некоторые эвристические соображения по выбору метрики, её можно считать гиперпараметром и подбирать соответствующими способами. Часто качество модели сильно зависит от выбора метрики, а иногда выбрать правильную метрику очень тяжело. Например, в случае когда данные имеют сильно разный масштаб, выбрать подходящую метрику почти невозможно, и нужно сперва проводить нормализацию. Замечание. Упомянутые в этом параграфе функции мы называем «метриками», но, конечно же, они не обязаны быть метриками в строгом математическом смысле. Они неотрицательны и симметричны, но могут не удовлетворять неравенству треугольника. У оригинального алгоритма есть один большой недостаток: он никак не учитывает расстояния до соседних объектов, хотя эта информация может быть полезной. Давайте попробуем придумать, как исправить этот недостаток. Нам нужно каким-то образом увеличивать вклад близких объектов и уменьшать вклад далёких. Можно заметить, что все индикаторы в формулеучитываются в сумме с одинаковыми коэффициентами. Возникает идея — назначить этим индикаторам веса, которые тем больше, чем ближе объект к целевому. Таким образом, получаем следующую формулу: Такой алгоритм называетсявзвешенным KNN(weighted KNN). Есть множество вариантов выбора весов для объектов, которые можно поделить на две большие группы. В первой группе веса зависят лишь от порядкового номера объекта в отсортированном по близости кмассиве. Чаще всего затухающие веса берутся линейноили экспоненциально. Однако здесь мы также не используем всю информацию, которая нам доступна. Зачем использовать порядок соседей, порождаемый расстояниями, если можно использовать сами расстояния? Во второй группе методов вес — это некоторая функция от расстояния. Давайте подумаем, какие должны быть свойства у этой функции. Очевидно, она должна быть положительной на своей области определения, иначе модель будет поощрять несовпадение с некоторыми ближайшими соседями. Также необходимо, чтобы функция монотонно не возрастала, чтобы вес близких соседей был больше, чем далёких. Таким образом вводится так называемаяядерная функция(kernel function), обладающая перечисленными выше свойствами, с помощью которой и высчитывается вес каждого соседа: где— некое положительное число, которое называетсяшириной окна. От выбора ядра зависит гладкость аппроксимации, но на её качество этот выбор почти не влияет. Примеры ядерных функций в порядке увеличения их гладкости: — прямоугольное ядро; — треугольное ядро (непрерывное); — ядро Епанечникова (гладкое везде, кроме –1 и 1); — биквадратное ядро (гладкое везде); — гауссовское ядро (бесконечно гладкое везде). На практике чаще всего используют либо прямоугольное для простоты, либо гауссовское, в случае когда важна гладкость модели (немного забегая вперёд — это особенно важно в регрессии). Ширина окна, в свою очередь, сильно влияет как раз на качество модели. При слишком маленькой ширине модель сильно подстраивается под обучающую выборку и теряет свою обобщающую способность. При слишком большой ширине, напротив, модель становится слишком простой. Универсальной ширины окна не существует, поэтому для каждой задачи её приходится подбирать отдельно. Алгоритм KNN можно довольно легко обобщить и на задачу регрессии. Самые очевидные способы — брать для некоторого ядралибо обычное среднее: либо взвешенный вариант: Последняя формула называетсяформулой Надарая — Ватсона. Она — один из непараметрических методов восстановления регрессии, объединённых названиемядерная регрессия(kernel regression). Выписать ответ, конечно, просто, но возникает интересный вопрос: можно ли использовать оптимизационные формулы из задачи классификации? Сначала давайте подумаем, что выдаст алгоритм, если формулуприменить без изменений. В задаче регрессии почти наверняка все значениябудут различными. Поэтому для любогосумма в формулебудет состоять из не более чем одного слагаемого, а значит, максимум будет достигаться на соседе с наибольшим весом, то есть на ближайшем соседе. Это означает, что метод всегда вырождается в 1-NN. Это не совсем то, чего мы добиваемся, поэтому давайте немного модифицируем алгоритм. Давайте сперва подумаем, а для чего вообще в формулеиспользуется индикатор. В задаче классификации индикатор — естественная мера близости двух объектов: если объекты совпадают, то значение, если различаются, то. Проблема в том, что в задаче регрессии объекты являются действительными числами, и для них функция, которая выдаёт отличное от нуля значение лишь в одной точке, — плохая мера близости. В случае непрерывных значенийестественно использовать более гладкие функции для выражения близости. Таким образом, для обобщения формулына задачу регрессии нам необходимо всего лишь заменить индикатор на некоторую более гладкую функцию. При этом для действительных чисел чаще всего рассматривают не близость, а расстояние между ними, то есть некоторую метрику. Например, в качестве такой метрики можно взять квадрат евклидова расстояния. Отметим, что максимизация близости эквивалентна минимизации расстояния, и получим следующую формулу: Выбор именно этой функции хорош тем, что у этой оптимизационной задачи есть точное решение, и оно записывается как раз формулой. Для ядерной регрессии справедливы те же рассуждения про выбор ядра и ширины окна, которые были приведены в прошлом разделе про классификацию. Влияние ширины окна и вида ядра на вид функции: Сперва поговорим о преимуществах алгоритма. Непараметрический, то есть не делает явных предположений о распределении данных. Очень простой в объяснении и интерпретации. Достаточно точный, хоть и чаще всего уступает градиентному бустингу и случайному лесу в accuracy. Может быть использован как для классификации, так и для регрессии. Несмотря на большие преимущества, алгоритм не лишён и минусов. Неэффективный по памяти, поскольку нужно хранить всю обучающую выборку. Вычислительно дорогой по той же причине. Чувствителен к масштабу данных, а также к неинформативным признакам. Для применения алгоритма необходимо, чтобы метрическая близость объектов совпадала с их семантической близостью, чего не всегда просто добиться. Представим, например, что мы решаем задачу нахождения похожих изображений. Мы хотим, чтобы картинки с лесом находились близко друг к другу, однако, если взять любую попиксельную метрику, такие картинки могут быть очень далеки друг от друга. Зачастую для решения этой проблемы вначале обучают представления. Из-за своих недостатков алгоритм очень неэффективен в задачах с большим количеством данных. Однако у него всё равно есть много применений в реальном мире. Приведём лишь некоторые из них: Рекомендательные системы. Если посмотреть на саму формулировку задачи «предложить пользователю что-то похожее на то, что он любит», то KNN прямо напрашивается в качестве решения. Несмотря на то что сейчас часто используются более совершенные алгоритмы, метод ближайших соседей всё равно применяется в качестве хорошего бейзлайна. Поиск семантически похожих документов. Если векторные представления близки друг к другу, то темы документов схожи. Поиск аномалий и выбросов. Из-за того что алгоритм запоминает обучающую выборку полностью, ему легко посмотреть, насколько целевой объект похож на все данные, которые он видел. Задача кредитного скоринга. Рейтинги двух людей, у которых примерно одинаковая зарплата, схожие должности и кредитные истории, не должны сильно отличаться, поэтому KNN отлично подходит для решения такой задачи. Вопрос сложности алгоритма неочевиден и требует детального анализа, который будет частично проведён в следующем разделе.",
    "source_type": null,
    "useful_links": [
      {
        "text": "ссылке",
        "url": "https://yastatic.net/s3/academy/ml/knn_clf/knn_clf.html"
      },
      {
        "text": "Анастасия Чирикова.",
        "url": "mailto:Aechirikova@edu.hse.ru"
      }
    ]
  },
  {
    "document_title": "Метрические методы",
    "url": "https://education.yandex.ru/handbook/ml/article/metricheskiye-metody",
    "section_title": "Поиск ближайших соседей",
    "text": "Для того чтобы применять метод ближайших соседей, нужно уметь как-то находить этих самых соседей. С первого взгляда может показаться, что никакой проблемы нет: действительно, можно ведь просто перебрать все объекты из обучающей выборки, посчитать для каждого из них расстояние до тестового объекта и затем найти минимум. Однако несмотря на то что сложность такого поиска линейная по, она также зависит и от размерности пространства признаков. Если, то сложность такого алгоритма поиска. Если вспомнить, что в типичной задаче машинного обучения количество признаковможет быть порядка, а размер выборки и вовсе может исчисляться десятками и сотнями тысяч объектов, то становится ясно, что такая сложность никуда не годится. Проблема осложняется ещё и тем, что данный поиск необходимо выполнять на этапе применения модели, который должен быть быстрым. Всё это означает, что возникает необходимость в более быстрых методах поиска ближайших соседей, чем простой перебор. Все такие методы можно поделить на две основные группы: точные и приближённые. Последние, как следует из их названия, находят соседей лишь приближённо, то есть найденные объекты хоть и будут действительно близки, но не обязательно будут самыми близкими. В этом разделе мы подробнее рассмотрим методы из каждой группы. Перед началом обзора стоит сказать, что хоть мы и рассматриваем алгоритмы поиска соседей именно в контексте их использования в KNN, область их применения значительно шире, и она не ограничивается исключительно машинным обучением. Например, на их основе работает любая информационно-поисковая система, от поиска в «Гугле» или «Яндексе» до всем известных алгоритмов «Ютьюба».",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Метрические методы",
    "url": "https://education.yandex.ru/handbook/ml/article/metricheskiye-metody",
    "section_title": "Поиск ближайших соседей: точные методы",
    "text": "Точных методов существует довольно мало. Можно сказать, что их, по сути, два. Первый — полный перебор с различными эвристиками. Например, можно выбрать подмножество признаков и считать расстояние только по ним. Оно будет оценкой снизу на реальное расстояние, поэтому если оно уже больше, чем до текущего ближайшего объекта, то можно сразу отбросить этот объект и переходить к следующему. Такие эвристики хоть и могут давать некоторый выигрыш по времени, но не улучшат асимптотическую сложность. Второй — k-d-деревья, о которых стоит поговорить подробнее. Представим на секунду, что у нас есть всего лишь один признак, то есть объекты выражаются вещественными числами, а не векторами. В этом случае для поиска ближайшего соседа напрашивается всем вам известное бинарное дерево поиска, которое позволяет находить элементы за логарифмическое время. Оказывается, существует аналог данной структуры в многомерном пространстве, который называетсяk-d-дерево(k-d tree, сокращение от k-dimensional tree). Как и в обычном дереве поиска, в k-d-дереве каждый узел является объектом обучающей выборки, который особым образом делит пространство на два полупространства. Таким образом, всё пространство оказывается поделено на множество малых областей, и такое деление оказывается очень полезным при поиске ближайших соседей. Рассмотрим подробнее, как строится такое дерево. Трудность в применении обычного дерева поиска состоит в том, что мы не можем напрямую сравнить два вектора так же, как два вещественных числа. Чтобы эту проблему преодолеть, узлы дерева будут делить пространство лишь по одной оси. При движении вниз по дереву оси, по которым точки делят пространство, циклически сменяют друг друга. Например, в двумерном пространстве корень будет отвечать за деление по x-координате, его сыновья — за деление по y-координате, а внуки — снова за x-координату, и т. д. Посмотрим, как это работает на примере: На картинке выше кореньделит все точки по оси х: слева оказываются точки, у которых, а справа — те, у которых. Аналогично левый сын корняделит своё поддерево по оси y: слева оказываются точки, у которых, а справа — те, у которых. Остаётся вопрос — как выбирать точки, которые будут делить пространство пополам? Чтобы дерево было сбалансированным, нужно находить точку с медианой, соответствующей уровню поддерева координаты. На практике часто ограничиваются выбором случайной точки или любой эвристикой по приближённому поиску медианы (например, медиана некоторого подмножества точек). Это позволяет ускорить построение дерева, но убирает все гарантии на его сбалансированность. Добавлять новые точки можно так же, как и в одномерном дереве поиска. Спускаясь по дереву, можно однозначно определить лист, к которому нужно подвесить новую точку, чтобы не нарушить все свойства дерева. При добавлении большого количества точек, однако, дерево может перестать быть сбалансированным, и нужно проводить ребалансировку. Также существуют варианты k-d-деревьев, которые сохраняют сбалансированность при добавлении / удалении точек. Поговорим теперь про то, как же находить ближайших соседей с помощью такого дерева. Будем производить обход дерева в глубину с двумя модификациями. Во-первых, будем запоминать наиболее близкую точку. Это позволит не заходить в поддеревья, задающие области, которые заведомо дальше, чем текущая наиболее близкая точка, поэтому не имеет смысла искать в них ближайших соседей. Во-вторых, будем прежде всего обходить те поддеревья, которые задают наиболее близкие области, а значит, с большей вероятностью содержат ближайшего соседа. Сложность метода по размеру обучающей выборки в среднем равнапри равномерном распределении точек. При большой размерности пространства, однако, алгоритму приходится посещать больше ветвей дерева, чтобы найти ближайших соседей. Например, если, то сложность становится примерно такой же, как и в случае полного перебора. В общем случае считается, что для того чтобы асимптотика действительно была логарифмической, нужно, чтобы. Поэтому уже при количестве признаков порядка сотни алгоритм не даёт существенных преимуществ перед полным перебором. Почитать по теме: Хорошая презентация, объясняющая структуру и поиск соседей. Балансировка деревьев.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Хорошая презентация",
        "url": "https://www.cs.cmu.edu/~ckingsf/bioinfo-lectures/kdtrees.pdf"
      },
      {
        "text": "Балансировка деревьев",
        "url": "https://en.wikipedia.org/wiki/K-d_tree#Balancing"
      }
    ]
  },
  {
    "document_title": "Метрические методы",
    "url": "https://education.yandex.ru/handbook/ml/article/metricheskiye-metody",
    "section_title": "Поиск ближайших соседей: приближённые методы",
    "text": "Почти всегда находить именно самых близких соседей необязательно. Например, в задаче подбора рекомендаций фильмов пользователю чаще всего не нужны наиболее похожие картины, достаточно, к примеру, 10 из 15 наиболее близких. Поэтому, чтобы ускорить процесс поиска соседей, используют приближённые методы. Разберём основные идеи, которые применяются в таких методах. Алгоритмы, основанные на деревьях, очень часто применяются в задачах поиска соседей. Идея всех таких методов заключается в итеративном разделении пространства случайными гиперплоскостями и построении на базе этого разделения дерева, в листах которого содержится малое число объектов. Одним из наиболее ярких представителей этого семейства являетсяAnnoy— алгоритм, который используется Spotify для рекомендаций музыки. Задача подобных рекомендательных систем довольно простая — нужно посоветовать пользователю композиции, которые он ещё не слушал, но которые при этом с высокой вероятностью ему понравятся. Простая и рабочая идея — предлагать композиции, похожие на те, которые он уже слушает. Здесь на помощь как раз и приходят методы поиска ближайших соседей. Annoy в какой-то степени похож на k-d-деревья. Сначала выбираются два случайных объекта обучающей выборки и проводится гиперплоскость, симметрично их разделяющая. Затем для каждого полученного полупространства итеративно запускается такая же процедура, которая продолжается до тех пор, пока в каждой области будет не болееобъектов (— гиперпараметр). Таким образом задаётся бинарное дерево с глубиной порядкав среднем. Спускаясь по этому дереву, можно найти область, в которой лежит целевой объект и некоторое количество близких к нему элементов обучающей выборки. Проблема в том, что это не обязательно будут самые близкие объекты, поэтому для увеличения точности составляется лес из таких деревьев и берётся объединение соответствующих целевому объекту областей. Чем больше таких деревьев берётся, тем более точным будет результат, но придётся тратить большее время на его поиск. Преимущество алгоритма — простота нахождения компромисса между скоростью работы и точностью с помощью тюнинга гиперпараметров. К минусам можно отнести то, что алгоритм плохо параллелится и переносится на GPU, не работает эффективно с батчами, а также то, что для добавления новой точки в обучающую выборку придётся перезапускать процедуру с самого начала. Почитать по теме: Отличная статьяс иллюстрациями и подробным описанием алгоритма. Предположим, что мы можем построить такую хеш-функцию, которая переводит близкие объекты в один бакет. Тогда близких соседей целевого объекта можно найти, посчитав его хеш и посмотрев на коллизии. Оказывается, такие хеш-функции существуют, и на этой идее основано несколько алгоритмов, которые объединяются названиемLocality-sensitive hashing(LSH). К этому классу алгоритмов относится, например,FAISS, используемый Facebook. Определим формально семейство хеш-функций, которое мы хотим использовать. Нам нужно, чтобы вероятность коллизии на близких объектах была высокая, а на далёких — низкая. Назовём семейство хеш-функций-чувствительным, если для любой: длявероятность коллизии; длявероятность коллизии. Формулы могут выглядеть сложными, но это всего лишь формализация нашей интуиции. Картинка ниже поясняет определение: для близких красных объектов в шаре радиусомвероятность коллизии больше, для далёких синих объектов на расстоянии большевероятность коллизии меньше, а про серые объекты в слое междуимы ничего не знаем. Для каждой функции расстояния, используемой в задаче, существует своё подходящее семейство хеш-функций. Например, для евклидовой и манхэттенской метрик используютсяслучайные проекции, где хеш-функция имеет следующий вид: гдеи— случайные параметры, авыбирается пользователем.выбирается равномерно из отрезка, агенерируется либо из нормального распределения, что соответствует евклидовой метрике, либо из распределения Коши — для манхэттенской метрики. По сути, такая функция разбивает всё пространство на слои в направлении вектора. Параметрпри этом задаёт ширину слоя. На практике при использовании лишь одной хеш-функции разница междуиоказывается очень маленькой, поэтому применяют различные методы для её увеличения. Первый способ — уменьшать размер бакетов в хеш-таблице путём использования композиции разных хеш-функций из одного семейства. Преимущество этого способа как раз хорошо видно на примере случайных проекций. При использовании лишь одной хеш-функции бакетами являются слои бесконечного объёма. Однако при использовании композиции размером, как минимум равным количеству признаков, из-за случайности выбора векторабакеты почти наверное станут замкнутыми фигурами с конечным объёмом. Второй способ повышения эффективности алгоритма — использовать несколько хеш-таблиц и искать соседей среди коллизий в каждой из них. На практике используют оба метода сразу, подбираяи— количество хеш-таблиц как гиперпараметры. К плюсам алгоритма можно отнести хорошие теоретические гарантии на сублинейное время и, как и в Annoy, простой поиск компромисса между точностью и скоростью работы. Минусами можно назвать высокую потребность в памяти, плохую адаптируемость под GPU, а также тот факт, что, несмотря на теоретические гарантии в среднем, на практике алгоритм может работать даже чуть дольше полного перебора из-за того, что, помимо самого поиска, требуется искать хеши объектов. Почитать по теме: Отличная статьяс объяснением в иллюстрациях и примерами хеш-функций для других метрик. Ещё одна статья, в которой шаг за шагом выводится алгоритм на примере расстояния Жаккара. Следующий класс алгоритмов основан на построении специальногографа близости(proximity graph) на объектах выборки и дальнейшем жадном поиске по этому графу. Алгоритмы этого семейства сейчас считаются state-of-the-art (SotA) для многих задач. Рассмотрим подробнее этот класс алгоритмов на примере одного из наиболее популярных из них под названиемNavigable small world (NSW). Идея его в следующем: на данных строится граф (он также называется NSW), который удовлетворяет двум следующим свойствам: Между любыми двумя точками существует короткий путь, или, более формально, матожидание числа кратчайшего пути между двумя случайно выбранными вершинами растёт как. Средняя степень вершины мала. На первый взгляд может показаться, что тяжело выполнить одновременно оба свойства, но на самом деле большая часть графов в реальном мире являются NSW-графами. Самый простой пример — это известное правило шести рукопожатий: любые два случайных человека соединены короткой последовательностью личных контактов длиной не более шести, несмотря на то, что количество знакомых у среднего человека (–) мало по сравнению с населением Земли. В таких графах существует очень простой метод поиска соседей. Нужно выбрать случайную точку, среди её соседей выбрать того, который ближе всего к целевому объекту, и повторить процедуру уже для него. Показано, что такой жадный поиск имеет полилогарифмическую асимптотику. Проблема такого подхода в том, что можно попасть в плотный кластер и очень долго оттуда выбираться. Для решения этой проблемы используется иерархия NSW, илиHierarchical navigable small world (HNSW). Исходный граф является нулевым слоем. Каждый следующий слой строится в два шага: Каждая вершина текущего слоя попадает в следующий с некоторой вероятностью. На всех вершинах, попавших в новый слой, строится NSW. По построению количество слоёв будет. Поиск начинается в самом верхнем слое. После нахождения ближайшей к целевому объекту вершины спускаемся на слой ниже и начинаем поиск из этой вершины. Повторяем процедуру, пока не спустимся до нулевого слоя. Таким образом, на каждом слое мы всё больше уточняем наш ответ. Стоит отметить, что для ускорения работы иногда поиск останавливают не при нахождении ближайшей вершины, а раньше, используя критерии остановки. Интуитивно легко понять, почему такая иерархическая структура решает проблему плотных кластеров: в верхних слоях вершин мало, а расстояния между ними в среднем большие, а значит, таких кластеров там почти нет. Поэтому, попадая в нижний слой, мы чаще всего оказываемся уже в нужном кластере и просто уточняем результат работы алгоритма. HNSW, так же как и рассмотренные ранее приближённые методы, позволяет искать трейд-офф между точностью и скоростью работы. Плюс ко всему на реальных данных он часто работает лучше других методов и сейчас считается SotA. Однако этот способ поиска не лишён и недостатков. Главный заключается в том, что нельзя добавлять точки в обучающую выборку без перестройки структуры. Помимо этого, он довольно требователен по памяти из-за того, что для каждого слоя приходится хранить как вершины, которые в него входят, так и связи между этими вершинами. Подробнее — воригинальной статье. В завершение стоит сказать, что не существует универсального метода поиска соседей — каждый из описанных методов может быть лучше других в определённой задаче. К тому же, несмотря на то что приближённые методы имеют лучшую асимптотику, многие из них плохо переносятся на GPU. Из-за этого на практике полный перебор бывает быстрее любого из таких приближённых методов.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Отличная статья",
        "url": "https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html"
      },
      {
        "text": "Отличная статья",
        "url": "https://randorithms.com/2019/09/19/Visual-LSH.html"
      },
      {
        "text": "Ещё одна статья",
        "url": "https://towardsdatascience.com/understanding-locality-sensitive-hashing-49f6d1f6134"
      },
      {
        "text": "оригинальной статье",
        "url": "https://arxiv.org/abs/1603.09320"
      }
    ]
  },
  {
    "document_title": "Временные ряды",
    "url": "https://education.yandex.ru/handbook/ml/article/vremennye-ryady",
    "section_title": "Введение",
    "text": "Временной ряд— значения меняющихся во времени признаков, полученные в некоторые моменты времени. Задача прогнозирования Пусть– временной ряд, для которого известны значения. Требуется построитьпрогноз– функцию, такую что величинакак можно лучше приближает значение, где– количество шагов, на которое нужно построить прогноз, а величина– горизонт прогнозирования, то есть максимальное количество шагов для построения прогноза. Иными словами, прогноз значения ряда в момент временистроится на основе известных значений ряда до момента времени. Кроме этого имеет смысл строитьпредсказательный интервал, то есть интервал, т.ч.. Например, пусть– значение какого-то признака в момент времени, и у нас есть значения ряда за месяц, то есть. Пусть также требуется предсказать значения ряда на неделю вперед. Тогда прогноз на первые сутки вперед будет равен, а прогноз на пятые сутки. Спустя некоторое время прогноз можно перестроить. Например, пусть прогноз перестраивается один раз в трое суток. Тогда оценку значениямы уточним как. При этом может оказаться, что функцияумеет принимать на вход лишь фиксированное количество предыдущих значений ряда. Например, если она умеем строить прогноз по последним 30 значениям ряда, то запись будет иметь вид. Иногда для уточнения того, в какой момент построен прогноз значения, указывают момент времени построения прогноза. Например, записьозначает, что прогноз на 35-й день построен в день 30, а– в день 33. Если признаков несколько, не обязательно прогнозировать каждый признак. Часто выделяется один или несколько целевых признаков, а остальные признаки являются вспомогательными и могут улучшить прогноз. Практические примеры: Прогноз погоды на 10 дней вперед. Прогноз осадков на 2 часа вперед.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Временные ряды",
    "url": "https://education.yandex.ru/handbook/ml/article/vremennye-ryady",
    "section_title": "Примеры временных рядов",
    "text": "Ежемесячные продажи антидиабетических лекарств в Австралии с июля 1991 по июнь 2008.На этом графике мы можем видеть возрастающий тренд, возможно, даже нелинейный, и кроме этого есть сезонность (периодичность) значений по годам. Максимальный спрос на электричество в штате Виктория (Австралия) за 30-минутные интервалы с 10 января 2000 в течении 115 дней.Здесь мы можем наблюдать сразу две сезонности – суточную и недельную. Первая сезонность вызвана тем, что люди обычно больше потребляют электричество днем, чем ночью. Недельная сезонность вызвана более высоким потреблением электричества по будням. Если бы мы посмотрели данные за несколько лет, то увидели бы еще одну сезонность – годовую, например, вызванную тем, что в теплое время года работает больше кондиционеров. Почему бы нам не построить прогноз простыми методами, например, линейной регрессией по времени? Общий тренд так можно уловить. Но в остатках (то есть в разности между истинными значениями и прогнозом) этой модели будет достаточно много информации, которую хотелось бы как-то учесть. Можно также добавить квадрат значения времени. Тогда можно уловить квадратичный тренд, но не более.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Временные ряды",
    "url": "https://education.yandex.ru/handbook/ml/article/vremennye-ryady",
    "section_title": "Прогнозирование с помощью сведения к задаче регрессии",
    "text": "Давайте для начала поймем, что мы вообще хотим сделать. Посмотрим на этот график, на котором показаны продажи одного из товаров в магазине за разные года. Мы знаем значения ряда (зеленые) до момента времени, в данном случае за 4 года с 2013 по 2016 включительно. Предположим также, что в данный момент мы отмечаем Новый год 2017. В этот момент мы хотели бы предсказать (синее) будущие значения ряда (оранжевое) за весь 2017 год на основе четырехлетней истории продаж. Основная идея – подадим известные (зеленые) значения ряда в какую-то регрессионную функцию, получив тем самым предсказания. При этом можем брать не все известные значения ряда, а толькопоследних значений. Иначе говоря, модель имеет вид где– произвольная функция. Ее можно построить некоторым известным методом машинного обучения, например, линейной регрессией, решающими деревьями, бустингами, нейронными сетями (как сверточными, так и рекуррентными). Разберёмся, какие признаки мы подадим на вход регрессии. На практике при генерации идей о том, какие признаки можно создавать для построения модели, рекомендуется строить следующий график. На нем нужно отметить момент времении мысленно поставить себя в этот момент времени. Затем нужно подумать, какие данные нам при этом доступны. В модель можно брать любые признаки, которые доступны к моменту времени. Если все данные поступают сразу, то можно брать все признаки, которые зависят только от значений до момента времени. В реальности часть данных может поступать с задержкой. Например, если данные загружаются в базу данных раз в сутки в полночь, то в полдень нам не доступны данные за последние 12 часов. Также нужно помнить о том, на сколько времени вперед нужно сделать прогноз. Например, пусть у нас задача состоит в том, чтобы построить прогнозы продаж в магазине с целью планирования новых поставок. После того, как на основе прогноза мы примем решение о составе товаров в новой поставке, необходимо сначала собрать данные товары на складе, потом отправить машину в магазин, и затем еще разложить товар на полки в магазине. На эту процедуру может уходить от нескольких часов до нескольких дней. Тем самым еще до момента начала формирования новой поставки модель прогнозирования продаж должна построить прогноз спроса на товар к тому моменту, когда его выложат на полки. Посмотрим на то, какие признаки можно извлечь Пусть дана какая-то дата:13.04.2021 09:00. Отсюда можно получить следующие признаки: день недели: [2]; месяц: [4]; год: [2021]; сезон: [весна]; праздник: [0]; выходной: [0]; час: [9]. Например, если мы хотим построить признаки в момент временидля прогнозирования, то можно рассмотреть в качестве признаковпредыдущих значений ряда. Для реализации таких признаков можно выполнить сдвигивпередвременного ряда нашагов. Например, в таблице для прогнозирования значений ряда мы рассматриваем два предыдущих значений ряда, выполняя тем самым два сдвига вперед. Таким образом, для прогнозирования значения 5 января, которое равно 235, мы берем признаки 230 и 215, которые являются значением ряда за 4 и 3 января соответственно. Не всегда имеет смысл в качестве признаков в чистом виде брать все предыдущие значения ряда. Например, если данные приходят раз в секунду, то для того чтобы учесть изменения ряда за последний час, пришлось бы создавать 3600 признаков. Вместо этого по предыдущим значениям рядаможно посчитать: среднее; взвешенное среднее; экспоненциальное сглаживание; медиана; минимум/максимум; стандартное отклонение; любую другую статистику. Подобное скользящее окно можно рассматривать и по другим временным факторам, которые мы не прогнозируем. Примеры: Средняятемпературана прошлой неделе для предсказания температуры на завтра. Средняявлажностьна прошлой неделе для предсказания температуры на завтра. Если в задаче данные хорошие и удаётся использовать более-менее стандартные признаки, то можно воспользоваться готовыми инструментами. Если данные не очень приятные, стоит подумать над тем, какие признаки использовать и как реализовать их получение. Если во временном ряду наблюдается сезонность, то стоит использовать сезонные признаки, например, следующие. Значение переменной сутки/неделю/месяц/год назад. Такие факторы также можно усреднять. Сезонность, полученная методами декомпозирования ряда (об этом расскажем ниже). Примеры: Значение температуры год назад. Среднее значение температуры 23 ноября за 5 последних лет. Среднее значение температуры за 5 последних лет на неделе, в которую входит 23 ноября. Идея состоит в том, чтобы группировать данные не только по временным факторам, но и по любым категориальным. Например, пусть сегодня нет ветра. Тогда в качестве признака можно рассмотреть среднюю температуру в безветренные дни по историческим данным. Можно также использовать сразу несколько факторов. Например, мы строим прогноз в апреле. Тогда можно рассматривать среднюю температуру в безветренные дни в апреле по историческим данным. Подведем итог о том, какие признаки можем использовать для построения нашей модели. Используютсятолькоданные из прошлого, никакие данные из будущего нельзя использовать при прогнозировании. Нужно также учитывать возможные задержки в поступлении данных. Большое количество признаков может привести к вычислительным затратам. Можно генерировать и другие признаки с учетом знаний о предметной области. Мы определились с тем, какие брать признаки. Теперь разберемся с тем, как прогнозировать. Пусть требуется построить прогноз нашагов вперед. Выделяют три основных способа построить прогнозы: Рекурсивная стратегия; Прямая стратегия; Гибридная стратегия. Для каждого момента временисоздается объект обучающей выборки: Признаковое описание– история ряда до момента времени. Целевая метка– значение. По этим данным мы обучаем какую-либо регрессионную модель строить прогнозы на один шаг вперед. При построении прогноза на несколько шагов вперед мы сначала построим прогноз на один шаг. Затем – на второй шаг, используя полученный прогноз на первый шаг в качестве признаков, и далее аналогично. Иначе говоря, если для прогнозированияпризнаковое описание имеет вид, то для построения прогнозарассматривается признаковое описание. На картинке считаем, что M-2, M-1 и M это названия признаков у построенной модели. В прямой стратегии предполагается, что построением каждого прогноза в рамках горизонта прогнозирования должна заниматься своя модель. Тем самым создаетсямоделей прогнозирования для каждого момента времени. Признаковое описание– история ряда до момента времени, причем признаки одни и те же для каждой модели. Целевая метка– значение. Гибридная стратегия объединяет в себе преимущества рекурсивной и прямой стратегий. Как и в прямой стратегии, создаетсямоделей прогнозирования, но при этом каждая следующая модель использует прогнозы предыдущей подобно тому, как это делает рекурсивная стратегия. Итак, мы должны построить модель для прогноза на 1 шаг вперед; модель для прогноза на 2 шага вперед, используя прогноз уже обученной модели на 1 шаг вперед в качестве признака; модель для прогноза на 3 шага вперед, используя прогноз уже обученных моделей на 1 и 2 шага вперед в качестве признаков; и так далее обучаетсямоделей. Признаковое описание: история ряда до момента времени; предсказание предыдущих моделей для. На картинке показаны признаковые описания для моделей в такой стратегии. Можно задаться вопросом: что лучше брать при обучении моделей для прогноза на несколько шагов вперёд – истинные значения или же предсказания предыдущих моделей. Если брать истинные, то мы можем точнее построить модели прогнозирования, но, с другой стороны, на этапе применения вы будете использовать прогнозы, а они могут иметь другое распределение, чем истинные данные, в частности, могут иметь смещение и большую дисперсию. В таком случае мы получим плохие следующие прогнозы. В реальности очень часто нужно прогнозировать сразу огромное количество временных рядов. Примеры: Предсказание температуры для различных регионов/городов. Предсказания уровня продаж для различных типов товаров (молоко/яблоки/мясо). Проблема: модель на каждый временной ряд – слишком много ресурсов и не масштабируемо; мало моделей – плохие предсказания для каждого ряда по отдельности. Идея: создавать модели не для каждого временного ряда, а для группы временных рядов. Иначе говоря, разделить объекты на категории, и для каждой категории создавать отдельную модель. Для оценка качества моделей прогнозирования временного ряда в основном используются метрики качества регрессии. Средняя квадратичная ошибка Средняя абсолютная ошибка Эти метрики показывают, например, на сколько рублей или на сколько единиц товара мы ошибемся. Также могут использоваться: Средняя абсолютная ошибка в процентах Взвешенная средняя ошибка в процентах. Эти метрики достаточно популярны из-за того, что позволяют оценить качество в относительных величинах без зависимости от шкалы измерений. Стандартные схемы кросс-валидации нельзя применять для временных рядов потому что значения во временных рядах нельзя перемешивать. Существует два способа построить кросс-валидацию на временных рядах. Схема 1. Обучаемся на первыхзначениях временного ряда, прогнозируем следующиезначений ряда. Обучаемся на, прогнозируем. ... Обучаемся на, прогнозируем. На каждой итерации считаем ошибки и усредняем. Схема 2. Обучаемся на первыхзначениях временного ряда, прогнозируем следующиезначений ряда. Обучаемся на, прогнозируем. ... Обучаемся на,~прогнозируем~. Считаем ошибки и усредняем. Эти две схемы отличаются только размером обучающего множества. В первом случае он постоянно растет, во втором – не меняется, а само обучающее множество при этом сдвигается. Ту или иную схему на практике стоит использовать в зависимости от того, какая решается задача. Например, если данных достаточно много и предполагается онлайн работа модели с периодическим дообучением, то обычно при каждом дообучении размер обучающего множества фиксируют. В таком случае имеет смысл воспользоваться второй схемой, чтобы оценить качество модели, обученной именно на таким количестве данных. Если же данных немного, то для обучения желательно использовать все доступные данные. В таком случае имеет смысл использовать первую схему. Обратите внимание, что во всех случаях размер тестового интервала времени фиксирован. Это необходимое условие, потому как распределение значений метрики на разных размерах данных может отличаться. Вспомните, например, про зависимость дисперсии выборочного от размера выборки. Преимущества Свободно используют дополнительную информацию – экзогенные факторы или признаки. Много рядов – много моделей. Нейронная сеть может иметь несколько выходов, и это позволяет прогнозировать сразу несколько рядов одной моделью. Пример: прогнозирование продаж различных товаров. Недостатки Предсказательные интервалы напрямую не строятся. Иногда работают хуже стандартных моделей. Обработка признаков может быть труднее, чем в других моделях, которые мы рассмотрим далее. Интерпретация моделей может вызывать трудности у заказчика.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Временные ряды",
    "url": "https://education.yandex.ru/handbook/ml/article/vremennye-ryady",
    "section_title": "Декомпозиция временных рядов",
    "text": "Декомпозиция – процедура разложения временного ряда на три временных компоненты: Тренд– плавное долгосрочное изменение временного ряда. Сезонность– циклические изменения временного ряда с постоянным периодом сезонности. Ошибка– непрогнозируемая случайная компонента ряда. Можно рассматривать аддитивную декомпозицию, в которой ряд представляется в виде, а также мультипликативную в виде. Нетрудно понять, что для построения мультипликативного разложения достаточно выполнить аддитивную декомпозицию для ряда. Пусть– известный заранее период сезонности. Компоненты разложения вычисляются последовательно по следующим правилам. Тренд Вычисляется с помощью скользящего окна длины:. СезонностьУсреднение значений по сезону после удаления тренда.Вычитаем тренд;Формируютсяподгрупп:;-е значение сезонности вычисляется усреднением по-й группе. Вычитаем тренд; Формируютсяподгрупп:; -е значение сезонности вычисляется усреднением по-й группе. Ошибка. Название метода расшифровывается какSeasonal-Trend decomposition usingLOESS. Является более продвинутой моделю для декомпозиции временного ряда. Напоминание: LOESS – взвешенная линейная регрессия, где вес объекта пропорционален расстоянию от него до точек обучающей выборки. Принцип работы: Инициализация тренда нулем:; В цикле подо сходимости:Вычитаем из ряда текущее значение тренда.Формируютсяподгрупп:.С помощью LOESS в каждой группе в каждый момент времени предсказывается сезонность.Вычитаем из ряда полученную сезонность.С помощью LOESS предсказывается новое значение тренда. Вычитаем из ряда текущее значение тренда. Формируютсяподгрупп:. С помощью LOESS в каждой группе в каждый момент времени предсказывается сезонность. Вычитаем из ряда полученную сезонность. С помощью LOESS предсказывается новое значение тренда. Замечание.Пропущен шаг работы с выбросами. Преимущества STL-декомпозиции: Больше настраиваемых параметров, позволяющих подогнать модель под любые данные. Сезонная компонента может изменяться с течением времени, и это изменение контролируется пользователем. Модель может быть устойчива к выбросам.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Случайность как источник несовершенства модели",
    "text": "Практически любая наша модель — несовершенна. Но объяснять это несовершенство можно по-разному. Представим, что мы решаем задачу регрессии: например, пытаемся по университетским оценкам выпускника предсказать его годовую зарплату. Ясно, что точная зависимость у нас не получится как минимум потому, что мы многого не знаем о выпускнике: куда он пошёл работать, насколько он усерден, как у него с soft skills и так далее. Как же нам быть? Первый вариант — просто признать, что мы не получим идеальную модель, но постараться выучить оптимальную, насколько это возможно. То есть приблизить таргет предсказаниями наилучшим образом с точки зрения какой-то меры близости, которую мы подберём из экспертных соображений. Так мы получаем простой инженерный подход к машинному обучению: есть формула, в которой присутствуют некоторые параметры (), есть формализация того, что такое «приблизить» (функция потерь) — и мы бодро решаем задачу оптимизации по параметрам. Второй вариант — свалить вину за неточности наших предсказаний на случайность. В самом деле: если мы что-то не можем измерить, то для нас это всё равно что случайный фактор. В постановке задачи мы заменяем приближённое равенствона точное Например, это может быть аддитивный шум (чаще всего так и делают): где— некоторая случайная величина, которая представляет этот самый случайный шум. Тогда получается, что для каждого конкретного объектасоответствующий ему истинный таргет — это суммаи конкретной реализации шума. При построении такой модели мы можем выбирать различные распределения шума, кодируя тем самым, какой может быть ошибка. Чаще всего выбирают гауссовский шум:с некоторой фиксированной дисперсией— но могут быть и другие варианты. Проиллюстрируем, как ведут себя данные, подчиняющиеся закону,: Вопрос на подумать. Зачем человеку может прийти в голову предположить, что в модели линейной регрессиишумимеет распределение Лапласа? А распределение Коши? Чем свойства таких моделей будут отличаться от свойств модели с нормальным шумом? Как вы могли заметить, в каждом из подходов после того, как мы зафиксировали признаки (то есть координаты), остаётся своя степень свободы: в инженерном это выбор функции потерь, а в вероятностном — выбор распределения шума. Дальше в этом параграфе мы увидим, что на самом деле эти два подхода глубинным образом связаны между собой, причём выбор функции потерь — это в некотором смысле то же самое, что выбор распределения шума.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Условное распределение на таргет, непрерывный случай",
    "text": "Допустим, что мы исследуем вероятностную модель таргета с аддитивным шумом где— некоторая функция, не обязательно линейная с (неизвестными пока) параметрами, а— случайный шум с плотностью распределения. Для каждого конкретного объектазначение— это просто константа, но дляоно превращается в случайную величину, зависящую от(и ещё от, на самом деле). Таким образом, можно говорить об условном распределении Для каждого конкретногоираспределение соответствующего— это просто, ведь. Пример. Рассмотрим вероятностную модель, где. Тогда для фиксированногоимеем. Поскольку— константа, мы получаем Это можно записать и так: где выражение справа — это значение функции плотности нормального распределения с параметрамив точке. В частности,.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Более сложные вероятностные модели",
    "text": "На самом деле, мы можем для нашей задачи придумывать любую вероятностную модель, не обязательно вида. Представьте, что мы хотим предсказывать точку в плоскости штанг, в которую попадает мячом бьющий по воротам футболист. Можно предположить, что она имеет нормальное распределение со средним (цель удара), которое определяется ситуацией на поле и состянием игрока, и некоторой дисперсией (то есть скалярной ковариационной матрицей), которая тоже зависит от состояния игрока и ещё разных сложных факторов, которые мы объявим случайными. Состояние игрока — это сложное понятие, но, вероятно, мы можем выразить его, зная пульс, давление и другие физические показатели. В свою очередь, ситуацию на поле можно описать, как функцию от позиций и движений других игроков, судьи и зрителей — но всего не перечислишь, поэтому нам снова придётся привлекать случайность. Таким образом, мы получаем то, что называетсяграфической моделью: Здесь стрелки означают статистические зависимости, а отсутствие стрелок — допущение о статистической независимости. Конечно же, это лишь допущение, принятое нами для ограничения сложности модели: ведь пульс человека и давление взаимосвязаны, равно как и поведение различных игроков на поле. Но мы уже обсуждали, что каждая модель, в том числе и вероятностная, является лишь приблизительным отражением бесконечно сложного мира. Впрочем, если у нас много вычислительных ресурсов, то никто не мешает нам попробовать учесть и все пропущенные сейчас зависимости. Расписав всё по определению условной вероятности, мы получаем следующую вероятностную модель: в которой, конечно же, мы должны все вероятности расписать через какие-то понятные и логически обоснованные распределения — но пока воздержимся от этого.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Оценка максимального правдоподобия = оптимизация функции потерь",
    "text": "Мы хотим подобрать такие значения параметров, для которых модельбыла бы наиболее адекватна обучающим данным. Сутьметода максимального правдоподобия(maximum likelihood estimation) состоит в том, чтобы найти такое, для которого вероятность (а в данном, непрерывном, случае плотность вероятности) появления выборкибыла бы максимальной, то есть Величинаназываетсяфункцией правдоподобия(likelihood). Если мы считаем, что все объекты независимы, то функция правдоподобия распадается в произведение: Теперь, поскольку перемножать сложно, а складывать легко (и ещё поскольку мы надеемся, что раз наши объекты всё-таки наблюдаются в природе, их правдоподобие отлично от нуля), мы переходим к логарифму функции правдоподобия: эту функцию мы так или иначе максимизируем по, находя оценку максимального правдоподобия. Как мы уже обсуждали выше,, то есть Максимизация функции правдоподобия соответствует минимизации а это выражение можно интерпретировать, как функцию потерь. Вот и оказывается, что подбор параметров вероятностей модели с помощью метода максимального правдоподобия — это то же самое, что «инженерная» оптимизация функции потерь. Давайте посмотрим, как это выглядит в нескольких простых случаях. Пример. Давайте предположим, что наш таргет связан с данными вот так: где, то есть Случайная величинаполучается из шумасдвигом на постоянный вектор, так что она тоже распределена нормально с той же дисперсиейи со средним Правдоподобие выборки имеет вид Логарифм правдоподобия можно переписать в виде Постоянными слагаемыми можно пренебречь, и тогда оказывается, что максимизация этой величины равносильна минимизации Мы получили обычную квадратичную функцию потерь. Итак, обучать вероятностную модель линейной регрессии с нормальным шумом — это то же самое, что учить «инженерную» модель с функцией потерь MSE. Вопрос на подумать. Какая вероятностная модель соответствует обучению линейной регрессии с функцией потерь MAE",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Предсказание в вероятностных моделях",
    "text": "Теперь представим, что параметры подобраны, и подумаем о том, как же теперь делать предсказания. Рассмотрим модель линейной регрессии Еслиизвестен, то для нового объектасоответствующий таргет имеет вид Таким образом,дан нам не точно, а в виде распределения (и логично: ведь мы оговорились выше, что ответы у нас искажены погрешностью, проинтерпретированной, как нормальный шум). Но что делать, если требуют назвать конкретное число? Кажется логичным выдать условное матожидание, тем более что оно совпадает с условной медианой и условной модой этого распределения. Если же медиана, мода и математическое ожидание различаются, то можно выбрать что-то из них с учётом особенностей задачи. Но на практике в схемечаще всего рассматривают именно симметричные распределения с нулевым матожиданием, потому что для нихсовпадает с условным матожиданиеми является логичным точечным предсказанием. Приведём пример. Допустим шумбыл бы из экспоненциального распределения. Тогдабыла бы условным минимумом распределения. В принципе, можно придумать задачу, для которой такая постановка (предсказание минимума) была бы логичной. Но это всё же довольно экзотическая ситуация. Приводим для сравнения модели с нормальным, лапласовским и экспоненциальным шумом:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Условное распределение на таргет, дискретный случай",
    "text": "Допустим, мы имеем дело с задачей классификации склассами. Как мы можем её решать? Самый наивный вариант — научиться по каждому объектупредсказывать некоторое число для каждого класса, и у кого число больше — тот класс и выбираем! Наверное, так можно сделать, если мы придумаем хорошую функцию потерь. Но сразу в голову приходит мысль: почему бы не начать предсказывать не просто число, а вероятность? Таким образом, задача классификации сводится к предсказанию и как будто бы выбору класса с наибольшей вероятностью. Впрочем, как мы увидим дальше, всё не всегда работает так просто. Одну такую модель — правда, только для бинарной классификации — вы уже знаете. Это логистическая регрессия: которую также можно записать в виде где— распределение Бернулли с параметром. Нахождение вероятностей классов можно разделить на два этапа: где, напомним,— это сигмоида: Сигмоида тут не просто так. Она обладает теми счастливыми свойствами, что монотонно возрастает; отображает всю числовую прямую на интервал; . Вот такой вид имеет её график: Иными словами, с помощью сигмоиды можно делать «вероятности» из чего угодно, то есть более или менее для любого отображения(из признакового пространства в) с параметрамипостроить модель бинарной классификации: Как и в случае логистической регрессии, такая модель равносильна утверждению о том, что Похожим способом можно строить и модели для многоклассовой классификации. В этом нам поможет обобщение сигмоиды, которое называетсяsoftmax: А именно, для любого отображенияиз пространства признаков вмы можем взять модель Если все наши признаки — вещественные числа, а— просто линейное отображение, то мы получаем однослойную нейронную сеть Предостережение. Всё то, что мы описали выше, вполне работает на практике (собственно, классификационные нейросети зачастую так и устроены), но корректным не является. В самом деле, мы говорим, что строим оценки вероятностей, но для подбора параметров используем не эмпирические вероятности, а только лишь значения, то есть метки предсказываемых классов. Таким образом, при обучении мы не будем различать следующие две ситуации: Это говорит нам о некоторой неполноценности такого подхода. Заметим ещё вот что. В случае бинарной классификации выбор предсказываемого класса какравносилен выбору того класса, для которого. Но если наши оценки вероятностей неадекватны, то этот вариант проваливается, и мы встаём перед проблемой выбора порога: каким должно быть значение, чтобы мы могли приписать класс 1 тем объектам, для которых? В одном из следующих параграфов мы обсудим, как всё-таки правильно предсказывать вероятности.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Как оценивать вероятности",
    "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
    "section_title": "Что же такое вероятность класса, если объект либо принадлежит этому классу, либо нет?",
    "text": "Ограничимся пока случаем двухклассовой классификации — с классами 0 и 1. Если утверждается, что мы предсказываем корректную вероятность класса 1 (обозначим её), то прогноз «объектпринадлежит классу 1 с вероятностью» должен сбываться вслучаев. То есть, условно говоря, если мы возьмём все объекты, то среди них что-то около двух третей действительно имеет класс 1. На математическом языке это можно сформулировать так:Если— предсказанная вероятность класса 1, то. К сожалению, в реальной жизни— это скорее всего вещественные числа, которые будут различными для различных, и никаких вероятностей мы не посчитаем, но мы можем разбить отрезокна бины, внутри каждого из которых уже вычислить, каковая там доля объектов класса 1, и сравнить эту долю со средним значением вероятности в бине: У модели, которая идеально предсказывает вероятности (как обычно говорят, у идеальнокалиброванноймодели) жёлтые точки на диаграмме калибровки должны совпадать с розовыми. А вот на картинке выше это не так: жёлтые точки всегда ниже розовых. Давайте поймём, что это значит. Получается, что наша модель систематически завышает предсказанную вероятность (розовые точки), и порог отсечения нам, выходит, тоже надо было бы сдвинуть вправо: Но такая картинка, пожалуй, говорит о какой-то серьёзной патологии классификатора. Гораздо чаще встречаются следующие две ситуации: Слишком уверенный (overconfident) классификатор:Такое случается с сильными классификаторыми (например, нейросетями), которые учились на метки классов, а не на вероятности: тем самым процесс обучения стимулировал их всегда давать ответ, как можно более близкий к 0 или 1. Неуверенный (underconfident) классификатор: Такое может случиться, например, если мы слишком много обращаем внимания на трудные для классификации объекты на границе классов (как, скажем, в SVM), в каком-то смысле в ущерб более однозначно определяемым точкам. Этим же могут и грешить модели на основе бэггинга (например, случайный лес). Грубо говоря, среднее нескольких моделей предскажет что-то близкое к единице только если все слагаемые предскажут что-то, близкое к единице — но из-за дисперсии моделей это будет случаться реже, чем могло бы. Подробнее можно почитать встатье.",
    "source_type": null,
    "useful_links": [
      {
        "text": "статье",
        "url": "https://www.cs.cornell.edu/~alexn/papers/calibration.icml05.crc.rev3.pdf"
      }
    ]
  },
  {
    "document_title": "Как оценивать вероятности",
    "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
    "section_title": "Вам скажут: логистическая регрессия корректно действительно предсказывает вероятности",
    "text": "Вам даже будут приводить какие-то обоснования. Важно понимать, что происходит на самом деле, и не дать ввести себя в заблуждение. В качестве противоядия от иллюзий предлагаем рассмотреть два примера. Рассмотрим датасет c двумя классами (ниже на картинке обучающая выборка) Обучим на нём логистическую регрессию из sklearn безо всяких параметров (то есть-регуляризованную, но это не так важно). Классы не так-то просто разделить, вот и логистическая регрессия так себе справляется. Ниже изображена часть тестовой выборки вместе с предсказанными вероятностями классов для всех точек области Видим, что модель не больно-то уверена в себе, и ясно почему: признаковое описание достаточно бедное и не позволяет нам хорошо разделить классы, хотя, казалось бы, это можно довольно неплохо сделать. Попробуем поправить дело, добавив полиномиальные фичи, то есть вседляв качестве признаков, и обучив поверх этих данных логистическую регрессию. Снова нарисуем некоторые точки тестовой выборки и предсказания вероятностей для всех точек области: Видим, что у нас сочетание двух проблем: неуверенности посередине и очень уверенных ошибок по краям. Нарисуем теперь калибровочные кривые для обеих моделей: Калибровочные кривые весьма примечательны; в любом случае ясно, что с предсказанием вероятностей всё довольно плохо. Посмотрим ещё, какие вероятности наши классификаторы чаще приписывают объектам: Как и следовало ожидать, предсказания слабого классификатора тяготеют к серединке (та самая неуверенность), а среди предсказаний переобученного очень много крайне уверенных — и совсем не всегда правильных.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Как оценивать вероятности",
    "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
    "section_title": "Но почему же все твердят, что логистическая регрессия хорошо калибрована?!",
    "text": "Попробуем понять и простить её. Как мы помним, логистическая регрессия учится путём минимизации функционала Отметим между делом, что каждое слагаемое — это кроссэнтропия распределения, заданного вероятностямии, и тривиального распределения, которое равнос вероятностью. Допустим, что мы обучили по всему универсуму данныхидеальную логистическую регрессию с идеальными весами. Пусть, далее, оказалось, что у нас естьобъектовс одинаковым признаковым описанием (то есть по сути представленных одинаковыми векторами), но, возможно, разными истинными метками классов. Тогда соответствующий им кусок функции потерь имеет вид где— частота-го класса среди истинных меток. В скобках также стоит кросс-энтропия распределения, задаваемого частотой меток истинных классов, и распределения, предсказываемого логистической регрессией. Минимальное значение кросс-энтропии (и минимум функции потерь) достигается, когда Результат, полученный длясовпадающих точек будет приблизительно верным и длядостаточно близких точек в случае, когда: признаковое описание данных достаточно хорошее — классы не перемешаны как попало и всё-таки близки к разделимым; модель не переобученная — то есть, предсказания вероятностей не скачут очень уж резко — вспомните второй пример. На всех этих точках модель будет выдавать примерно долю положительных, то есть тоже хорошую оценку вероятности.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Как оценивать вероятности",
    "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
    "section_title": "Как же всё-таки предсказать вероятности: методы калибровки",
    "text": "Пусть наша модель (бинарной классификации) для каждого объектавыдаёт некоторое число. Как же эти числа превратить в корректные вероятности? Гистограммная калибровка. Мы разбиваем отрезокна бины(одинаковой ширины или равномощные) и хотим на каждом из них предсказывать всегда одну и ту же вероятность:, если. Вероятностиподбираются так, чтобы они как можно лучше приближали средние метки классов на соответствующих бинах. Иными словами, мы решаем задачу Вместо разности модулей можно рассматривать и разность квадратов. Метод довольно простой и понятный, но требует подбора числа бинов и предсказывает лишь дискретное множество вероятностей. Изотоническая регрессия. Этот метод похож на предыдущий, только мы будем, во-первых, настраивать и границыбинов, а кроме того, накладываем условие. Искатьимы будем, приближаякусочно постоянной функциейот: Минимизация осуществляется при помощи pool adjacent violators algorithm, и эти страницы слишком хрупки, чтобы выдержать его формулировку. Калибровка Платтапредставляет собой по сути применение сигмоиды поверх другой модели (то есть самый наивный способ получения «вероятностей»). Более точно, если— предсказанная вероятность, то мы полагаем гдеиподбираются методом максимального правдоподобия на отложенной выборке: Для избежания переобучения Платт предлагал также заменить меткиина регуляризованные вероятности таргетов: Калибровка Платта неплохо справляется с выколачиванием вероятностей из SVM, но для более хитрых классификаторов может спасовать. В целом, можно показать, что этот метод хорошо работает, если для каждого из истинных классов предсказанные вероятностираспределы нормально с одинаковыми дисперсиями. Подробнее об этом вы можете почитать вэтой статье. Там же описано обобщение данного подхода — бета-калибровка. С большим количеством других методов калибровки вы можете познакомиться вэтой статье",
    "source_type": null,
    "useful_links": [
      {
        "text": "этой статье",
        "url": "https://research-information.bris.ac.uk/ws/portalfiles/portal/154625753/Full_text_PDF_final_published_version_.pdf"
      },
      {
        "text": "этой статье",
        "url": "https://dyakonov.org/2020/03/27/%D0%BF%D1%80%D0%BE%D0%B1%D0%BB%D0%B5%D0%BC%D0%B0-%D0%BA%D0%B0%D0%BB%D0%B8%D0%B1%D1%80%D0%BE%D0%B2%D0%BA%D0%B8-%D1%83%D0%B2%D0%B5%D1%80%D0%B5%D0%BD%D0%BD%D0%BE%D1%81%D1%82%D0%B8"
      }
    ]
  },
  {
    "document_title": "Как оценивать вероятности",
    "url": "https://education.yandex.ru/handbook/ml/article/kak-ocenivat-veroyatnosti",
    "section_title": "Как измерить качество калибровки",
    "text": "Калибровочные кривые хорошо показывают, что есть проблемы, но как оценить наши усилия по улучшению предсказания вероятностей? Хочется иметь какую-то численную метрику. Мы упомянем две разновидности — прямое воплощение описанных выше идей. Expected/Maximum calibration error. Самый простой способ, впрочем — он наследник идеи с калибровочной кривой. А именно, разобьём отрезокна биныпо предсказанным вероятностям и вычислим или где— среднее значение, а— среднее значениедля, таких что. Проблема этого способа в том, что мы можем очень по-разному предсказывать в каждом из бинов вероятности (в том числе константой) без ущерба для метрики. Brier score. Одна из популярных метрик, которая попросту измеряет разницу между предсказанными вероятностями и: Казалось бы, в чём смысл? Немного подрастить мотивацию помогает следующий пример. Допустим, наши таргеты совершенно случайны, то есть. Тогда хорошо калиброванный классификатор должен для каждогопредсказывать вероятность; соответственно, его brier score равен. Если же классификатор хоть в одной точке выдаёт вероятность, то в маленькой окрестности он должен выдавать примерно такие же вероятности. Поскольку же таргет случаен, локальный кусочек суммы из brier score будет иметь вид, что хуже, чем получил бы всегда выдающийклассификатор. Не обязательно брать квадратичную ошибку; сгодится и наш любимый log-loss: Это же и помогает высветить ограничения подхода, если вспомнить рассуждения о калиброванности логистической регрессии. Для достаточно гладких классификатора и датасета brier score и log-loss будут адекватными средствами оценки, но если нет — возможно всякое. Вопрос на засыпку: а как быть, если у нас классификация не бинарная, а многоклассовая? Что такое хорошо калиброванный классификатор? Как это определить численно? Как заставить произвольный классификатор предсказывать вероятности? Мы не будем про это рассказывать, но призываем читателя подумать над этим самостоятельно или, например, посмотретьтуториалс ECML KDD 2020.",
    "source_type": null,
    "useful_links": [
      {
        "text": "туториал",
        "url": "https://classifier-calibration.github.io/"
      }
    ]
  },
  {
    "document_title": "Матричная факторизация",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
    "section_title": "Итак, я разложил матрицу в произведения — и что же?",
    "text": "Предположим, что нашу матрицу объекты-признакимы представили в виде произведения (или, более общно, приблизили в каком-либо смысле таким произведением): где внизу указаны размеры матриц (то есть в нашем датасетеобъектов ипризнаков). Что это может означать? Мы считаем, что каждый изпризнаков нашего исходного датасета — это смесь (то есть линейная комбинация)скрытых (латентных) признаков: По сути это одна из самых простых моделей с латентными переменными, в которой исходные признаки выражаются через латентные линейным образом. Если, то мы получаем приближённое описание нашего датасета с помощью меньшего количества признаков. На уровне объектов каждый объект(-мерная строка) приобретаетлатентное представление(-мерная строка), с которой он связан соотношением. Мы можем представлять, что наши объектыпредставляют из себя не-мерное облако, а лежат на некоторой-мерной плоскости; переходя к-мерным представлениям, мы обнажаем эту структуру. Точность аппроксимации можно измерять по-разному; наиболее популярной (в силу вычислительной простоты) является норма Фробениуса— соответствующую модель называютанализом главных компонент, или PCA (Principal Component Analysis). Мы можем захотеть описать наш датасет меньшим чемколичеством признаков (а может быть, и вообще каким-то весьма маленьким). У нас может быть несколько причин для этого, например: Признаков очень много, и мы боимся, что обучение на них будет занимать очень много времени или что в процессе обучения нам потребуется слишком много оперативной памяти; Мы считаем, что в данных есть шум или что часть признаков связаны соотношением приближённой линейной зависимости — иными словами, мы уверены, что значительную часть информации можно закодировать меньшим числом признаков Мы уже обсуждали, что это можно получить, построив приближённое разложение: Математика помогает. Матрица имеет рангтогда и только тогда, когда она представляется в видедляи не представляется в таком виде для меньших. Доказывать это мы не будем, но подметим, чтоприблизить датасет линейной смесьюпризнаков — это то же самое, что приблизить матрицуматрицейранга. Качество приближения.Нам, конечно же, хочется, чтобы приближение было наилучшим — скажем, в том смысле, чтобы разностьбыла минимальной в каком-либо смысле. Можно предложить много разных метрик; остановимся на двух: Норма Фробениуса.Представим, что матрица— это просто вектор изчисел, который зачем-то записали в виде прямоугольной таблицы. Тогда его норму можно записать в видеЭту норму (а точнее, её квадрат) легко оптимизировать. Операторная-норма.Вычислять её тяжко, а уж оптимизировать вообще непонятно как, зато звучит круто. Идея в том, что отображения можно сравнивать в зависимости от того, как оно действует на векторы: чем больше оно умеет удлинять векторы — тем оно «больше»:Поскольку, достаточно брать супремум только по векторам единичной длины, то есть по единичной сфере. Так как это компакт, непрерывная функциядостигает на нём своего максимального значения, то есть мы можем переписать Мы считаем, что каждый изобъектов нашего исходного датасета — смесь (то есть линейная комбинация)скрытых объектов: Такая интерпретация может быть полезна, например, в ситуации, когда объекты — это записи с каждого из нескольких микрофонов в помещении, признаки — фреймы, а скрытые объекты — это голоса отдельных людей. Также данную модель можно интерпретировать как что-то вроде поиска типичных объектов. Эту интерпретацию лучше всего пояснить на примере. Пусть объекты нашего датасета соответствуют пользователям интернет-магазина, а признаки — товарам, причём в клетке с индексомзаписана единица, если пользователь интересовался товаром, и ноль — если нет (или, в более общей ситуации, рейтинги, которые пользователи ставят товарам). При перемножении матрицина-м месте произведении стоит скалярное произведение-й строкии-го столбца. Таким образом, степень релевантности товара пользователю моделируется скалярным произведением (напрашивается сравнение с косинусным расстоянием) вектора, представляющего-го пользователя, и вектора, представляющего-й товар. Заметим ещё, чтокоординат вектора, ответчающего пользователю, равно как икоординат вектора, отвечающего товару, можно рассматривать каклатентных признаков, которые в идеальном мире являются интерпретируемыми и характеризуют «сродство» пользователя и товара с некоторым аспектом бытия: Но матрицы в разложении обычно не абы какие — так какие из разновидностей могут быть полезны? Во всех известных вам матричных разложениях к отдельным сомножителям предъявляются определённые требования: симметричность, треугольность, ортогональность — некоторые из них (скажем, симметричность) не имеют физического смысла ни в одной из указанных выше интерпретаций. Но одно оказывается полезным. Для начала — и это важно —предположим, что матрицацентрирована по столбцам, то есть среднее в каждом из столбцов (= признаков) равно нулю (если это не так, то вычтем из каждого столбца его среднее). Теперь матрица ковариации признаков может быть с точностью до константы оценена как: И мы видим:-й и-й столбцы матрицыортогональны тогда и только тогда, когда соответствующие признаки не коррелированы. При этом-й диагональный элемент матрицы— это дисперсия-го признака. Вывод: матрица, ортонормированная по столбцам, отвечает датасету, в котором признаки не коррелированы и имеют единичную дисперсию",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Матричная факторизация",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
    "section_title": "Сингулярное разложение",
    "text": "С помощью сингулярного разложения можно перейти отисходных признаков к потенциально небольшому количеству «самых важных» , по-быстрому визуализовать данные или построить простенькую рекомендательную систему. Конечно, глубинные автоэнкодеры, TSNE или DSSM справятся с этим гораздо лучше, но если данных относительно немного или если хочется что-нибудь быстро попробовать «на коленке», старое доброе сингулярное разложение всегда подставит плечо. Сингулярным разложениемматрицыназывается разложение гдеи— матрицы, ортонормированные по столбцам, а— диагональная матрица, у которой. Числаназываются, а столбцыи—исингулярными векторами соответственно (их алгебраический смысл станет ясен чуть ниже). Сингулярное разложение можно записать в полном или в усечённом виде: Пара предостережений по поводу ортогональности по столбцам: ортогональна по столбцам (элементы— скалярные произведения столбцов) но(не обязательно равно; элементы— скалярные произведения строк) Ясно, что хранить полное разложение нет смысла: ведь бесполезные, умножающиеся на нули, блоки будут лишь занимать память. По-английски сингулярное разложение называется SVD (singular value decomposition), и мы будем активно использовать эту аббревиатуру. Если вы не любите математику, можете пропустить. С точки зрения математики сингулярное разложение говорит следующее. Пусть— матрица линейного отображения. Тогда найдётся ортонормированый базисв пространствеи ортонормированый базисв пространстве, в которых действие оператора записывается следующим образом: (знатоки функционального анализа могут узнать в этом частный случай теоремы Гильберта-Шмидта). Сингулярное разложение и операторная l2-норма.Можно показать, что, эта самая операторная l2-норма матрицы, равна— квадрату наибольшего сингулярного числа. Сингулярное разложение и норма Фробениуса. Можно показать, что Есть и более тонкие, хотя и весьма частные, ситуации. Можете ли вы, например, указать несколько различных сингулярных разложений матрицы? Да-да, для неё сингулярное разложение максимально неоднозначно. Можете ли вы теперь придумать не скалярную матрицу, у которой были бы различные SVD, отличающиеся не только знаками столбцов матрици? Если(рассмотрим сейчас не усечённое, а полное разложение, в котором матрицыиквадратные ортогональные), то Отметим, что в рассматриваемой ситуациине обязательно квадратная, и поэтому нельзя написать, что; тем не менее,— это квадратная матрица с числамина диагонали. Как бы то ни было, в (ортогональном!) базисе из (ортогональных!) столбцовматрицаприводится к диагональному виду с числамина диагонали. Теперь представим, что наши объектывыбраны из-мерного нормального распределения где— вектор средних, а— матрица ковариации. Это, в частности, значит, что облако точек представляет из себя нечто вроде эллипсоида в-мерном пространстве с центром. Предположим, что(все признаки центрированы); тогда оценкой матрицы ковариации признаков является матрица. Допустим, что эта оценка точная, тогда разложениедаёт нам аналогичное разложение. Теперь замена координат(с матрицей замены— то есть переход происходит в базис из столбцов матрицы) даёт нам Обратите внимание, чтоистоят в формуле на непривычных местах, как будто их перепутали, но нет — простоу нас является строкой, а не столбцом. Итак, если наши данные взяты из многомерного нормального распределения, после перехода к базису из столбцовновые координаты становятся независимыми; вместе с тем это соответствует переходу к главным осям ковариационной матрицы — и геометрически столбцысоответствуют главным осям эллипсоида-облака точек.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Матричная факторизация",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
    "section_title": "Использование SVD: латентные признаки",
    "text": "Запишем и вспомним самую первую интерпретацию матричного разложения. латентные признаки не коррелированы латентные признаки упорядочены по невозрастанию дисперсии Заметим, что перед применением SVD признаки лучше центрировать, иначе первая компонента будет указывать в сторону центра масс облака точек (зачем нам это?), а остальные вынуждены будут ей быть ортогональны: Мы уже обсуждали, что это можно получить, построив приближение рангаили, что то же самое, приближённое разложение для некоторого и желательно небольшого. И тут SVD приходится более чем кстати. Наилучшее по норме Фробениуса приближение ранга— это Таким образом, если вы хотите получить«самых важных» признаков, то вы можете использовать SVD. Но что это за признаки? Что именно означают эти слова «самые важные»? Давайте обратимся к геометрии, которая, как мы помним, тесно связана с теорией вероятностей: Если применить SVD к датасету, изображённому на последней картинке, и взять два первых латентных признака, то эллипсоид превратится в эллипс; меньшая из полуосей, похожая на шум, будет забыта, останется две бOльших. Видим: самое важное для SVD — это самое масштабное. А правда ли у нас получится хорошее приближение с помощьюновых признаков? Посчитаем норму разности. Везде нижеи— квадратные ортогональные матрицы; в частностине обязательно квадратная матрица размера. Аналогичным образом потому что умножение на ортогональную матрицу не меняет операторную-норму. Таким образом, если сингулярные значения убывают достаточно медленно (например, линейно), то мы вряд ли сможем приблизить исходную матрицу матрицей маленького ранга с очень хорошей точностью. Как избавиться от иллюзий.Сгенерируйте матрицус помощьюnp.random.randилиnp.random.randn. Для какоговы сможете найти матрицу ранга, приближающую исходную с относительной точностью? К счастью, в реальных датасетах сингулярные значения убывают достаточно быстро или же нам хватает довольно грубого приближения. Допустим, мы построили приближённое разложение ранга: Матрица— это первыестолбцов матрицы, и они же первыестолбцов матрицы. Таким образом,для перевода объектав новое признаковое пространство нужно произвестии взять первыестолбцов или, что то же самое,. Теперь пусть задана вектор-строкадлины— латентное представление, соответствующего некоторому объекту, то есть одна из строк матрицы. Тогда точно восстановить исходныймы не сможем: ведь равенствоне точное, нодля приближённого восстановлениямы должны произвести.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Матричная факторизация",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
    "section_title": "На что не способно сингулярное разложение",
    "text": "Сингулярное разложение умеет находить дающие самый существенный вклад в дисперсию линейные комбинации признаков, притом некоррелированные; в случае нормально распределённых данных эти направления оказываются главными осями эллипсоида, которым является облако данных. К сожалению, эта суперспособность SVD столь же охотно превращается в слабость, ведь: Данные не всегда распределены нормально, они могут обладать сложной геометрией, но SVD будет упрямо искать эллипсоид. Самое важное не всегда самое масштабное. Забыть привести признаки к одному масштабу — хороший способ выстрелить себе в ногу при работе с сингулярным разложением. Новые признаки не обязаны быть хорошо интерпретируемыми. Линейная комбинация возраста, стажа работы и зарплаты — это не то, что хотелось бы показывать банковскому регулятору. Выбросы почти наверняка усложнят вам жизнь, хотя, возможно, SVD поможет вам их увидеть.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Матричная факторизация",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
    "section_title": "Практические кейсы",
    "text": "Возьмём большой датасет MNIST, состоящий из чёрно-белых изображений рукописных цифр размерапикселей (его можно загрузить, к примеру,отсюда), вытянем каждое из изображений в вектор, получив тем самым матрицу размера, и применим к этой матрице SVD. Теперь возьмём первые два латентных признака (то есть первые два столбца матрицы) — получается, что каждая рукописная цифра у нас теперь кодируется вектором из двух чисел. Нарисуем на плоскости точки, соответствующие этим векторам (скажем, по 100 из каждого класса, чтобы хоть что-нибудь было понятно): Что же мы видим? Единицы и нули оказались особенными, то есть уже первые два латентных признака хорошо их различают, правда, с середине какая-то каша. А почему? Да потому, что мы забыли центрировать данные. Давайте перед применением SVD вычтем из каждого признака (то есть из каждого пикселя) его среднее по всем картинкам, а потом нарисуем всё заново: Теперь стало получше: например, семёрки, девятки и четвёрки сгуппировались вместе с другой стороны от восьмёрок и троек (собственно говоря, это отражает тот факт, что рукописные написания семёрок, девяток и четвёрок могут быть похожи друг на друга, так и человек не сразу отличит — а вот с тройкой их спутать намного труднее). Заметим ещё вот что. В-мерном пространстве наборов пикселей совсем не каждая точка соответствует какой-то рукописной цифре — то, что может приходить из реального мира, лежит на некоторой хитрой поверхности в этом пространстве (если выражаться корректнее, то на подмногообразии). Если же мы попробуем нарисовать «изображения», лежащие на отрезке, соединяющем два изображения цифр, то получим нечто не слишком интересное: Одно изображение просто наложилось и затем сменило другое — скучно! Но если мы сделаем то же самое в двумерном пространстве, образованном первыми двумя латентными признаками SVD, то мы будем получать, может быть, не совсем реалистичные изображения цифр, но что-то явно из мира рукописных символов: Посмотрим на небольшой кусок вотэтого датасета, который доступен для скачивания нигде (ха-ха), и попробуем что-нибудь понять про химических состав рек европейского союза, а заодно соберём шишки, которые могут попасться при визуализации с помощью SVD. Конечно, сразу хочется нарисовать все объекты датасета в виде точек на плоскости. Мы знаем, что в этом может помочь SVD — попробуем же! Центрируем признаки — и рисуем: Ой, что-то пошло не так. Но почему же?! Наверное, надо хотя бы посмотреть на данные... Объекты имеют вид «GBPKER0059», «GB20227», «LVV0120100» и так далее — это коды станций, измеряющих состав воды; Признаки имеют вид «1985 BOD5», «1985 Chlorophyll a», «1985 Orthophosphates» и так далее — тут указан год измерения и показатель; Посмотрев статистики, убеждаемся, что все показатели неотрицательны (то есть уж точно распределены не нормально — но может, и так сработает); при этом почти все элементы нашей матрицы находятся в пределах 1000, но три значения космически огромны, причём в одном столбце «2008 Total oxidised nitrogen» (а строки соответствуют каким-то греческим станциям, с которыми вообще всё странно), и ещё одно тоже очень большое («2005 Total organic carbon (TOC)») — вот они-то и дали нам четыре точки на графике, отличных от начала координат.Кстати говоря, если космически большие значения, по-видимому, являются результатам поломки, то по поводу четвёртого, не столь злостного, выброса есть подозрение, что это реальные значения. Посмотрев в данные, мы видим, что показатель был измерен на станции Zidlochovice, на реке Srvatka ниже Брно — а, как говорит нам википедия:As a result of water pollution by communal sewage, the reservoir suffered from an extensive amount of cyanobacteria for a long time. Так или иначе, все четыре станции мы уберём, чтобы они не портили нам SVD. Один из признаков «2002 Kjeldahl Nitrogen» принимает только нулевые значения. Уберём его, чтобы не мешался. Почистив выбросы в исходных данных, опять центрируем и рисуем: Уже лучше. Попробуем понять, что за вещества внесли вклад в первые два латентных признака. Как это сделать? Латентные признаки — это столбцы матрицы; линейная алгебра говорит нам, что-й столбец произведения— это линейная комбинация столбцовс коэффициентами из-го столбца. Находим номера самых больших по модулю координат— и оказывается, что первые два латентных признака складываются почти сплошь из насыщения воды кислородом, только за разные годы (первый за более старые, второй за чуть более свежие): First latent feature Second latent feature Неужели насыщение кислородом действительно так важно? Нет, просто мы не отмасштабировали признаки. Оказывается, что насыщение кислородом имеет на порядок больший масштаб, чем многое другое, и потому забивает все остальные признаки. Тем не менее, мы можем попробовать сделать вывод и из имеющейся картинки. По оси \"у\" что-то не очень интересное, а по оси \"х\" видим большой кластер (напомним, это меньшие значения насыщения воды кислородом в начале 2000-х), содержащий, если проверить, примерно три четверти всех точек, и ещё некоторой размазанный шлейф. Итак, на многих станциях насыщение воды кислородом в начале 2000-х было примерно в одинаковой степени мало — проверив глазами, обнаруживаем, что там просто нули. Поскольку вряд ли это так на самом деле, видимо, стоит сделать вывод, что в первой половине 2000-х насыщение кислородом измерялось из рук вон плохо. Теперь вдобавок к центрированию поделим каждый признак на его стандартное отклонение и снова нарисуем: Опять видим тесный кластер. При этом первый латентный признак складывается в основном из «Nitrate» , «pH» и «Dissolved oxygen» за разные годы, все с положительными коэффициентами, а второй — из «Total ammonium», «Total phosphorus» и «Kjeldahl Nitrogen» за разные годы, причём с отрицательными коэффициентами. В частности, справа у нас точки с высоким содержанием нитратов и высокой кислотностью. Среди этих точек: Река Тейм, про которую Википедия пишет:The Tame was once one of Britain's dirtiest rivers. Река Кёрёш, про которую тоже можно найти вот такую информацию:For some time the municipal government of Kanjiža (to which the mouth of the river belongs) protests about the extreme pollution of the Kereš's water, as it represents the single largest polluter of the Tisa river Темза (станция немного выше Лондона). Что ещё можно было бы сделать? Например, мы можем посмотреть распределения признаков и увидеть, что многие из них далеки от нормальных и в целом выиграли бы от логарифмирования — тогда, возможно, итоговая картинка стала бы красноречивей.",
    "source_type": null,
    "useful_links": [
      {
        "text": "отсюда",
        "url": "https://ru-keras.com/datasets"
      },
      {
        "text": "этого датасета",
        "url": "https://data.europa.eu/euodp/en/data/dataset/data_waterbase-rivers-10"
      },
      {
        "text": "Река Тейм",
        "url": "https://en.wikipedia.org/wiki/River_Tame,_West_Midlands"
      }
    ]
  },
  {
    "document_title": "Матричная факторизация",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
    "section_title": "Использование SVD: разделённые представления и рекомендательная система для бедных",
    "text": "Мы уже обсуждали, что, вообще говоря, любое матричное разложение можно с той или иной степенью успеха использовать для построения рекомендательной системы. Основанные на этом модели называютсямоделями латентных факторов(Latent factor models). В 2006 году SVD-подобный алгоритм даже помог Саймону Фанку (Simon Funk; под этим псевдонимом скрывался Brandyn Webb) занять высокое место на соревновании Netflix Prize. Вернёмся к примеру из пункта 1.3. Пусть вновь объекты нашего датасета соответствуют пользователям интернет-магазина, а признаки — товарам, причём в клетке с индексомзаписаны рейтинги, которые пользователи ставят товарам. На основе этих данных мы хотим порекомендовать некоторому-му пользователюочередных товаров. Если бы нам были известныдля всех индексов товаров, задача не стоила бы выеденного яйца: мы бы просто взялитоваров с максимальными значениями рейтингов. Более того, мы могли бы с помощью матричного разложения построить модель и надеяться, что координаты латентных представлений пользователей и товаров окажутся интерпретируемыми (нет). А именно, если бы мы знали все, построить отдельные представления для пользователей и для товаров некоторой (подбираемой; это гиперпараметр модели) длинымы могли бы с помощью SVD и приближения из теоремы Эккарта-Янга: Но на деле матрицаобычно разреженная: в ней лишь сравнительно немного известных рейтингов, а в остальных ячейках стоят пропуски. Что же делать? Наивный вариант — заменить все пропуски нулями (то есть положить, что если пользователь не ставил рейтинг товару, то он ему вдребезги не интересен, что не всегда правдоподобно) или средними по строке/столбцу, после чего сделать SVD и радоваться жизни. В этой ситуации наша приближённая модель предсказывает рейтинг, выставленный-м пользователем-му товару, как скалярное произведение представлений пользователя и товара — то есть-й строки матрицыи-го столбца матрицы Теперьчтобы порекомендовать n-му пользователю k очередных товаров, мы просто берём n-ю строку матрицыи находим номера её наибольших элементов. К сожалению, у этого метода есть как минимум две проблемы: Пропусков обычно очень много; если их все заменить какими попало значениями, оценка будет очень шумной; При таком подходе нет простого способа обновить рекомендации при добавлении новых данных — SVD придётся переучивать заново. К счастью, есть и другой путь. Давайте подумаем: чего вообще мы требуем от матрици? По сути нам нужны две вещи: ; Обе матрицы ортогональны по столбцам. Последнее можно опустить. Ясной пользы для рекомендательной системы от этого нет; да, это давало бы нам некоррелированность латентных признаков, но мы уже видели, что интерпретируемости это не влечёт. Первое же условие удобно сформулировать в терминах векторов латентных представлений пользователей (обозначим их; это строки) и товаров (обозначим их— это строки). А именно, нам нужно, чтобыскалярное произведениебыло как можно ближе кдля всех пар, для которыхнам известно. Вот именно! Мы можем просто не обращать внимания на неизвестные значения, оптимизируя только по тем клеткам, для которых нам что-то известно: Но как решить эту оптимизационную задачу? Разумеется, с помощью стохастического градиентного спуска. В базовом варианте мы случайным образом перебираем пары, для которыхнам известно, и обновляем координаты векторовиследующим образом: где— гиперпараметр, отвечающий за темп обучения. Приятное свойство такого подхода: в нём легко добавлять новые товары/пользователей (дообучаем их векторы, заморозив остальные), а также новые оценки(добавляем в оптимизируемый функционал и проводим дооптимизацию). Отметим, что в ходе оптимизации мы попеременно осуществляем градиентный спуск, обновляя то, то. Эту идею можно развить следующим образом. Заметим, что при фиксированной матрицезадача минимизации повыражения превращается по сути в обычный метод наименьших квадратов, для которого можно даже выписать «точное» решение (а вы можете это сделать?). Точно так же и при фиксированномлегко находится минимум по. Чередуя эти два шага, мы будем сходиться к решению быстрее и надёжнее, чем с помощью SGD. Данный алгоритм носит названиеAlternating Least Squares (ALS). Можно ввести много дополнительных эвристик и предположений, которые уведут нас совсем далеко от старого доброго SVD. Например: Рейтинг не всегда является продуктом чистого взаимодействия пользователя с товаром. Бывают товары, которые сами по себе ужасно популярны (скажем, человек купит туалетную бумагу даже если не очень интересуется товарами для дома) или так ужасны, что даже интересующийся данной «латентной категорией» покупатель не станет их высоко оценивать. Это можно промоделировать, добавив к скалярному произведению члены, зависящие только от пользователя и только от товара соответственно: Тогда наша задача оптимизации примет вид: Можно добавлять регуляризационные члены. Например: Мы можем не игнорировать неизвестные нам элементы матрицы, а присвоить им нулевые значения и ставить более низкие веса соответствующим слагаемым функции потерь: гдемаленькое, если, и большое в противном случае. Это имеет смысл, например, если отсутствие данных в самом деле может быть логично интерпретировать, как отсутствие интереса. Можно ввести требования неотрицательности:,. Подробнее об этом в параграфе про неотрицательное матричное разложение. Или даже всё это вместе 😄",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Матричная факторизация",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
    "section_title": "Вероятностное обличье модели латентных факторов",
    "text": "Вы могли заметить, что задача подозрительно напоминает задачу наименьших квадратов, и неспроста. В базовой формулировке мы предполагаем, что Иными словами, По крайней мере, те из них, которые нам известны. Нахождениеиметодом максимального правдоподобия как раз и приводит к описанной выше оптимизационной задаче. Как обычно, мы можем добавить априорную информацию о распределении латентных векторови. Например, такую: Расписывая логарифм правдоподобия и убирая константные члены, которые содержат только сигмы, приводим задачу максимизации логарифма правдоподобия к виду вполне объясняющему, почему в предыдущем пункте у нас могла появляться L2-регуляризация.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Матричная факторизация",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
    "section_title": "Анализ независимых компонент (ICA)",
    "text": "ICA изначально был придуман для задачи разделения сигналов («blind source separation»). Рассмотримпример из sklearn Изначально были три сигнала (красный, рыжий и синий на второй сверху картинке), их смешали, получив три линейных комбинации (на верхней картинке). Теперь попробуем их разделить. Первая мысль, которая нам приходит в голову: воспользуемся SVD (проинтерпретировав моменты времени как объекты, а сигналы из смеси как признаки — то есть взяв матрицу)! Но на нижней картинке мы видим результат, который не радует, но не радует ожидаемо, и вот почему: В первый латентный признак SVD старается собрать максимально возможную дисперсию — мы видим, что красный график на нижней картинке действительно ловит самые значительные колебания сигналов из смеси; при этом в третий (рыжий) сигнал уже попадает более или менее случайный шум. Если посмотреть на значения исходных сигналов, то они распределены не нормально (распределения значений синего и красного имеют две моды, а у рыжего близко к равномерному), а мы помним, что SVD плохо приспособлено к работе с не гауссовскими данными. Анализ независимых компонент (ICA)состоит в аппроксимациинаблюдаемых признаков линейной смесью латентных, которые являютсянезависимымикак случайные величины. Замечание. Оригинальная формулировка несколько другая: изначально ICA — это аппроксимация наблюдаемых сигналов линейной смесью некоторого числа независимых сигналов, то есть речь шла о смеси объектов. Описываемые далее методы можно точно также использовать и для разделения смеси объектов, конечно. Важно, что в данном случае предъявляется требованиенезависимости, а не простонекоррелированности— более сильное, впрочем, труднодостижимое и столь же трудно проверяемое. Мы будем излагать алгоритм FastICA постатье его создателей, она же реализована в библиотеке sklearn; в статье вас ждёт гораздо больше подробностей и тонкостей реализации. Алгоритм базируется на следующем эвристическом соображении:линейная комбинация нескольких независимых негауссовских величин в большей степени гауссовская, чем сами эти величины— довольно смелый вывод из Центральной предельной теоремы. Таким образом, мы будем искатьлинейную комбинацию исходных признаков, которая была бы в наименьшей степени гауссовской— это и будет первая из независимых компонент. Но как померить близость к нормальности? Пусть— некоторая (одномерная) случайная величина с плотностью. Рассмотрим её энтропию Имеет место теорема:гауссовская случайная величина имеет максимальную энтропию среди всех случайных величин с заданной дисперсией. Рассмотрим теперь где— гауссовская случайная величина с той же дисперсией, что и у. Величинавсегда неотрицательна и равна нулю в том случае, еслигауссовская. Решая задачу мы могли бы найти самую негауссовскую линейную комбинацию наших признаков. Проблема в том, чтотрудно посчитать. Авторы статьи предлагают использовать приближение где, анеквадратичная функция (в статье предлагаются конкретные варианты). Последующие независимые компоненты можно искать в ортогональном подпространстве (всё-таки они должны быть и некоррелированными). Перед тем, как строить разложение нужно центрировать данные (вычесть из признаков их средние) и убедиться, что ковариационная матрица признаков является единичной.",
    "source_type": null,
    "useful_links": [
      {
        "text": "пример из sklearn",
        "url": "https://scikit-learn.org/stable/auto_examples/decomposition/plot_ica_blind_source_separation.html#sphx-glr-auto-examples-decomposition-plot-ica-blind-source-separation-py"
      },
      {
        "text": "статье его создателей",
        "url": "https://www.cs.helsinki.fi/u/ahyvarin/papers/TNN99new.pdf"
      }
    ]
  },
  {
    "document_title": "Матричная факторизация",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya",
    "section_title": "Неотрицательное матричное разложение (NMF)",
    "text": "Допустим, что у нас есть датасет, в котором объекты — тексты, признаки — токены (например, слова), а на-м месте написана частота встречаемости-го токена в-м тексте (то есть, где— сколько раз-й токен встретился в-м документе, а— общее число токенов в этом документе). Приблизим нашу матрицу произведением Одна из возможных интерпретаций такова. Естьтем: За этим стоит вполне ясная вероятностная модель: Вопрос в том, как получить такое разложение. Конечно, чисто технически можно использовать SVD. Но тогда элементы матриц разложения вряд ли будут иметь вероятностный смысл: они же даже не обязаны быть неотрицательными. С другой стороны, если потребовать, чтобы все элементыибыли неотрицательными, ситуация исправится. Неотрицательное матричное разложениенеотрицательной матрицы— это произведениематриц с неотрицательным элементами, наилучшим образом приближающеепо норме Фробениуса ALS — один из популярных методов для решения факторизационных задач. Несмотря на то, что оптимизационная задача в целом не является выпуклой, по отдельности задача поиска каждого из сомножителей является выпуклой и может решаться с помощью привычных нам методов. Таким образом, мы можем чередовать поискпри фиксированноми поискпри фиксированном, итеративно сходясь к итоговому решению: Заметим, что из-за насильного обнуления элементов будут получаться разреженные матрицы. Разумеется, можно рассматривать и более сложные функционалы, прибавляя кразличные регуляризационные члены, скажем, поощряющие большую разреженность матрици.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Случайность как источник несовершенства модели",
    "text": "Практически любая наша модель — несовершенна. Но объяснять это несовершенство можно по-разному. Представим, что мы решаем задачу регрессии: например, пытаемся по университетским оценкам выпускника предсказать его годовую зарплату. Ясно, что точная зависимость у нас не получится как минимум потому, что мы многого не знаем о выпускнике: куда он пошёл работать, насколько он усерден, как у него с soft skills и так далее. Как же нам быть? Первый вариант — просто признать, что мы не получим идеальную модель, но постараться выучить оптимальную, насколько это возможно. То есть приблизить таргет предсказаниями наилучшим образом с точки зрения какой-то меры близости, которую мы подберём из экспертных соображений. Так мы получаем простой инженерный подход к машинному обучению: есть формула, в которой присутствуют некоторые параметры (), есть формализация того, что такое «приблизить» (функция потерь) — и мы бодро решаем задачу оптимизации по параметрам. Второй вариант — свалить вину за неточности наших предсказаний на случайность. В самом деле: если мы что-то не можем измерить, то для нас это всё равно что случайный фактор. В постановке задачи мы заменяем приближённое равенствона точное Например, это может быть аддитивный шум (чаще всего так и делают): где— некоторая случайная величина, которая представляет этот самый случайный шум. Тогда получается, что для каждого конкретного объектасоответствующий ему истинный таргет — это суммаи конкретной реализации шума. При построении такой модели мы можем выбирать различные распределения шума, кодируя тем самым, какой может быть ошибка. Чаще всего выбирают гауссовский шум:с некоторой фиксированной дисперсией— но могут быть и другие варианты. Проиллюстрируем, как ведут себя данные, подчиняющиеся закону,: Вопрос на подумать. Зачем человеку может прийти в голову предположить, что в модели линейной регрессиишумимеет распределение Лапласа? А распределение Коши? Чем свойства таких моделей будут отличаться от свойств модели с нормальным шумом? Как вы могли заметить, в каждом из подходов после того, как мы зафиксировали признаки (то есть координаты), остаётся своя степень свободы: в инженерном это выбор функции потерь, а в вероятностном — выбор распределения шума. Дальше в этом параграфе мы увидим, что на самом деле эти два подхода глубинным образом связаны между собой, причём выбор функции потерь — это в некотором смысле то же самое, что выбор распределения шума.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Условное распределение на таргет, непрерывный случай",
    "text": "Допустим, что мы исследуем вероятностную модель таргета с аддитивным шумом где— некоторая функция, не обязательно линейная с (неизвестными пока) параметрами, а— случайный шум с плотностью распределения. Для каждого конкретного объектазначение— это просто константа, но дляоно превращается в случайную величину, зависящую от(и ещё от, на самом деле). Таким образом, можно говорить об условном распределении Для каждого конкретногоираспределение соответствующего— это просто, ведь. Пример. Рассмотрим вероятностную модель, где. Тогда для фиксированногоимеем. Поскольку— константа, мы получаем Это можно записать и так: где выражение справа — это значение функции плотности нормального распределения с параметрамив точке. В частности,.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Более сложные вероятностные модели",
    "text": "На самом деле, мы можем для нашей задачи придумывать любую вероятностную модель, не обязательно вида. Представьте, что мы хотим предсказывать точку в плоскости штанг, в которую попадает мячом бьющий по воротам футболист. Можно предположить, что она имеет нормальное распределение со средним (цель удара), которое определяется ситуацией на поле и состянием игрока, и некоторой дисперсией (то есть скалярной ковариационной матрицей), которая тоже зависит от состояния игрока и ещё разных сложных факторов, которые мы объявим случайными. Состояние игрока — это сложное понятие, но, вероятно, мы можем выразить его, зная пульс, давление и другие физические показатели. В свою очередь, ситуацию на поле можно описать, как функцию от позиций и движений других игроков, судьи и зрителей — но всего не перечислишь, поэтому нам снова придётся привлекать случайность. Таким образом, мы получаем то, что называетсяграфической моделью: Здесь стрелки означают статистические зависимости, а отсутствие стрелок — допущение о статистической независимости. Конечно же, это лишь допущение, принятое нами для ограничения сложности модели: ведь пульс человека и давление взаимосвязаны, равно как и поведение различных игроков на поле. Но мы уже обсуждали, что каждая модель, в том числе и вероятностная, является лишь приблизительным отражением бесконечно сложного мира. Впрочем, если у нас много вычислительных ресурсов, то никто не мешает нам попробовать учесть и все пропущенные сейчас зависимости. Расписав всё по определению условной вероятности, мы получаем следующую вероятностную модель: в которой, конечно же, мы должны все вероятности расписать через какие-то понятные и логически обоснованные распределения — но пока воздержимся от этого.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Оценка максимального правдоподобия = оптимизация функции потерь",
    "text": "Мы хотим подобрать такие значения параметров, для которых модельбыла бы наиболее адекватна обучающим данным. Сутьметода максимального правдоподобия(maximum likelihood estimation) состоит в том, чтобы найти такое, для которого вероятность (а в данном, непрерывном, случае плотность вероятности) появления выборкибыла бы максимальной, то есть Величинаназываетсяфункцией правдоподобия(likelihood). Если мы считаем, что все объекты независимы, то функция правдоподобия распадается в произведение: Теперь, поскольку перемножать сложно, а складывать легко (и ещё поскольку мы надеемся, что раз наши объекты всё-таки наблюдаются в природе, их правдоподобие отлично от нуля), мы переходим к логарифму функции правдоподобия: эту функцию мы так или иначе максимизируем по, находя оценку максимального правдоподобия. Как мы уже обсуждали выше,, то есть Максимизация функции правдоподобия соответствует минимизации а это выражение можно интерпретировать, как функцию потерь. Вот и оказывается, что подбор параметров вероятностей модели с помощью метода максимального правдоподобия — это то же самое, что «инженерная» оптимизация функции потерь. Давайте посмотрим, как это выглядит в нескольких простых случаях. Пример. Давайте предположим, что наш таргет связан с данными вот так: где, то есть Случайная величинаполучается из шумасдвигом на постоянный вектор, так что она тоже распределена нормально с той же дисперсиейи со средним Правдоподобие выборки имеет вид Логарифм правдоподобия можно переписать в виде Постоянными слагаемыми можно пренебречь, и тогда оказывается, что максимизация этой величины равносильна минимизации Мы получили обычную квадратичную функцию потерь. Итак, обучать вероятностную модель линейной регрессии с нормальным шумом — это то же самое, что учить «инженерную» модель с функцией потерь MSE. Вопрос на подумать. Какая вероятностная модель соответствует обучению линейной регрессии с функцией потерь MAE",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Предсказание в вероятностных моделях",
    "text": "Теперь представим, что параметры подобраны, и подумаем о том, как же теперь делать предсказания. Рассмотрим модель линейной регрессии Еслиизвестен, то для нового объектасоответствующий таргет имеет вид Таким образом,дан нам не точно, а в виде распределения (и логично: ведь мы оговорились выше, что ответы у нас искажены погрешностью, проинтерпретированной, как нормальный шум). Но что делать, если требуют назвать конкретное число? Кажется логичным выдать условное матожидание, тем более что оно совпадает с условной медианой и условной модой этого распределения. Если же медиана, мода и математическое ожидание различаются, то можно выбрать что-то из них с учётом особенностей задачи. Но на практике в схемечаще всего рассматривают именно симметричные распределения с нулевым матожиданием, потому что для нихсовпадает с условным матожиданиеми является логичным точечным предсказанием. Приведём пример. Допустим шумбыл бы из экспоненциального распределения. Тогдабыла бы условным минимумом распределения. В принципе, можно придумать задачу, для которой такая постановка (предсказание минимума) была бы логичной. Но это всё же довольно экзотическая ситуация. Приводим для сравнения модели с нормальным, лапласовским и экспоненциальным шумом:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Вероятностный подход в ML",
    "url": "https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml",
    "section_title": "Условное распределение на таргет, дискретный случай",
    "text": "Допустим, мы имеем дело с задачей классификации склассами. Как мы можем её решать? Самый наивный вариант — научиться по каждому объектупредсказывать некоторое число для каждого класса, и у кого число больше — тот класс и выбираем! Наверное, так можно сделать, если мы придумаем хорошую функцию потерь. Но сразу в голову приходит мысль: почему бы не начать предсказывать не просто число, а вероятность? Таким образом, задача классификации сводится к предсказанию и как будто бы выбору класса с наибольшей вероятностью. Впрочем, как мы увидим дальше, всё не всегда работает так просто. Одну такую модель — правда, только для бинарной классификации — вы уже знаете. Это логистическая регрессия: которую также можно записать в виде где— распределение Бернулли с параметром. Нахождение вероятностей классов можно разделить на два этапа: где, напомним,— это сигмоида: Сигмоида тут не просто так. Она обладает теми счастливыми свойствами, что монотонно возрастает; отображает всю числовую прямую на интервал; . Вот такой вид имеет её график: Иными словами, с помощью сигмоиды можно делать «вероятности» из чего угодно, то есть более или менее для любого отображения(из признакового пространства в) с параметрамипостроить модель бинарной классификации: Как и в случае логистической регрессии, такая модель равносильна утверждению о том, что Похожим способом можно строить и модели для многоклассовой классификации. В этом нам поможет обобщение сигмоиды, которое называетсяsoftmax: А именно, для любого отображенияиз пространства признаков вмы можем взять модель Если все наши признаки — вещественные числа, а— просто линейное отображение, то мы получаем однослойную нейронную сеть Предостережение. Всё то, что мы описали выше, вполне работает на практике (собственно, классификационные нейросети зачастую так и устроены), но корректным не является. В самом деле, мы говорим, что строим оценки вероятностей, но для подбора параметров используем не эмпирические вероятности, а только лишь значения, то есть метки предсказываемых классов. Таким образом, при обучении мы не будем различать следующие две ситуации: Это говорит нам о некоторой неполноценности такого подхода. Заметим ещё вот что. В случае бинарной классификации выбор предсказываемого класса какравносилен выбору того класса, для которого. Но если наши оценки вероятностей неадекватны, то этот вариант проваливается, и мы встаём перед проблемой выбора порога: каким должно быть значение, чтобы мы могли приписать класс 1 тем объектам, для которых? В одном из следующих параграфов мы обсудим, как всё-таки правильно предсказывать вероятности.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Трансформеры",
    "url": "https://education.yandex.ru/handbook/ml/article/transformery",
    "section_title": "Зачем нам внимание",
    "text": "Для начала вспомним, что основным подходом для работы с последовательностями до 2017 года (выхода оригинальной статьи про архитектуру «трансформер») было использование рекуррентных нейронных сетей, или RNN. Однако у такого подхода есть несколько известных минусов: Во-первых, RNN содержат всю информацию о последовательности в скрытом состоянии, которое обновляется с каждым шагом. Если модели необходимо «вспомнить» что-то, что было сотни шагов назад, то эту информацию необходимо хранить внутри скрытого состояния и не заменять чем-то новым. Следовательно, придется иметь либо очень большое скрытое состояние, либо мириться с потерей информации. Во-вторых, обучение рекуррентных сетей сложно распараллелить: чтобы получить скрытое состояние RNN-слоя для шага, вам необходимо вычислить состояние для шага. Таким образом, обработка батча примеров длинойдолжна потребоватьпоследовательных операций, что занимает много времени и не очень эффективно работает на GPU, созданных для параллельных вычислений. Обе этих проблемы затрудняют применение RNN к по-настоящему длинным последовательностям: даже если вы дождетесь конца обучения, ваша модель по своей конструкции будет так или иначе терять информацию о том, что было в начале текста. Хочется иметь способ «читать» последовательность так, чтобы в каждый момент времени можно было обратиться к произвольному моменту из прошлого за константное время и без потерь информации. Таким способом и является лежащий в основе трансформеров механизм self-attention, о котором далее пойдет речь. Как мы узнаем позже, благодаря своей универсальности и масштабируемости этот механизм оказался применим к множеству задач помимо обработки естественного языка. Ниже приведено устройство архитектуры «трансформер» из оригинальнойстатьи: Слева на схеме представлено устройство энкодера. Он по очереди применяется к исходной последовательности изблоков: Каждый блок выдаёт последовательность такой же длины. В нём есть два важных слоя, multi-head attention и feed-forward. После каждого из них к выходу прибавляется вход (это стандартный подход под названием residual connection) и затем активации проходят через слой layer normalization: на рисунке эта часть обозначена как “Add &Norm”. У декодера схема похожая, но внутри каждого изблоков два слоя multi-head attention, в одном из которых используются выходы энкодера. Давайте подробнее обсудим каждую из составляющих частей этого механизма.",
    "source_type": null,
    "useful_links": [
      {
        "text": "статьи",
        "url": "https://arxiv.org/pdf/1706.03762.pdf"
      }
    ]
  },
  {
    "document_title": "Трансформеры",
    "url": "https://education.yandex.ru/handbook/ml/article/transformery",
    "section_title": "Слой внимания",
    "text": "Первая часть transformer-блока — это слой self-attention. От обычного внимания его отличает то, что выходом являются новые представления для элементов той же последовательности, что мы подали на вход, причем каждый элемент этой последовательности напрямую взаимодействует с каждым. Если говорить более подробно, то в вычислении внимания для последовательности будет участвовать три обучаемых матрицы. Представлениекаждого элемента входной последовательности мы умножаем на, получая вектор-строки(— номер элемента), которые соответственно называютсязапросами,ключамиизначениями(query, key и value). Их роли можно условно описать следующим образом: — запрос к базе данных; — ключи хранящихся в базе значений, по которым будет осуществляться поиск; — сами значения. Близость запроса к ключу можно определять, например, с помощью скалярного произведения: где— некоторая нормировочная константа. Именно так и делали в исходной статье; в качестве нормировочной константы брался кореньиз размерности ключей и значений. Теперь мы складываем значенияс полученными коэффициентами. Это и будет выходом слоя self-attention. В векторизованном виде можно записать: где,,— матрицы запросов, ключей и значений соответственно, в которых по строкам записаны,,, аберётся построчно. Как мы уже упоминали выше, в декодере один из attention-слоёв является слоем кросс-внимания (cross-attention), в котором запросы берутся из выходной последовательности, а ключи и значения — из входной (то есть из результатов работы энкодера). Также стоит учитывать, что в описанном выше виде внимания каждый токен будет «смотреть» на всю последовательность, что нежелательно для декодера. Действительно, на этапе генерации мы будем порождать по одному токену за шаг, и доступ к последующим шагам на этапе обучения приведёт к утечке информации в декодере и низкому качеству модели. Чтобы избежать этой проблемы, при обучении к вниманию нужно применять авторегрессивную маску, вручную обращая ввеса до softmax для токенов из будущего, чтобы после softmax их вероятности стали нулевыми. Как можно увидеть на рисунке внизу, эта маска имеет нижнетреугольный вид. Один набор,иможет отражать только один вид зависимостей между токенами, и матрицы извлекают лишь ограниченный набор информации из входных представлений. Чтобы скомпенсировать эту неоптимальность, авторы архитектуры предложили подход с несколькими «головами» внимания (multi-head attention): по сути вместо одного слоя внимания мы применяем несколько параллельных с разными весами, а потом агрегируем результаты. Рисунок ниже показывает, как выглядит multi-head attention: Подход к обработке последовательностей целиком через внимание позволяет избавиться от такого понятия, как скрытое состояние, обновляющееся рекуррентно: каждый токен может напрямую «прочитать» любую часть последовательности, наиболее полезную для предсказания. В частности, отсутствие рекуррентности означает, что мы можем применять слой ко всей последовательности одновременно, так как матричные умножения прекрасно параллелятся. Однако стоит помнить о затратах памяти и времени: поскольку каждый элемент последовательности взаимодействует с каждым, легко показать, что сложность self-attention составляетпо длине последовательности, а простые реализации, формирующие полную матрицу внимания, будут расходовать ещё ипамяти. С оптимизацией вычислительной сложности внимания связано множество работ как инженерного, так и архитектурного плана: в частности, есть подходы, которые позволяют сократить время работы self-attention до линейного или существенно уменьшают константы за счёт учёта иерархии памяти GPU. Например, на графиках ниже сравнивается время работы и потребление памяти трансформера со стандартным вниманием и с механизмом изстатьиLongformer:",
    "source_type": null,
    "useful_links": [
      {
        "text": "статьи",
        "url": "https://arxiv.org/abs/2004.05150"
      }
    ]
  },
  {
    "document_title": "Трансформеры",
    "url": "https://education.yandex.ru/handbook/ml/article/transformery",
    "section_title": "Полносвязный слой и нормализация",
    "text": "Вторая часть трансформерного блока называется feed-forward network (FFN) и представляет собой два обычных полносвязных слоя, применяемых независимо к каждому элементу входной последовательности. В последних архитектурах размер промежуточного представления (то есть выхода первого слоя) бывает весьма большим — в 4 раза больше выходов блока. Из-за этого вычислительной стоимостью FFN не стоит пренебрегать: несмотря на квадратичную асимптотику внимания, в больших моделях или на коротких последовательностях FFN может занимать существенно больше времени по сравнению с self-attention. В виде формулы применение FFN можно представить так: Промежуточные активациив FFN бывают разными: начиналось всё с широко известной ReLU, но в какой-то момент сообщество перешло наGELU (Gaussian Error Linear Unit)с формулой, где— функция распределения стандартной нормальной случайной величины. Скажем ещё пару слов о layer normalization: как было показано врядеработ, их положение внутри residual-ветки довольно важно. В стандартной архитектуре используется формулировка PostLN, где нормализация применяется после остаточной связи. Однако такое применение нормализации оказывается довольно нестабильным при обучении моделей с большим числом слоёв: вместо этого предлагается использовать PreLN (справа на рисунке снизу), где нормализация применяется ко входу residual-ветки.",
    "source_type": null,
    "useful_links": [
      {
        "text": "GELU (Gaussian Error Linear Unit)",
        "url": "https://arxiv.org/abs/1606.08415v4"
      },
      {
        "text": "ряде",
        "url": "https://arxiv.org/abs/2002.04745"
      },
      {
        "text": "работ",
        "url": "https://aclanthology.org/2020.emnlp-main.463/"
      }
    ]
  },
  {
    "document_title": "Трансформеры",
    "url": "https://education.yandex.ru/handbook/ml/article/transformery",
    "section_title": "Кодирование позиций",
    "text": "Внимательный читатель может заметить, что все операции внутри трансформер-блока, строго говоря, инвариантны к порядку элементов в последовательности. Например, результат внимания зависит от скалярных произведений между эмбеддингами токенов, но расположение этих токенов внутри текста значения не имеет. Таким образом, итоговые представления каждого токена на выходе из модели будут одинаковыми вне зависимости от порядка слов, что вряд ли нас устроит. Как с этим справиться? На помощь приходит такая вещь, как позиционные эмбеддинги. Это вспомогательные представления, которые прибавляются к обычным эмбеддингам токенов входной последовательности и позволяют слоям внимания различать одинаковые токены на разных местах. Исторически первым подходом были фиксированные эмбеддинги, однозначно кодирующие позицию тригонометрическими функциями (ниже— номер позиции,— индекс элемента в векторе, кодирующем эту позицию,— размерность эмбеддинга): С момента появления архитектуры «трансформер», однако, появилось множество других способов кодировать позиции токенов. Например, можно просто сделать позиционные эмбеддинги обучаемыми наряду с эмбеддингами токенов. Иной подход — напрямую учесть тот факт, что нам важны не абсолютные позиции токенов, а расстояние между ними, и обучатьотносительныепозиционные представления: подобный подход заметно улучшает качество на чувствительных к порядку слов задачах, а его более современныемодификациирегулярно используются в самых мощных моделях.",
    "source_type": null,
    "useful_links": [
      {
        "text": "относительные",
        "url": "https://arxiv.org/abs/1803.02155"
      },
      {
        "text": "модификации",
        "url": "https://arxiv.org/abs/2108.12409"
      }
    ]
  },
  {
    "document_title": "Трансформеры",
    "url": "https://education.yandex.ru/handbook/ml/article/transformery",
    "section_title": "Про BERT и GPT",
    "text": "Несомненно, трансформер-модели не были бы так интересны, если бы практически все задачи NLP сейчас не решались бы с помощью этой архитектуры. Главными факторами, повлиявшими на бурный рост популярности идеи self-attention, послужили два семейства хорошо всем известных архитектур — BERT и GPT, которые в некотором роде являются энкодером и декодером трансформера, которые зажили своей жизнью. МодельGPT(Generative Pretrained Transformer) хронологическипоявиласьраньше. Она представляет собой обычную языковую модель, реализованную в виде последовательности слоев декодера трансформера. В качестве задачи при обучении выступает обычное предсказание следующего токена (то есть многоклассовая классификация по словарю). Важно, что в качестве маски внимания как раз выступает нижнетреугольная матрица: в противном случае возникла бы утечка в данных из-за того, что токены из «прошлого» будут видеть «будущее». Полученную модель можно использовать для генерации текстов и всех задач, которые на это опираются. Даже ChatGPT, обученная на специальных инструкциях, по своей сути незначительно отличается от базовой модели. Как понятно из названия, модельBidirectional Encoder Representations from Transformers(илиBERT) отличается от GPT двунаправленностью внимания: это значит, что при обработке входной последовательности все токены могут использовать информацию друг о друге. Это делает такую архитектуру более удобной для задач, где нужно сделать предсказание относительно всего входа целиком без генерации, например, при классификации предложений или поиске пар похожих документов. Важно, что при этом BERT не учится генерировать тексты с нуля: одна из его задач при обучении — это masked language modeling (предсказание случайно замаскированных слов по оставшимся, изображено на рисунке ниже), а вторая — next sentence prediction (предсказание по паре текстовых фрагментов, следуют они друг за другом или нет). Заметим, что самое ключевое отличие в моделях BERT и GPT (а не в задачах для обучения или применениях) можно свести к использованию разных видов внимания, изображенных на рисунке снизу.",
    "source_type": null,
    "useful_links": [
      {
        "text": "появилась",
        "url": "https://openai.com/research/language-unsupervised"
      }
    ]
  },
  {
    "document_title": "Трансформеры",
    "url": "https://education.yandex.ru/handbook/ml/article/transformery",
    "section_title": "Тонкости обучения",
    "text": "К сожалению, если вы просто напишете код Transformer-нейросети и попробуете сразу обучить что-то содержательное, используя привычные для других архитектур гиперпараметры, то вас с большой вероятностью постигнет неудача. Оптимизационный процесс для таких моделей зачастую требуется изменить, и недостаточное внимание к этому может повлечь за собой существенные потери в итоговом качестве или вообще привести к нестабильному обучению. Первый момент, на который стоит обратить внимание, — размер батча для обучения. Практически все современные Transformer-модели обучаются на больших батчах, которые для самых больших языковых моделей могут достигать миллионов токенов. Разумеется, ни одна современная GPU не может обработать столько данных за один шаг: на помощь приходят распределенное обучение и чуть более универсальныйтрюкс аккумуляцией градиентов по микробатчам. Также в последних статьях зачастую прибегают кувеличению размера батчапо ходу обучения: идея заключается в том, что на ранних этапах важнее быстрее совершить много шагов градиентного спуска, а на поздних становится важнее иметь точную оценку градиента. Второй немаловажный фактор — выбор оптимизатора и расписания для learning rate. Обучить трансформер стандартным SGD, скорее всего, не выйдет: в оригинальной статье в качестве оптимизатора использовался Adam, и де-факто он остаётся стандартом до сих пор. Однако стоит заметить, что для больших размеров батча Adam порой работает плохо: из-за этого порой приходится прибегать к алгоритмам наподобиеLAMB, нормализующим обновления весов для каждого слоя.",
    "source_type": null,
    "useful_links": [
      {
        "text": "трюк",
        "url": "https://sebastianraschka.com/blog/2023/llm-grad-accumulation.html#what-is-gradient-accumulation"
      },
      {
        "text": "увеличению размера батча",
        "url": "https://openreview.net/forum?id=B1Yy1BxCZ"
      },
      {
        "text": "LAMB",
        "url": "https://arxiv.org/abs/1904.00962"
      }
    ]
  },
  {
    "document_title": "Трансформеры",
    "url": "https://education.yandex.ru/handbook/ml/article/transformery",
    "section_title": "Трансформеры не для текстов",
    "text": "Разумеется, успех этого семейства архитектур на множестве текстовых задач не мог остаться незамеченным для исследователей в других доменах. Одним из наиболее ярких примеров областей, в которой Transformer-модели нашли новое приложение, несомненно, является компьютерное зрение. К примеру,архитектураViT (Vision Transformer) в свое время побила рекорды качества по классификации изображений, задействуя идею self-attention для картинок, разделенных на множество «лоскутных» (patches) сегментов квадратной формы. Как пишут авторы статьи, идея использовать Transformer-архитектуру в зрении пришла к ним после наблюдения за успехами таких моделей в NLP: использование такого общего подхода, как self-attention, позволяет избежать необходимости явно закладывать в архитектуру особенности задачи (это ещё называют inductive bias) при достаточном времени обучения, числе параметров и размере выборки. Также именно на трансформерах базируется генеративная часть DALL-E — модели, положившей начало активным исследованиям последних лет в генерации изображений по тексту. Концептуально DALL-E довольно проста: её можно рассматривать как авторегрессивную «языковую модель», генерирующую изображение по одному «визуальному токену» за шаг. Применяют трансформеры и к обучению с подкреплением: ярким примером являетсяработаDecision Transformer, в которой предлагают использовать авторегрессивное моделирование с использованием этой архитектуры для построения агента. Авторы показали, что такой же подход, который используют для генерации текстов, можно использовать для предсказания действий в динамической среде: как показано на рисунке ниже, модель последовательно принимает стандартные тройки из закодированных состояний, текущих действий и наград и в качестве ответа на каждом шаге выдаёт следующее действие.",
    "source_type": null,
    "useful_links": [
      {
        "text": "архитектура",
        "url": "https://arxiv.org/abs/2010.11929"
      },
      {
        "text": "работа",
        "url": "https://arxiv.org/abs/2106.01345"
      }
    ]
  },
  {
    "document_title": "Адаптивный FTRL",
    "url": "https://education.yandex.ru/handbook/ml/article/adaptivnyj-ftrl",
    "section_title": "Синтаксический сахар",
    "text": "В выкладках очень часто используются суммы, и без сокращенных обозначений читать их невозможно. В литературе про онлайн-обучение приняты вот такие сокращения: ; Особо отметим обозначение, т.е. точкафиксирована и не меняется с индексацией в сумме; (обычно это будет сумма функции потерь и регуляризатора); — субградиент функциив точке.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Адаптивный FTRL",
    "url": "https://education.yandex.ru/handbook/ml/article/adaptivnyj-ftrl",
    "section_title": "Аддитивные регуляризаторы",
    "text": "В новых обозначениях описанные выше алгоритмы примут вид: Adaptive FTRL: Adaptive Linearized FTRL: Опишем условия, накладываемые нами на алгоритм. В обзоре они называются Setting 1. От функциймы потребуем, чтобы они представлялись в виде: Слагаемые должны удовлетворять следующим условиям: Всевыпуклы (вниз); ; . Также наложим следующие требования на: Область определения— непустое множество. Это требование может показаться странным, но при желании можно придумать примерс пустой областью определения: достаточно взять несколько регуляризаторов-проекцийна непересекающиеся выпуклые множества (подробнее о таких регуляризаторах мы расскажем в одном из следующих разделов); Субдифференциалв точкенепуст.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Адаптивный FTRL",
    "url": "https://education.yandex.ru/handbook/ml/article/adaptivnyj-ftrl",
    "section_title": "Классы алгоритмов FTRL",
    "text": "Будем рассматривать аддитивные регуляризаторыиз двух семейств в зависимости от того, где у них минимум: FTRL-Centered:; FTRL-Proximal:; Composite Objective: смешение первых двух семейств. Обратите внимание: название Proximal напрямую связано с проксимальным градиентным спуском (ссылка на учебник с проксимальными методами). В обоих случаях мы накладываем регуляризатор в текущей точке. Обратите внимание: для Proximal регуляризаторов зачастую требуют выполнения более сильного условия:. Это не такое уж и серьёзное ограничение: все разумные Proximal регуляризаторы (например,) ему удовлетворяют. Обратите внимание: у обоих семейств есть значимые высокоцитируемые статьи FTRL-Centered: методRegularized Dual Averaging. Статья получила премию Test of Time Award на NeurIPS 2021, так как огромное количество последующих громких результатов (тот же AdaGrad) напрямую основывались на этих результатах. В названии Dual Averaging под dual average имеется в виду, то есть среднее по градиентам. Кардинально других техник оценок regret там нет, обзор McMahan строго улучшает все доступные там результаты. FTRL-Proximal: самая известная статья от гуглаAd Click Prediction. Известна она скорее потому, что там выписаны формулы и объяснено, как правильно реализовывать метод для large-scale задач с результатами применения различных дополнительных инженерных идей. Это хорошийинженерный обзор, а не математическая статья. Рассмотрим отдельно каждую из разновидностей алгоритмов Задача оптимизации имеет вид гдетаковы, что Пример: Рассмотрим SGD с фиксированным learning rate и стартом в точке. Положим Как мы уже знаем, итеративное обновление весов будет иметь вид Задача имеет похожий вид новыбираются так, чтобы Пример: Рассмотрим SGD с убывающим learning rate: Подробный вывод связиимы приведём в одном из следующих разделов, а сейчас просто приведём результат: Обратите внимание: как правило, на практике Proximal методы работают лучше. Интуитивно, центрирование в недавних точках вместо Рассмотрим смесь центрированных и проксимальных регуляризаторов: гдеитаковы, что Пример: FTRL-Proximal с L1 и L2 регуляризацией Обратите внимание: как правило, центрированные регуляризаторы в довесок к проксимальным вводят уже не для «дополнительной стабилизации» алгоритма, а для наложения ограничений на решение. Обратите внимание: наиболее правильные и хорошо работающие на практике способы подбора коэффициентовимы приведём в параграфе про учет дополнительнойирегуляризации.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Regularized Dual Averaging",
        "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/xiao10JMLR.pdf"
      },
      {
        "text": "Ad Click Prediction",
        "url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41159.pdf"
      }
    ]
  },
  {
    "document_title": "Адаптивный FTRL",
    "url": "https://education.yandex.ru/handbook/ml/article/adaptivnyj-ftrl",
    "section_title": "Гарантии сходимости для алгоритмов FTRL",
    "text": "В этом разделе мы обсудим теоретические оценки на скорость сходимости алгоритма FTRL или, что то же самое, на скорость убывания maxRegret. Напомним формулу: Чтобы делать оценки на maxRegret, нужно пытаться оценить асимптотику ряда, каждое слагаемое которого — это решение сложной оптимизационной задачис произвольными функциями. Работать с такой сущностью крайне сложно. Наша основная цель — сделать верхнюю оценку на regret, в которой не будет этого члена.(???) Пусть— последовательность произвольных (не обязательно) функций; Пусть— последовательность выпуклых неотрицательных регуляризаторов; Пусть такжевсегда определен (относительно слабые условия 1-2 требуют от нас это явно проговорить);Тогда алгоритм, выбирающийпо правилу (3), удовлетворяет неравенству Из чего состоит эта лемма? Слагаемое— это суммарная регуляризация в точке. Совсем избавиться от вхожденияне получится, но мы можем выбирать регуляризатор так, чтобы оценить сверхубыло не очень сложно. Каждое слагаемое суммыотражает, насколько улучшается-й лосспри заменена. Поведение разностейхарактеризует стабильность алгоритма. Мы ожидаем, что при большиху хорошо сходящегося алгоритма на очередном шагебудет достаточно близок к оптимуму, то есть вся сумма будет меняться всё медленнее, и её получится разумно оценить. Пример ситуации, когда это не так, мы уже видели, когда рассматривали FTL без регуляризации для линейной функции потерь (там всё было максимально нестабильно и расходилось). К счастью, введение регуляризации обычно помогает добиться стабильности. Обе компоненты неразрывно связаны. Добавляя регуляризацию, мы увеличиваем первую компоненту, но улучшает стабильность алгоритма, чем уменьшаем вторую, и наоборот. Обратите внимание: в условиях леммы допускаются невыпуклые, и это позволяет применять её в весьма общей ситуации. Впрочем, все наши последующие выкладки все-таки будут опираться на выпуклость. Ниже мы представим теоремы 1,2 и 10 изобзора McMahan. Они дают оценки на regret в немного разных исходных предположениях и для разных типов регуляризаторов; асимптотика regret в каждом из случаев, хотя константы будут различными. О важности констант в сходимости мы поговорим в одной из следующих параграфов, когда будем разбирать метод AdaGrad. В самом конце параграфа мы обсудим, какие оценки получаются для линеаризованного regret. А в следующем параграфе мы займёмся выводом конкретных алгоритмов FTRL для разных видов регуляризаторов. Мы не будем полностью пересказывать обзор (если вам стало интересно, рекомендуем прочитать его самостоятельно) и докажем в качестве примера теорему 2, а для остальных приведём лишь формулировки. ОпределениеВыпуклая функцияназывается-сильно выпуклой по отношению к некоторой норме, если выполнено ОпределениеДвойственной нормойпо отношению к норменазывается Более подробно о-сильной выпуклости и двойственных нормах вы можете почитать, например, в книгеBoyd, 2004, Convex Optimization. Пусть Обновление параметров происходит по правилу Выполнены все условия Setting 1; Регуляризаторвыбирается так, чтобы выражениебыло 1-сильно выпукло по отношению к некоторой норме(возможно, своей на каждом шаге). Тогда где— норма, двойственная к норме. Пусть Обновление параметров происходит по правилу Выполнены все условия Setting 1; Все регуляризаторылежат в семействе FTRL-Proximal, причёмдля всех; выбирается так, чтобы выражениебыло 1-сильно выпукло по отношению к некоторой норме(возможно, своей на каждом шаге). Тогда где— норма, двойственная к норме. Пусть Обновление параметров происходит по правилу Выполнены все условия Settning 1; ; — неубывающая последовательность; — Centered регуляризатор с минимумом в точке; — Proximal регуляризаторы; выбирается так, чтобы выражениебыло 1-сильно выпукло по отношению к некоторой норме(возможно, своей на каждом шаге). Тогда Если мы рассматриваем regret относительно, то Если мы рассматриваем regret относительно, то где— норма, двойственная к норме. Обратите внимание. Оценки Proximal и General отличаются индексацией: доили досоответственно. Это чисто техническое различие, однако именно из-за него с Proximal регуляризаторами удобнее работать как в теоретических выкладках, так и при выведении практических методов. Обратите внимание. Намы не хотим накладывать ограничения сильной выпуклости, но сильную выпуклость функцииможно обеспечить за счет выбора сильно выпуклых регуляризаторов. В самом деле, сумма выпуклой и сильно выпуклой функций сильно выпукла. Если и то Обратите внимание. Нормаявляется сопряженной к норме, относительно которой 1-сильно выпукла функция. Это значит, что норму мы будем выбирать посуммерегуляризаторов, а не просто по. Нам понадобится следующая чисто техническая лемма, доказательство которой мы опустим. Желающие могут прочитать Appendix B вобзоре. Lemma 7. Пусть — выпуклая функция, для которой существует; — выпуклая функция; — выпуклая функция, для которой существуети которая, кроме того, 1-сильно выпукла по норме. Тогда, для любого элементасубдифференциалаимеет место неравенство и для любогоимеет место неравенство Доказательство теоремы 2 Рассмотрим соседние раундыи. Имеем Обозначим. Посколькуодновременно минимизирует и(т.к. это proximal регуляризатор), и, имеем Далее, Выпишем оценку из Strong FTRL Lemma и постараемся оценить отмеченные рыжим слагаемые Так как по условию теоремы, мы можем убрать это слагаемое: Обозначим. Применив Лемму 7, получаем Вспомним, что для линеаризованного FTRL имеет место неравенство: Увы, верхняя оценка на левую часть неравенства не помогает оценить правую. Поэтому рассмотрим линеаризованный алгоритм более подробно. Он работает с последовательностью функций, где. Субдифференциалсостоит из одного вектора (градиента это функции) Применим приведённые выше оценки на regret для исходного и для линеаризованного алгоритма: Легко убедиться, чтооценки regret для обычного и линеаризованного FTRL совпадаюти выполнено соотношение Таким образом, для линеаризованного варианта любого алгоритма FTRL не нужно доказывать собственные оценки. А поскольку линеаризованный FTRL намного эффективнее, в дальнейшем мы всегда будем сразу переходить от исходного алгоритма к линеаризованному.",
    "source_type": null,
    "useful_links": [
      {
        "text": "обзора McMahan",
        "url": "https://www.jmlr.org/papers/volume18/14-428/14-428.pdf"
      },
      {
        "text": "Boyd, 2004, Convex Optimization",
        "url": "https://web.stanford.edu/~boyd/cvxbook/"
      },
      {
        "text": "обзоре",
        "url": "https://www.jmlr.org/papers/volume18/14-428/14-428.pdf"
      }
    ]
  },
  {
    "document_title": "Адаптивный FTRL",
    "url": "https://education.yandex.ru/handbook/ml/article/adaptivnyj-ftrl",
    "section_title": "Построение эффективного адаптивного FTRL",
    "text": "Теперь, когда мы получили теоретические оценки на качество работы адаптивного FTRL, настала пора рассмотреть несколько конкретных примеров алгоритмов из этого класса. Во всех дальнейших выкладках мы сразу ограничим себя семейством квадратичных регуляризаторов: Для FTRL-Centered алгоритмов:, Для FTRL-Proximal алгоритмов:, где— некоторая симметричная положительно определённая матрица (возможно, своя для каждого шага). Помимо того, что они удобны и привычны, таки регуляризаторы позволяют достаточно просто выписывать оценки на regret. Чтобы в этом убедиться, вспомним, какие нетривиальные сущности возникают в теоремах: на каждом шаге нам нужно выбрать норму, по отношение к которой выражениебыло бы 1-сильно выпуклым; во всех оценках участвует(или), и его хорошо бы уметь оценивать сверху; также в оценках фигурирует норма, двойственная к, и её нужно уметь выводить. Давайте разберёмся с каждым из пунктов и поймём, почему для квадратичных регуляризаторов всё довольно хорошо. Выбор нормы Тут всё просто: Регуляризаторявляется 1-сильно выпуклым относительно нормы(т.е. относительно себя же); Регуляризаторявляется 1-сильно выпуклым относительнотой же самой нормы. Нам, впрочем, нужна 1-сильная выпуклость всей суммы, но легко убедиться, что1-сильно выпукло относительно суммарной нормы. Поскольку— тоже симметричная положительно определенная матрица, мы остаёмся в том же классе норм Махаланобиса. Двойственная норма Оказывается, что Ограничение сверху для Строго говоря, здесь никаких гарантий нет, и, например, очень плохая инициализация может всё сильно испортить. На практике, впрочем, всё работает нормально, но авторы статей не могут себе позволить надеяться на благосклонность судьбы. Поэтому в статьях часто встречается следующий костыль. Для вывода оценок на regret вводится регуляризатор, где это проекция на шар. Тогда можно доказать, что. Для ряда частных задач вроде expert advice problem и оптимизаций по вероятностным распределениям используется также семейство энтропийных регуляризаторов Более подробно о нём можно почитать вобзоре Shai-Shalev Schwartz, пример 2.5. Простейший пример — это константный регуляризатор Легко показать, что. Соответствующий итерационный процесс оптимизации имеет вид Как мы уже наблюдали ранее, этот метод эквивалентен методу стохастического градиентного спуска с константным learning rate. А именно, шаг обновления весов можно сформулировать двумя способами: на языке FTRL:; на языке градиентного спуска:. Оценка на Regret(3.1 Constant Learning Rate Online Gradient Descent). Пусть ; . Тогда, если взять, то для любого В целом, такая стратегия регуляризации не самая оптимальная. Интуитивно, наш регуляризатор фиксирован вне зависимости от того, сколько мы уже сыграли раундов, и со временем может перестать компенсировать член, и тогда стабильность алгоритма может падать. Чтобы исправить нестабильность алгоритма, возьмём-регуляризатор, не равный нулю на каждом шаге. Процесс оптимизации примет вид: Для FTRL-Proximal:; Для FTRL-Centered:. Посмотрим, какое обличье примет алгоритм FTRL-Proximal, если его изложить на языке градиентного спуска. Для этого продифференцируем и приравниваем нулю выражение, которое мы минимизируем: Попробуем получить рекуррентную формулу для выражениячерез: Если теперь положить, мы получаем формулу градиентного спуска: Таким образом,темп обучения градиентного спуска равен обратной сумме коэффициентов регуляризации ftrl. Точно так же можно выразить В качестве классической непокоординатной последовательности learning rate обычно берут Оценка на Regret(3.2, Dual Averaging) Пусть , . Тогда, если выбрать, то Как и в случае с константным learning rate, константавна практике никому не известна, так что ее подменяют наи перебирают руками с learning rate, равным. До сих пор мы рассматривали в качестве нормыстандартное скалярное произведение, в которое различные компоненты вектора весов (которые, грубо говоря, соответствуют различным признакам) вносят равный вклад. Такой подход может быть слишком наивным для «боевых» задач, где геометрия оптимизации имеет форму, например, вытянутого эллипса. Нетрудно обобщить предыдущие рассуждения на случай произвольного скалярного произведения Коэффициентыв этом выражении теперь спрятались в. Найдем точку минимума: Но сразу возникают проблемы: Нужно хранить, в общем случае это квадрат по памяти от числа параметров. Ни в какой реальной задаче мы не сможем себе этого позволить; На каждой итерации метода нужно решать гигантскую систему линейных уравнений для поиска. Есть все шансы состариться, так и не успев увидеть решение задачи оптимизации. Упростим себе жизнь и предположим, что все матрицыдиагональны. Тогдаможно хранить в виде вектора диагональных элементов того же размера, что и, а система на каждой итерации будет решаться за линию. Разрешив себе брать нормыс диагональными матрицами, мы сделали алгоритм более гибким, но при этом приобрели дополнительные степени свободы (выбор диагональных элементов). Попробуем ответить на два вопроса: Можно ли матрицыне угадывать, а настраивать по доступной на очередном шаге информации? Как выбирать матрицытак, чтобы минимизировать оценки на regret? В процессе поисков ответов на них мы придём к известному методу оптимизацииAdaGrad. Помня, что, выпишем общий вид оценки на regret: Чтобы упростить выкладки, введем новую симметричную положительно определенную матрицуи перепишем формулы С членомявно будет очень сложно работать: чтобы им пользоваться, нужно иметь на руках оптимальное решениедля всей предыдущей выборки. Более перспективным выглядит слагаемое: вычислять их одно удовольствие. Идея методаAdaGradкак раз в том, чтобы не пытаться работать с первым членом и минимизировать второй, надеясь, что итоговые оценки на regret при этом тоже улучшатся. Для начала выведем диагональный AdaGrad как более простой случай. Если вседиагональны, то матрицатоже диагональна и представляется набором диагональных элементов(уберем индексдля сокращения выкладок, так как мы рассматриваем фиксированный раунд). Распишем второе слагаемое в regret Попробуем минимизировать его Условиевозникает из неотрицательной определенности матрицы. Решеним такой задачи, очевидно, является. Однако в этом случае члениз оценки на regret станет, наоборот, бесконечно большим, и нужен какой-то компромисс. Введем довольно слабое ограничение на положительные коэффициенты и найдём оптимум с помощью метода множителей Лагранжа. Функция Лагранжа имеет вид Отметим, что здесь— это вектор, а— число. Приравняем к нулю частные производные: Вспомним про условия дополняющей нежесткости, требующие, чтобы. Так какмы нулю приравнять здесь не можем, получаем, что: Теперь вспомним про условие. Можно показать, что оптимум достигается на границе (то есть когда неравенство превращается в равенство). Тогда Вернемся к оценке на regret. Чему равномы не знаем, поэтому мы просто констатируем, что оптимальные коэффициентыпропорциональны: Теперь— диагональная матрица с диагональными элементами. Следовательно,- тоже диагональная матрица с диагональными элементами: и легко убедиться, что Теперь вспомним, что эти формулы в точности повторяют то, что мы получили выше для соотношения, только вместо общего коэффициентау нас теперь покоординатные коэффициенты: Получаем формулы для метода AdaGrad в градиентной постановке: где коэффициентприобретает значение learning rate. Оценка на Regret(3.4, FTRL-Proximal with Diagonal Matrix Learning Rates) Если использовать AdaGrad с покоординатными learning rate, то Отметим, что это оценка отличается от предыдущей тем, что вместоиспользуется. Таким образом, если у градиента на какой-то из позиций стоит что-то большое, это повлияет лишь на одно из слагаемых под корнем вместо того, чтобы умножиться на. Эффективный размер шага. Предположим, что градиенты ограничены по норме. Перепишем наши формулы в виде Из этих формул следует, что в среднем learning rate в AdaGrad убывает как, то есть так же, как в предыдущем методе. Отличие состоит лишь в более правильной покоординатной нормировке, которая улучшает сходимость.",
    "source_type": null,
    "useful_links": [
      {
        "text": "обзоре Shai-Shalev Schwartz",
        "url": "https://www.cs.huji.ac.il/w~shais/papers/OLsurvey.pdf"
      }
    ]
  },
  {
    "document_title": "Генеративный подход к классификации",
    "url": "https://education.yandex.ru/handbook/ml/article/generativnyj-podhod-k-klassifikacii",
    "section_title": "Генеративный и дискриминативный подходы к обучению",
    "text": "Если модель позволила точно оценить распределение, с её помощью можно генерировать объекты из этого условного распределения, в нашем примере — изображения кошек и рысей соответственно. А вместе распределениедало бы нам возможность генерировать изображения и кошек, и рысей, причём именно в той пропорции, в которой они встречаются в реальном мире. Поэтому модели, оценивающие, называютгенеративными. Ещё одно достоинство генеративных моделей — их способность находить выбросы в данных: объектможно считать выбросом, еслимало для каждого класса. Заметим, что находить выбросы с помощью генеративной модели можно и когда класс всего один — то есть никакие метки классов не доступны. Такая задача называется одноклассовой классификацией. Например, если у нас есть не размеченный датасет с аудиозаписями речи людей, то, обучив на нём генеративную модель, оценивающую в данном случае, мы сможем для нового аудиоопределить, похоже ли оно на аудиозапись человеческой речи (значениевелико), или это что-то другое: синтезированная речь, посторонний шум и т.п. (значениемало). Если мы знаем, что «выбросы», с которыми модели предстоит сталкиваться, — это, как правило, синтезированная речь, то, мы можем дополнить датасет вторым классом, состоящим из синтезированной речи, и смоделировать также распределение этого класса. Это позволит существенно увеличить качество детектирования таких выбросов. Чтобы использовать генеративную модель для классификации, необходимо выразитьчерези. Сделать это позволяет формула Байеса: Классификация в генеративных моделях осуществляется с помощью байесовского классификатора: Оценить, как правило, несложно. Для этого используют частотные оценки, полученные в обучающей выборке: Выражение (1) Отметим ещё раз, что использование генеративного подхода позволяет внедрять в модель априорные знания о. Это не очень впечатляет, когда речь идёт о бинарной классификации, но всё меняется, если рассмотреть задачу ASR (автоматического распознавания речи), в которой по записи голоса восстанавливается произносимый текст. Таргетами здесь могут быть любые предложения или даже более развёрнутые тексты. При этом размеченных данных (запись, текст) обычно намного меньше, чем доступных текстов, и обученная на большом чисто текстовом корпусе языковая модель, которая будет оценивать вероятность того или иного предложения, может стать большим подспорьем, позволив из нескольких фонетически корректных наборов слов выбрать тот, который в большей степени похож на настоящее предложение. Но как смоделировать распределение? Пространство всех возможных функций распределениябесконечномерно, из-за чего оценить произвольное распределение с помощью конечной выборки невозможно. Поэтому перед оценкойна это распределение накладывают дополнительные ограничения. Некоторые простые примеры таких ограничений мы рассмотрим в следующих разделах. Модель гауссовского (или квадратичного) дискриминантного анализа (GDA) строится в предположении, что распределение объектов каждого классаподчиняется многомерному нормальному закону со средними ковариационной матрицей: Тогда функция правдоподобия достигает максимума при И, представленной вышесм. выражение. Рассмотрим, как выглядит разделяющая поверхность в модели GDA. На поверхности, разделяющей классыивыполняется Выражение(2) Поскольку левая частьуравнения (2)квадратична по, разделяющая поверхность между двумя классами будет представлять из себя гиперповерхность порядка 2. Пример разделяющей поверхности многоклассовой модели GDA приведённа рис. Плотность классов и разделяющая поверхность в многоклассовой модели LDAсм. рисунок. Ввыражении (2)член второго порядказануляется при. Таким образом, если дополнительно предположить, что все классы имеют общую ковариационную матрицу, разделяющая поверхность между любыми двумя классами будет линейной (см. рисунок). Поэтому такая модель называется линейным дискриминантным анализом (LDA). На этапе обучения единственное отличие модели LDA от GDA состоит в оценке ковариационной матрицы: Заметим, что в модели GDA для каждого класса требовалось оценить порядкапараметров. Это может привести к переобучению в случае, если размерность пространства признаков велика, а некоторые классы представлены в обучающей выборке малым количеством объектов. В LDA для каждого класса требуется оценить лишь порядкапараметров (значениеи элементы вектора), и ещёобщих для всех классов параметров (элементы матрицы). Таким образом, основное преимущество модели LDA перед GDA — её меньшая склонность к переобучению, недостаток — линейная разделяющая поверхность.",
    "source_type": null,
    "useful_links": [
      {
        "text": "см. выражение",
        "url": "#eq:class_proba_estimation"
      },
      {
        "text": "уравнения (2)",
        "url": "#eq:GDA_boundary"
      },
      {
        "text": "на рис.",
        "url": "#fig:GDA_boundary"
      },
      {
        "text": "см. рисунок",
        "url": "#fig:LDA_boundary"
      },
      {
        "text": "выражении (2)",
        "url": "#eq:GDA_boundary"
      },
      {
        "text": "см. рисунок",
        "url": "#fig:LDA_boundary"
      }
    ]
  },
  {
    "document_title": "Генеративный подход к классификации",
    "url": "https://education.yandex.ru/handbook/ml/article/generativnyj-podhod-k-klassifikacii",
    "section_title": "Метод наивного байеса",
    "text": "Предположим, что признакиобъектов каждого класса— независимые случайные величины: В таком случае говорят, что величиныусловно независимы относительно. Тогда справедливо Выражение (3) То есть для того, чтобы оценить плотность многомерного распределениядостаточно оценить плотности одномерных распределений,см. рисунок. На рисунке приведён пример условно независимых относительнослучайных величин. Для оценки плотности двумерных распределений объектов классов достаточно оценить плотности маргинальных распределений, изображённые графиками вдоль осей. Рассмотрим пример. Пусть решается задача классификации отзывов об интернет-магазине на 2 категории:— отрицательный отзыв, клиент остался не доволен, и— положительный отзыв. Пусть признакравен 1, если словоприсутствует в отзыве, и 0 иначе. Тогда условиевыраженияозначает, что, в частности, наличие или отсутствие слова «дозвониться» в отрицательном отзыве не влияет на вероятность наличия в этом отзыве слова «телефон». На практике в процессе feature engineering почти всегда создаётся много похожих признаков, и условно независимые признаки можно встретить очень редко. Поэтому генеративную модель, построенную в предположении условиявыражения, называют наивным байесовским классификатором (Naive Bayes classifier, NB). Обучение модели NB заключается в оценке распределенийи. Дляможно использовать частотную оценкувыражения.— одномерное распределение. Рассмотрим несколько способов оценки одномерного распределения.",
    "source_type": null,
    "useful_links": [
      {
        "text": "см. рисунок",
        "url": "#fig:blobs_density"
      },
      {
        "text": "выражения",
        "url": "#eq:cond_independent"
      },
      {
        "text": "выражения",
        "url": "#eq:cond_independent"
      },
      {
        "text": "выражения",
        "url": "#eq:class_proba_estimation"
      }
    ]
  },
  {
    "document_title": "Генеративный подход к классификации",
    "url": "https://education.yandex.ru/handbook/ml/article/generativnyj-podhod-k-klassifikacii",
    "section_title": "Оценка одномерного распределения",
    "text": "Пусть мы хотим оценить одномерное распределение. Если распределениедискретное, требуется оценить его функцию массы, то есть вероятность того, что величинапримет значение. Метод максимума правдоподобия приводит к частотной оценке: Выражение (4) Где— размер выборки, по которой оценивается распределение(количество объектов классав случае оценки плотности класса). При этом может оказаться, что некоторое значениени разу не встречается в обучающей выборке. Например, в случае классификации отзывов методом Наивного Байеса, слово «амбивалентно» не встретилось ни в одном положительном отзыве, но встретилось в отрицательных. Тогда использованиеоценки выраженияприведёт к тому, что все отзывы с этим словом будут определяться NB как отрицательные с вероятностью 1. Чтобы избежать принятия таких радикальных решений при недостатке статистики, используют сглаживание Лапласа: где— количество различных значений, принимаемых случайной величиной,— гиперпараметр. Для оценки плотностиабсолютно непрерывного распределения в точкеможно разделить количество объектов обучающей выборки в окрестности точкина размер этой окрестности: Обычно объекты, лежащие дальше от точки, учитывают с меньшим весом. Таким образом, оценка плотности приобретает вид где функция, называемая ядром, обычно имеет носитель(см. рисунок ниже). Такой способ оценки плотности называют непараметрическим. Результат оценки плотности с разными ядрами. Использованыизображения из: При параметрической оценке плотности предполагают, что искомое распределение лежит в параметризованном классе, и подбирают значения параметров при помощи метода максимума правдоподобия. Например, предположим, что искомое распределение нормальное. Тогда функция его плотности имеет вид Таким образом, чтобы оценить плотность, достаточно оценить параметры. Метод максимума правдоподобия в этом случае даст такие оценки: — выборочное среднее,— выборочное стандартное отклонение. Если в модели NB распределения всех признаков объектов каждого класса нормальные, оценив параметры этих распределений, мы сможем каждый классописать нормальным распределением со средними диагональной ковариационной матрицей, значения на диагонали которой обозначим. Таким образом, полученная модель (Gaussian Naive Bayes, GNB) эквивалентна моделиGDAс дополнительным ограничением на диагональность ковариационных матриц.",
    "source_type": null,
    "useful_links": [
      {
        "text": "оценки выражения",
        "url": "#eq:freq_estimation"
      },
      {
        "text": "см. рисунок ниже",
        "url": "#fig:kernels.png"
      },
      {
        "text": "изображения из:",
        "url": "https://scikit-learn.org/stable/auto_examples/neighbors/plot_kde_1d.html"
      },
      {
        "text": "GDA",
        "url": "#ss:GDA"
      }
    ]
  },
  {
    "document_title": "Генеративный подход к классификации",
    "url": "https://education.yandex.ru/handbook/ml/article/generativnyj-podhod-k-klassifikacii",
    "section_title": "Наивный байесовский подход и логистическая регрессия",
    "text": "Предположим теперь, что в модели GNB класса всего 2, причём соответствующие им ковариационные матрицы совпадают, как это было в модели LDA. Таким образом. Посмотрим, как будет выглядетьв этом случае. По теореме Байеса имеем Разделим числитель и знаменатель полученного выражения на числитель: Из условной независимостиотносительнополучаем Формула (5) Перепишем сумму в знаменателе, воспользовавшись формулой плотности нормального распределения Подставляя это выражение вформулу (5), получаем Таким образом,представляется в GNB с общей ковариационной матрицей в таком же виде, как в модели логистической регрессии: Формула (6) где в случае GNB Однако это не значит, что модели эквивалентны: модель логистической регрессии накладывает менее строгие ограничения на распределение, чем GNB. Так,могут не являться условно независимыми относительно, а распределениямогут не удовлетворять нормальному закону, номожет при этом всё равно представляться в видеформулы (6). В этом случае использование метода логистической регрессии предпочтительнее. С другой стороны, если есть основания полагать, что требования GNB выполняются, то от GNB можно ожидать более высокого качества классификации по сравнению с логистической регрессией.",
    "source_type": null,
    "useful_links": [
      {
        "text": "формулу  (5)",
        "url": "#eq:posterior"
      },
      {
        "text": "формулы  (6)",
        "url": "#eq:logreg"
      }
    ]
  },
  {
    "document_title": "Аналитика временных рядов",
    "url": "https://education.yandex.ru/handbook/ml/article/analitika-vremennyh-ryadov",
    "section_title": "Автокорреляционная функция",
    "text": "Временной ряд – зависимые между собой наблюдения. Например, температура воздуха сегодня достаточно сильно зависит от вчерашнего показателя температуры. Эту зависимость хотелось бы описать численно. Для этого часто используют разные виды коэффициентов корреляции, например, корреляции Пирсона, Спирмена и Кендалла. Каждый из этих коэффициентов корреляции вычисляется по двум выборкам, корреляцию между которыми требуется посчитать. В данном случае мы имеем один временной ряд, и наша задача – оценить корреляцию между разными наблюдениями ряда, считая, что она не меняется со временем. В качестве оценки корреляции значенийидля любыхрассмотрим коэффициент корреляции Пирсона ряда с самим собой со сдвигом на. Тем самым мы получим численную оценку степени влияния значенияна значение: где– лаг автокорреляции, а среднее вычисляется по всему ряду. Например, если мы хотим оценить степень влияния сегодняшней температуры на завтрашнюю, то посчитаем коэффициент корреляции исходного ряда и им же, сдвинутым на 1 день. Замечание.Формула содержит некоторые упрощения при оценке ковариации и дисперсий. Свойства коэффициента корреляции: ; – отсутствие автокорреляции, при этом значения могут быть зависимыми (см. подробнее про разницу между независимостью и некоррелированностью); – положительная корреляция, то есть чембольшебыло значение вчера, тем оно будетбольшесегодня; – отрицательная корреляция, то есть чембольшебыло значение вчера, тем оно будетменьшесегодня; означает строгую линейную зависимость. Посмотреть простые примеры и потренировать свою интуицию вы можете в игреGuess The Correlation. Пусть мы посчитали значение автокорреляции. А как понять, значение 0.1 – это много или мало? На этот вопрос может ответитьстатистический критерий Льюнга-Бокса(Ljung–Box), который проверяет значимость отклоненияот нуля. Основное правило, которое нужно здесь понять – если значение p-value критерия не превосходит(или другогозаранеефиксированного порога значимости), то автокорреляция с лагомзначима. Это число вычисляется с помощью стандартных статистических пакетов (например,statsmodelsв Питоне). Рассмотрим временной ряд дорожно-транспортных происшествий за 14 лет с дискретностью 1 месяц, то есть с 12 измерениями в год. На графике мы видим явную сезонность. На нижнем графике изображенакоррелограмма– график, визуализирующий автокорреляционную функцию. Точками на графике показаны значения автокорреляционной функции. Ее значение в нуле всегда равно 1, так как это автокорреляция ряда с собой же. Также мы видим, что значениеявляется локальным максимумом, что означает высокую положительную корреляцию значения ряда за текущий месяц с аналогичным значением год назад. Иными словами, ряд со сдвигом на год ведёт себя «похожим образом», и это подкрепляет наше наблюдение про наличие годичной сезонности. Наоборот, значениеминимально в своей окрестности, что означает высокую отрицательную корреляцию значения ряда со значением полгода назад. Закрашенная область визуализирует границу незначимой автокорреляции, то есть тех значений автокорреляции, для которых не выявлена статистически значимое отличие от 0 (иначе говоря, доверительный интервал пересекает 0). Так мы видим, что последняя значимая сезонная автокорреляция это – это. Кроме нее также значима сезонная корреляцияи корреляция за половину сезона. Из несезонных автокорреляций значимы оказалисьи. Отсюда можно сделать вывод, что для построения прогноза значенияимеет смысл рассматривать признаки. Рассмотрим временной ряд потребления электричества в Австралии с дискретностью 30 минут. По графику мы можем заметить две разных сезонности – суточную и недельную. Кроме того, при наличии большего количества данных мы смогли бы увидеть еще и годовую сезонность. На данном графике видно повышенное потребление электричества в январе-феврале, когда в Австралии жарко и работает много кондиционеров. По графику автокорреляций мы видим, что наибольшую корреляцию имеют соседние измерения, а также значения сутки назад, двое суток назад, и т.д. Наоборот, значения 12, 36, ... часов назад имеют отрицательную корреляцию.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Guess The Correlation",
        "url": "http://guessthecorrelation.com/"
      },
      {
        "text": "statsmodels",
        "url": "https://www.statsmodels.org/dev/generated/statsmodels.stats.diagnostic.acorr_ljungbox.html"
      }
    ]
  },
  {
    "document_title": "Аналитика временных рядов",
    "url": "https://education.yandex.ru/handbook/ml/article/analitika-vremennyh-ryadov",
    "section_title": "Стационарные временные ряды",
    "text": "Временной рядназываетсястационарным в узком смысле, если для любыхвекторсовпадает по распределению с, то есть при сдвиге всех моментов времени на одно и тоже число совместное распределение значений временного ряда в эти моменты времени не поменяется. в широком смысле, еслидля любого.не зависит от, то есть в среднем значение временного ряда постоянно.для любых, то есть значение автокорреляции зависит только от длины отрезка времени между двумя значениями. для любого. не зависит от, то есть в среднем значение временного ряда постоянно. для любых, то есть значение автокорреляции зависит только от длины отрезка времени между двумя значениями. для гауссовских распределений, то есть для случая, когда все векторы видаимеют нормальное распределение, определения эквивалентны. Это следует из того, что распределение гауссовского случайного вектора полностью определяется математическим ожиданием и ковариациями. Пример.Рассмотрим временной ряд, гдеи независимы и одинаково распределены, причем. Можем заметить, чтои. Тем самым имеем стационарность в широком смысле. Но приполучаем, а приполучаем Мы получили разные распределения, поэтому нет стационарности в узком смысле. Некоторые примеры нестационарных временных рядов: Случайное блуждание– пример:, где– белый шум, то есть независимые одинаково распределенные случайные величины. Математическое ожидание постоянно, но ряд не является стационарным, посколькубесконечно растет. Временной ряд с трендом– пример:, где– белый шум. Ряд не стационарен, так какменяется с течением времени. Временной ряд с сезонностью– пример:, где– белый шум. Не стационарен, так как Стационарный ряд визуально не имеет предсказуемых закономерностей. Если посмотреть на график такого ряда издалека, то он будет горизонтален. Ряд можно проверить строго на станционарность с помощью различных статистических критериев. Наиболее популярны следующие критерии: критерий KPSS (Kwiatkowski–Phillips–Schmidt–Shin): если p-value, то отвергаем стационарность; критерий Дики-Фуллера: если p-value, то отвергаемстационарность. Рассмотрим несколько примеров временных рядов: рядыа,c,d,e,f,iне стационарны, поскольку они имеют тренд; рядbскорее всего стационарный, имеется выброс; рядыd,g,h,iне стационарны, потому что имеют сезонность. Когда вы определяете, чем вызвано изменение данных – трендом или шумом – стоит учитывать природу данных. Например, колебания значений рядаfтеоретически можно было бы объяснить шумом в данных, но по временной оси мы видим, что данные представлены за 15 лет, соответственно, понимаем данные колебания как изменения тренда. Аналогично, для рядаdмы говорим о наличии меняющегося тренда помимо годовой сезонности. Зачем? Данные методы рекомендуется использовать, если задача требует некоторой аналитики временного ряда. Если же требуется только построить точечный прогноз на будущее без построения предсказательных интервалов, то стабилизация дисперсии не является необходимой процедурой. Если же нас интересует предсказательный интервал, то многие методы лучше обрабатывают именно стационарные ряды, поэтому имеет смысл стабилизировать дисперсию. Преобразования: Класс преобразований Бокса-Кокса с параметром: Если есть предположения о зависимостиот, то можно рассмотреть ряд. После построения прогноза для преобразованного ряда нужно сделать обратное преобразование. Преобразования: Дифференцирование ряда, то есть переход к ряду, где. Данное преобразование используется для снятие тренда. Сезонное дифференцирование ряда, то есть переход к ряду, где,– длина сезона. Преобразования можно применять несколько раз. Обычно сначала применяют сезонное дифференцирование. Посмотрим на пример. В критерии KPSS для исходного ряда, то есть ряд можно считать нестационарным. После логарифмирования ряда, а после ещё и сезонного дифференцированная, тем самым полученный ряд мы уже не можем отличить от стационарного. Не редко временной ряд выглядит довольно шумным, что может достаточно плохо сказаться на работе других моделей и подходов к анализу этого временного ряда. В таком случае можно попытаться сгладить значения ряда. Далее мы рассмотрим несколько моделей сглаживания ряда, в том числе при наличии тренда и сезонности ряда. Помимо сглаживания истории ряда, с помощью данных методов можно также осуществлять простое прогнозирование ряда. Пусть имеется временной ряд. В результате экспоненциального сглаживания получается новый временной рядпо правилу где– прогноз значенияв момент времени, а–параметр сглаживания. Смысл преобразования следующий – сглаженное значение в момент времениесть взвешенная комбинация предыдущего значения рядаи предыдущего сглаженного значения ряда. Свойства: прибольший вес последнему значению ряда, поэтому получается слабое сглаживание; прибольший вес отдается предыдущему сглаженному значению, и получается сильное сглаживание, что в пределе вырождается в среднее; Оптимальное значениеможно подобрать либо по графику, либо оптимизируя Существуют следующие эмпирические правила: еслито ряд стационарен, можно применять экспоненциальное сглаживание без риска большой потери информации; еслито ряд нестационарен, применение экспоненциального сглаживания может привести к потере информации или смещению. Примеры: на каждом из графиков изображен исходный ряд (синий) и сглаженный ряд (оранжевый) для разных значений параметра сглаживания. Если имеется тренд или сезонность, то при большом сглаживании полученный ряд начинает «запаздывать» за исходным рядом. Откуда взялась эта формула экспоненциального сглаживания? Покажем, что сглаженное значение соответствует прогнозу величиныв момент времени, подбираемому по правилу Иначе говоря, для прогнозирования мы берем взвешенный MSE с экспоненциально убывающими по времени весами. Приравняем производную к нулю: Отсюда выразими воспользуемся разложением функциив ряд Тейлора Тем самым мы получили модель экспоненциального сглаживания для. Аддитивный линейный тренд: Прогноз нашагов вперед выражается с помощью линейной функции от числа шагов, где коэффициенты меняются по формулам, аналогичным экспоненциальному сглаживанию Модель для мультипликативного линейного тренда выглядит аналогично Модель Хольта: пояснение формул Поясним на примере аддитивного тренда, почему формулы дляиполучаются именно такими. Заметим, что дляии момента времениполучаем,. Хотелось бы, чтобы эти прогнозы примерно совпадали, то есть чтобы имело место. Рассмотрим ряд разностейи задачу константного прогноза для него (то есть) методом простого экспоненциального сглаживания Ее решение мы уже получили ранее: Получилась формулу дляв модели аддитивного тренда. Далее, мы хотим, чтобы имело место. Рассматривая дляэкспоненциальное сглаживание, в котором в качестве предыдущего значения сглаженного ряда берется, а в качестве нового –, получаем Аддитивная сезонность с трендом: где– длина сезона Мультипликативная сезонность Без тренда С линейным трендом Разные модели с трендом и сезонностью В примерах выше мы видели, что при изменении локального тренда ряда экспоненциальное сглаживание запаздывает за значениями ряда при использовании сильного сглаживания. Если же использовать слабое сглаживание, то существенного запаздывания не происходит, но ряд остается шумным. Если для ряда предполагаются значительные структурные изменения, можно использовать модель адаптивного экспоненциального сглаживания, в которой параметр сглаживания может меняться для разных отрезков временного ряда. Пусть– прогноз значенияв момент времениобычным экспоненциальным сглаживанием, а– ошибка прогноза, сделанного на шаге. Определим следующие значения Среднее значение ошибки: Средний разброс ошибки: – статистика, которая сигнализирует, насколько адекватно модель работает в момент времени.– модель систематически ошибается в одну сторону.– модель работает адекватно. – модель систематически ошибается в одну сторону. – модель работает адекватно. Обычно берут значения.Чтобы экспоненциальное сглаживание быстро приспосабливалось к резким структурным изменениям берут. Однако, у данного подхода есть и недостатки, например, плохо реагирует на одиночные выбросы; требует подбора.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Независимость и условные распределения вероятностей",
    "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
    "section_title": "Условная вероятность",
    "text": "Условная вероятность возникает при ответе на вопрос о том, каковы шансы событияпри условии,что случилось событие, и обозначается. Пример. Согласно исследованиям, в среднемпациентов испытывают приступы кашля в течение дня, однако среди курильщиков доля кашляющих составляет. То есть (безусловная) вероятностьпри добавлении обусловливания может существенно измениться:. Упражнение. Известно, что в семье два ребёнка, причём один из них мальчик. Какова вероятность, что другой ребёнок тоже мальчик? В общем случае условная вероятностьприполагается равной В зависимости от соотношения событийиусловная вероятностьможет принимать разные значения, например: если, то событиеисключает реализацию события, и; если, то событиегарантирует осуществление события, и. Разумеется, чаще всего событияисоотносятся между собой более хитрым образом, и значение условной вероятностинаходится строго междуи.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Независимость и условные распределения вероятностей",
    "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
    "section_title": "Формула полной вероятности",
    "text": "Пусть пространстворазбивается на попарно несовместные события: Тогда отсюда по свойству конечной аддитивности находим, что Переходя к условным вероятностям, получаемформулу полной вероятности: Пример. Среди населенияимеют первую группу крови,— вторую,— третью,— четвёртую. При переливании крови надо учитывать группы крови донора и рецепиента: реципиенту с четвёртой группой крови можно перелить кровь любой группы; реципиентам со второй и третьей группами можно перелить кровь той же группы или первой; реципиентам с первой группой крови можно перелить только кровь первой группы. С какой вероятностью допустимо переливание в случайно взятой паре донор—реципиент? Решение. Пусть событиесостоит в том, что переливание возможно, а событие— в том, что донор имеет группу. По формуле полной вероятности Вероятностиданы в условии, оттуда же находим, что Подставляя численные значения, получаем Упражнение. Решите предыдущий пример, выбирая в качестве разбиения набор событий, каждое из которых заключается в том, что реципиент имеет группу. Формула полной вероятности легко обобщается на случай счётного числа попарно несовместных событий, а также на случай обусловливания по некоторому событию, например:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Независимость и условные распределения вероятностей",
    "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
    "section_title": "Формула Байеса",
    "text": "Заметим, что вероятностьможно записать двумя способами Оставимв левой части и получим формулу Байеса. Формула Байеса. Для любых событий,c положительной вероятностью Для вычисления знаменателя в формуле Байеса часто используется формула полной вероятности. Упражнение. Среди определенной группы людей вероятность некоторой болезни 0.02. Тест, позволяющий выявить болезнь, несовершенен. На больном он дает позитивный результат в 98 случаях из 100, и, кроме того, он дает позитивный результат в 4 случаях из 100 на здоровом. Найдите вероятность того, что человек, на котором тест дал положительный результат, действительно болен. Для непрерывного случая тоже есть своя формула полной вероятности, см. раздел проусловную вероятность.",
    "source_type": null,
    "useful_links": [
      {
        "text": "условную вероятность",
        "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej#uslovnye-raspredeleniya"
      }
    ]
  },
  {
    "document_title": "Независимость и условные распределения вероятностей",
    "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
    "section_title": "Независимые события",
    "text": "Событияиназываютсянезависимыми, если, то есть информация о реализации событияникак не влияет на вероятность события. По определению условной вероятности независимость событийиэквивалентна тому, что Последнее равенство годится для определения независмости событийидаже в том случае, еслиили. Пример. В полной колоде карт находитсякарты:масти от двойки до туза. Вероятность вытащить туза равна, карту пиковой масти —. Эти события независимы, поскольку в пересечении этих событий лежит ровно одна карта — туз пик, вероятность появления которого равна. Пусть теперь вытаскивается сразу две карты. Зависимы ли события «вытащены две карты пиковой масти» и «вытащены туз и король»? Посчитаем: Вероятность вытащить туза и короля пик равна, что отличается от. Таким образом, эти события зависимы. Событияпопарно независимы, еслипри. Эти же событиянезависимы в совокупности, если Упражнение. Приведите пример попарно независимых событий,,, не являющихся независимыми в совокупности. Определениенезависимости случайных величиниз предыдущего параграфа полностью согласуется с только что введённым определением независимых событий. Например, для случая дискретных случайных величиниобозначим тогда, и поэтому независимость случайных величиниэквивалентна независимости событийидля всевозможных значенийи.",
    "source_type": null,
    "useful_links": [
      {
        "text": "независимости случайных величин",
        "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya#nezavisimost-sluchajnyh-velichin"
      }
    ]
  },
  {
    "document_title": "Независимость и условные распределения вероятностей",
    "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
    "section_title": "Условная независимость",
    "text": "Бывает так, что зависимые событияистановятся независимыми при выполнении некоторого третьего события. Более формально, событияиусловно независимыпо отношению к событию, еслии Поскольку то условная независимость событийиэквивалетна равенству а это, в свою очередь, означает, что Таким образом, вероятность произведения условно независимых событий равна произведению условных вероятностей. Эта формула полностью аналогична формуледля (безусловно) независимых событий. Пример(цепь Маркова). Последовательность событийназываетсямарковской цепью, если выполняетсямарковское свойство В марковском свойстве заложен следующий смысл: в каждый момент времени«будущее»зависит только от «настоящего», но не зависит от «прошлого» Итак, цепь Маркова характеризуется равенством, которое означает, что событияиусловно независимы по отношению к событию.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Независимость и условные распределения вероятностей",
    "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
    "section_title": "Условные распределения",
    "text": "Пустьи— дискретные случайные величины и. По аналогии с условными вероятностямиусловное распределениеслучайной величиныпри условии, что значение случайной величиныравно, определяется по формуле Это действительно распределение вероятностей, посколькуи В непрерывном случае условное распределение задаётсяусловной плотностью где— совместная плотность случайных величини. И снова проведением маргинализации поубеждаемся в том, что с нормировкой всё в порядке: Поскольку, из формулы условной плотности получаем непрерывный аналогформулы полной вероятности: Пример. Выберем случайное число, а затем — случайное число. Как распределена случайная величина? Переформулируем задачу: известно, чтои. Требуется найти плотность случайной величины. Имеем Применяя формулу полной вероятности, находим Упражнение. Пусть случайные величины,, независимы в совокупности. Чему равна вероятность?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Независимость и условные распределения вероятностей",
    "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
    "section_title": "Условные математические ожидания",
    "text": "Условное математическое ожиданиеотвечает на вопрос «чему равно среднее значение случайной величиныпри условии, что?».Имея в распоряжении матрицу условного дискретного распределенияили условную плотность, условное математическое ожидание можно вычислить следующим образом: в дискретном случае; для непрерывныхи. Важно отметить, что после суммирования или интегрирования по переменнойв формуле условного математического ожидания остаются зависимость от. Таким образом, в отличие от обычного среднего, которое является просто числом, условное ожидание представляет собой случайную величину, поскольку его значение зависит от случайного значения. Свойства условного математического ожидания (линейность). Если, то(монотонность). Если случайные величиныинезависимы, то. . (law of total expectation). Упражнение.Prove the law of total expectation. Условная дисперсияопределяется по формуле Справедливо равенство(law of total variance).",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Независимость и условные распределения вероятностей",
    "url": "https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej",
    "section_title": "Регрессия",
    "text": "В машинном обучении часто встречается задачарегрессии, в которой требуется восстановить зависимостьпри наличии выборки из некоторого неизвестного распределения с совместной плотностью. Стандартный способ решения задачи регресии — минимизация среднего значенияфункции потерь: В качестве функции потерь на одном объектев задаче регрессии обычно выбирают квадратичную функцию:. Тогда для минимизации этого функционала применим немножко вариационного исчисления и продифференцируем по функции. Получим откуда Полученное условное математическое ожидание, называемоефункцией регрессии, показывает, чему в среднем равно значение зависимой переменнойпри условии, что.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Графовые нейронные сети",
    "url": "https://education.yandex.ru/handbook/ml/article/grafovye-nejronnye-seti",
    "section_title": "Введение",
    "text": "Наряду с обработкой табличных, текстовых, аудио данных и изображений, в глубинном обучении довольно часто приходится решать задачи на данных, имеющихграфовуюструктуру. К таким данным относятся, к примеру, описания дорожных и компьютерных сетей, социальных графов и графов цитирований, молекулярных графов, а также графов знаний, описывающих взаимосвязи между сущностями, событиями и абстрактными категориями. В этом параграфе мы с вами познакомимся с основными задачами, которые возникают при обработке графов, а также поговорим ографовых сверткахиграфовых нейронных сетях— специальном классе обучаемых преобразований, способных принимать в качестве входа графы и решать задачи на них.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Графовые нейронные сети",
    "url": "https://education.yandex.ru/handbook/ml/article/grafovye-nejronnye-seti",
    "section_title": "Описание графовых данных",
    "text": "Графпринято представлять двумя множествами: множеством, содержащим вершины и их признаковые описания, а также множеством, содержащим связи между вершинами (то есть рёбра) и признаковые описания этих связей. Для простоты математических выкладок и изложения дальнейшего материала давайте считать, что мы всегда работаем с ориентированными графами. Если граф содержит ненаправленное ребро, мы его заменяем на пару направленных ребер. Кроме того, давайте обозначать окрестность вершины как. Графовые данные довольно разнообразны. Они могут отличаться между собой в следующих моментах: По размеру, т.е.количеству вершин и/или ребер. Поналичию признаковых описаний вершин и рёбер. В зависимости от решаемой задачи, графы могут содержать информацию только в вершинах, только в ребрах, либо же и там и там. Кроме того, графы могут бытьгомо- и гетерогенными— в зависимости от того, имеют ли вершины и ребра графа одну природу либо же нет. Например, социальные графы содержат огромное количество вершин и ребер, часто измеряющееся в тысячах, содержат информацию в вершинах и очень редко в ребрах, а также являются гомогенными, так как все вершины имеют один тип. В то же время, молекулярные графы — это пример графов с, как правило, средним количеством вершин и ребер; вершины и связи в молекулярных графах имеют признаковое описание (типы атомов и ковалентных связей, а также информацию о зарядах и т.п.), но при этом также являются гомогенными графами. К классу гетерогенных графов относятся, например, графы знаний, описывающие некоторую систему, различные сущности в ней и взаимодействия между этими сущностями. Вершины (сущности) и связи (ребра) такого графа могут иметь различную природу: скажем, вершинами могут быть сотрудники и подразделения компании, а рёбра могут отвечать отношениям «Х работает в подразделении Y», «X и Z коллеги» и так далее.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Графовые нейронные сети",
    "url": "https://education.yandex.ru/handbook/ml/article/grafovye-nejronnye-seti",
    "section_title": "Задачи на графах",
    "text": "Разнообразие графовых данных закономерно породило множество разнообразных задач, которые решаются на этих данных. Среди них можно встретить классические постановки классификации, регрессии и кластеризации, но есть и специфичные задачи, не встречающиеся в других областях — например, задача восстановления пропущенных связей внутри графа или генерации графов с нужными свойствами. Однако даже классические задачи могут решаться на различныхуровнях: классифицировать можно весь граф (graph-level), а можно отдельные его вершины (node-level) или связи (edge-level). Так, в качестве примераgraph-levelзадач можно привести классификацию и регрессию на молекулярных графах. Имея датасет с размеченными молекулами, можно предсказывать их принадлежность к лекарственной категории и различные химико-биологические свойства. Наnode-level, как правило, классифицируют вершины одного огромного графа, например, социального. Имея частичную разметку, хочется восстановить метки неразмеченных вершин. Например, предсказать интересы нового пользователя по интересам его друзей. Часто бывает такое, что граф приходит полностью неразмеченным и хочетсябез учителяразделить на компоненты. Например, имея граф цитирований, выделить в нем подгруппы соавторов или выделить области исследования. В таком случае принято говорить оnode-levelкластеризации графа. Наконец, довольно интересна задача предсказания пропущенных связей в графе. В больших графах часто некоторые связи отсутствуют. Например, в социальном графе пользователь может добавить не всех знакомых в друзья. А в графе знаний могут быть проставлены только простые взаимосвязи, а высокоуровневые могут быть пропущены. В конце, хотелось бы отметить очень важные особенности всех задач, связанных с графами. Алгоритмы решения этих задач должны обладать двумя свойствами. Во-первых, графы в датасетах, как правило, могут отличаться по размерам: как по количеству вершин, так и по количеству связей. Алгоритмы решения задач на графах должны уметь принимать графы различных размеров. Во-вторых, алгоритмы должны быть инварианты к перестановкам порядка вершин. То есть если взять тот же граф и перенумеровать его вершины, то алгоритмы должны выдавать те же предсказания с учетом этой перестановки.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Графовые нейронные сети",
    "url": "https://education.yandex.ru/handbook/ml/article/grafovye-nejronnye-seti",
    "section_title": "Графовые нейронные сети",
    "text": "Развитие глубинного обучения повлияло на подходы к решению задач на графовых данных. Был предложен концептграфовых нейронных сетей, которые в последнее время либо полностью заменили классические алгоритмы обработки графов, либо породили мощные синергии с этими алгоритмами. Графовые нейронные сети по принципу работы и построения идейно очень похожи на сверточные нейронные сети. Более того, забегая немного вперед, графовые нейроные сети являютсяобобщениемсверточных нейронных сетей. На вход графовой нейронной сети подается граф. В отличие от сверточных нейронных сетей, которые требуют, чтобы все картинки в батче были одинакового размера, графовые нейронные сети допускают разные размеры у объектов батча. Кроме того, в отличие от картинок, у которых информация довольно однородна (это, как правило, несколько цветовых каналов) и хранится в пикселях, у графов информация может также храниться в вершинах и/или ребрах. Причем в одних задачах информация может быть только в вершинах, в других только в ребрах, а в третьих и там, и там. Сама информация может быть довольно разнородной: это могут быть и вещественные значения, и дискретные значения, в зависимости от природы графа и от типа решаемой задачи. Поэтому, довольно часто первым слоем в графовых нейронных сетях идут Embedding слои, которые переводят дискретные токены в вещественные векторы. Однако, сама суть работы у графовых и сверточных сетей совпадает. В графовой нейронной сети по очереди применяются слои, которые собирают информацию с соседей и обновляют информацию в вершине. То же самое делают и обычные свертки. Поэтому такие слои и называютсяграфовыми свертками. Графовая свертка принимает на вход граф со скрытыми состояниями у вершин и ребер и выдает тот же граф, но уже с обновленными более информативными скрытыми состояниями. В отличие от сверточных нейронных сетей, при обработке графа pooling слои вставляют редко, в основном в graph-level задачах, при этом придумать разумную концепцию графового пулинга оказалось нелегко. Если вам станет интересно, вы можете познакомиться с несколькими вариантами графовых пулингов в следующих статьях: Learning Spectral Clustering Kernel k-means, Spectral Clustering and Normalized Cuts Weighted Graph Cuts without Eigenvectors В большинстве же архитектур пулинги не используются, и структура графа на входе и выходе графовой нейронной сети совпадает. Полученная после череды сверток информация с вершин и ребер в конце обрабатывается с помощью полносвязных сетей для получения ответа на задачу. Для node-level классификации и регрессии полносвязная сеть применяется к скрытым состояниям вершин, а для edge-level, соответственно, к скрытым состояниям ребер. Для получения ответа на graph-level уровне информация с вершин и ребер сначала агрегируется с помощьюreadoutоперации. На месте readout операции могут располагаться любые инвариантные к перестановкам операции: подсчет максимума, среднего или даже обучаемый self-attention слой. Как говорилось ранее, графовые нейронные сети являются обобщением сверточных. Если представить пиксели изображения вершинами графа, соединить соседние по свертке пиксели ребрами и предоставить относительную позицию пикселей в информации о ребре, то графовая свертка на таком графе будет работать так же, как и свертка над изображением. К графовым нейронным сетям, как и к сверточным, применим терминreceptive field. Это та область графа, которая будет влиять на скрытое состояние вершины после N сверток. Для графов receptive field после N графовых сверток — это все вершины и ребра графа, до которых можно дойти от фиксированной вершины не более чем за N переходов. Знание receptive field полезно при проектировании нейронной сети - имея представление о том, с какой окрестности вершины надо собрать информацию для решения задачи, можно подбирать нужное количество графовых сверток. Многие техники стабилизации обучения и повышения обобщаемости, такие как Dropout, BatchNorm и Residual Connections, применимы и к графовым нейронным сетям. Однако стоит помнить про их особенности. Эти операции могут независимо применяться (или не применяться) к вершинам и ребрам. Так, если вы применяете Dropout, то вы вправе поставить для вершин и для рёбер различные значения dropout rate. Аналогично и для Residual Connections - они могут применяться только для вершин, только для ребер или же и там и там. Кроме того, стоит иметь ввиду, что графы различных размеров будут неравноценно влиять на среднее и дисперсию в BatchNorm слое. Более стабильной альтернативой BatchNorm в обработке графов, например, являютсяLayerNormиGraphNorm, которые производят нормировку активаций по каждому графу независимо. LayerNorm, по сути, применяет BatchNorm для каждого графа: A вот GraphNorm содержит несколько обучаемых параметров и является более гибким вариантом нормализации:",
    "source_type": null,
    "useful_links": [
      {
        "text": "Learning Spectral Clustering",
        "url": "https://www.di.ens.fr/~fbach/nips03_cluster.pdf"
      },
      {
        "text": "Kernel k-means, Spectral Clustering and Normalized Cuts",
        "url": "https://www.cs.utexas.edu/users/inderjit/public_papers/kdd_spectral_kernelkmeans.pdf"
      },
      {
        "text": "Weighted Graph Cuts without Eigenvectors",
        "url": "https://www.cs.utexas.edu/users/inderjit/public_papers/multilevel_pami.pdf"
      },
      {
        "text": "LayerNorm",
        "url": "https://arxiv.org/pdf/1607.06450.pdf"
      },
      {
        "text": "GraphNorm",
        "url": "https://arxiv.org/pdf/2009.03294.pdf"
      }
    ]
  },
  {
    "document_title": "Графовые нейронные сети",
    "url": "https://education.yandex.ru/handbook/ml/article/grafovye-nejronnye-seti",
    "section_title": "Парадигмы построения графовых сверток",
    "text": "Важно отметить, что в отличие от свертки, применяемой для изображений, являющейся четко определенной операцией, графовая свертка представляет собой именно концепт, абстрактную операцию, обновляющую скрытые представления объектов графа, используя доступную информацию с соседей и ребер. На практике, конкретный механизм графовой свертки разрабатывается для конкретной задачи, и различные реализации графовых сверток могут очень сильно отличаться между собой. И если зайти на сайты популярных фреймворков глубинного обучения на графах (например,PyG), то можно обнаружить десятки различных реализаций графовых сверток. Во-первых, графовые свертки отличаются между собой по тому набору информации, которые они могут использовать. Есть свертки, которые используют только скрытые представления вершин, игнорируя информацию на ребрах. Существуют свертки, которые по разному обрабатывают информацию от ребер различного типа. А есть свертки, которые используют информацию с ребер и вершин, обновляя одновременно и те и другие. Во-вторых, и что более важно, графовые свертки можно разделить на два семейства, которые отличаются математической парадигмой, в которой они работают. Есть spatial (пространственный) и spectral (спектральный) подходы. Пространственные свертки основываются на message-passing парадигме, в то время как спектральные работают с графовым лапласианом и его собственными векторами. На практике, спектральные свертки чаще применяются и показывают лучшие результаты в задачах связанных с обработкой одного большого графа, где важно понимать относительное месторасположение вершины в этом большом графе. Например, графа соцсетей или графа цитирований. Пространственные свертки показывают хорошие результаты в остальных задачах, где для решения задачи важно находить локальные подструктуры внутри графа. Несмотря на принципиальную противоположность этих двух подходов, активно предпринимаются попытки их совмещения в одну парадигму, например, в этойработе. Давайте разберемся с этими двумя парадигмами. Пространственная (spatial) парадигма основывает на алгоритме передачи сообщений (message passing) между вершинами графа. Концепт этого подхода заключается в следующем - каждая вершина графа имеет внутреннее состояние. Каждую итерацию это внутреннее состояние пересчитывается, основываясь на внутренних состояниях соседей по графу. Каждый сосед влияет на состояние вершины, так же как и вершина влияет на состояния соседей. Итерация работы Message passing подхода для одной вершины можно описать следующим абстрактным алгоритмом. Для каждой вершинысобираются все тройкисостоящие из скрытых представлений текущей вершини ее соседа, а также из типа ребра,соединяющего текущую вершину и её соседа. Ко всем этим тройкам применяется обучаемое преобразование(от слова message), которая считает сообщение — информацию, которая идет от соседа к вершине. Посчитанные сообщения агрегируются в одно, обозначаемое. Сообщения могут быть сагрегированы любой ассоциативной операцией, например взятием поэлементного минимума, максимума или среднего. Далее, агрегированное сообщение и текущее внутреннее состояние вершины подаются на вход обучаемой операции(от слова update), которая обновляет внутреннее состояние вершины. Конкретные имплементации операцийнепосредственно зависят от алгоритма и той задачи, которую он решает. Одним из самых известных классических алгоритмов, построенных на пространственной парадигме, является PageRank. АлгоритмPageRankпроходит по графу веб страниц и выставляет каждой веб-странице значение ее \"важности\", которое впоследствии можно использовать для ранжирования поисковой выдачи. Формула подсчета PageRank выражается через коэффициент затухания, а также значения PageRank соседейвершины и количество исходящих ссылок из этих соседейследующим образом: В такой постановке операции подсчета сообщенийи операции обновленияимеют следующий вид: Графовые свертки, работающие на парадигме передачи сообщений, как правило делаютиобучаемыми преобразованиями. Рассмотрим несколько конкретных примеров архитектур. СверткаGraphSAGEработает по следующему принципу. Для каждой вершины вычисляется набор скрытых представлений соседних вершин, из которых идут связи в текущую. Далее, собранная информация агрегируется с помощью некоторой коммутативной операциив вектор фиксированного размера. В качестве операции агрегации авторы предлагают использовать операции взятия средних или максимальных значений скрытых представлений объектов из набора. Далее агрегированный вектор объединяется со скрытым представлением вершины, они домножаются на обучаемую матрицуи к результату умножения поэлементно применяется сигмоида. Обучаемые параметры данного слоя, как и в случае GCN, содержат только одну матрицу. Данная свертка использует только скрытые представления вершин, однако уделяет больше внимания локальному окружению вершины, нежели её глобальному положению во всем графе. Авторы показали высокое качество данной архитектуры в задачах, связанных с выучиванием представлений вершин, однако использование данной свертки можно встретить и в других задачах, связанных с обработкой графов, не содержащих дополнительной информации о рёбрах. СверткаGAT(Graph ATtention) является развитием идеи GraphSAGE. В качестве механизма агрегации эта архитектура предлагает использовать механизм внимания, у которого матрицы преобразования для ключей, значений и запросов совпадают и обозначены в формуле буквой. Как и в GraphSAGE, агрегированное сообщение проходит через сигмоиду, но не домножается перед этим на обучаемую матрицу. Здесь act — некоторая функция активации. Как и в случае механизма внимания для последовательностей, в момент обновления представления для вершиныattention «смотрит» на все остальные вершиныи генерирует веса, которые указывают, информация из каких вершин«важнее» для нас. Благодаря мощности и гибкости механизм внимания, эта свертка показала отличные результаты на множестве задач и является одной из самых популярных сверток. По умолчанию, эта свертка, как и GraphSAGE, использует только признаки вершин, однако, в некоторых проектах можно встретить модификации свертки, в которых механизм внимания учитывает ещё и информацию для ребер. Наконец, есть специально разработанные свертки для обработки графов, ребра которых могут быть нескольких типов. Одна из них называетсяRGCN(Relational Graph Convolutional Networks). Она суммирует скрытые представления соседей, однако каждое представление соседа домножается на матрицу, зависящую от типа ребра, которое соединяет соседа с текущей вершиной. Если в графе присутствует ребратипов, то данная свертка будет учитьматриц - по одной для каждого типа связи. Противоположностью пространственной парадигме является спектральная (spectral) парадигма. В своей постановке спектральная парадигма опирается на анализ процесса диффузии сигнала внутри графа и анализирует матрицы, описывающих граф — матрицу смежности и матрицу, которая называется Лапласианом графа. Лапласиан графа — это матрица, где— диагональная матрица, хранящая в-й диагональной ячейке количество исходящих из-й вершины рёбер, а— матрица смежности графа,-й элемент которой равен числу рёбер, соединяющих-ю и-ю вершину. Лапласиан графа имеет неотрицательные собственные значения. Количество нулевых собственных значений всегда совпадает с количеством компонент связности. Потрясающим свойством Лапласиана является то, что его собственные векторы, соответствующие положительным собственным значениям, в порядке возрастания собственных значений, описывают разрезы графа — его разделения пополам таким образом, чтобы между разделенным половинами было как можно меньше ребер. Так, собственный вектор, соответствующий наименьшему положительному собственному значению, будет описывать кластеризацию графа на два подграфа. Все индексы, соответствующие положительным элементам вектора задают вершины, которые должны оказаться в первом кластере, а отрицательные элементы будут соответствовать вершинам, которые должны оказаться во втором кластере. Этим свойством Лапласиана графа пользуются для того, чтобы проводить кластеризацию графа без учителя. Для этого надо: Посчитать Лапласианматрицы Посчитатьсобственных векторов, соответствующих наименьшим собственным значениям Сформировать из них матрицу размера, каждая строка которой описывает вершинупризнаками Кластеризовать объекты, описываемые этой матрицей (например, c помощью K-Means) Таким образом, спектральный подход отлично подходит для того, чтобы находить в графе компоненты, вершины которых связаны друг с другом и имеют похожие свойства. СверткаGCN, основанная на спектральной парадигме, использует только скрытые состояния вершини матрицу смежности— она учитывает лишь наличие или отсутствие ребра в графе, но не признаки ребер. С математической точки зрения, GCN очень проста и представляет собой один шаг итеративного процесса поиска собственных значений Лапласиана графа: мы берем скрытые представления вершин и домножаем их на нормированную матрицу смежности — матрицу, домноженную слева и справа на матричный корень матрицы. Этот шаг применяется ко всем каналам скрытого представления вершины. После этого шага, обновленные скрытые представления ещё домножаются на обучаемую матрицу: Здесь— это матрица размера (число вершин)(длина вектора представления), то есть к каждому «каналу» представлений свёртка применяется отдельно. Если же мы хотим работать с несколькими каналами, то есть вместоу нас матрицаразмера (число вершин)(число каналов), и ещё добавить нелинейность, формула переписывается следующим образом: Авторы данной свертки показали отличное качество работы в задачах классификации вершин графов цитирования и графа знаний. Однако, различные модификации данной свертки применяются и в других задачах, например, для выучивания векторных представлений вершин и для кластеризации вершин графа.",
    "source_type": null,
    "useful_links": [
      {
        "text": "PyG",
        "url": "https://www.pyg.org"
      },
      {
        "text": "работе",
        "url": "https://arxiv.org/pdf/2107.10234.pdf"
      },
      {
        "text": "PageRank",
        "url": "https://ru.wikipedia.org/wiki/PageRank"
      },
      {
        "text": "GraphSAGE",
        "url": "https://arxiv.org/abs/1706.02216"
      },
      {
        "text": "GAT",
        "url": "https://arxiv.org/abs/1710.10903"
      },
      {
        "text": "RGCN",
        "url": "https://arxiv.org/abs/1703.06103"
      },
      {
        "text": "GCN",
        "url": "https://arxiv.org/abs/1609.02907"
      }
    ]
  },
  {
    "document_title": "Введение в онлайн-обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
    "section_title": "О чём раздел про онлайн-обучение, кому и зачем его читать?",
    "text": "Во многих случаях обучение ML-модели ― это однократный процесс, после которого она не меняется и только используется для предсказания. А что, если к нам постоянно поступает новая информация и мы должны её учитывать? Тогда модель должна уметь обновляться при поступлении нового объекта или батча объектов. Грубо говоря, этим и занимается онлайн-оптимизация. Можно заметить, что обновление модели на батче объектов проходит и в процессе стохастической оптимизации, ― и это сходство не случайно. Оказывается, что все известные вам методы стохастической оптимизации первого порядка ― такие как SGD, AdaGrad, Adam, AMSgrad и другие ― являются в первую очередь алгоритмами онлайн-обучения. Чтобы в этом убедиться, достаточно открыть эти статьи и увидеть, для какой задачи выводятся гарантии на сходимость. Постановка задачи онлайн-обучения является одновременно математически простой и очень общей, соединяя три больших темы: «Классическое» онлайн обучение. Стохастическую оптимизацию на фиксированном датасете. Мы покажем, что любой алгоритм онлайн обучения можно переформулировать, как алгоритм стохастической оптимизации; при этом из гарантий на сходимость, полученных для онлайн обучения, автоматически будет следовать сходимость на фиксированном датасете. Adversarial обучение. Данный текст является в первую очередь систематизирующим. Мы постараемся достичь следующих целей: Подведем единую математическую базу, необходимую для вдумчивого чтения статей по оптимизации. Это будет полезноML-теоретикам. Покажем, как исторически развивались методы оптимизации, как из одного метода получался другой, какие проблемы они решали и ― главное ― актуальны ли эти проблемы сейчас. Разберём все «именные» методы оптимизации на набор базовых концепций и покажем, как вы можете самостоятельно их сочетать, создавая оптимальный метод для решения своей задачи. Спойлер: базовых концепцийнамногоменьше, чем наименований методов. Эти знания будут полезныML-инженерам. Пройдемся по относительно нишевым темам, таким как разреженные методы регуляризациии, и рассмотрим наилучшие методы оптимизации для них. Такие методы невозможно получить в стандартной постановке стохастической оптимизации. Эти знания будут полезныML-инженерам, занимающимся рекомендательными системами. В параграфе «Введение в онлайн-обучение», которую вы читаете сейчас, вы познакомитесь с общей постановкой задачи онлайн-обучения, а также с семейством алгоритмов Follow the Regularized Leader (FTRL), которое включает в себя все методы первого порядка. Кроме того, вы узнаете, как сводить задачи стохастической оптимизации к задачам онлайн-обучения и увидите, что этот переход позволяет строить более эффективные методы стохастической оптимизации, особенно для разреженных регуляризаторов вроде. В параграфе «Адаптивный FTRL» вы узнаете, как улучшить сходимость алгоритмов стохастической оптимизации с помощью регуляризаторов и каковы гарантии сходимости для регуляризованных задач. Это позволит вывести AdaGrad как наилучший адаптивный метод для онлайн-оптимизации. В параграфе «Регуляризация в онлайн-обучении» мы снова поговорим о регуляризации, но на этот раз речь пойдёт о регуляризаторах, которые накладывают на решение определённые органичения, например, разреженность. Вы сможете с новой стороны взглянуть на разреживающие свойства-регуляризаторов. Кроме того, мы получим не достижимые с помощью обычных SGD/AdaGrad результаты для разреженныхирегуляризаторов. В параграфе «Стохастическая оптимизация в Deep Learning» мы перейдём к методам оптимизации в глубоких нейросетях. Вас ждёт краткий исторический обзор и мотивация появления двух важных модификаций AdaGrad ― Adam и RMSprop. Мы покажем, что эти методы ломаются вокруг критических точек, и поговорим о том, как починить это и достичь более точной сходимости (этого эффекта можно достичь либо прямой модификацией алгоритмов (AMSgrad и RAdam), либо косвенно с помощью Learning Rate Scheduler'ов). В конце параграфа мы соберём воедино все рассмотренные концепции и покажем, как можно комбинировать лучшее из разных методов оптимизации в один новый метод.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Адаптивный FTRL",
        "url": "https://academy.yandex.ru/handbook/ml/article/adaptivnyj-ftrl"
      },
      {
        "text": "Регуляризация в онлайн-обучении",
        "url": "https://academy.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii"
      },
      {
        "text": "Стохастическая оптимизация в Deep Learning",
        "url": "https://academy.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning"
      }
    ]
  },
  {
    "document_title": "Введение в онлайн-обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
    "section_title": "Постановка задачи",
    "text": "Литература. Отсюда и далее, пока явно не скажем о переходе на другие источники информации, используется материал из книги Shai Shalev-ShwartzOnline Learning and OnlineConvex Optimization Онлайн-обучение ― это процесс предсказания ответов на последовательность вопросов с учётом знания (возможно, неполного) о предыдущих правильных ответах. Представим себе следующую игру (назовём еёигра (1)). На каждом раунде игрымы: Получаем― частичную информацию о текущем «вопросе»; Выбираем модель, которой будем делать прогноз; Прогнозируем; Получаем истинный ответ; Получаем обратную связь-лосс. Лоссы обычно имеют семантику функции ошибки: больше ― хуже, меньше ― лучше. Цельлюбогоалгоритма онлайн обучения ― минимизация суммарной ошибки прогнозовдля любого количества раундов. Пока рассмотрим интуитивный пример: линейная регрессия (обозначения взяты изпараграфа про линейные модели). Пусть у нас уже сыграны раундыи есть выборка данныхи ответов. Получаем новый. В данном случае просто получаем и пока не используем; Выбираем модель, которая наилучшим образом объясняет всю предыдущую имеющуюся выборку(алгоритм обучения можем выбирать любой, какой нам нравится); Прогнозируем; Получаем правильный ответ; Считаем loss; Действуя таким образом, мы делаем интуитивное предположение, что ответыкак-то зависят от нашихи что эту зависимость мы можем выучить из предыдущей выборки, улучшив прогноз на новых объектах. Теория онлайн обучения выгодно отличается от классической теории статистического обучения довольно расслабленными и гораздо более простыми (с точки зрения математических формулировок) условиями. Мыне делаемпредположений о некой статистической зависимости между,. Зависимость может быть детерминированной, стохастической или даже adversarial: Детерминированная: в самом начала игры делается выбор детерминированной зависимости Стохастическая:может быть реализациями случайной величины, зависящей от Adversarial: мы играем против активного противника, который может на каждом раунде игры по своему усмотрению менять зависимостьи/или подбирать, имея на рукахв том числе текущий ответ, не доступный алгоритму онлайн-обучения Adversarial постановка включает в себя все остальные как частные случаи, так что сразу будем строить теорию для наиболее общего случая. Начнем с введения метрики качества алгоритма на некотором раунде игры, а затем расширим ее на все раунды игры. Если у противника нет никаких ограничений, то противник всегда выигрывает. Посколькувыбираетсяпосленашего прогноза, он может выбрать любую функцию с сколь угодно большим штрафом. Чтобы такого не случалось, мы предположим, что все ответы на шагедолжны быть сгенерированы некоторым отображением, где― пространство возможных решений,известное и онлайн-алгоритму, и противнику. С учетом введенного ограничения на поведение противника, введем понятиеregret: Regret ― это метрика того, насколько онлайн алгоритм работает хуже, чем некоторая фиксированная модель-бейзлайн h (regret переводится как «сожаление»: насколько мы пожалели о том, что взяли онлайн алгоритм, а не модель h). Поскольку мы работаем в adversarial случае, то логично сравнивать наш онлайн алгоритм с сильнейшим возможным противником, а именно: противник всегда выбирает не «некоторую», анаилучшую модель-бейзлайн: Вспомним, что вообще-то мы играем игру с бесконечным числом раундов. В таком случае, естественно будет анализировать поведение ряда. Здесь хочется еще раз подчеркнуть, в чем заключается adversarial поведение: на каждом шаге t maxRegret будет иметьсвоюнаилучшую модельв бейзлайне: Когда мы говорим про adversarial setting и игру с противником, мы хотим не просто как-то минимизировать кумулятивный, но еще и хотим бытьне хуже нашего противника. Потребуем, чтобы Такое условие означает, что regret должен расти медленнее чем линейно (в таком случае говорят, что алгоритм имеетсублинейный regret). Сублинейности бывают разные. Так,может быть ограничен сверху рядом с асимптотикойили же рядом с асимптотикой Асимптотика, очевидно, приводит к намного лучшей сходимости. Но достичь этого не всегда возможно.Стандартнойасимптотикой regret в большинстве используемых на практике алгоритмов является, для этой асимптотики условия на задачу наименее жесткие. Все рассматриваемые нами ниже алгоритмы будут иметь асимптотикуи отличаться в основном константами в оценках (но, конечно, отличия в константах при оценке Regret часто приводят к существенно разному поведению на практике). Любые более мощные асимптотики требуют условий, которые крайне редко выполняются в практических задачах В данном обзоре мы будем анализировать методы, которые гораздо чаще используются для оптимизации в классической постановке: есть фиксированный датасет, модельс обучаемыми параметрамии функция потерь, задача ― найти минимум функции Если представить, что все наши― независимые одинаково распределенные случайные величины, то можно считать, что на самом деле мы оптимизируем Такую постановку задачи часто называть батчевой (англ. batch). Это означает, что мы можем использовать два класса методов оптимизации: методы, которые на каждом шаге смотрят сразу на всю выборку (например, градиентный спуск или метод Ньютона); методы, которые на каждом шаге смотрят на случайное подмножество данных в надежде, что, итерируясь по таким подмножествам, мы сможем соптимизировать матожидание(например, SGD). Такие методы называют стохастическими. Существует специальный класс методов анализа сходимости, называемый online to batch conversion. Они позволяют адаптировать алгоритм онлайн-обучения к постановке задачи стохастической оптимизации на фиксированном датасете; при этом оценка на regret транслируется в асимптотику сходимости стохастической оптимизации. Математически строгий вывод этих методов обычно довольно громоздкий и не дарит более глубокого понимания идей в современных стохастических методах, это чисто технические выкладки, поэтому мы здесь ограничимся интуитивным описанием. Строгий вывод можно найти, например, в упомянутой выше книге Shai Shalev-Schwartz. Процесс стохастической оптимизации на фиксированном датасете можно представить в виде задачи онлайн обучения, если вытянуть все эпохи (проходы по датасетам) в единую последовательность. Мы получим задачу онлайн обучения, в которойсэмплируются из фиксированного множества. Строго говоря, тут сэмлпирование двухстадийное: Берем исходное множество функций Сэмплируем из него без возвращения, пока множество не станет пустым Как только оно стало пустым ― заново заполняем его Таким образом, деление на \"эпохи\" отчетливо видно и в вытянутой последовательности. Легко видеть, что эта задача является корректной задачей онлайн обучения. Тут мы активно пользуемся тем, что постановка задачи онлайн обучения математически простая и очень общая. Из корректности данной задачи следует, что все алгоритмы онлайн обучения будут иметь на такой последовательности сублинейный regret. Следующим шагом давайте взглянем на regretв момент смены эпохи. Обозначим за―число эпох, тогда: Из сходимости последовательности следует сходимость любой ее подпоследовательности, а значит, последовательность regret'ов в моменты смены эпох тоже ведет себя сублинейно: Последнее слагаемое уже выглядит практически как постановка задачи стохастической оптимизации на фиксированном датасете! Интуиция на данный момент подсказывает нам, что разрыв между решениями, даваемыми онлайн обучением, и точным решением задачи батч-оптимизации, будет постепенно сокращаться. В этот момент интуицию можно выключать―остаются только строгие технические выкладки по ссылкам выше.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Online Learning and OnlineConvex Optimization",
        "url": "https://www.cs.huji.ac.il/w~shais/papers/OLsurvey.pdf"
      },
      {
        "text": "параграфа про линейные модели",
        "url": "https://academy.yandex.ru/handbook/ml/article/linejnye-modeli"
      }
    ]
  },
  {
    "document_title": "Введение в онлайн-обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
    "section_title": "Выпуклая онлайн-оптимизация",
    "text": "Выпуклая оптимизация играет центральную роль в анализе алгоритмов онлайн-обучения и позволяет получать эффективные алгоритмы. Вот примеры задач, в которых она хорошо работает: Линейная оптимизация; Expert Advice problem; Линейная/логистическая регрессия. Для задач, возникающих в глубинном обучении, мы поступим согласно рекомендациям ведущих ученых: возьмем теоретически обоснованный алгоритм выпуклой оптимизации, воткнем в нейросеть и помолимся, чтобы он сохранил свои хорошие свойства. С методами первого порядка, как правило, работает (а здесь мы будем рассматривать только такие методы) Введём в нашу игру предположение о выпуклости, а заодно попробуем сделать вычисления менее громоздкими. Для этого определим упрощённуюигру (2): Выбираем параметрическую модель; Получаем извневыпуклуюфункцию потерь; Считаемв точкеи получаем наш loss. Первое упрощение состоит в том, что прогнози бейзлайнмы теперь берём не из абстрактного функционального множества, а из некоторого параметризованного семейства. Говоря «модель», мы имеем в виду «модель, заданная параметрами». Скажем, для линейной регрессии это может быть вектор весов и bias. Regret будет записываться следующим образом: Второе упрощение в том, что мы не думаем о признакахи таргетах. Вся эта информация спрятана в определение функции. Например, для линейной регрессии. При этом теперь у нас нет частичной информации о текущем раунде игрыпередвыбором новой модели: ведь мы сначала выбираеми лишь потом получаем. Обратите внимание: если вы попробуете себе представить онлайн алгоритм на практике, то, как правило, частичная информация о функцииперед выборомвамдоступна. Например, рассмотрим рекомендательную систему с онлайн-дообучаемой ранжирующей моделью: Пользователь пришел, мы сразу пошли в базу данных за его историей покупок и получили признаковое описание (возможно частичное); С учётом этого признакового описания мы выбираем модельи с её помощью оцениваем релевантность товаров этому пользователю; Смотрим, что купил пользователь и купил ли, это даёт нам. Тем не менее, в этом параграфе мы будем считать, что частичной информации нет, потому что хотим разрабатывать наиболее общий фреймворк, а не ad-hoc алгоритмы, использующие конкретный вид этой частичной информации. Если даже для какой-то узкой проблемы можно сформулировать специфический алгоритм, учитывающий частичную информацию, с высокой вероятностью он не будет работать значимо лучше стандартного решения. Если знаете контрпримеры ― напишите, добавим сюда для полноты.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Введение в онлайн-обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
    "section_title": "Follow the Leader",
    "text": "Предположим, что мы провелишагов игры (2) и теперь выбираем модель(как условились, без информации о). Наиболее естественным выбором будет алгоритм, минимизирующий ошибку на всех предыдущих раундах Такой алгоритм называетсяFollow The Leader (FTL), потому что мы идем вплотную за наилучшим возможным алгоритмом-бейзлайном в regret (лидером), который учитывает ещё и информацию с-го шага: К сожалению, для алгоритма в таком виде есть важные примеры выпуклых задач, когда он не работает. Допустим, наши функции потерь линейны. Вам может показаться, что линейная функция не особенно похожа на функцию потерь, но, забегая вперед, именно такие функции потерь встретятся дальше при изучении градиентных онлайн-алгоритмов (). Рассмотрим одномерную задачу,,. Пусть Алгоритм FTL выглядит так: Такие осциллирующие суммы коэффициентов будут заставлять FTL выбирать наихудшее возможное решение в каждом раунде. Функция потерь в каждом раунде будет равна, а кумулятивная функция потерь примет вид. При этом кумулятивная функция потерь константного решениябудет равна 0. Получаем линейный regretотносительно бейзлайна, алгоритм не сходится.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Введение в онлайн-обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
    "section_title": "Follow The Regularized Leader",
    "text": "Чтобы стабилизировать алгоритм, мы добавим регуляризаторы, и назовем получившийся алгоритмFollow The Regularized Leader (FTRL): Упражнение. Проверьте, что в примере из предыдущего параграфа добавление регуляризатора стабилизирует осцилляцию решения. Добавкадолжна быть выпуклой и неотрицательной. При этом различный выборбудет приводить к различным алгоритмам и различным оценкам на regret. Первое, что приходит в голову ― эторегуляризатор. Он даёт алгоритм",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Введение в онлайн-обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
    "section_title": "Adaptive FTRL",
    "text": "Следующая идея―сделать регуляризатор зависящим от данных (то есть от) и своим на каждом раунде T: Забегая вперед―все современные градиентные алгоритмы Adam, RMSProp, AdaGrad и т.д. попадают в это семейство data-dependent регуляризаторов и работаютзначительноэффективнее любых алгоритмов с константными регуляризаторами. Обратите внимание: регуляризаторы являются частью алгоритма FTRL, онине входятв формулу для regret, которая по-прежнему имеет вид Таким образом, мы не изменили постановку решаемой нами задачи, изменили лишь метод ее решения. Обратите внимание: введение регуляризаторов влияеттолькона онлайн-алгоритм и выбор. Бейзлайнывыбираются как и раньше:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Введение в онлайн-обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
    "section_title": "Линеаризация и вычислительно эффективный FTRL",
    "text": "Рассмотрим пример с логистической регрессиейи константнымрегуляризатором: Классический пример использования онлайн логистической регрессии ―предсказание CTR в рекламе. Миллионы запросов в секунду =>миллионы решений этой оптимизационной задачи в секунду (если разбивать на батчи ― тысячи, но сути это не меняет). Успех онлайн-алгоритма в таких задачах определяется его вычислительной эффективностью, как по памяти, так и по скорости. Увы, с этим у нашего алгоритма не всё так хорошо: Скорость: аналитически задача не решается =>FAIL Память: нужно хранить все предыдущие запросы,=>FAIL Здесь нам на помощь приходит линеаризация задачи. Если фунциивыпуклые (вниз) и гладкие (на негладкие посмотрим позже), то они удовлетворяют основному свойству выпуклых функций Разложим все функциив точках: Просуммируем от 1 до Теперь обозначими рассмотрим выпуклуюлинейнуюзадачу онлайн обучения с функцией потерь. Regret для нее выглядит как Неравенство выше позволяет нам оценить regret исходной задачи через regret линеаризованной: Минимизируя правую часть неравенства, мы, безусловно, будем минимизировать и левую, так что мы можем выбиратьалгоритмом, решающим линеаризованную задачу, и получать хорошо сходящийся метод для исходной задачи. Посмотрим, будет ли линеаризованный алгоритм вычислительно эффективнее. Посмотрим на линеаризацию задачи с data-depedent регуляризатором: Линейные задачи имеют аналитическое решение для широкого спектра. Собственно, это и есть основное, что нужно помнить на практике ― выбирать регуляризатор так, чтобы эта задача решалась аналитически. Мы рассмотрим простейший случай: Справа дифференцируемая функция, так что мы можем найти, приравняв к нулю градиент: где― это сумма векторов, которую не нужно пересчитывать заново на каждом шаге, а можно инкрементально обновлять. Благодаря этому нам больше не нужно помнить все предыдущие объекты выборки, достаточно хранить лишь некоторую статистику. Готово, мы построили наш первый вычислительно эффективный алгоритм онлайн обучения! В дальнейшем мы займемся тем, чтобы найтинаилучшийвычислительно эффективный алгоритм. Обратите внимание: теперь вы понимете, почему пример с линейной функцией потерь был так важен: линейные функции соответствуют линеаризованному regret. При этом, как мы уже выяснили, без регуляризатора такие линеаризованные задачи нестабильны. Обратите внимание: если переписать немного формулу для, мы получим: Таким образом, формулы FTRL c константным регуляризаторомэквивалентны формулам обычного стохастического градиентного спуска. Забегая вперед, скажем, что различия в формулах градиентного спуска и FTRL будуттольков разделе Composite objective FTRL. В этих отличиях и будет заключаться преимущество FTRL перед привычным SGD. Обратите внимание: концепции FTRL и gradient descent в литературе часто называютlazy(ленивая) иgreedy(жадная) соответственно. Gradient descent жадный, потому что алгоритм для обновленияиспользует только текущийи текущий градиент. Всё, что было на предыдущих шагах, алгоритм забывает. FTRL ленивый, потому что алгоритм в явном виде сохраняет всю информацию с начала обучения и рассчитывает, исходя из всей истории, и только после этого применяет все регуляризаторы. Подробнее мы расскажем об этом в разделе «Сравнение Composite Objective FTRL-Proximal и Adaptive Gradient Descent».",
    "source_type": null,
    "useful_links": [
      {
        "text": "предсказание CTR в рекламе",
        "url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41159.pdf"
      }
    ]
  },
  {
    "document_title": "Введение в онлайн-обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/onlajn-obuchenie-i-stohasticheskaya-optimizaciya",
    "section_title": "Субдифференциал и субградиентные методы",
    "text": "Выше мы рассматривали гладкие функции. Гладкость ― сильное ограничение, и оно на самом деле необязательно, можно ослабить условие, если использовать субградиенты. Когда мы переходили от исходной задачи к линеаризованной, мы использовали основное свойство гладких выпуклых функций Гладкость обеспечивает существованиедля всех. Но нам ведь не нужно, чтобы существовал именноградиентфункции. Нам достаточно, чтобы существовалкакой-товектор, для которого выполнено неравенство И в этом помогают следующие два понятия. Субдифференциаломфункциив точкеназывается множество Субградиентомфункциив точкеназывается любой элемент множества. Потребуем, чтобы для любой точки был непустой субдифференциал, и дело в шляпе, можно вместовезде подставлять субградиенти обобщить все выкладки выше на негладкий случай. Примеры. Для гладких функций субдифференциал состоит из одной точки: градиента функции, а субградиент равен градиенту. В качестве примера функции с нетривиальным субградиентом рассмотрим функцию, где― скаляр. Субградиент в точке― это можество Легко видеть, что― это отрезок. Замечание. На практике субдифференциал используют не так часто. Оптимизационные задачи с популярными негладкими регуляризаторамирешают «в лоб», без перехода к субградиентной оценке, например, с помощьюпроксимальных методов. Обратите внимание. В литературе очень часто используется термин Online Mirror Descent. Mirror descent ― это оптимизационная процедура вида в которой― дополнительный негладкий регуляризатор (например, тот же), который мы как раз таки не заменяем на субградиентную оценку, а вместо этого оптимизируем всё «в лоб». Заметьте, что эти формулыидентичныформуламProximal Gradient Descent. Если у нас нет регуляризатора, то формулы эквивалентны обычному gradient descent. Как вы увидите дальше, Mirror Descent ― это частный случай общего фреймворка, который мы описываем. Почти все градиентные методы оптимизации обобщаются на негладкие функции. Модифицируется необходимое и достаточное условие минимума для выпуклых функций: точкаявляется минимумом, если субдифференциал содержит ноль:. Очевидно, это прямое обобщение условия для гладких функций, где субдифференциал состоит только из градиента функции.",
    "source_type": null,
    "useful_links": [
      {
        "text": "проксимальных методов",
        "url": "https://ysda_trove.gitlab.io/ml-handbook/chapters/optimization/proximal"
      },
      {
        "text": "Proximal Gradient Descent",
        "url": "https://ysda_trove.gitlab.io/ml-handbook/chapters/optimization/proximal"
      }
    ]
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "Вступление",
    "text": "Для обучения и проверки качества ML-модели необходимы данные, размеченные человеком. Студенты обычно получают эти данные уже в готовом виде, но в работе над реальными продуктами задачи по сбору и разметке приходится решать самостоятельно, учитывая специфику конкретного продукта. Готовые наборы зачастую однообразны, а иногда и вовсе мешают достичь требуемых результатов: так, модели компьютерного зрения для беспилотного транспорта необходимо обучать на данных, собранных в той же среде, где используется модель. Кроме того, высокие темпы развития нейросетевых технологий провоцируют все большую необходимость в крупных объемах данных: чем лучше текущее качество модели, тем больше новых данных требуется, чтобы поднять это качество на новый уровень. Как следствие, сбор и разметка данных становится неотъемлемой частью почти любого ML-производства, а качество и количество этих данных напрямую влияет на качество конечного продукта. Краудсорсинг зарекомендовал себя, как один из эффективных способов сбора и разметки данных в больших масштабах. Его используют в разработке новых технологий, чтобы создавать обучающие датасеты для ML-моделей беспилотных автомобилей, голосовых помощников, чат-ботов, поисковых систем и других разработок. Качественные данные удается собрать благодаря краудсорсинговым платформам: они помогают снизить количество ошибок с помощью специальных настроек, которые можно найти на платформе, а также дают доступ к огромному количеству исполнителей, способных в любое время присоединиться к работе. Также секрет успеха кроется в той последовательности действий, которые нужно соблюдать, создавая проект на карудсорсинговой платформе. Участникам краудсорсинговых платформ под силу выполнить не все задания, а только простые: сложные задания нужно разбивать на несколько небольших. Качество выполняемой ими работы нужно проверять с помощью доступных на платформе инструментов контроля качества. Полученные результаты в некоторых случаях нужно правильно обрабатывать (здесь полезно разобраться в способах агрегации данных). Чтобы исполнители получили оплату только за правильно выполненные задания, нужно сформулировать подходящую модель ценообразования и т. д. Нюансов в работе с краудсорсингом достаточно много, поэтому мы подготовили этот параграф в учебник. Стоит отметить, что в ней мы уделим внимание нетехническим аспектам краудсорсинга для ML. Такой уклон связан с тем, что использование краудсорсинга в качестве инструмента работы с данными требует не только знания технических и математических методов (они пригодятся в финальной части, когда полученные данные необходимо будет обработать), но и умения правильно организовать процесс сбора данных, понимания самого феномена краудсорсинга, который сегодня используется в разных сферах для решения разных задач.По этой причине структура этого параграфа будет выглядеть следующим образом: В первой части мы сделаем общий обзор краудсорсинга в ML и объясним, для каких задач он применим. Во второй части мы остановимся на основных этапах запуска краудсорсингового проекта: от деления проекта на небольшие задачи до обработки полученных от исполнителей данных. Кроме того, в этом параграфе мы разберем примеры некоторых ML-задач, которые встречаются в проектах в сфере AI и ML. Это сбор данных для поисковых сетей, разметка изображений для беспилотных автомобилей и сбор аудиозаписей для голосовых помощников. Надеемся, что вам будет интересно погружаться в мир краудсорсинга для ML. Будем рады, если мы поможем вам разложить все по полочкам, чтобы вы смогли дальше наращивать свои знания и изучать отдельные темы более глубоко.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "Что такое краудсорсинг в ML?",
    "text": "Существует довольно много определений краудсорсинга, а также близких к нему по значению терминов (например, «человеческие вычисления», «мудрость толпы» и «коллективный разум»). Это связано с тем, что этот метод используется в разных сферах и применяется для решения разного рода задач, в том числе поиска креативных идей, создания контента, сбора денежных средств. Например, автор термина «краудсорсинг», Джефф Хоу, в 2006 году предложил следующее определение этого метода: Краудсорсинг (от англ. crowd — «толпа», source — «использование ресурсов») — это процесс, в котором компания переносит определенные функции, ранее возлагавшиеся на сотрудников, аутсорсинговые предприятия и поставщиков, на неопределенное, достаточно большое количество людей в формате открытого запроса. Это определение отражает основную идею краудсорсинга. Однако его недостаточно в контексте рассматриваемой нами темы. Мы говорим о краудсорсинге в машинном обучении. Это значит, что мы передаем облаку исполнителей те задачи, которые связаны со сбором и разметкой данных, а также с оценкой этих данных для разного рода проектов. Разработчики используют эти данные, чтобы обучать машины, а именно модели этих машин, выполнять требуемые задачи. Поэтому в машинном обучении краудсорсинг — это дополнительный вычислительный кластер, который помогает командам создавать и улучшать их продукты. Один из первых проектов, который задействовал краудсорсинг в получении данных для обучения модели, — проектDistributed Proofreaders(с англ. — «Распределенные корректоры»). Его главная цель — цифровизация печатных книг с помощью программы для оптического распознавания символов (OCR). Вовлекая тысячи волонтёров, проект Distributed Proofreaders оцифровывает печатные книги и улучшает программу для распознавания текстов. Чем больше данных модель этой программы получает от волонтеров, тем лучше она считывает текст с отсканированных страниц книг. Соответственно, чем лучше становится эта модель, тем меньше времени и усилий человека требуется для того, чтобы находить и исправлять ее ошибки. Рассмотрим этот проект подробнее: Добровольцам предлагают сравнить отсканированное изображение страницы и текст этой страницы, распознанный с помощью программного обеспечения для оптического распознавания символов (OCR). Поскольку программа оптического распознавания текста не справляется с задачей в полном объеме, в тексте часто появляются ошибки. Задача добровольца — исправить ошибки OCR и загрузить файл обратно на сайт. Выполненная работа передается второму добровольцу, он проверяет ее, исправляет ошибки. Книга аналогичным образом проходит третий этап корректуры и два этапа форматирования с использованием одного и того же веб-интерфейса. После того, как все страницы книги прошли через несколько этапов проверки, постпроцессор собирает их в электронную книгу и отправляет в архив проекта«Гутенберг». Отредактированные страницы книг в дальнейшем используются разработчиками, как данные для обучения OCR. Модель программы обучается на данных и в дальнейшем совершает меньше ошибок при распознавании текста на изображениях. Другой пример использования краудсорсинга в ML — сервисreCaptcha. Он был запущен учеными Университета Карнеги-Меллона в 2007 году и стал продолжением проекта Captcha, появившегося в 2000 году. Напомним, что Captcha — это программа, которая защищает сайты от интернет-ботов. Посещая сайт и совершая на нем определенные действия, пользователь получает просьбу заполнить веб-форму. Его задача — вписать в эту форму буквы и цифры, которые он видит на изображении. Люди с хорошим зрением могут легко распознать эти символы, а боты не могут. Так сервис определяет, кто из посетителей сайта человек, а кто — бот. Ботам доступ к сайтам закрывается, так как они наносят вред сайтам. Создатели проекта Captcha пошли дальше. Они подсчитали, что у каждого человека уходит примерно 10 секунд на ввод одной капчи. А у человечества (10 умножаем на 200 млн) — 500 000 часов. Тогда появилась идея о том, что время, потраченное на ввод капчи, можно использовать с пользой для людей. Это стало началом проекта reCaptcha. Отличие этого проекта от проекта Captcha состоит в том, что вы не только печатаете капчу и подтверждаете, что вы человек, но и одновременно делаете минимальное полезное усилие. В 2007 году таким усилием была оцифровка книг, а с 2012 года reCaptcha стали использовать для распознавания изображений из онлайн-карт. Мы расскажем про инициативу, вошедшую в историю под девизом Stop Spam, Read Books. В чем она заключалась? Каждая страница книги сканируется. Компьютер расшифровывает слова на каждом отсканированном изображении. Для этого используется технология OCR — та, же технология, что и в первом проекте. При распознавании текста OCR допускает ошибки. Их особенно много в распознанных текстах старых книг, поскольку в некоторых местах чернила выцвели и страницы пожелтели. Например, в книгах, написанных более 50 лет назад, компьютер не может распознать более 30% слов. Все нераспознанные слова направляются людям, чтобы они их распознали, когда вводят капчу в интернете. Задача добровольцев — ввести слова, взятые из отсканированных книг, которые компьютер не смог распознать. Добровольцу необходимо распознать два слова из книги. Почему именно два? Одно из слов взято из книги, и оно неизвестно компьютеру. Соответственно, проверить ответ добровольца компьютер не может. Поэтому волонтер получает второе слово — его компьютер знает. Мы не говорим, какое из слов известно компьютеру, и просим добровольца ввести оба. Если доброволец вводит известное слово правильно, система получает подтверждение, что он — человек, а также получает уверенность в правильности ввода другого слова. Одно и то же слово, которое неизвестно компьютеру, направляется десяти участникам проекта. Если все они вводят его одинаково, то есть их ответы совпадают, то это слово отправляется в книгу. Как и в случае с первым проектом, данные, полученные от добровольцев, используются для обучения технологии OCR. Инициативой проекта reCaptcha впечатлилось множество владельцев сайтов. Новый сервис взамен традиционной Captcha установили такие сайты, как Tiketmaster, Facebook, Twitter и примерно 350 000 других сайтов. Каждый день на этих сайтах вплоть до 2012 года люди оцифровывали примерно 100 млн слов в день. Это 2,5 млн книг в год. В результате, в течение пяти лет с момента его запуска в проекте по оцифровке книг поучаствовали минимум 750 млн людей (это 10% всего населения). Книги, оцифрованные в рамках этого проекта сегодня представлены на сайтеbooks.google.com. Подводя итоги вышесказанного, сформулируем определение краудсорсинга в ML. Краудсорсинг в ML — это способ сбора данных, которые необходимы разработчикам, чтобы обучать машины выполнять необходимые действия. С помощью краудсорсинга разработчики вовлекают в процесс выполнения задач обычных людей, которые не владеют определенными навыками и экспертизой. В рамках четко заданных инструкций они выполняют нужное количество заданий. Результаты этих заданий — собранные, размеченные или оцененные данные — входят в те датасеты, которые используются для обучения машин.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Distributed Proofreaders",
        "url": "https://www.pgdp.net/c/"
      },
      {
        "text": "«Гутенберг»",
        "url": "https://www.gutenberg.org/"
      },
      {
        "text": "reCaptcha",
        "url": "https://www.google.com/recaptcha/about/"
      },
      {
        "text": "books.google.com",
        "url": "https://books.google.com/"
      }
    ]
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "Ключевые принципы краудсорсинга в ML",
    "text": "Применение краудсорсинга в машинном обучении значительно ускорило процесс развития AI продуктов. Беспилотные автомобили, голосовые помощники, поисковые системы, онлайн-карты, машинный перевод появились и развиваются во многом благодаря данным, полученным с помощью краудсорсинга. Например, чтобы поисковая система смогла точно отвечать на вопросы пользователей, нужно проделать большую работу по разметке данных: проанализировать запросы и поведение пользователя, оценить возможные результаты на соответствие запросу, сравнить разные варианты поисковых выдач и выбрать лучший. Все эти данные ложатся в основу моделей, которые учатся искать лучшие ответы, опираясь на размеченные людьми образцы. Такие задачи, на первый взгляд, кажутся трудозатратными и продолжительными по времени. Но если воспользоваться возможностями краудсорсинга и подойти к ним, как к инженерной проблеме, эти сложности будут преодолены. В этом тезисе содержится основная идея краудсорсинга для AI и машинного обучения:чтобы решить задачу по разметке данных для обучения или оценки качества модели, нужно подойти к ней как к инженерной проблеме. Это значит, что нужно организовать выполнение задачи таким образом, чтобы конечный результат зависел от качества самого процесса, а не от добросовестности или экспертности отдельных исполнителей. Такой подход требует соблюдения ряда правил. Прежде всего, чтобы проект был доступен максимальному количеству исполнителей и не зависел от редких компетенций, его необходимо разделить на сценарии или небольшие задачи. Принцип деления сложной задачи на несколько микрозадач называетсядекомпозицией. Это основополагающий принцип для каждого краудсорсингового проекта, создаваемого для задач машинного обучения. Каждую микрозадачу необходимо детально продумать. Определить элементы, которые будут ее сопровождать. Некоторые из них (например, инструкции или интерфейсы) обязательно должны присутствовать в проекте. Другие — такие как предварительная фильтрация исполнителей или отслеживание их поведения в проекте — используются в случае необходимости. Все эти элементы решают вопрос качества данных: чем лучше продуман проект, чем эффективнее он «сопровождает» исполнителя во время разметки, тем меньше остается пространства для ошибок или недобросовестного поведения. Детальную схему проекта, состоящую из цепочки микрозадач и сопровождающих их элементов, называют пайплайном (от англ. pipeline — «линия, очередь»). Его создают на этапе планирования проекта и обращаются к нему как к «дорожной карте».",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "ML-задачи, где используется разметка",
    "text": "Краудсорсинг помогает решить разнообразный спектр ML-задач. Разделим их на две основные группы — разметка и сбор данных.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "Разметка данных",
    "text": "К этой группе относится целый ряд задач, в рамках которых пользователю краудсорсинговой платформы необходимо выполнить некоторое действие с уже полученными данными. Например, его могут попросить перевести записи из аудио в текст (транскрипция аудио) или выделить в запросе пользователя в поисковой системе определенные смысловые части, такие как тип продукта, цвет, бренд (NLP-задания). Также в эту группу входят задачи по проверке автоматического перевода, модерации контента, разметке видео или сегментации объектов на изображениях. В качестве примера рассмотрим задачи по сегментации изображений. Как правило, они нужны для обучения алгоритмов компьютерного зрения. Они используются, например, для создания беспилотного транспорта, который должен распознавать всевозможные препятствия на дорогах: людей, светофоры, разметку, дорожные знаки, дома, заборы, искусственные неровности и т. д. Чтобы эти модели были качественными и могли без труда распознавать любые объекты на своем пути, им нужно показать большое количество изображений и в, более сложных случаях, видео с выделенными на них объектами разных классов. Выделением этих объектов занимаются пользователи краудсорсинговых платформ. На 2D и 3D изображениях, а также видео, снятых во время движения с помощью камер, радаров и лидаров, они находят нужные объекты и обводят их. Изображения и видео, размеченные по требованиям инструкции, используются для обучения моделей компьютерного зрения. Самый простой пайплайн задачи по сегментации изображений для беспилотных автомобилей состоит из трех проектов (рис. 1). В первом проекте исполнители отвечают на вопрос, есть ли на фото нужные объекты (например, дорожные знаки). Те изображения, на которых эти объекты есть, перенаправляются в проект номер два. В нем вторая группа исполнителей обводит дорожные знаки с помощью прямоугольников. Эту разметку проверяет еще одна группа исполнителей в следующем проекте, третьем по счету. Далее включается схема так называемой отложенной приёмки заданий. В случае отклонения задание отправляется на повторную разметку. Верно выполненная работа включается в итоговый датасет. Подобные пайплайны, но еще более многоступенчатые, используются для обучения моделей компьютерного зрения Яндекса. В январе 2020 года инженерам компании удалось продемонстрировать одну из моделей на конференции Consumer Electronics в Лас-Вегасе. Беспилотные автомобили со встроенной моделью проследовали по маршруту с разными дорожными сценариями: нерегулируемыми перекрестками, сложными поворотами со встречным разъездом, пешеходными переходами и многополосными участками. Всего эти автомобили преодолели более 7 тысяч км.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "Сбор данных",
    "text": "Суть задач, связанных со сбором контента, заключается в поиске материалов (изображений, фотографий, фактов), необходимых для решения проблемы. Например, используя краудсорсинг, инженеры собирают фразы для обучения голосового помощника (рис. 2). Пайплайн такого проекта выглядит довольно просто: исполнители записывают необходимую фразу, например, «Привет, Алиса», и загружают ее в интерфейс задания на краудсорсинговой платформе. Далее другая группа исполнителей проверяет эти записи на предмет ошибок и других требований: если запись соответствует инструкции, вторая группа подтверждает ее, а если в записи допущены ошибки, отклоняет. В следующем проекте еще одна группа исполнителей записывает недостающие фразы, затем они вновь проходят проверку. Этот процесс повторяется по кругу, пока не будет собрано достаточное количество фраз нужного качества.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "Краудсорсинговые платформы",
    "text": "Масштабируемость и скорость выполнения задач по разметке данных напрямую зависят от доступа заказчика к большому облаку исполнителей. Залог успеха здесь — использование открытых краудсорсинговых платформ, которые позволяют постоянно пополнять это облако и, следовательно, масштабировать процессы сбора или разметки данных. Открытые краудсорсинговые платформы — например, Amazon Mechanical Turk или Толока — работают по принципу маркетплейсов. Заказчик может создать на такой платформе свой проект, найти для него нужных исполнителей, обучить их и поручить им выполнение задания, контролируя качество результата. Пользователи открытой платформы, в свою очередь, могут выбрать интересующий их проект, выполнить задания и получить за проделанную работу вознаграждение. Свой выбор проекта они могут сделать как на основе рейтинга проекта, так и с учетом итогового вознаграждения — либо просто потому, что какая-то задача им интересна больше других. Открытые краудсорсинговые платформы — инструмент для тех, кто планирует самостоятельно контролировать разметку данных. А это, как правило, большинство проектов в сфере AI и машинного обучения. Для ML-разработчиков крайне важно, чтобы кропотливая работа по написанию инструкций, проектированию интерфейсов, отбору и обучению участников, настройке контроля качества была выполнена в точности так, как это запланировано в пайплайне проекта. Все эти шаги напрямую влияют на качество тренировочных данных, а от них в немалой степени зависит успех продукта. При выборе краудсорсинговой платформы важно учесть и то, какими инструментами они располагают. Например, с готовыми шаблонами можно быстрее спроектировать интерфейс задания, а инструменты контроля качества помогут отсеять роботов и недобросовестных исполнителей. Кроме того, выбор платформы во многом определит то, с какими исполнителями будет вестись работа. Изучение их характеристик даст понимание, в каких странах они проживают, на каких языках разговаривают и, что немаловажно, сталкивались ли они с проектами, подобными тому, над которым планируется работа. Альтернативой платформам-маркетплейсам могут стать проекты, которые предлагают готовые датасеты и помощь в разметке данных для проекта. Это, например, Scale AI, Hive Data, Alegion. Такие платформы подойдут не всем — выше уже шла речь о том, что некоторые проекты (как, например, обучение алгоритмов компьютерного зрения) нуждаются в специфическом контексте для сбора датасета. Кроме того, построенные по общим принципам краудсорсинга проекты могут запускаться и на внутреннее облако исполнителей, связанных с компанией какими-либо договорными отношениями. Это важно в случаях, если речь идет о разметке чувствительных данных. Однако такой процесс тяжело поддается масштабированию, потому что требует больших ресурсов для сопровождения сотрудников.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "Границы применимости краудсорсинга",
    "text": "Несмотря на все многообразие задач, которые можно решить с помощью краудсорсинга, есть случаи, когда его применение затруднено либо просто нецелесообразно. Во-первых, необходимо оценить затраты, сопутствующие запуску проекта. Создание и настройка эффективного пайплайна для сбора или обработки данных требуют времени и квалификации высокоуровневого специалиста. Потраченный им ресурс может не окупиться, если требуется лишь один раз разметить небольшое количество данных. Облаку исполнителей с трудом поддаются задачи, требующие серьезного включения и поддержания контекста. Секрет краудсорсинга — в создании небольших автономных заданий, каждое из которых может быть решено согласно несложной инструкции. Если исполнителю требуется учитывать большой объем сопутствующей информации, чтобы выполнить задачу верно — скорее всего, ее лучше выполнять без использования краудсорсинга. Например, облако исполнителей вряд ли сможет осуществить перевод книги: ее не стоит разбивать на отдельные предложения, ведь перевод должен быть последовательным и согласованным. В то же время, краудсорсинг может помочь при переводе отдельных фраз в конечном контексте, например, отдельных реплик для голосового ассистента. Наконец, если задача требует крайне специфических навыков, то поиск или обучение подходящего исполнителя на краудсорсинговой платформе сравнится с наймом эксперта. В таких случаях стоит оценить возможность декомпозиции задачи так, чтобы она оказалась разбита на ряд менее сложных действий. Если сделать это невозможно (например, для выполнения задания требуется знание редкого языка), оптимальным способом поиска исполнителя могут стать профессиональные сообщества.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "Этапы создания краудсорсингового проекта",
    "text": "Типичная краудсорсинговая задача состоит из шести этапов: Декомпозиция; Инструкция и интерфейс; Контроль качества; Отбор и обучение исполнителей; Выбор схемы оплаты и бонусирования; Агрегация ответов. Разберем каждый из этапов на примере уже упомянутого проекта по сбору данных для обучения беспилотных автомобилей. Мы запустим этот проект на краудсорсинговой платформе «Толока».",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "Декомпозиция",
    "text": "В качестве исходных данных возьмем объемный набор фотографий с изображением улиц. После запуска краудсорсингового проекта мы должны получить те же изображения, но с выделенными на них дорожными знаками. Наша задача — выделить прямоугольниками дорожные знаки на каждой фотографии. Пример того, как должен выглядеть итоговый датасет с выделенными на них объектами приведен на рисунке 3. Можем ли мы поручить нашу задачу участникам краудсорсинговой платформы напрямую? В данном случае — нет. Изображения для разметки могут полностью не соответствовать нашему запросу. Например, на изображениях может не быть нужных объектов. Некоторые фотографии могут не загрузиться в интерфейсе (появится ошибка). Чтобы избежать подобных ситуаций, нам нужно отобрать фотографии с подходящими объектами. Отбор фото или их фильтрация станет первой микрозадачей илипервым пулом(так называется набор заданий в рамках проекта на платформе «Толока») нашего проекта. Что дальше? Когда мы получили фотографии с дорожными знаками, мы сможем запустить проект по выделению объектов на изображениях. Наша задача — выделить на фотографиях все дорожные знаки прямоугольниками. Чтобы создать подобное задание на краудсорсинговой платформе «Толока», можно воспользоваться готовым шаблоном. Он предусматривает специальный инструмент, «полигон», который с легкостью позволяет выполнять подобные задания. На этом мы могли бы остановиться. Получили изображения с выделенными объектами — задача выполнена. Однако для данного проекта потребуется запустить еще одно микрозадание. Фотографии с выделенными объектами необходимо проверить. Кто-то из исполнителей может пропустить некоторые знаки или выделить их неверно. Таким образом, проверка размеченных изображений в конкретном проекте необходима. Но специфика задачи такова, что мы не можем просто сравнить работу отдельного исполнителя с заведомо верным примером: выделенные области могут отличаться на несколько пикселей, но это не будет означать, что ответ неверен. Итак, что мы делаем? Мы создаем новый пул заданий, в котором спрашиваем «Верно ли выделены объекты на фото?». Участники отвечают на вопрос, после чего фото с верно отмеченными объектами отправляются в итоговый датасет и оплачиваются. Фото с неверно выделенными объектами отклоняются и не оплачиваются. Все фотографии, которые не проходят проверку, отправляются на переразметку (т. е. размечаются повторно). Какие выводы мы можем сделать по итогу разбора декомпозиции проекта? Самый главный вывод — решение о декомпозиции задачи следует принимать, исходя из типа задачи и данных, которые есть на входе — это могут быть изображения, видео, ссылки, точки на карте, координаты этих точек. Также следует различать типичные случаи, в которых декомпозиция особенно рекомендована для проекта. Речь идет об объемных проектах, многослойных задачах, задачах со множеством вариантов ответов и объемных процессах: Объемные проекты. Если в рамках проекта нужно ответить на несколько вопросов, то лучше сделать это поочередно или в выбранной последовательности. Многослойные задачи. Если в рамках одной задачи нужно выполнить более одного действия (например, отнести объект к определенной группе и ответить на вопрос, предназначен ли он только для взрослых), то лучше сделать это поочередно или в выбранной последовательности. Задачи со множеством вариантов ответов. Если в задании есть один вопрос и 10 и более вариантов ответа, то лучшим решением будет группировка ответов по темам, а затем создание отдельного проекта для каждой группы ответов. Объемные процессы. Если задача включает сложные механизмы контроля качества и отложенную проверку, необходимо создать отдельный проект, в котором одна группа исполнителей будет проверять другую. Есть ли случаи, когда декомпозировать задачу не нужно? Да. Нет необходимости разбивать задачу на части, если соблюдаются два критерия: инструкции к задаче помещаются на половине листа бумаги формата А4, или задача выполнена с помощью одного действия, например, выбора из нескольких категорий.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "Инструкция",
    "text": "После декомпозиции нашего проекта нам необходимо создать для него инструкцию. Инструкция потребуется для каждой микрозадачи. В нашем случае нам необходимо создать три инструкции. Какие пункты мы обязательно в них укажем? Первым пунктом инструкции станет описание задачи. В нем мы объясним участнику, что предстоит сделать и где будет использован результат этой работы. Например: Вашему вниманию представлен проект, результаты которого помогут сделать беспилотные автомобили безопасным транспортом. Ваша задача — определить, есть ли дорожные знаки на изображении. Выберите ответ «Да», если изображение содержит дорожные знаки. Выберите ответ «Нет», если на изображении дорожных знаков нет. На изображении, представленном ниже, есть несколько дорожных знаков. Значит, правильный ответ — «Да». Далее, мы подробно опишем условия входа в задание: расскажем, будет ли обучение и экзамен, с каким качеством его нужно пройти, есть ли в проекте повторный экзамен для тех, кто не прошел испытание с первого раза. Также опишем ценообразование. Например: Чтобы выполнить это задание, вам потребуется пройти обучение на тренировочном пуле. В тренировочный пул войдут задания аналогичные тем, что будут в основном проекте. После обучения мы предложим вам пройти экзамен. В экзамен войдут 5 изображений. Следующий элемент инструкции — технические нюансы. Здесь мы расскажем, с какого устройства потребуется выполнить задание — со смартфона или с компьютера — и какие дополнительные настройки браузера будут необходимы. Этот пункт в особенности важен для второго задания в рамках нашего проекта. Разметить дорожные знаки прямоугольниками участники смогут только с компьютера: Мы рекомендуем выполнять это задание с персонального компьютера. Это необходимо, чтобы вы смогли корректно выделить все необходимые объекты на изображении. Краткое описание интерфейса задания — еще один важный пункт в инструкции. Для большей наглядности мы сделаем скриншот с комментариями о том, для чего нужны те или иные блоки и кнопки. Если в задании простой интерфейс, эту часть можно пропустить. Например: Используйте желтый квадрат («полигон») в левой части экрана, чтобы выделять дорожные знаки на изображении. Теперь о самом задании. Чтобы избежать ошибок, мы пошагово опишем все частые сценарии, которые могут случиться при выполнении наших задач. Также мы укажем, что делать с нестандартными случаями. Добавим примеры: несколько кейсов сделают теорию намного понятнее. Справочные материалы — глоссарий, faq — важное дополнение к этим сценариям. Наконец, мы расскажем, куда направлять вопросы по заданию или проекту в целом. На что мы обратим внимание при написании текста? Первое, за чем стоит проследить — сам язык, которым написана инструкция. Мы откажемся от профессионального сленга и не будем использовать терминологию. Некоторые термины, например, «полигоны», мы объясним или заменим синонимами — «прямоугольники». Наша задача — сделать инструкцию простой и понятной для большого числа участников. Следуя этой же задаче, мы упростим стиль и синтаксис (одна мысль = одно предложение; одна тема = один абзац), не будем использовать пояснения в скобках и сделаем форматирование единообразным. Готовый текст инструкции мы обязательно проверим, выполнив некоторое количество заданий. Такое упражнение быстро покажет, какие случаи еще не описаны в инструкции, а какие описаны мало. Кроме того, оно позволит проверить как выглядит наше задание на разных устройствах: умещаются ли все картинки и скриншоты на экранах мобильного телефона, планшета и компьютера. В итоге каждая инструкция не займет больше двух экранов. Это максимальное количество пространства для инструкции, за пределы которого лучше не выходить. Если инструкция все же не вписывается в такой объем, вероятно, задача слишком многосоставная и ее нужно декомпозировать.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Краудсорсинг",
    "url": "https://education.yandex.ru/handbook/ml/article/kraudsorsing",
    "section_title": "Агрегация результатов",
    "text": "Представим, что мы запустили наш проект и получили необходимые данные. В краудсорсинговых проектах данные обычно собираются в перекрытии (мнения большинства) — это один из распространенных механизмов контроля качества исполнителей и улучшения качества итогового набора данных. Но как выбрать из нескольких оценок финальную? В данном случае нам помогут механизмы агрегации данных. Что они делают? Они обрабатывают файлы с ответами исполнителей и выбирают из нескольких ответов тот, который с наибольшей вероятностью окажется верным. Рассмотрим принцип работы механизмов агрегации данных на примере первого пула с заданиями (см. рис. 4). У нас есть набор изображений, и наша цель — отнести каждое изображение к группе «изображения с дорожными знаками» или к группе «изображения без дорожных знаков». В соответствии с принципом краудсорсинга задание должно быть распределено между несколькими исполнителями, каждый из которых размечает некое подмножество изображений. В результате для каждого изображения у нас есть несколько результатов разметки. Цель метода агрегации — объединить эти результаты в один качественный ответ. Алгоритм агрегации данных «Мнение большинства» основан на предположении, что правильный ответ — этот тот, который выбирают большинство исполнителей (рис. 5). Самый популярный ответ становится финальным ответом. Практика показывает, что при помощи метода, основанного на мнении большинства, можно получить достойные результаты. Поэтому этот метод с успехом применяется во многих проектах. Также одно из преимуществ этого метода заключается в том, что он весьма нагляден и логика его работы понятна. Однако в проектах краудсорсинга существуют определенные временные и бюджетные ограничения. Наша цель в том, чтобы собрать минимальный объем данных, необходимый для достижения желаемой точности. С этой точки зрения, метод, основанный на мнении большинства, далеко не всегда будет оптимальным выбором. Чтобы осознать слабые стороны метода, рассмотрим его модель. Модель, лежащая в основе метода, проста. Есть N изображений и M исполнителей. Каждое изображениеподразумевает некий неизвестный ответ («изображения с дорожными знаками» или «изображения без дорожных знаков» в нашем случае). При использовании модели, основанной на мнении большинства, предполагается, что если исполнительразметил изображение, его ответ является правильным с некоторой вероятностью При этом вероятность правильного ответа полагается одинаковой для каждого исполнителя и вопроса. Допущение, чтоучитывает, что для каждого исполнителя вероятность правильного ответа выше, чем неправильного. В таком случае, поскольку число разметок для каждого изображения достаточно велико, мнение большинства с высокой вероятностью даст истинные ответы. В силу своей простоты, метод основанный на мнении большинства имеет ряд ограничений: **Однородность исполнителей.**Во-первых, данный метод предполагает, что все исполнители обладают одинаковыми способностями. Иными словами,для каждого конкретного вопроса вероятность того, что исполнитель правильно ответит на вопрос, одинакова для всех исполнителей.Однако на практике пул исполнителей на краудсорсинговых платформах чрезвычайно разнообразен: кто-то из них очень аккуратно и скрупулезно выполняет задачи, а кто-то небрежен и чаще допускает ошибки. Таким образом, одно из направлений совершенствования модели, основанной на мнении большинства, — это учет различия в способностях исполнителей в рамках модели. **Однородность вопросов.**Во-вторых, модель, основанная на мнении большинства, предполагает, что вопросы имеют одинаковую сложность. Другими словами,вероятность того, что исполнитель правильно ответит на вопрос, одинакова для всех вопросов.Однако некоторые вопросы в рамках проекта могут быть сложнее других. Таким образом, еще одно направление по улучшению модели на основании мнения большинства — это учесть в модели разную степень сложности вопросов. Далее мы рассмотрим оба направления развития модели и расскажем о других алгоритмах, учитывающих особенности краудсорсинговых заданий. Рассмотрим модель, которая учитывает неоднородность исполнителей при агрегации ответов. Естественный способ учесть различия в способностях исполнителей — ввести параметр качества для каждого исполнителя. Если естьисполнителей, то мы можем связать каждого исполнителяс неизвестным параметром качества. Чем выше параметр качества исполнителя, тем больше вероятность того, что исполнитель ответит на вопрос правильно: Другими словами, вероятность того, что исполнитель правильно ответит на вопрос, своя для каждого исполнителя (но от вопроса она все еще не зависит). В ситуации, когда у исполнителей разные способности, логично присваивать больший вес ответам более сильных исполнителей и меньший вес — ответам более слабых. Однако проблема в том, что параметры качества для исполнителей априори нам не известны. Основная идея двух методов модели агрегации данных с учетом способностей исполнителей заключается том, чтобы одновременно оценить параметры качества для исполнителей и ответы на поставленные вопросы. Рассмотрим каждый их них. Контрольные вопросы (такжеhoneypots,golden sets) — это задания, на которые заказчик заранее знает правильные ответы. На практике мы часто добавляем в набор данных определенное количество контрольных вопросов, чтобы контролировать качество работы исполнителей. Когда этих вопросов достаточно много, мы можем использовать их для оценки качества работы. Предположим, что у нас естьконтрольных вопросов и некий исполнитель, который правильно ответил навопросов изконтрольных вопросов. Тогда мы можем оценить параметр качества для исполнителя следующим образом: Теперь, когда у нас есть оценка параметра качества, мы можем оценить ответ каждого исполнителя по-разному. Эта идея подводит нас к концепции взвешенного мнения большинства (от англ.Weighted majority vote). Идея этого метода проиллюстрирована на рисунке ниже (рис. 6). Предположим, что у нас есть нестандартное изображение, на котором столб похож на дорожный знак. В этом случае модель, основанная на простом мнении большинства, не делает отличия между ответами исполнителей с меньшими способностями (первых двух исполнителей) и ответами исполнителя-эксперта (последнего исполнителя) и допускает ошибку. Напротив, модель взвешенного мнения большинства дополнительно взвешивает каждый ответ полученным коэффициентом качества исполнителя. Такая модель приводит к правильному ответу, поскольку мнение исполнителя-эксперта в таком случае перевешивает мнения двух других исполнителей. Метод взвешенного мнения большинства подходит для тех случаев, когда в проекте есть достаточное количество контрольных заданий, необходимых для оценки качества работы исполнителя. Однако зачастую контрольных заданий в проекте не хватает, в связи с чем оценки могут быть довольно неточными. Кроме того, исполнители могут коллективно выявить контрольные вопросы и начать обманывать систему, давая правильные ответы на контрольные вопросы и случайные ответы на другие. В этом случае, чтобы оценить параметры качества исполнителей при ответе на неизвестные вопросы, мы можем использовать метод Дэвида — Скина: Метод Дэвида-Скинаодновременно находит значения качества исполнителей и ответы на вопросы, которые согласуются с наблюдаемыми данными в наибольшей степени.Мы имеем в качестве данных— количество раз, при которых разметчикпоставил классобъекту(возможно, разметчик видел этот объект несколько раз). Обозначим через это наши латентные величины. В качестве параметров имеем — вероятность того, что разметчикпоставил классвместо правильного класса. — вероятность класса. Примем также обозначения: , , . Поймём, какой будет функция неполного правдоподобия в этой задаче. Прежде всего, Если– номер класса-го объекта, то (значенияоднозначно определяются номером истинного класса, поэтому справапропадает). Далее, мы считаем, что разметчики действуют независимо, поэтому Разберёмся с величиной. Она отвечает за то, какие классы-й разметчик ставил-му объекту. Мы считаем, что встречи разметчика с объектом упорядочены по времени, тогда Эту вероятность можно переписать в виде а итоговое неполное правдоподобие предстаёт в виде Его нам нужно максимизировать пои Пояснение к формуле: Вне больших скобок фиксируются объект и его класс, сама скобка возводится в степень 1, если рассматривается правильный класс объекта, и в степень 0 иначе. Внутри сначала записана вероятность того, что объект имеет данный класс, а затем — перебор по всем пользователям и всем классам, которые мог поставить данный пользователь. Наконец, записывается вероятность того, что пользователь нашему объекту поставил некоторый класс, которая возводится в степень того, сколько раз он поставил этот класс. Например, если пользователь видел изображение котика 5 раз, при этом 3 раза он сказал, что котик, а два раза — песик, то вероятностьдля данного котика учтется 3 раза, а вероятность— 2 раза. Рассмотрим концепцию метода Дэвида-Скина на простом примере (рис. 7).Предположим, что у нас есть тольковопросов иисполнителей. Каждый исполнитель отвечает на все вопросы. В этом случае наблюдаемые данные — это ответы исполнителей на вопросы. Давайте разберемся в том, каким образом метод Дэвида — Скина позволяет найти параметры качества для исполнителей и те ответы на вопросы, которые лучше всего соответствуют наблюдаемым данным. Для этого рассмотрим два варианта, показанные на картинках ниже (см. рис. 7.1). Каждая картинка предполагает свой набор параметров. Посмотрим, какой из предложенных вариантов лучше соответствует наблюдаемым данным. Во-первых, обратите внимание, что на обоих изображениях предложенные ответы согласуются с ответами исполнителя, у которого, по оценкам, высокий параметр качества. Но какой выбор параметров подходит данным лучше всего? Чтобы ответить на этот вопрос, обратите внимание, что ответы второго и третьего исполнителей полностью совпадают. Если параметры качества для этих исполнителей соответствуют первой картинке, тогда, если верить этой модели, эти два исполнителя отвечают наугад. В таком случае высокая степень согласия между исполнителями нас бы скорее удивила, поскольку отвечая наугад, они должны время от времени расходиться в своих ответах. Напротив, если исполнители 2 и 3 — эксперты, как на втором изображении, тогда мы ожидаем, что у них будет высокая степень согласия, и это то, что мы видим в данных. Интуитивно, второй набор параметров лучше согласуется с наблюдаемыми данными. Приведенный простой пример показывает, что концепция согласованности между потенциальными параметрами и наблюдаемыми данными позволяет нам исключить те варианты, которые плохо согласуются с наблюдаемыми данными. Оба метода — взвешенное мнение большинства и агрегация по методу Дэвида — Скина — входят в стандартный функционал Толоки. В двух наших пулах, в первом и третьем, мы будем использовать метод Дэвида — Скина. Он позволит нам получить наиболее точные данные для нашего проекта. Подробнее узнать о том, как получить агрегированные результаты из размеченного пула, можно вдокументации. Метод Дэвида-Скина и метод, основанный на мнении взвешенного большинства, — основа современного краудсорсинга. Многие создатели проектов повышают качество данных, используя эти методы агрегации. Однако существуют и другие современные подходы. Например, есть группа подходов, которые учитывают сложность вопроса при агрегировании ответов. Аналогично тому, как мы замеряли качество для каждого исполнителя, вводя параметр качества, точно так же для каждого исполнителя мы можем ввести параметр сложностидля каждого вопроса. Тем не менее, главная проблема заключается в том, как описать взаимодействие между качеством исполнителя и сложностью вопроса, и в результате рассчитать вероятность того, что конкретный исполнитель правильно ответит на выбранный вопрос. В работе Уайтхилла с соавторами (2009) предлагается следующее решение. Во-первых, параметр качества для исполнителя, который раньше мерился в диапазоне, теперь задается в интервале. В частности, возможно нулевое качество, которое соответствует ситуации, когда исполнитель отвечает на все вопросы наугад. Положительные значения качества подразумевают, что работник с большей вероятностью даст правильный ответ, а отрицательные значения означают, что исполнитель настроен враждебно и с большей вероятностью даст неправильный ответ. Во-вторых, для параметра сложности каждого вопросатакже может быть дана интуитивная интерпретация: низкая сложность вопросаозначает что вопрос настолько прост, что любой исполнитель ответит на него правильно с вероятностью, близкой к 1. Чем выше уровень сложности, тем меньше вероятность того, что конкретный исполнитель ответит на вопрос правильно. Объединив эти параметры, модель предполагает, что вероятность для конкретного исполнителяпри ответе на конкретный вопросможет быть корректно описана следующим параметрическим выражением: Следует заметить, что в таком случае вероятность является функцией и самого исполнителя, и вопроса, на который исполнитель отвечает. Как только мы выбрали параметрическое уравнение для описания взаимосвязи между уровнем качества исполнителя и сложностью вопроса, с одной стороны, и вероятностью правильного ответа, с другой, мы можем применять все те же принципы, что и для расчета параметров по модели Дэвида – Скина. Таким образом мы можем оценить не только параметры модели, но и полученные ответы на вопросы. Более подробно об этом можно почитать встатье. Несмотря на то, что параметрические модели позволяют делать весьма эффективные выводы, в них неизбежно заложены сильные допущения о когнитивных процессах, присущих исполнителям при ответе на вопросы. Эти допущения обычно невозможно проверить, поэтому неясно, насколько хорошо они согласуются с реальностью. Соответственно, если допущения параметрической модели неверны, то и методы, используемые такой моделью, могут дать неожиданные результаты. Это подводит нас к идее непараметрического подхода, где можно попробовать избежать сильных допущений о мыслительных процессах. Непараметрический подход предложил Нихар Б. Шах с коллегами в 2016 году. Вместо моделирования вероятностей, что исполнительверно ответит на вопрос, считается, что между этими вероятностями есть взаимосвязь. При этом модель использует два ключевых допущения: Во-первых, предполагается, что исполнителей можно выстроить в ряд в порядке возрастания способностей. Если исполнительзанимает в этом ряду более высокую позицию, чем исполнитель, то при ответе на каждый вопрос исполнительс большей вероятностью даст правильный ответ, чем исполнитель. Во-вторых, предполагается, что вопросы можно выстроить в ряд в зависимости от их сложности. Если вопроссложнее вопроса, то любой исполнитель совершит ошибку при ответе на вопросс не меньшей вероятностью, что и отвечая на вопрос. Стоит заметить, что эти допущения гораздо слабее, чем в параметрической модели. В самом деле, параметрическая модель не только предполагает существование таких упорядоченных рядов, но и задает все вероятности. С другой стороны, непараметрический подход делает всего лишь естественное предположение о существовании последовательных рядов, но не ограничивает набор когнитивных механизмов, характерных для исполнителей. Было показано, что в некоторых случаях непараметрическая модель позволяет лучше делать выводы. Более подробно об этом можно почитать вполном тексте статьи. Как мы уже говорили, эти подходы еще достаточно новые и не успели стать классикой краудсорсинга. Если сложность вопросов в вашем проекте существенно варьируется, мы рекомендуем более основательно изучить упомянутые методы и лежащие в их основе допущения, а затем опробовать их на практике. Использованная литература Jeff Howe,The Rise of Crowdsourcing, The Wired, 2006. Джефф Хау, Краудсорсинг: Коллективный разум как инструмент развития бизнеса, Альпина Паблишер, 2012. Omar Alonso, The Practice of Crowdsourcing, 2019. «Cамая богатая часть планеты работает бесплатно во время перерывов на кофе»: редактор Wired Джефф Хау о краудсорсинге, T &P, 2012. Р. А. Долженко, А. В. Бакаленко, Краудсорсинг как инструмент мобилизации интеллектуальных ресурсов: опыт использования в Сбербанке России, Российский журнал менеджмента, Том 14, №3, 2016, С. 77–102. Беспилотные автомобили Яндекса на CES 2020: 7 тысяч км без водителя за рулём по улицам Лас-Вегаса, Новости Яндекса, 2020. Метод Дэвида и Скина",
    "source_type": null,
    "useful_links": [
      {
        "text": "документации",
        "url": "https://yandex.ru/support/toloka-requester/concepts/result-aggregation.html?lang=ru"
      },
      {
        "text": "статье",
        "url": "https://arxiv.org/pdf/1602.03481.pdf"
      },
      {
        "text": "полном тексте статьи",
        "url": "https://arxiv.org/pdf/1606.09632.pdf"
      },
      {
        "text": "The Rise of Crowdsourcing",
        "url": "https://www.wired.com/2006/06/crowds/?pg=1&topic=crowds&topic_set="
      },
      {
        "text": "«Cамая богатая часть планеты работает бесплатно во время перерывов на кофе»: редактор Wired Джефф Хау о краудсорсинге",
        "url": "https://theoryandpractice.ru/posts/5001-camaya-bogataya-chast-planety-rabotaet-besplatno-vo-vremya-pereryvov-na-kofe-redaktor-wired-dzheff-khau-o-kraudsorsinge"
      },
      {
        "text": "Беспилотные автомобили Яндекса на CES 2020: 7 тысяч км без водителя за рулём по улицам Лас-Вегаса",
        "url": "https://yandex.ru/company/services_news/2020/2020-01-14-1"
      },
      {
        "text": "Метод Дэвида и Скина",
        "url": "https://www.jstor.org/stable/2346806?seq=1"
      }
    ]
  },
  {
    "document_title": "Первые шаги",
    "url": "https://education.yandex.ru/handbook/ml/article/pervie-shagi",
    "section_title": "Рабочее окружение для ML-специалиста",
    "text": "Грубо говоря, оно делится на две большие категории: Железо и вычислительные ресурсы для обучения моделей; Программы и библиотеки для работы с данными. Начнём со второй категории. Чтобы начать работу, нужно установить Python — именно этот язык программирования доминирует в индустрии, благодаря большому количеству библиотек и фреймворкам, предназначенным именно для машинного обучения — TensorFlow или PyTorch. Фреймворк — слой абстракции над языком программирования, который облегчает разработку. Например — нам нужно сделать отверстие в доске. Эту задачу можно решить разными способами: закрутить и выкрутить шуруп, забить и вытащить гвоздь и так далее. А можно взять дрель и сверло. Дрель в этом примере и есть фреймворк. PyTorch чаще выбирают для академических исследований — он более гибкий и больше подходит для экспериментов. TensorFlow — для продакшен-решений, поскольку он более подходит для масштабирования моделей. Далее нужно установить библиотеки для Python. Продолжая строительную аналогию: библиотека — это насадка для дрели. То есть инструмент для конкретной задачи: можно установить сверло для дерева, для бетона, для металла, а можно коронку или щётку — зависит от задачи. Чаще всего применяют: Scikit-learn — библиотека машинного обучения для классических алгоритмов: классификации, регрессии, ансамблей и других. О них мы подробнее поговорим далее в этом хендбуке. Pandas — библиотека для предварительной обработки данных, и работы с данными вообще. С её помощью можно загрузить датасет, обработать недостающие значения, закодировать категориальные переменные и многое другое. Matplotlib и Seaborn — библиотеки для создания визуализаций и графиков в Python. После этого — выбрать IDE, то есть текстовый редактор для кода: Visual Studio Code, Jupyter, Sublime, PyCharm, и так далее. Теоретически, всё это можно установить на домашний компьютер или ноутбук — именно так и делали ещё 15-20 лет назад. Но вам не хватит вычислительных ресурсов для обучения моделей, в первую очередь — объёма памяти GPU (видеокарты). Даже для файнтюнинга небольших языковых моделей, таких как BERT, необходим графический процессор с минимум 16 Гб видеопамяти. Мало кто может позволить себе дома оборудование для обучения более сложных моделей. Сейчас исследователи и студенты чаще берут вычислительные мощности в аренду. Тут есть два способа: арендовать устройство «в облаке» (эта модель называется IaaS), воспользоваться специальной платформой для ML (эта модель называется SaaS). IaaS-сервис, грубо говоря, — очень мощный удалённый компьютер. Это значит, что прежде чем решать задачу на такой машине, её всё равно необходимо настроить: развернуть IDE, установить Python, фреймворки и библиотеки и многое другое. Это не всегда удобно: иногда хочется, чтобы всё работало «из коробки». «Из коробки», как вы могли догадаться, работают SaaS-сервисы: они предоставляют полностью настроенные среды, готовые к немедленному использованию в решении задач. Эти платформы обычно включают в себя: IDE или другие среды программирования, часто представленные в формате ноутбуков. Заранее настроенные рабочие окружения, оптимизированные для конкретной системы. Возможности для загрузки и хранения данных и файлов. Интеграцию с известными сервисами, такими как GitHub. О них мы и поговорим далее. Но если вам ближе путь самурая — то вот несколькоIaaSпровайдеров. По ссылкам можно узнать, как развернуть окружение для ML в IaaS-сервисе.",
    "source_type": null,
    "useful_links": [
      {
        "text": "IaaS",
        "url": "https://cloud.google.com/learn/what-is-iaas"
      },
      {
        "text": "провайдеров",
        "url": "https://aws.amazon.com/ru/ai/machine-learning/"
      }
    ]
  },
  {
    "document_title": "Первые шаги",
    "url": "https://education.yandex.ru/handbook/ml/article/pervie-shagi",
    "section_title": "SaaS-платформы",
    "text": "Как мы уже выяснили, главное преимущество SaaS – это простота входа: вы получаете доступ к необходимым ресурсам без забот о их настройке и оптимизации, что позволяет быстро приступить к работе над ML-задачами. К популярным SaaS-платформам относят: Google Colab Kaggle Notebooks AWS SageMaker Azure ML Studio Yandex DataSphere Ниже мы собрали в таблицу их возможности, плюсы и минусы. Далее мы расскажем, как решать ML-задачи на примере Yandex DataSphere. Но если вас заинтересовали другие платформы, то в конце параграфа будет список ссылок на руководства по работе с ними.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Первые шаги",
    "url": "https://education.yandex.ru/handbook/ml/article/pervie-shagi",
    "section_title": "Получение доступа и настройка DataSphere",
    "text": "Прежде чем мы начнём настройку — несколько важных моментов. DataSphere — это платный сервис, но вы можете начать работу бесплатно, с помощьютестового гранта. Также у сервиса есть специальные гранты для учебных программ. Чтобы воспользоваться грантом, нужно попросить своего преподавателя заполнитьформу, — это откроет доступ к сервису для всех студентов группы. Отлично, теперь можем приступить к настройке. Для этого: Перейдите на сайтDataSphere Нажмите большую синюю кнопку и авторизуйтесь в Яндекс ID Создайте сообщество и нажмите «Привязать платежный аккаунт»на появившемся красном дисклеймере. В созданном сообществе вы сможете взаимодействовать со всеми важными сущностями в DataSphere. Теперь можно создать проект на вкладке «Проект». В созданном проекте вы можете запустить JupyterLab: После незначительного ожидания откроется выбор среды исполнения. Там вы можете выбрать любой из примеров ноутбуков с различными снипеттами кода под разные задачи. Создадим новый пустой ноутбук, нажав “DataSphere Kernel”. Теперь, в появившемся новом ноутбуке, если мы запустим любой код в одной из ячеек, вам будет предложено выбрать конфигурацию виртуального рабочего места (более подробно о доступных конфигурациях можно почитатьтут). После выделения ресурсов, которое тоже займет небольшое количество времени, все последующие выполнения ячеек будут происходить без выбора конфигурации. Теперь, когда у нас всё готово — DataSphere настроена, ресурсы выделены, можем выполнить тестовую лабораторную работу!",
    "source_type": null,
    "useful_links": [
      {
        "text": "тестового гранта",
        "url": "https://yandex.cloud/ru/docs/getting-started/usage-grant"
      },
      {
        "text": "форму",
        "url": "https://cloud.yandex.ru/for-education-and-science/for-tutors"
      },
      {
        "text": "DataSphere",
        "url": "https://datasphere.yandex.ru/"
      },
      {
        "text": "тут",
        "url": "https://cloud.yandex.ru/ru/docs/datasphere/concepts/configurations"
      }
    ]
  },
  {
    "document_title": "Первые шаги",
    "url": "https://education.yandex.ru/handbook/ml/article/pervie-shagi",
    "section_title": "Лабораторная работа",
    "text": "В ней мы будем обучать генеративную трансформерную модель с помощью библиотекиtransformers. Сама работа находится в DataSphere — переходите поссылке, чтобы ознакомиться с заданием. А как закончите — возвращайтесь, чтобы завершить урок. Вот и всё! Если вы читаете эти строки, и у вас всё получилось — вы большой молодец. Если не получилось — ничего страшного, с первого раза мало у кого всё получается. Советуем вступить всообщество хендбукаи попросить помощи или совета.",
    "source_type": null,
    "useful_links": [
      {
        "text": "ссылке",
        "url": "https://datasphere.yandex.cloud/import-ipynb?path=https://raw.githubusercontent.com/yandex-datasphere/sda-homeworks/main/train-trans/train-trans.ipynb"
      },
      {
        "text": "сообщество хендбука",
        "url": "https://t.me/MLhandbook"
      }
    ]
  },
  {
    "document_title": "Первые шаги",
    "url": "https://education.yandex.ru/handbook/ml/article/pervie-shagi",
    "section_title": "Полезные ссылки",
    "text": "Руководствопо работе с Google Colab. Гайддля новичков по Kaggle Notebooks. Руководстводля AWS SageMaker. Документацияпо настройке Azure ML Studio Статьяпро то, как используется DataSphere в образовании КакDataSphere помогает изучать снежных барсов",
    "source_type": null,
    "useful_links": [
      {
        "text": "Руководство",
        "url": "https://colab.research.google.com/"
      },
      {
        "text": "Гайд",
        "url": "https://www.kaggle.com/code/shagkala/a-complete-guide-for-beginners"
      },
      {
        "text": "Руководство",
        "url": "https://docs.aws.amazon.com/sagemaker/latest/dg/onboard-quick-start.html"
      },
      {
        "text": "Документация",
        "url": "https://learn.microsoft.com/en-us/azure/machine-learning/tutorial-azure-ml-in-a-day?view=azureml-api-2"
      },
      {
        "text": "Статья",
        "url": "https://education.yandex.ru/journal/kak-ispolzovat-datasphere-vandnbspobrazovanii"
      },
      {
        "text": "Как",
        "url": "https://habr.com/ru/companies/yandex/articles/786560/"
      }
    ]
  },
  {
    "document_title": "Контентные рекомендации",
    "url": "https://education.yandex.ru/handbook/ml/article/kontentnye-rekomendacii",
    "section_title": "Введение",
    "text": "Все рекомендательные системы можно поделить на три типа в зависимости от того, какую информацию они используют для построения рекомендаций: Контентные; Коллаборативые; Гибридные. В данном разделе мы подробнее рассмотрим основные алгоритмы построения контентных рекомендаций. Основная идея контентных рекомендаций состоит в том, что для их построения будут использоваться атрибуты объектов и пользователей. На основе данных атрибутов мы можем найти релевантные данному пользователю объекты и рекомендовать их. Представим, например, что мы работаем в музыкальном онлайн-сервисе и хотим подбирать наиболее релевантную музыку нашим пользователям. Допустим у нас есть пользователь Иван, который интересуется русским роком. Тогда наша система может рекомендовать Ивану музыку этого или подобных жанров. Можно придумать много различных атрибутов трека: жанр, автор, год выхода, продолжительность и так далее. Также можно использовать дополнительную информацию о пользователе: возраст, уровень дохода и тому подобные. Допустим, мы работаем в музыкальном сервисе. Тогда в качестве признаков объектов можно использовать: Стандартные статистики объекта: количество лайков, кликов, полных прослушиваний; Признаки автора: количество слушателей, жанр; Неструктурированные данные: названия треков, обложки альбомов или даже предобученные эмбеддинги треков целиком. В качестве признаков пользователей можно использовать: Информацию про пользователя, если она нам доступна: возраст, пол, язык, насколько долго пользуется сервисом; Информацию про контекст запроса: с какого устройства был сделан, в какое время. Информацию про друзей пользователя и их взаимодействия. Например, усреднённый эмбеддинг всех треков, которые слушал каждый из друзей. Или же можно обучить RNN или Transformer на истории и результат конкатенировать к остальным признакам.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Контентные рекомендации",
    "url": "https://education.yandex.ru/handbook/ml/article/kontentnye-rekomendacii",
    "section_title": "Факторизационные машины",
    "text": "Начнём с постановки задачи. Пусть I – множество объектов (айтемов), U - множество пользователей. Для каждой пары объект-пользователь построим вектор размерностивзаимодействия этой пары, в котором единицы стоят на месте соответствующих пользователя и объекта: Предсказывать будем пользовательские рейтинги объектов. Можно рассмотреть простейшую регрессионную модель: Заметим, что к этой модели легко добавить любые фичи объектов, пользователей или пар объект-пользователь: Дальше будем обозначать черезобщее число фичей. Модель можно обогатить признаками, отвечающими за взаимодействия второго порядка: Матрицуможно считать симметричной: в любом случае, мы используем только её верхний треугольник. Из-за использования попарных взаимодействий пользователей и объектов в полученной модели будетпараметр, и так какможет быть очень большим, работать с такой моделью может оказаться непросто. Для решения этой проблемы можно использовать следующий трюк. Сопоставим каждому признакувектордля некоторого не очень большогои представим модель в виде: Таким образом, мы заменяем симметричную матрицу коэффициентовна её низкоранговое приближение, где– матрицас векторамипо столбцам. Число параметров модели при этом можно снизить до. На практике матрицаразреженная, и, как правило, даже при небольшомполучается её неплохо приблизить. В то же время, при небольшихмодель обладает лучшей обобщающей способностью. Вычислитьпо можно за: Итоговая модель имеет вид Данная модель и называетсяфакторизационной машиной. Первоначально факторизационные машины использовали только коллаборативный сигнал, но, как мы уже видели, в такую модель можно естественным образом добавить и контентную информацию. Факторизацонную машину можно обучать для решения разных задач. Например: Предсказание рейтинга. Ответ моделиможно интерпретировать, как вещественный рейтинг, и решать задачу регрессии. Бинарную классификацию рекомендовать/не рекомендовать. Тогдаимеет смысл логита, и мы можем оптимизировать оптимизировать log loss или hinge loss. Ранжирование объектов. Тогда– это ранжирующая функция. Модель обычно обучается градиентным спуском. Оригинальная статья Статья про практическое применение Как следующий этап развития факториационных машин, появилась идея иметь несколько различных латентных представлений для каждой из фичей. Пример: есть три разных по своей природе признака: год выпуска, цвет и марка автомобиля. В факторизационной машине для учёта взаимодействия год-цвет и год-марка используется один и тот же вектор для года. Но так как эти признаки разные по смыслу, то и характер их взаимодействия может отличаться. Идея: использовать 2 разных вектора для признака «год выпуска» при учёте взаимодействий год-цвет и год-марка. Таким образом, модель принимает вид: Авторы статьи выложилиисходный код своей библиотеки libffm, с помощью которой они смогли войти в топ-3 сразу в трёх соревнованиях на kaggle (Criteo, Avazu, Outbrain). Подробнее об этом можно почитатьвот тут.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Оригинальная статья",
        "url": "https://www.csie.ntu.edu.tw/~cjlin/papers/ffm.pdf"
      },
      {
        "text": "Статья про практическое применение",
        "url": "https://arxiv.org/pdf/1701.04099.pdf"
      },
      {
        "text": "исходный код своей библиотеки libffm",
        "url": "https://github.com/ycjuan/libffm"
      },
      {
        "text": "вот тут",
        "url": "https://www.csie.ntu.edu.tw/~r01922136/libffm/"
      }
    ]
  },
  {
    "document_title": "Контентные рекомендации",
    "url": "https://education.yandex.ru/handbook/ml/article/kontentnye-rekomendacii",
    "section_title": "DSSM (deep sematic similiarity model)",
    "text": "Теперь рассмотрим ещё одну популярную модель, которая использует контентную информацию для построения рекомендаций –DSSM. Оригинальная статья В оригинальной статье DSSM была использована для нахождения «схожести» между поисковым запросом и документом. Для этого она использовала текст запроса и текст документа. DSSM представляет из себя «двуногую» (two-tower) нейронную сеть. В исходной постановке на первый вход подаётся текст запроса, а на второй – текст документа. Далее, независимо для текста запроса и текста документа строятся эмбеддинги. Итоговая «схожесть» вычисляется, как косинусная мера близости между ними. На схеме ниже Q – это запрос (query), а D – документ (document). Некоторые авторы пытались в качестве меры близости рассматривать вместо косинусной меры обучаемый MLP, но это оказалось гиблой идеей. Эта архитектура оказалась крайне удобной при использовании на практике, так как эмбеддинги пользователя и объекта можно предподсчитать независимо и дальше хранить сразу готовые представления для них, а при запросе к рекомендациям просто пересчитывать меру близости, что ускоряет применение модели. Данная идея хорошо обобщается на построение рекомендаций. Поиск релевантных объектов можно представить, как задачу ранжирования, где вместо текстов запроса и документа мы будем иметь некоторую контентную информацию о пользователе и объекте. Давайте считать, что мы для каждого запросапредсказываем один релевантный документ. Обозначим черезипостроенные моделью эмбеддинги запросаи документасоответственно. Будем вычислять условную вероятность клика по документупри условии запросаследующим образом: где Здесь– коэффициент сглаживания, который подбирается эмпирически, а– число всех документов. Если в качестве функции потерь мы выбираем кросс-энтропию, то на паре запрос-кликнутый документона принимает вид Но вычислять градиент такого функционала для каждого примера дорого, ведь для этого придётся для каждого запроса находить вероятность клика по всем документам. Что же делать? На помощь приходитnegative sampling. Заметим, что среди документовв знаменателеесть лишь один кликнутый, а остальные тысячи и миллионы являются отрицательными примерами. Есть смысл на каждом шаге оптимизации рассматривать не все из них, а только небольшую выборку, вместо полной суммы беря где– подобранные для запросанегативные примеры. Генерировать их можно по-разному; на практике чаще всего используют одну из следующих стратегий: Равновероятно выбирать подмножество документов из некликнутых. В оригинальной статье предлагают брать позитивные и негативные в соотношении. С большей вероятностью выбирать те из некликнутых документов, популярность которых выше. На каждой эпохе обучения выбирать некликнутые документы, получившие максимальный скор для этого запроса на предыдущей эпохе. Задачу построения рекомендаций можно решать, как задачу ранжирования. Например, это можно делать с помощью попарного лосса. А именно, рассмотрим пару объектов, в которой– релевантный, ане релевантный для пользователя. Тогда мы можем использовать один из двух вариантов функции потерь: . Тем самым модель будет учиться ранжировать положительные примеры выше отрицательных. (triplet loss). При этом модель обучается так, чтобы положительный и отрицательный примеры как можно больше отличались. Эта функция потерь довольно популярна не только в DSSM сетках, но и в целом в задачах, где нужно обучить парные представленияобъектовиз разных доменов так, чтобы для релевантных друг другуиэмбеддинги оказывались близкими, а для не релевантных далёкими. Рассмотрим батчразмера, где– пользователь,– пользователю, а– таргет, степень релевантности объекта пользователю. Построим по ним: матрицу эмбеддингов пользователей; матрицу эмбеддингов объектов; вектор таргетов. Рассмотрим матрицу где softmax берётся по строкам Рассмотрим функцию потерь вид Эта функция потерь старается сделать так, чтобы для релевантных друг другу (с) парскалярное произведение эмбеддинговбыло максимальным.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Оригинальная статья",
        "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/cikm2013_DSSM_fullversion.pdf"
      }
    ]
  },
  {
    "document_title": "Контентные рекомендации",
    "url": "https://education.yandex.ru/handbook/ml/article/kontentnye-rekomendacii",
    "section_title": "Трансформеры для рекомендаций",
    "text": "В 2018 году появилась архитектура трансформеров на основе механизма внимания. Модели на основе трансформеров показали state-of-the-art результаты на большом числе NLP задач, а впоследствии оказалось, что они отлично подходят и для задач компьютерного зрения. С их помощью можно решать и задачи рекомендаций. Аналогия заключается в следующем: если в NLP трансформеры работают с последовательностями токенов, то в рекомендациях в качестве последовательности можно взять историю событий пользователя. Каждый элемент последовательности – это взаимодействие пользователя с объектом, например, клик на объект. Классические модели рекомендаций часто игнорируют тот факт, что история пользователя – это направленная последовательность, в которой порядок событий имеет значение. Трансформеры позволяют учитывать как порядок событий, так и сложные паттерны в поведении и интересах пользователя. Например, исследователи из Alibaba представили модель, которую назвали Behaviour Sequence Transformer. Авторы заявляют, что модель используется в продакшене. Модель решает задачу Click Through Rate (CTR) prediction – предсказание вероятности клика по объекту. На вход модели подается история кликов пользователя, на основе которой нужно предсказать вероятность клика по заданному объекту. Роль архитектуры трансформера здесь в том, чтобы качественно закодировать представление пользователя, после чего применяется обычный multi layer perceptron (MLP) для предсказания вероятности. Помимо архитектур, которые специально разрабатываются под задачи рекомендаций, трансформеры можно использовать и как обособленные предобученные модели для построения векторых представлений текстов или изображений, которые затем подаются как признаки для решения downstream задач в домене рекомендаций. Несмотря на очевидные преимущества трансформеров с точки зрения качества, их использование в продакшене часто ограничивается имеющимися вычислительными ресурсами. Это особенно актуально для рекомендаций, где модели важно применять непосредственно в момент запроса пользователя.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Машинное обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/mashinnoye-obucheniye",
    "section_title": "Критерии качества",
    "text": "По обучающей выборке мы хотим построить модель, предсказания которой достаточно хороши. Что вообще значит «достаточно хороши»? Не понимая, чего мы хотим добиться, мы не предложим хорошего решения, поэтому нужно внимательно отнестись к выборуметрик качества. Возможно, вы уже участвовали в соревнованиях по анализу данных. На таких соревнованиях метрику организатор выбирает за вас, и она, как правило, непосредственным образом связана с результатами предсказаний. Но на практике всё бывает намного сложнее. Например, мы хотим: решить, сколько коробок с бананами нужно завтра привезти в конкретный магазин, чтобы минимизировать количество товара, который не будет выкуплен, и минимизировать вероятность того, что покупатель к концу дня не найдёт желаемый продукт на полке; увеличить счастье пользователей от работы с нашим сервисом, чтобы пользователи стали лояльнее, а сервис мог получать стабильный прогнозируемый доход; решить, нужно ли направить пациента на дополнительное медицинское обследование. В каждом конкретном случае может возникать целая иерархия метрик. Самый верхний уровень – этобизнес-метрики, например, будущий доход сервиса. Их трудно измерить в моменте, они сложным образом зависят от совокупности всех наших усилий, не только связанных с машинным обучением. Онлайн(online)метрики– это характеристики работающей системы, с помощью которых мы надеемся оценить, что будет с бизнес-метриками. Например, это может быть:– Медианная длина сессии в онлайн-игре. Можно предположить, что пользователь, который долго сидит в игре – это довольный пользователь.– Среднее количество бананов на полках во всех магазинах торговой сети в конце дня. Не всегда плоды наших трудов оцениваются числами. Многое может зависеть от субъективного восприятия людей, и для того, чтобы оценить их реакцию до выпуска в продакшен, применяется оценка специально нанятыми людьми – асессорами. Например, так можно оценивать, получилось ли у нас улучшить качество машинного перевода или релевантность выдачи в поисковой системе. Офлайн(offline)метрикимогут быть измерены до введения модели в эксплуатацию, например, по историческим данным. В задачах, в которых нужно предсказывать какой-то конкретный таргет, офлайн метрики обычно оценивают отклонение предсказаний модели от истинных значений таргета. Например, это может быть точность предсказания, то есть число верно угаданных значений, или среднеквадратичное отклонение. Асессорскую оценку тоже можно считать офлайн-метрикой В этой книге речь в основном пойдёт об офлайновых метриках и о функциях потерь. И прежде, чем вы начнёте знакомиться с методами решения задач обучения с учителем, полезно посмотреть, какими бывают метрики качества. Вот несколько примеров: для задачи постановки диагноза хорошими метриками могут быть, например, доля правильно поставленных диагнозов или доля больных, которым удалось поставить правильный диагноз (а вы поняли разницу?); для задачи предсказания цены квартиры метрикой качества может быть доля квартир, для которых разница между предсказанным и истинным значением цены не превысила какого-то порога, или средний модуль разницы между предсказанным и истинным значением; для задачи ранжирования поисковых документов по запросу — доля пар документов, которые мы упорядочили неправильно. Цель обычно в том, чтобы найти модель, для которой значение метрики будет оптимальным. Вопрос на подумать.Важно помнить, что разные нужды заказчика могут диктовать самые разные метрики. Вернёмся к задаче постановки диагноза пациентам больницы. Какие метрики вы предложили бы использовать в каждом из следующих случаев: обычный год в обычном терапевтическом отделении обычной больницы; определение очень неприятной болезни, которая жутким клеймом падёт на каждого, кому поставили такой диагноз; определение опасной и очень заразной болезни. Вопрос на подумать.Рассмотрим задачу детектирования людей на изображении. Чаще всего под детектированием понимают указание местоположения человека на картинке. Например, модель пытается выделить прямоугольник, в котором, по её мнению, есть человеческая фигура. Подумайте, какие метрики можно было бы использовать в различных ситуациях для измерения качества решения этой задачи. Не забудьте, что метрики — это способ численно измерить то, насколько модель помогает нам в жизни, так что важно думать о том, зачем нам вообще детектировать людей. Критерии качества не всегда сводятся к метрикам. Бизнес или общество могут накладывать и другие требования, например: Модель может выдавать предсказания в режиме реального времени. Заметим, что это требование не только к модели, но и к её реализации, а также к тому железу или к тем серверам, на которых она работает. Модель достаточно компактна, чтобы помещаться на мобильном телефоне или другом устройстве. Можно объяснить, на основании чего модель сделала то или иное предсказание для конкретного объекта. Это может быть важным в случае, если модель решает что-то важное в жизни человека, например, дадут ли кредит или будет ли согласовано дорогостоящее лечение. Такое требование является частным случаем более общего понятия интерпретируемости модели. Предсказания модели не дискриминируют какую-либо категорию пользователей. Например, если двум людям с одинаковой и достаточно длинной историей просмотров онлайн-кинотеатр рекомендует разные фильмы только из-за того, что у них разный пол, то это не здорово.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Машинное обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/mashinnoye-obucheniye",
    "section_title": "Данные",
    "text": "Машинное обучение начинается с данных. Важно, чтобы их было достаточно много и чтобы они были достаточно качественными. Некоторые проекты приходится откладывать на неопределённый срок из-за того, что просто невозможно собрать данные. Чем сложнее задача, тем больше данных нужно, чтобы её решить. Например, существенные успехи в задачах распознавания изображений были достигнуты лишь с появлением очень больших датасетов (и, стоит добавить, вычислительных мощностей). Вычислительные ресурсы продолжают совершенствовать, но во многих ситуациях размеченных данных (то есть объектов, которым кто-то сопоставил ответ) было бы по-прежнему слишком мало: например, для решения задачи аннотирования изображений (image captioning) потребовалось бы огромное количество пар (изображение, описание). В некоторых случаях можно воспользоваться открытыми датасетами. Сейчас их доступно довольно много и некоторые весьма велики, но чаще всего они создаются для довольно простых задач, например, для задачи классификации изображений. Иногда датасет можно купить. Но для каких-то задач вы нигде не найдёте данных. Скажем, авторам неизвестно больших и качественных корпусов телефонных разговоров с расшифровками – в том числе и по причинам конфиденциальности таких данных. Бороться с проблемой нехватки данных можно двумя способами. Первый – использованиекраудсорсинга, то есть привлечение людей, готовых разметить много данных. Во многих ситуациях (например, когда речь заходит об оценке поисковой выдачи) без дополнительной разметки никак не обойтись. Мы расскажем про краудсорсинг подробнее в соответствующем параграфе. Некоторые проекты, в первую очередь научные и социальные, используют такжеcitizen science– разметку данных волонтёрами без какого-либо вознаграждения, просто за чувство причастности к доброму делу исследования животных Африки или формы галактик. Второй же способ состоит в использовании неразмеченных данных. К примеру, в задаче аннотирования изображений у нас есть огромное количество никак не связанных друг с другом изображений и текстов. Однако, мы можем использовать их для того, чтобы помочь компьютеру понять, какие слова в принципе могут стоять рядом в предложении. Подходы, связанные с использованием неразмеченных данных для решения задач обучения с учителем, объединяются терминомself-supervised learningи очень активно используются сейчас. Важной составляющей являетсяобучение представлений(representation learning) — задача построения компактных векторов небольшой размерности из сложных по структуре данных, например, изображений, звука, текстов, графов, так, чтобы близкие по структуре или семантике данные получали метрически близкие представления. Делать это можно разными способами — например, используя фрагменты моделей, обученных для решения какой-либо другой задачи, или строя модель, предсказывающую скрытую часть объекта по оставшейся его части — например, пропущенное слово в предложении. Этому будет посвященотдельный параграфнашего учебника. Но кроме количества данных важно ещё и то, насколько они хороши и удобны для анализа. Давайте разберёмся, что это значит и какие с этим бывают проблемы. Для работы с объектом модель должна опираться на какие-то его свойства, например, доход человека, цвет левого верхнего пикселя на изображении или частоту встречаемости слова «интеграл» в тексте. Эти свойства обычно называютсяпризнаками, а совокупность свойств, которые мы выделили у объекта – егопризнаковым описанием. Вот несколько простых и распространённых разновидностей признаков: Численные– например, рост или доход. Иногда отдельно выделяют вещественные и целочисленные признаки. Категориальныепризнаки принимают значения из некоторого дискретного множества. Например, профессия человека или день недели. Бинарные признакипринимают два значения:иили «да» и «нет». С ними можно работать и как с численными, и как с категориальными. Среди категориальных признаков иногда выделяютординальные. Они принимают значения из некоторогоупорядоченногодискретного множества. Например, класс опасности химического вещества (бывает от 1-го до 4-го) или год обучения для студента являются ординальными. Приходится иметь дело и с более сложно устроенными признаками. Например, описание ресторана может содержать тексты отзывов или фотографии, а профиль человека в социальной сети – список его друзей. Для многих однородных типов данных, таких как изображения, видео, тексты, звук, графы, разработано большое количество методов извлечения признаков – сейчас в первую очередь нейросетевых. О них вы сможете прочитать в разделах про нейросетевые архитектуры для соответствующих типов данных. Если же попадаются какие-то более сложно устроенные данные, могут потребоваться дополнительные усилия для извлечения из них признаков – этот процесс называютfeature engineering. Удобно бывает записать данные в виде таблицы, строки которой соответствуют объектам, а столбцы – признакам. Например: Данные, представленные в таком виде, называютсятабличными. Табличные данные – один из самых удобных для анализа форматов. Свои успешные пайплайны работы есть также для уже упомянутых текстов, звука, изображений, видео, графов. Лучше всего, если все признаки являются численными. Тогда с таблицей можно работать как с объектом линейной алгебры –матрицей объекты-признаки. Создание информативного признакового описания очень важно для дальнейшего анализа. Но нужно также следить за качеством полученных данных. Вам могут встретиться, например, следующие проблемы: Пропуски(пропущенные значения). Так, в примере табличных данных выше нам неизвестен возраст Васи. Объекты или признаки, в которых есть пропуски, можно удалять из выборки, но если пропусков довольно много, мы можем потерять таким образом слишком много информации. Кроме того, наличие пропуска само по себе может нести информацию: скажем, это может говорить о систематической проблеме в сборе данных для того или иного сегмента выборки. Некоторые модели, например, решающие деревья, обладают собственными средствами для работы с пропусками, другие же – например, линейные модели или нейросети – требуют, чтобы пропуски были вычищены или заменены на что-то. Выбросы, то есть объекты, которые резко отличаются от большинства остальных. Например, в датасете с информацией о клиентах банка 140-летний человек, очевидно, будет весьма нетипичным. Выбросы могут возникать из-за ошибок при сборе данных или представлять собой реально существующие аномалии. Обычно выбросы лучше удалять, но в некоторых случаях выбросами могут быть важные объекты (например, очень богатые клиенты банка), и тогда их, возможно, стоит отлавливать и обрабатывать отдельно. Ошибки разметки. Если, например, вы собираете данные с помощью разметчиков-людей, то вы должны быть готовы к тому, что часть таргетов будет отмечена неправильно. Даже если не думать о том, что не все из разметчиков совершенно честные и старательные, задача может оказаться для них сложной. Data drift. С течением времени данные могут меняться. Например, может измениться схема сбора данных, и они начнут приходить в формате, который вообще не обрабатывается моделью. Или же может поменяться распределение данных: скажем, если вы делали образовательный сервис для студентов, а к вам стали приходить и более зрелые люди. Data drift – это суровая реальность для любой системы, которая решает не сиюминутную задачу, поэтому нужно уметь мониторить распределение данных и, если нужно, обновлять модель. Встречаются и другие проблемы. Нередко существенную часть данных приходится выкидывать, потому что в процессе сбора что-нибудь сломалось или потому, что полгода назад в сервисе изменили систему логирования и более старые данные невозможно склеить с более новыми.",
    "source_type": null,
    "useful_links": [
      {
        "text": "отдельный параграф",
        "url": "https://academy.yandex.ru/handbook/ml/article/obuchenie-predstavlenij"
      }
    ]
  },
  {
    "document_title": "Машинное обучение",
    "url": "https://education.yandex.ru/handbook/ml/article/mashinnoye-obucheniye",
    "section_title": "Модель и алгоритм обучения",
    "text": "Модель — это некоторый способ описания мира. Например, «Земля плоская» — это модель, и не такая плохая, как вам может показаться. Ей активно пользуются, когда всё происходит в масштабах одного города и кривизной поверхности можно пренебрегать. С другой стороны, если мы попробуем рассчитать кратчайший путь из Парижа в Лос-Анджелес, модель плоской Земли выдаст неадекватный ответ, она войдёт в противоречие с имеющимися данными, и её придётся заменить на «Земля круглая», «Земля имеет форму эллипсоида» и так далее — в той мере, в которой нам важна точность и в какой нам это позволяет (не)совершенство измерительной техники. Так, модель «Земля — это похожая на геоид с шершавостями на месте горных хребтов» очень точная и замечательная, но, возможно, будет избыточно сложной для большинства практических задач и при этом слишком тяжёлой в плане вычислений. В первых параграфах мы будем рассматривать в основном предсказательные модели, то есть модели вида, которые пытаются уловить зависимость между признаковым описаниемобъекта и таргетом. Но порой мы будем иметь дело и с моделями данных: например, «такой-то признак имеет нормальное распределение». Чаще всего предсказательные модели мы будем брать из некоторого параметрического семейства, где— параметры, которые мы будем подбирать по данным. Для примера давайте возьмём задачу предсказания цены квартиры. В качестве класса моделей выберем константные функции(то есть будем для всех квартир предсказывать одно и то же значение цены). Поскольку значение не зависит от, нам не очень важно, в каком виде получено признаковое описание: это может быть набор совершенно любых сведений о квартире. Не забудем зафиксировать метрику качества —среднее абсолютное отклонение(mean absolute error, она жеMAE). где— это модель (та самая,),— обучающие примеры (данные о квартирах, которые мы смогли достать),— правильные ответы (то есть цены на известные нам квартиры). Чтобы найти минимум MAE, возьмём производную от выражения и приравняем её к нулю: Нам подходят точки, для которых число, строго меньших, равно числу, строго больших. Таким образом, нам подходитмедиананабора: Вопрос на подумать.Давайте теперь в задаче предсказания цены квартиры рассмотрим метрикусреднеквадратичное отклонение(MSE): Каким будет оптимальное значение параметрадля константной модели? Прекрасно, значит, в классе константных функций мы можем найти оптимальную модель. Может быть, это можно сделать и в каком-нибудь более интересном классе? Этому вопросу и будет посвящена большая часть нашей книги. Классический курс ML состоит из описания классов моделей и способов работы с ними. Несмотря на то что для решения большинства практических задач на сегодня достаточно знать только два типа моделей —градиентный бустинг на решающих деревьяхинейросетевые модели— мы постараемся рассказать и про другие, чтобы развить у вас глубинное понимание предмета и дать возможность не только использовать лучшие сложившиеся практики, но и, при вашем желании, участвовать в проработке новых идей и поиске новых методов — уже в роли исследователя, а не просто инженера. Кроме выбора модели важен также выборалгоритма обучения. Алгоритм обучения — это процедура, которая превращает обучающую выборку в обученную модель. Скажем, в примере выше для константной модели мы в качестве алгоритма обучения использовали поиск нуля градиента. Как мы увидим дальше, градиентные методы используются для обучения многих моделей, и это очень богатый класс методов оптимизации, из которого порой не так просто выбрать лучший. В качестве примера рассмотрим задачу бинарной классификации точек на плоскости, для которой выберем линейную модель: Метрикой будет accuracy, то есть доля верных предсказаний. Теперь нам нужно по обучающей выборке подобрать оптимальную разделяющую прямую. Числаиявляютсянастраиваемыми(обучаемыми)параметрамимодели, именно их будет по выборке восстанавливать алгоритм обучения. Но есть проблема: метрика accuracy не дифференцируема. Поэтому мы должны подобрать другую дифференцируемую функцию, минимизация которой будет более или менее соответствовать оптимизации вероятности. Такая функция называетсяфункцией потерь,лоссом(от словаloss) илилосс-функцией. О том, как могут выглядеть лосс-функции для бинарной линейной классификации, вы можете почитать в параграфе пролинейные модели. В качестве алгоритма обучения мы можем взять теперь градиентный спуск: где— шаг оптимизации — коэффициент, влияющий на скорость и устойчивость алгоритма. Отметим, что разный выбор коэффициента, вообще говоря, даёт разные алгоритмы обучения, которые могут приводить к разным результатам: еслислишком мал, то спуск может не дойти до оптимума, а если слишком велик, то алгоритм будет «скакать» вокруг оптимума и никогда туда не попадёт. Мы видим, что важен не только выбор модели, но и выбор алгоритма обучения. Числоявляетсягиперпараметромалгоритма, то есть задаётся до начала обучения — но его тоже можно подбирать по данным. Более подробно о подборе гиперпараметров вы можете узнать в соответствующемпараграфе. Может показаться, что мы вас обманули, когда пугали сложностями: очевидно, что для любой задачи машинного обучения можно построить идеальную модель, надо всего лишь запомнить всю обучающую выборку с ответами. Такая модель может достичь идеального качества по любой метрике, но радости от неё довольно мало, ведь мы хотим, чтобы она выявила какие-то закономерности в данных и помогла нам с ответами там, где мы их не знаем. Важно понимать, какая у построенной моделиобобщающая способность, то есть насколько она способна выучить общие закономерности, присущие не только обучающей выборке, и давать адекватные предсказания на новых данных. Для того чтобы предохранить себя от конфуза, поступают обычно так: делят выборку с данными на две части:обучающую выборкуитестовую выборку(trainиtest). Обучающую выборку используют для собственно обучения модели, а метрики считают на тестовой. Такой подход позволяет отделить модели, которые просто удачно подстроились к обучающим данным, от моделей, в которых произошлагенерализация(generalization), то есть от таких, которые на самом деле кое-что поняли о том, как устроены данные, и могут выдавать полезные предсказания для объектов, которых не видели. Например, рассмотрим три модели регрессионной зависимости, построенные на одном и том же синтетическом датасете с одним-единственным признаком. Жёлтым нарисованы точки обучающей выборки. Здесь мы представим, что есть «истинная» закономерность (пунктир), которая искажена шумом (погрешности измерения, влияние других факторов и т.д.). Левая, линейная модель недостаточно хороша: она сделала, что могла, но плохо приближает зависимость, особенно при маленьких и при больших. Правая «запомнила» всю обучающую выборку (и в самом деле, чтобы вычислить значение этой функции, нам надо знать координаты всех исходных точек) вместо того, чтобы моделировать исходную зависимость. Наконец, центральная, хоть и не проходит через точки обучающей выборки, довольно неплохо моделирует истинную зависимость. Алгоритм, избыточно подстроившийся под данные, называютпереобученным. С увеличением сложности модели ошибка на обучающей выборке падает. Во многих задачах очень сложная модель будет работать примерно так же, как модель, «просто запомнившая всю обучающую выборку», но с генерализацией всё будет плохо: ведь выученные закономерности будут слишком специфическими, подогнанными под то, что происходит на обучающей выборке. Мы видим это на трёх графиках сверху: линейная функция очень проста, но и закономерность приближает лишь очень грубо; на правом же графике мы видим довольно хитрую функцию, которая точно подобрана под значения из обучающей выборки, но явно слишком эксцентрична, чтобы соответствовать какой-то природной зависимости. Оптимальная же генерализация достигается на модели не слишком сложной и не слишком простой. В качестве иллюстрации для того же самого датасета рассмотрим модели вида Ясно, что с ростомсложность модели растёт, и она достигает всё лучшего качества на обучающей выборке. А что, если у нас есть ещё тестовая выборка? Каким будет качество на ней? Вот так могут выглядеть графики среднеквадратичного отклонения (MSE) для обучающей и тестовой выборок: Мы видим здесь типичную для классических моделей картину: MSE на обучающей выборке падает (может быть, даже до нуля), а на тестовой сперва падает, а затем начинает снова расти. Замечание. Для моделей глубинного обучения всё немного интереснее: в некоторых ситуациях есть грань, за которой метрика на тестовой выборке снова начинает падать. Но об этом в своё время. Пока давайте запомним, что слишком сложная модель — это вредно, а переобучение — боль. Точный способ выбрать алгоритм оптимальной сложности по данной задаче нам пока неизвестен, хотя какую-то теоретическую базу имеющимся философским наблюдениям мы дадим в главе про теорию обучения; при этом есть хорошо продуманная методология сравнения разных моделей и выбора среди них оптимальной — об этом мы обязательно расскажем вам в следующих главах. А пока дадим самый простой и неизменно ценный совет: не забывайте считать метрики на тестовой выборке и никогда не смешивайте её с обучающей! Вопрос на подумать.Обсуждая переобучение, мы упоминали про сложность модели, но не сказали, что это такое. Как бы вы её определили? Как описать / сравнить сложность моделей для двух приведённых ниже задач? Почему, кстати, мы решили, что средняя модель ОК, а правая переобученная? В момент, когда подобраны все обучаемые параметры и гиперпараметры модели, работа специалиста по машинному обучению не заканчивается. Во-первых, модель чаще всего создают для того, чтобы она работала в некотором продакшене. И чтобы она там оказалась, нужно эффективно её закодить, научить работать параллельно и подружить с используемыми вами фреймворками. Процесс выкатки в продакшен называется словомдеплойилидеплоймент(отdeploy). После деплоя можно посчитать онлайн-метрики. Также имеет смысл провестиАБ-тестирование, то есть сравнение с предыдущей версией модели на случайно выбранных подмножествах пользователей или сессий. Более подробно об АБ-тестировании вы сможете почитать в соответствующем параграфе. Если новая модель работает не очень здорово, должна быть возможность откатиться к старой. После деплоймента модели важно продолжать дообучать или переобучать её при поступлении новых данных, а также мониторить качество. Мы уже обсуждали data drift, но бывает также иconcept drift— изменение зависимости между признаками и таргетом. Например, если вы делаете музыкальные рекомендации, вам нужно будет учитывать и появление новых треков, и изменение вкусов аудитории. О мониторинге качества моделей мы подробнее расскажем в соответствующем параграфе. Теперь предлагаем вам потренировать изученный материал на практике. Скачайтеноутбукс лабораторной работой. В нём вы найдете описания заданий и дополнительные материалы. Задания из лабораторной прикреплены к этому параграфу в виде задач в системе Яндекс Контест. Чтобы проверить себя, отправляйте решения по соответствующим задачам в систему. Успехов в практике!",
    "source_type": null,
    "useful_links": [
      {
        "text": "медиана",
        "url": "https://en.wikipedia.org/wiki/Median"
      },
      {
        "text": "линейные модели",
        "url": "https://education.yandex.ru/handbook/ml/article/linear-models"
      },
      {
        "text": "параграфе",
        "url": "https://academy.yandex.ru/handbook/ml/article/podbor-giperparametrov"
      },
      {
        "text": "ноутбук",
        "url": "https://yastatic.net/s3/ml-handbook/admin/autohw_intro_ML_92e1d33a4d.ipynb?updated_at=2024-03-07T13:21:15.515Z"
      }
    ]
  },
  {
    "document_title": "Матричное дифференцирование",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
    "section_title": "Основные обозначения",
    "text": "Вспомним определение производной для функции. Функциядифференцируема в точке, если где—дифференциалфункции: линейное отображение из мира-ов в мир значений. Грубо говоря, он превращает «малое приращение» в «малое приращение» («малые» в том смысле, что на о-малое можно плюнуть): Отметим, что дифференциал зависит от точки, в которой он берётся:. Подподразумевается норма вектора, например корень из суммы квадратов координат (обычная евклидова длина). Давайте рассмотрим несколько примеров и заодно разберёмся, какой вид может принимать выражениев зависимости от формы. Начнём со случаев, когда— скалярная функция. В примерах выше нам дважды пришлось столкнуться с давним знакомцем из матанализа:градиентомскалярной функции (у нескалярных функций градиента не бывает). Напомним, что градиентфункции в точкесостоит из частных производных этой функции по всем координатам аргумента. При этом его обычно упаковывают в ту же форму, что и сам аргумент: если— вектор-строка, то и градиент записывается вектор-строкой, а если— матрица, то и градиент тоже будет матрицей того же размера. Это важно, потому что для осуществления градиентного спуска мы должны уметь прибавлять градиент к точке, в которой он посчитан. Как мы уже имели возможность убедиться, для градиента скалярной функциивыполнено равенство где скалярное произведение — это сумма попарных произведений соответствующих координат (да-да, самое обыкновенное). Посмотрим теперь, как выглядит дифференцирование для функций, которые на выходе выдают не скаляр, а что-то более сложное.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Матричное дифференцирование",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
    "section_title": "Простые примеры и свойства матричного дифференцирования",
    "text": "Производная константы.Пусть. Тогдато есть— это нулевое отображение. А если— скалярная функция, то и Производная линейного отображения.Пусть— линейное отображение. ТогдаПоскольку справа линейное отображение, то по определению оно и является дифференциалом. Мы уже видели примеры таких ситуаций выше, когда рассматривали отображения умножения на матрицу слева или справа. Если— (скалярная) линейная функция, то она представляется в видедля некоторого вектора— он и будет градиентом. Линейность производной.Пусть, где— скаляры, а— некоторые отображения, тогда Производная произведения.Пусть, где— некоторые отображения, тогда Это же правило сработает и для скалярного произведения: В этом нетрудно убедиться, повторив доказательство или заметив, что в доказательстве мы пользовались лишь дистрибутивностью (= билинейностью) умножения. Производная сложной функции.Пусть. ТогдаЗдесь— дифференциалв точке, а— это применение отображенияк тому, что в скобках. Итого получаем: Важный частный случай:дифференцирование перестановочно с линейным отображением. Пусть, где— линейное отображение. Тогдасовпадает с самими формула упрощается:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Матричное дифференцирование",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
    "section_title": "Простые примеры вычисления производной",
    "text": "Вычислим дифференциал и градиент функции, где— вектор-столбец,— постоянный вектор. Вычислим производную и градиент, где— вектор-столбец,— постоянная матрица. Вычислим производную обратной матрицы:, где— квадратная матрица. Вычислим градиент определителя:, где— квадратная матрица. Вычислим градиент функции. С этой функцией мы ещё встретимся, когда будем обсуждать задачу линейной регрессии.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Матричное дифференцирование",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
    "section_title": "Примеры вычисления производных сложных функций",
    "text": "Вычислим градиент функции. Вычислим градиент функции. Вычислим градиент функции.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Матричное дифференцирование",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
    "section_title": "Вторая производная",
    "text": "Рассмотрим теперь не первые два, а первые три члена ряда Тейлора: где— второй дифференциал, квадратичная форма, в которую мы объединили все члены второй степени. Вопрос на подумать.Докажите, что второй дифференциал является дифференциалом первого, то есть Зависит ли выражение справа от порядкаи? Этот факт позволяет вычислять второй дифференциал не с помощью приращений, а повторным дифференцированием производной. Вторая производная может оказаться полезной при реализации методов второго порядка или же для проверки того, является ли критическая точка (то есть точка, в которой градиент обращается в ноль) точкой минимума или точкой максимума. Напомним, что квадратичная форманазывается положительно определённой (соответственно, отрицательно определённой), если(соответственно,) для всех, причёмтолько при. Теорема.Пусть функцияимеет непрерывные частные производные второго порядкав окрестности точки, причём. Тогда точкаявляется точкой минимума функции, если квадратичная формаположительно определена, и точкой максимума, если она отрицательно определена. Если мы смогли записать матрицу квадратичной формы второго дифференциала, то мы можем проверить её на положительную или отрицательную определённость с помощьюкритерия Сильвестра.",
    "source_type": null,
    "useful_links": [
      {
        "text": "критерия Сильвестра",
        "url": "https://ru.wikipedia.org/wiki/%D0%9A%D1%80%D0%B8%D1%82%D0%B5%D1%80%D0%B8%D0%B9_%D0%A1%D0%B8%D0%BB%D1%8C%D0%B2%D0%B5%D1%81%D1%82%D1%80%D0%B0"
      }
    ]
  },
  {
    "document_title": "Матричное дифференцирование",
    "url": "https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie",
    "section_title": "Примеры вычисления и использования второй производной",
    "text": "Рассмотрим задачу минимизациипо переменной, где— матрица с линейно независимыми столбцами. Выше мы уже нашли градиент этой функции; он был равен. Мы можем заподозрить, что минимум достигается в точке, где градиент обращается в ноль:. Отметим, что обратная матрица существует, так как, а столбцыпо условию линейно независимы и, следовательно,равен размеру этой матрицы. Но действительно ли эта точка является точкой минимума? Давайте оставим в стороне другие соображения (например, геометрические, о которых мы упомянем в параграфе пролинейные модели) и проверим аналитически. Для этого мы должны вычислить второй дифференциал функции. Мы нашли квадратичную форму второго дифференциала; она, оказывается, не зависит от точки (впрочем, логично: исходная функция была второй степени по, так что вторая производная должна быть константой). Чтобы показать, чтодействительно является точкой минимума, достаточно проверить, что эта квадратичная форма положительно определена. Докажем, что функцияявляется выпуклой вверх на множестве симметричных, положительно определённых матриц. Для этого мы должны проверить, что в любой точке квадратичная форма её дифференциала отрицательно определена. Для начала вычислим эту квадратичную форму. Чтобы доказать требуемое в условии, мы должны проверить следующее: что для любой симметричной матрицыи для любого симметричного (чтобы не выйти из пространства симметричных матриц) приращенияимеем Покажем это явно.Так как— симметричная, положительно определённая матрица, у неё есть симметричный и положительно определённый квадратный корень:Тогда что, конечно, меньше нуля для любой ненулевой.",
    "source_type": null,
    "useful_links": [
      {
        "text": "линейные модели",
        "url": "https://education.yandex.ru/handbook/ml/article/linear-models"
      }
    ]
  },
  {
    "document_title": "Методы оптимизации в Deep Learning",
    "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning",
    "section_title": "Напоминания",
    "text": "ОпределениеКритической точкой гладкой функцииназывается точка, для которой В выпуклой оптимизации такая точка обязательно будет точкой глобального минимума. В невыпуклой оптимизации все сильно сложнее: Бывает много локальных минимумов Бывают седловые точки Локальный минимум — это критическая точка, в которой Гессианположительно определён. Отметим, что часто в методах глобальной оптимизации рассматривается так называемая «локальная выпуклость», для которой требуется, чтобы функциябыла выпуклой внутри некоторого шара радиусас центром в точке. Критические точки, в которых гессиан не является знакоопределённым, называются седловыми. Пример: функцияимеет седловую точку. Гессиан в точке 0 Обратите внимание: во многих современных статьях про сходимость методов оптимизации первого порядка на невыпуклых функциях (пример) в качестве критерия сходимости рассматривают сходимость по норме градиента:при некотором заранее фиксированном. В выпуклой оптимизации этот критерий сходимости эквивалентен двум другим: сходимости по расстоянию до оптимума в пространстве параметров:; сходимости по расстоянию до оптимума по значениям функции. В невыпуклой оптимизации всё не так просто и поиск глобального минимума является в общем случае NP-трудной задачей. Критерийдаёт возможность исследовать сходимость к любой критической точке, но если речь об обучении нейронных сетях, то остается лишь надеяться, что эта критическая точка будет хорошим локальным минимумом.",
    "source_type": null,
    "useful_links": [
      {
        "text": "пример",
        "url": "https://arxiv.org/pdf/2003.02395.pdf"
      }
    ]
  },
  {
    "document_title": "Методы оптимизации в Deep Learning",
    "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning",
    "section_title": "Скользящее среднее в знаменателе AdaGrad. Методы RMSprop и Adam",
    "text": "В далекие 2012-2014е в мире было не так много опыта по построению хороших нейросетевых архитектур. «Канонические» методы оптимизации нейросетей RMSprop и Adam появлялись во времена, когда ещё не придумали основополагающих вещей вроде: Residual connectionиDense connection(статьи опубликованы в 2015/2016 соответственно, во всех экспериментах используется SGD, в статье и в ссылках не упоминаются методы Adam/RMSprop), плохо решались проблемы взрывов/затуханий градиентов и т.д. Batch NormalizationиLayer Normalization(2015/2016 соответственно) Также люди не умели правильно инициализировать нейросети гигантской глубины. статьи вроде1000+ layer fully connectedи10000+ layer CNNпозже. Кстати, этот цикл статей хочется особо отметить за интересную технику анализа распространения сигнала по нейронной сети. В общем, в те времена царило архитектурное средневековье со всеми родовыми проблемами нейронных сетей: Взрывы градиентов; Затухания градиентов; Взрывы-затухания сигнала на прямом проходе; Плохие начальные инициализации, нестабильный старт обучения. При попытках применять метод AdaGrad особо остро стояли проблемы 1 и 4. AdaGrad аккумулирует всю прошедшую историюбез затухания. Если в какой-то момент возникает одна из указанных проблем, знаменатель резко возрастает и больше не выправляется. Чтобы побороть проблемы 1-4, решили поработать над оптимизатором и сделать так, чтобы история в AdaGrad аккумулировалась с затуханием и метод оптимизации мог со временем забыть плохие точки. Самый популярный и простой в реализации метод — экспоненциальное скользящее среднее. Самая первая и самая простая модификация метода AdaGrad — метод RMSprop — вместо суммы использует экспоненциальное скользящее среднее в знаменателе: Методу RMSprop не было посвящено ни одной специализированной статьи, равно как и не было никаких доказательств его сходимости даже для выпуклых задач. Авторы Adam в статьеAdam: A Method For Stochastic Optimizationвводят два новшества по сравнению с RMSprop. Во-первых, это Momentum. Во вторых — Bias correction term. Напомним, как работает этот метод. Применяем bias correction Сразу перепишемив нерекурсивной форме с зависимостью только от: Авторы статьи пишут, что для правильной работы методаидолжны быть несмещенными оценкамиисоответственно. Допустим, все— независимые одинаково распредёленные случайные величины. Это довольно сильное предположение, но иначе не получатся красивые формулы. Рассмотрим на примере: Отсюда очевидно, что исходныеисмещены на множитель, поэтому авторы Adam делят на негои. Так какпри, эффект смещения сильнее всего заметен в начале итерационного процесса. Например, при классическоммы получаем смещение в 0.001 раз. В начале обучения bias correction призван уменьшить слишком большие шаги оптимизатора. В оригинальной статье приводится теорема с доказательством сублинейного Regret. Доказательство содержало ошибку, в новой работе 2018 года было доказано, что для любого набора гиперпараметров Adam существуетвыпуклаязадача, на которой он не сходится. Проблемы со сходимостью, впрочем, не являются специфичными для выпуклых задач: в нейронных сетях Adam тоже может вести себя странно, и об этом мы поговорим ниже в разделе «Как сломать адаптивные методы». Разбирать доказательство исходной статьи мы не будем, зато обратим внимание на пару неприятных фактов о различиях между «продаваемой» частью статьи и бекендом с экспериментами и доказательствами теорем. После успешного введения метода Adam в эксплуатацию в нейросети его окрестили «method of choice» в задачах стохастической оптимизации. Это было на 100% обусловлено его успехом в обучении нейронных сетей с нестабильными архитектурами. Структура статьи выглядит следующим образом: Выделенный в большую красивую видную рамочку алгоритм с дефолтными настройками вроде; Формулировка теоремы в разделе про доказательства; Эксперименты на нейросетях и выпуклых задачах. В пункте 1 описан алгоритм, который все нынче знают, как Adam. Мало кто знает, что в доказательствах сходимости и в экспериментах на выпуклых задачах использовался немного другой алгоритм: вместо константногоавторы статьи взяли. Сравним эти learning rate с AdaGrad: Авторы в экспериментах на логистической регрессииубили основное свойство Adam — неубывающие learning rate. Вспомним, как в разделе провывод AdaGradмы анализировали порядок убывания learning rate — он был. Отсюда следует, что у такого Adam learning rate убывают так же, как в AdaGrad. Словом, будьте внимательны при чтении статей: смотрите не только в описание алгоритмов, но и в их реализацию. Настоящий Adam, который в pytorch и tensorflow реализован без множителя, в выпуклой задаче разреженной логистической регрессии обычно работает намного хуже AdaGrad. Это справедливо как для чисто линейных моделей, так и для комбинированныхWide &Deepархитектур, из-за чего в одной и той же нейросети приходится использовать разные методы оптимизации для разных параметров. Тут нужно запомнить три идеи: Momentum Скользящее среднее в learning rate Bias correction На практике, часто почему-то рассматривают методы RMSprop и Adam как нечто отлитое в граните и не пытаются брать от них лучшее. Например, методу RMSprop обычно идет на пользу добавление bias correction от adam. Так что полезно помнить идеи, стоящие за методами оптимизации, и уметь их комбинировать.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Residual connection",
        "url": "https://arxiv.org/pdf/1512.03385.pdf"
      },
      {
        "text": "Dense connection",
        "url": "https://arxiv.org/pdf/1608.06993.pdf"
      },
      {
        "text": "Batch Normalization",
        "url": "https://arxiv.org/abs/1502.03167"
      },
      {
        "text": "Layer Normalization",
        "url": "https://arxiv.org/abs/1607.06450"
      },
      {
        "text": "1000+ layer fully connected",
        "url": "https://arxiv.org/abs/1711.04735"
      },
      {
        "text": "10000+ layer CNN",
        "url": "https://arxiv.org/pdf/1806.05393.pdf"
      },
      {
        "text": "Adam: A Method For Stochastic Optimization",
        "url": "https://arxiv.org/pdf/1412.6980.pdf"
      },
      {
        "text": "вывод AdaGrad",
        "url": "https://academy.yandex.ru/handbook/ml/article/adaptivnyj-ftrl#ada-grad-nailuchshij-adaptivnyj-metod"
      },
      {
        "text": "Wide &Deep",
        "url": "https://arxiv.org/abs/1606.07792"
      }
    ]
  },
  {
    "document_title": "Методы оптимизации в Deep Learning",
    "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning",
    "section_title": "Как сломать адаптивные методы со скользящим средним",
    "text": "Все диагональные адаптивные методы так или иначе используют покоординатный learning rate. Методы отличаются лишь формулировкойи: Все эти методы имеют единый вид формул FTRL, аналогичный формулам FTRL-AdaGrad: Вспомним теоретические ограничения на: — выпуклый; . Адаптивные методы с регуляризаторамибудут удовлетворять этим условиям, если все. В этом месте и локаются методы со скользящим средним: никто не обещал, что последовательностьбудет монотонно неубывать. Если же то метод может ломаться Обратите внимание. Momentum в методе Adam никак не повлияет на справедливость наших рассуждений, поскольку в формулах для адаптивных learning rate он не используется. Адаптивные методы с такими learning rate сломаются и с momentum, и без него. Обратите внимание. Bias correction в методе Adam уменьшает learning rate в начале обучения, заставляя метод делать меньшие шаги. Все рекуррентные формулы из таблицы можно переписать в виде Тогда неравенствоможно записать в виде Здесь мы можем подвести общую черту и сказать, что методы Adam и RMSprop дают, когдастановится меньше предыдущей накопленной истории с точностью до некоторой константы. А когда такое бывает? Уменьшение, как правило, означает приближение к критическим точкам. Добавление квадратичных регуляризаторов с отрицательным коэффициентом приводит к тому, что метод оптимизацииштрафует за близость к критическим точкам, заставляя убегать от них. Это приводит к тому, что метод не может нормально сойтись к локальным минимумам (в выпуклых задачах — просто к минимумам, что намного более критично). Отметим, что по разным координатаммогут вести себя по-разному. Таким образом, можно получить ситуацию, когда мы поощряем близость по одним координатам и штрафуем за близость по другим. AdaGrad невозможно сломать таким способом: для него гарантируется, что. Подставим в условие, сразу сократив константный: Чисто технически, при выведении формул можно подумать, что Adam страдает от указанных эффектов гораздо сильнее RMSprop, но на самом деле это не так. Переобозначимиз статьи про Adam как простодля общности обозначений. Распишем неравенстводля метода Adam: В отличие от RMSprop, у нас появился дополнительный множитель. С одной стороны, можно подумать, что метод строго хуже. Однако, этот множитель сильно больше нуля только во время первых шагов оптимизации, тогда как рассматриваемая нами проблема играет роль только на поздних стадиях оптимизации при приближении к критическим точкам. А к тому моменту, этот множитель будет практически равен единице и мы получим формулы выше от RMSprop. Поэтому, на самом деле, методы в одинаковой степени страдают от этих эффектов, но bias correction добавляет стабильности в начале. Если представить, что нейросеть — очень плохая и жутко невыпуклая задача, то можно рассматривать подобное поведение как «защиту» от промежуточных плохих критических точек, позволяющую нам «убегать» от них. Данная интерпретация, к сожалению, имеет множество недостатков: Никто не обещал, что новая критическая точка будет лучше старой и что мы, прыгая таким образом, будем улучшать качество модели. Не каждый локальный минимум плохой. Если текущая критическая точка — хороший локальный минимум с хорошей обобщающей способностью, то мы просто нормально не сойдемся к нему и не достигнем хорошего качества модели. Общественность уже идентифицировала такое поведение как проблему и решила ее в более поздних популярных оптимизаторах (см.раздел проAMSgrad). Большинство современных рекомендаций по обучению больших неонлайновых моделей вроде GPT или картиночных моделей содержат в себе learning rate scheduler'ы как обязательный для успеха ингредиент. Эти рекомендации нивелируют проблему отрицательных регуляризаторов. Все learning rate scheduler'ы заставляют learning rate убывать, что позволяет достигать лучших результатов, чем с помощью обычных Adam и RMSprop. В параграфе про FTL мы узнали, что градиентный метод без регуляризации отвратительно работает даже на выпуклых задачах, а если мы начнём вводить отрицательную регуляризацию, да еще и на сложных невыпуклых задачах, то все может стать еще хуже. В целом, мировой опыт говорит, что полагаться на подобные интерпретации при тюнинге модели не стоит. Итак, методы RMSprop и Adam плохо работают для выпуклых задач, особенно для разреженных задач, и могут приводить к субоптимальным решениям на train. Тем не менее, есть искушение заявить, что «это такая регуляризация в классическом смысле: не слишком хорошо сходимся к оптимальной точке, не слишком сильно переобучаемся под датасет и можем лучше работать на тесте». Это искушение особенно опасно потому, что подобные эффекты действительно могут иметь место, особенно в классической (не онлайновой) постановке задачи. Любая регуляризация направлена на то, чтобы сдвинуть оптимум решения исходной некорректно поставленной задачи в надежде, что точка оптимума измененной задачи будет обладать лучшей обобщающей способностью на тесте. В частности, такой эффект может иметь ранняя остановка методов оптимизации до их сходимости к точке оптимума. Однако здесь есть одно очень важное «но». Если введение регуляризации в некорректно поставленную задачу — это полностью осмысленный и контролируемый гиперпараметрами процесс, то хаотично разваливающийся вокруг точки оптимума метод оптимизации — нет. Подумайте: вдруг ваша задача фактически не является некорректно поставленной? Вдруг у вас огромный и очень репрезентативный датасет, благодаря чему оптимум на train всегда отлично работает в проде? В этом случае кривой метод оптимизации способен подпортить качество вашей модели. В задачах с разреженными параметрами ситуациюполучить еще легче. Допустим, у нас есть некоторый параметр, который встречается в 0.1% объектов выборки. В такой ситуации между появлениями этого объекта в выборке и очередным расчетом градиентов для него проходит значительное время. За это значительное время модель дообучалась, и за счет других, менее разреженных параметров могла научиться лучше прогнозировать очередной объект с этим параметром. Тогдауменьшается и, следовательно, больше шансов попасть в плохую ситуацию. Ниже мы рассмотрим метод AMSgrad и наперёд скажем, что для оптимизации разреженных параметров Adam/RMSprop добавление AMSgrad очень часто дает прибавку в качестве. На первый взгляд, парадоксальным кажется следующий факт: чем меньше learning rate, тем в бОльшую сторону может отклониться отрицательный регуляризатор: Однако в «жадных» формулах все с точностью до наоборот: Из жадных формул очевидно, что уменьшениеведет к уменьшению шага и, как следствие, увеличению стабильности алгоритма. Чтобы разрешить парадокс, надо вспомнить, что в FTRL решающее значение имеет не один отдельный регуляризатор, асумма. В начале процесса оптимизации, первый регуляризатор точно не сломается. Чем меньше learning rate, тем меньшие шаги мы делаем от начальной точки и, следовательно,тем меньше должна отличаться норма градиентов. Если от шага к шагу норма градиента меняется не слишком сильно, то мы накопим огромную кумулятивную регуляризациюк моменту, когда регуляризатор решит отклониться в отрицательную сторону. При бОльшем learning rate мы шагаем быстрее, и точки, когда ломается регуляризатор, достигаем тоже быстрее, накопив гораздо меньшую сумму. Если теперь для очередной точки мы получили отрицательный регуляризатор, то насколько сильно он может всё поломать? Окей, допустим, мы шагнули к критической точке. А насколько сильно может расколбаситьоднаплохая точка в регуляризаторе? Так, чтобы он перекрыл всю предыдущую сумму? Если градиенты ограничены по норме, то катастрофы, очевидно, не будет. Ограниченность градиентов по норме мы, с одной стороны, гарантировать не можем, с другой — проблемам взрыва/затухания градиентов в архитектурах уделяется столько внимания, что на практике это условие зачастую выполняется.",
    "source_type": null,
    "useful_links": [
      {
        "text": "AMSgrad",
        "url": "https://academy.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning#am-sgrad"
      }
    ]
  },
  {
    "document_title": "Методы оптимизации в Deep Learning",
    "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning",
    "section_title": "Чиним RMSprop и Adam",
    "text": "Время шло, люди учились строить хорошо обучаемые архитектуры. Стали даже появляться революционные идеи вродеReZero(не путать с аниме) с полным отказом от batchnorm/layernorm нормализаций в глубоких сетях и с улучшением качества работы и скорости сходимости. Ситуация со стабильностью обучения нейросетей кардинально изменилась. Несмотря на улучшение стабильности обучения, люди стали замечать, что при длительном процессе оптимизации Adam начинает сбоить. Авторы метода AMSgrad в статьеOn the Convergence of Adam and Beyondбыли одними из первых, кто провел почти аналогичный нашему анализ и добавили в Adam костыль, который обеспечивает выполнение условияи исключает отрицательные регуляризаторы. Обратите внимание: в разделее проLearning Rate Scheduling vs AdaGradмы поговорим о «цикличности истории» развития методов оптимизации в deep learning. Авторы статьиOn the Convergence of Adam and Beyondанализируют последовательность и говорят, что отрицательные значения в ней вызывают проблемы с процессом оптимизации. Их анализ в целом аналогичен приведённому выше, поэтому мы не будем его здесь дублировать. Авторы статьи не стали предлагать новых схем learning rate и просто модифицировали старую: выполнениеобеспечивается «в лоб» при помощи. Итоговое правило апдейта без momentum и без bias correction (оригинальный Algorithm 2 из статьи bias correction не использует): Если нужен метод с momentum, то можно просто заменитьв последней формуле на Оригинальные формулы из статьипредполагают, что для расчетамы держим два параметра:и. RMSprop и Adam хранят только один параметр. Таким образом, включение метода требует дополнительных расходов памяти (х1.5 относительно RMSprop и x1.33 относительно Adam). Выше при разборе методов RMSprop/Adam мы сказали, что на практике AMSgrad помогает разреженным параметрам. Для разреженных моделей потребление памяти — краеугольный камень, поэтому простое включение дефолтной реализации amsgrad из статьи может быть болезненным и, к сожалению, не оправданным. На практике же эвристика видадля разреженных параметров обычно работает так же хорошо и не требует дополнительной памяти. Никаких теоретических гарантий для нее нет, но на практике она работает. Оригинальная статья (и следующие букве оригинала стандартные реализации алгоритма, например, в PyTorch) предполагает убирание bias correction. Эксперименты на разреженных данных показывают, что убирание bias correction вредит сходимости, это полезная вещь. С практической точки зрения, есть два способа реализовать bias correction в AMSgrad: Post-correction:, Pre-correction:. С точки зрения корректности метода AMSgrad, правильный вариант — pre-correction, так как он не ломает максимум. А вот эксперименты показывают, что добавление pre-correction ничего не даёт, а вот post-correction действительно помогает в том смысле, что AMSgrad + post-bias correction лучше, чем просто RMSProp/Adam с bias correction. Итоговые формулы можно использовать такие: Другим способом улучшения сходимости методов RMSprop/Adam/SGD является learning rate scheduling (расписание learning rate, шедулер). Learning rate scheduler — это мета-алгоритм: они берёт любой стандартный метод оптимизации с константным параметром learning rateи предписывает схему измененияна каждом шаге, или на каждой эпохе, или на любом другом заданном периоде. Поскольку мы работаем с одним параметром, мы можем с ним делать всего две вещи: увеличивать или уменьшать. Эти два варианта имеют свои названия: Learning rate decay — уменьшение learning rate с течением времени с целью нивелировать осцилляцию RMSprop/Adam около критических точек. (Warm)Restart — обычно резкое увеличение learning rate. Warm — потому что мы уже сошлись в какую-то хорошую точку и сбрасываем только состояние оптимизатора в ней, но не переинициализируем сами параметры. WarmRestart может заключаться не только в увеличении, но и, например, в дополнительном сбросе состояния оптимизатора (обнуление momentum или), хотя автор статьи такой подход встречали достаточно редко Существует огромное количество вариантов расписания, каждый со своим графиком измененияи со своим любовно подобранным множеством задач, на которых данный метод показывает себя лучше других. Приводить здесь их список особого смысла нет, лучше просто откройтедокументацию любого фреймворкаи наслаждайтесь разнообразием вариантов. Мы же обсудим влияние learning rate decay на осцилляцию вокруг критических точек и дадим практические рекомендации по подбору расписаний. Для выпуклых задач в разделе про схемы убывания learning rate для FTRL-методов (константный регуляризатор,и AdaGrad) мы буквально на оценках на regret видели, что это важный аспект для асимптотики сходимости. В выпуклом случае, при приближении к минимуму мы должны оптимизировать решение с куда большей точностью. Норма градиентов при приближении к минимуму тоже уменьшаются, поэтому даже с константнымlearning rate шаги будут становиться меньше, но — как показывают и теоретические оценки на regret, и многочисленные их валидации в статьях — этого недостаточно. Уменьшение learning rate с правильной асимптотикой уменьшения дает куда более хорошие результаты. Для глубинного обучения и оптимизации к каким-то локальным минимумам эта логика тоже применима. Возвращаясь к методам Adam/RMSprop — напомним, что у них асимптотика learning rate. Им в любом случае пойдет на пользу уменьшение learning rate, даже если не брать во внимание их проблемы вокруг критических точек и взять метод AMSgrad, который от этих проблем не страдает. Отсюда же очевидно, что проблемы adam/rmsprop начинают стрелять гораздо меньше. Learning rate уменьшается =>от критической точки мы в плохих ситуациях шагаем на гораздо меньшее расстояние =>область, вокруг которой мы будем «прыгать», сужается =>мы худо-бедно, но сходимся. Как мы уже отмечали выше, шедулеров существует поистине фантастическое количество, гораздо больше, чем базовых оптимизаторов, к которым они применяются. Без структуризации подхода к ним работать становится сложно. Мы хотели бы дать вам следующие рекомендации: Выучите свою модель без learning rate scheduling со стандартными методами оптимизации и посмотрите, как ведёт себя loss для различных learning rate. Обязательно переберите learning rate на этом шаге. Начинать внедрение расписаний рекомендуем с шедулеров, которые только уменьшают learning rate. Классические варианты — ReduceOnPlateou или linear decay. Правильный подбор learning rate и темпа его уменьшения очень важны в любой задаче стохастической оптимизации. Только после того, как вы хорошенько потюните learning rate decay, можно смотреть в сторону WarmRestart. Иногда рестарты могут помочь. Автор статьи занимается в основном рекомендательными моделями и там эту технику практически никто не применяет. У методов SGD/RMSprop/Adam последовательностьне является асимптотически убывающей, и для того, чтобы это скомпенсировать, используется расписание learning rate. А вот у AdaGrad си так всё в порядке. Давайте восстановим хронологию событий: Метод AdaGrad пытаются применять к нейросетям в 2012+ годах, но тогда архитектуры были нестабильны, градиенты взрывались и навсегда портили знаменатель AdaGrad, сильно уменьшая learning rate. Появляются методы RMSprop/Adam(2013/2014) со скользящим средним в знаменателе, которые могут оправиться от взрыва градиента. Развитие архитектур нейронных сетей не стоит на месте, появляются разные видыresidual connection(2015),LayerNorm/BatchNorm(2015-2016), крутые методыначальной инициализации— огромное количество способов улучшения стабильности обучения. С развитием архитектур люди замечают, что RMSProp/Adam умеют застревать на одном уровне значений функции потерь, и начинают применять техники для уменьшения learning rate. В дальнейших работах метод AdaGrad часто рассматривается наравне с Adam/RSMprop и дает очень похожее, либо даже лучшее качество (см, например, статью проShampoo). А дело в том, что архитектуры уже очень хорошо инициализируются и правильно проектируются так, чтобы не было взрывов/затуханий градиентов ни на какой стадии оптимизации. Развитие методов оптимизации в deep learning сделало небольшой круг, и мы рекомендуем об этом помнить. Порой люди могут одновременно рассуждать о бесценной пользе learning rate decay (особенно с линейным убыванием как) и корить AdaGrad за бесконечное аккумулирование квадратов градиентов (которые убывают как). Так что если у вас вдруг хорошо заработал шедулер с— возможно, обычный AdaGrad будет лучше? В последнее время в литературе часто появляются заявления, что решения, полученные адаптивными методами в нейросетях, обладают худшей обобщающей способностью. Сразу хотим отметить, что большинство этих статей исследуют эти эффекты только на задачах Computer Vision на одних и тех же датасетах MNIST/CIFAR/ImageNet. В реальной жизни куда большее разнообразие постановок задач и датасетов, что сразу заставляет сомневаться в воспроизводимости этих эффектов. Рекомендация тут одна, как и всегда — досконально сами все проверяйте. Данные методы предложены авторами в статьеDecoupled Weight Decay Regularization, которую мы подробно разобрали в разделее про продвинутуюрегуляризацию. Методы AdamW и SGDW — это просто модификации методов Adam и SGD с momentum, которые используют линеаризованный decoupled. Авторы статьи изучали проблему, почему в их экспериментах SGD обобщает лучше Adam (но учится дольше и требует более аккуратной настройки). Они пришли к выводу, что дело не в магии SGD, а в том, что-регуляризация у этих двух методов работает по-разному. Добавив decoupling, авторы сумели показать, что decoupled Adam обгоняет SGD. Эти эффекты, повторимся, были уже рассмотрены ранее в разделее про продвинутуюрегуляризацию. Единственное, что мы не обсудили тогда — это momentum. В постановке Proximal Gradient Descent градиент заменяется на momentum Покоординатныемогут рассчитываться любыми методами: AdaGrad, RMSprop или Adam, не принципиально. На всякий случай напомним, что мы вывели потенциально более правильные формулы Метод SGDW получается из формул выше, если убрать покоординатность К сожалению, здесь мы не почерпнули новых идей, так как выяснили, что это просто очередная инкарнация Proximal методов оптимизации. Этот метод заключается в том, чтобы стартовать с адаптивного метода Adam и в некоторый момент переключиться на SGD. «Некоторый момент» — это, интуитивно, момент стабилизации всех статистик в Adam, когда мы выжали все из ускоренного старта адаптивных методов и хотим получше сойтись к хорошему оптимуму в найденной им окрестности. Отметим, что позднее переключение на SGD с неубывающими learning rate автоматически починит проблемы расходимости Adam ровно там, где они чаще всего и возникают: при хорошем приближении к локальным минимумам. Мы не будем здесь подробно рассматривать их анализ, вы можете сами познакомиться с ним в статьеOn The Variance Of The Adaptive Learning Rate And Beyond",
    "source_type": null,
    "useful_links": [
      {
        "text": "ReZero",
        "url": "https://arxiv.org/pdf/2003.04887.pdf"
      },
      {
        "text": "On the Convergence of Adam and Beyond",
        "url": "https://openreview.net/pdf?id=ryQu7f-RZ"
      },
      {
        "text": "Learning Rate Scheduling vs AdaGrad",
        "url": "https://academy.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning#learning-rate-scheduling-vs-ada-grad"
      },
      {
        "text": "On the Convergence of Adam and Beyond",
        "url": "https://openreview.net/pdf?id=ryQu7f-RZ"
      },
      {
        "text": "документацию любого фреймворка",
        "url": "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate"
      },
      {
        "text": "Adam",
        "url": "https://arxiv.org/abs/1412.6980"
      },
      {
        "text": "residual connection",
        "url": "https://arxiv.org/abs/1512.03385"
      },
      {
        "text": "LayerNorm",
        "url": "https://arxiv.org/abs/1607.06450"
      },
      {
        "text": "BatchNorm",
        "url": "https://arxiv.org/abs/1502.03167"
      },
      {
        "text": "начальной инициализации",
        "url": "https://arxiv.org/abs/1711.04735"
      },
      {
        "text": "Shampoo",
        "url": "https://arxiv.org/pdf/1802.09568.pdf"
      },
      {
        "text": "Decoupled Weight Decay Regularization",
        "url": "https://arxiv.org/abs/1711.05101"
      },
      {
        "text": "регуляризацию",
        "url": "https://academy.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii#l-2-regulyarizacziya"
      },
      {
        "text": "регуляризацию",
        "url": "https://academy.yandex.ru/handbook/ml/article/regulyarizaciya-v-onlajn-obuchenii#l-2-regulyarizacziya"
      },
      {
        "text": "On The Variance Of The Adaptive Learning Rate And Beyond",
        "url": "https://arxiv.org/pdf/1908.03265.pdf"
      }
    ]
  },
  {
    "document_title": "Методы оптимизации в Deep Learning",
    "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning",
    "section_title": "Online RMSprop",
    "text": "Особняком стоит метод, описанный в статьеVariants of RMSProp and Adagrad with Logarithmic Regret Bounds. Авторы не придумывали очередной хотфикс, а аккуратно заново выводили формулы. Также важно, что данный метод является строгим обобщением метода AdaGrad. В работе есть два нововведения: Переформулировка метода RMSprop так, чтобы:— Осталось экспоненциальное скользящее среднее;— Не было проблемы с отрицательными регуляризаторами и взрывающимися learning rate;— Метод AdaGrad являлся частным случаем нового метода;— Чтобы все эмпирически хорошо работало в т.ч. на глубоких моделях Формулировка новых алгоритмов оптимизации SC-AdaGrad и SC-RMSprop для сильно выпуклых функций с логарифмическими гарантиями на regret. SC в названии — Strongly Convex. Пока рассмотрим только первый пункт. Авторы вводят следующий общий метод: Нововведение здесь в том, что вместо фиксированногомы будем рассматривать последовательность. Авторы доказывают сублинейный regret для любых последовательностей, удовлетворяющих Докажем, что метод Adagrad — это метод OnlineRMSprop с. Аналогично выводам momentum в FTRL, перепишем рекуррентное выражение для: Подставив, получим Далее, подставляя это в формулу, получаем Докажем, что OnlineRMSprop не может сломать регуляризаторы в regret. Для этого преобразуем неравенство Из условияполучаем, что правая часть неравенства неположительна, а левая неотрицательно. Значит, последнее неравенство невозможно, то есть все. Таким образом, регуляризаторы не сломаются, сходимость будет иметь место и данный метод можно использовать в выпуклых задачах. Строгое доказательство сходимости и оценки на Regret можно прочитать в исходной статье. Как и ранее в методе AdaGrad, допустим, что. Тогда Привыполнено Докажем, что все элементы предела <1. Из этого, в частности, будет следовать, что learning rate у OnlineRMSprop не меньше, чем learning rate в AdaGrad. Если все все, то итерационный процесс OnlineRMSprop превращается в Предположим, что. Тогда: По индукции разворачиваем вплоть до, получаем противоречие. Полное доказательство предела оставляем читателям. Надо бы чем-нибудь снизу подпереть, что тоже к 1 сходится. Автор сдавал матан почти 10 лет назад и ему было очень неохота откапывать все эти прекрасные пределы, поэтому ответ был получен с помощью wolfram. Вывод: learning rate у OnlineRMSprop убывает со скоростью. Мы исправили ошибку предыдущего RMSprop, изменивтолькоперевзвешивание, но не асимптотику в. Такой RMSprop можно пробовать использовать в выпуклых задачах",
    "source_type": null,
    "useful_links": [
      {
        "text": "Variants of RMSProp and Adagrad with Logarithmic Regret Bounds",
        "url": "http://proceedings.mlr.press/v70/mukkamala17a/mukkamala17a.pdf"
      }
    ]
  },
  {
    "document_title": "Методы оптимизации в Deep Learning",
    "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning",
    "section_title": "Momentum",
    "text": "Попробуем расписать классический momentum с константным learning rate в стиле FTRL: Всё, что нам нужно сделать — это взять все рекурсивные зависимости от предыдущей итерации и «размотать» их, получив явное выражение. Зависимостьотпереписать довольно просто, мы это уже делали для обычного градиентного спуска: Теперь надо размотать Теперь будет чуть сложнее. Подставим это и попробуем расписать, как суммус определенными коэффициентами: Множительсразу выносим за сумму и пока забываем. Отлично, а теперь нам нужно получить последовательность функций. В линеаризованной задаче это фактически эквивалентно получению зависимостиот, где, напомним,— это сумма градиентов. Теперь мы можем записать функцию, градиент которой равени онлайн-оптимизация которой эквивалентна процедуре с моментумом: Получаем, что для онлайн-обучения мы на самом деле каждую итерацию скармливаем экспоненциально взвешенную последовательность всех предыдущих функций исходной последовательности. В принципе, нечто такое мы и ожидали увидеть. Функции, очевидно, выпуклы, так что для данной измененной последовательности функций будет сублинейный regret. Рассмотрим классический SGD с momentum, для всех adaptive методов рассуждения аналогичны. Градиент функциипосчитан в предыдущей точке. Идея nesterov momentum в том, чтобы применить momentum на параметрыдо вычисления градиента: У метода много всяких «интуитивных объяснений», но изначально Nesterov Momentum был выведен сугубо аналитическими методами. Увы, попытки добавлять его в стохастическую оптимизацию «в лоб» обычно улучшением качества не заканчиваются. Анализ того, почему так нельзя и делать и как можно сделать правильно, проводится в работахKatyusha: The First Direct Acceleration of Stochastic Gradient MethodsиNatasha-2(мотивация их автора Zeyuan Allen-Zhu для выбора таких наименований доподлинно неизвестна). Katuysha правильным образом использует nesterov momentum для выпуклого случая, Natasha — для невыпуклого. Данные методы используют подход SVRG для улучшения сходимости и ускорение оптимизации происходиттолько при приближении к точке оптимума. До недавнего времени громких историй успеха для nesterov momentum в глубоком обучении не было. Метод Natasha распространения не нашел. Наконец, авторы статьиAdan(2022) нашли способ правильной обработки Nesterov Momentum. Метод показал отличные результаты и обновил SOTA метрики на широком спектре задач.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Katyusha: The First Direct Acceleration of Stochastic Gradient Methods",
        "url": "https://arxiv.org/pdf/1603.05953.pdf"
      },
      {
        "text": "Natasha-2",
        "url": "https://arxiv.org/abs/1708.08694"
      },
      {
        "text": "Adan",
        "url": "https://arxiv.org/abs/2208.06677"
      }
    ]
  },
  {
    "document_title": "Методы оптимизации в Deep Learning",
    "url": "https://education.yandex.ru/handbook/ml/article/metody-optimizacii-v-deep-learning",
    "section_title": "Собираем все идеи воедино",
    "text": "Авторы данного обзора очень хотят, чтобы читатель ушел не с знанием набора наименований методов оптимизации, а с знанием набора концепций, которые тот или иной метод реализует, и при случае мог сам подстроить метод под свои нужды. Тюнинг методов оптимизации — один из главных способов улучшения качества модели на фиксированном датасете. Adaptive learning rate — автоматическое подстраивание метода под геометрию задачи оптимизации. Крайне важный класс методов для выпуклых/невыпуклых задач. Must-have для разреженных моделей. Методы: AdaGrad/RMSprop/Adam. Скользящее среднее в adaptive learning rate представлено в методах RMSprop/Adam. Не забывайте про их плохое поведение вокруг критических точек и проблемы со сходимостью на финальных этапах оптимизации. BiasCorrection: стабилизация обучения на старте для адаптивных методов со скользящим средним. Большинство экспериментов показывают, что это крайне полезная штука и стоит всегда её использовать. В том числе стоит использовать RMSprop с bias correction, если вам не нужны momentum и Adam. AMSgrad: способ починить сходимость RMSprop/Adam. Не забывайте, что стандартные реализации при использовании AMSgrad отключают bias correction, а это на самом деле может навредить, а также о том, что можно реализовать AMSgrad без дополнительной памяти, и всё будет хорошо работать. Learning rate decay: убывание learning rate зачастую является очень важной деталью в стохастической оптимизации. Помните, что можно брать как AdaGrad, в котором это есть из коробки со скоростью(но архитектура нейросети должна быть хорошей), так и комбинацию RMSProp/Adam + learning rate scheduler. WarmRestart: эвристика, резко увеличивающая learning rate после достижения некоторой точки в процессе оптимизации. Практически всегда идет бок о бок с learning rate decay. Где-то помогает Проксимальные методы для функций потерь с регуляризаторами: ProximalGD/AdamW/SGDW/FTRL-Proximal. Must-have для-регуляризаторов, без проксимальности они вообще не работают. FTRL-Proximal: lazy vs greedy представление. Переписываем представление любого метода оптимизации в не-жадный вид. Позволяет по-новому взглянуть на любые регуляризаторы, особенно негладкие. Must-have для-регуляризации. -регуляризация в FTRL-Proximal: Incremental/Fixed/SquareIncremental. Все три имеют разные свойства и разную область применения. Fixed является наилучшим для отбора разреженных признаков/эмбеддингов. -регуляризатор для отбора эмбеддингов или автоматического подбора размерности. Можно использовать как аналог FSTR. Крайне полезный подход для разреженных нейросетей в рекомендательных системах, для которых рекомендуется использовать адаптивную схему SquareIncremental. Heavy-ball Momentum: используется для ускорения процесса оптимизации. В выпуклых задачах имеет доказанные оценки на улучшение скорости сходимости, в нейросетях используется как эвристика (зачастую опциональная). Nesterov momentum: в выпуклом случае гораздо мощнее для batch gradient descent, чем обычный momentum, и это подверждается теоретическими гарантиями. В стохастических методах оптимизации и в онлайн обучении «в лоб» применять нельзя: для выпуклого случая подойдет Katyusha, для нейросетей — Adan. Главное, что мы хотим подчеркнуть, — эти идеи друг другу не противоречат и их можно свободно комбинировать друг с другом. Например, можно собрать себе FTRL-Proximal метод с-регуляризацией, любым momentum и RMSprop learning rate с AMSgrad. Или любую другую комбинацию. Всегда можно выбрать оптимальный набор под задачу. Эти формулы используют все подходы выше в едином фреймворке, чтобы наглядно убедиться в том, что все можно друг с другом комбинировать. Generic FTRL-Proximal Generic Mirror (Proximal) Gradient Descent Связь:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Хорошие свойства рекомендательных систем",
    "url": "https://education.yandex.ru/handbook/ml/article/horoshie-svojstva-rekomendatelnyh-sistem",
    "section_title": "Введение",
    "text": "Предположим, выдача нашей рекомендательной системы имеет высокие значения метрик ранжирования. Значит ли это, что система действительно хорошая? Не всегда просто ответить на этот вопрос. Оптимизируя определенные метрики, можно выкрутить кликбейт, и пользователи будут охотно кликать в моменте, но больше не станут пользоваться таким сервисом. Соответственно, нужно как-то измерять «счастье пользователей», попытаться формализовать свойства, которыми должна обладать хорошая рекомендательная система. Однозначного ответа на этот вопрос нет, всё зависит от контекста применения рекомендательной системы. В этом разделе мы поговорим о наиболее распространённых критериях, которые довольно часто оказываются важными.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Хорошие свойства рекомендательных систем",
    "url": "https://education.yandex.ru/handbook/ml/article/horoshie-svojstva-rekomendatelnyh-sistem",
    "section_title": "Полнота (Coverage)",
    "text": "Под полнотой в данном контексте понимается доля рекомендованных объектовсреди всех объектов. Эта метрика была предложена в статье Ge, M., Delgado-Battenfeld, C., Jannach, D. (2010, September). Beyond accuracy: evaluating recommender systems by coverage and serendipity. In Proceedings of the fourth ACM conference on Recommender systems (pp. 257-260). Данную метрику имеет смысл оценивать в разных временных интервалах, при этом принимая во внимание возможные ограничения, связанные с объемом данных. Например, нас может интересовать значение полноты за первый день работы рекомендательной системы, а может – за неделю. Целевое поведение полноты будет различаться в зависимости от доменных областей и бизнес деталей конкретного случая. Например, в рекомендациях музыки может быть полезно периодически повторно рекомендовать треки, которые пользователю в наибольшей степени нравятся, так как пользователь может захотеть послушать их еще раз. В то же время в рекомендациях фильмов это реже оказывается осмысленным: обычно проходит много времени, прежде чем пользователь захочет пересмотреть фильм. Таким образом, во втором случае полнота будет расти быстрее за счет отсутствия повторов. Еще одним фактором, влияющим на полноту, является алгоритм холодного старта, который может использоваться для того чтобы найти подходящие объекты для нового пользователя или подходящих пользователей для нового объекта. Часто пользователям на этапе холодного старта показывают самые популярные объекты. Из-за этого свежедобавленные объекты (например, музыкальные треки) могут неявно пессимизироваться алгоритмом. Один из способов решения проблемы – бустить свежие объекты в течение определённого времени, чтобы они показывались чаще. Настройки логики холодного старта могут сильно повлиять на метрику полноты. Среди других актуальных вопросов, которыми стоит задаваться: Cколько нужно дней, чтобы полнота достигала заданного значения? Возможно ли достичь такого значения в принципе, используя текущий алгоритм? Чтобы ответить на эти вопросы, нужно принимать во внимание ряд факторов: Какой объём трафика у системы рекомендаций? Есть ли у бизнеса ограничения, влияющие на конечный список рекомендаций? Имеет ли алгоритм рекомендаций достаточную степень персонализации? Можно ли регулировать режимы exploration и exploitation во время работы рекомендательной системы? Каждый из этих факторов может по-разному влиять на динамику полноты. Бизнес ограничения и слабая степень персонализации могут сдерживать рост полноты. Напротив, если модель высокоперсонализированная и учитывает много пользовательских факторов, то она способна рекомендовать больше уникальных объектов из хвоста распределения, которые тоже могут ему понравиться, тем самым обеспечивая рост полноты.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Хорошие свойства рекомендательных систем",
    "url": "https://education.yandex.ru/handbook/ml/article/horoshie-svojstva-rekomendatelnyh-sistem",
    "section_title": "Новизна (Novelty)",
    "text": "Один из способов оценить новизну рекомендательной системы – использовать статистическую меру собственной информации объекта (self information), которая используется в теории информации и тесно связана с понятием энтропии. Значение собственной информации для событияравняется логарифму вероятности наступления данного события. Согласно теории, чем меньше вероятность наступления события, тем больше потенциальной информации принесет это событие при его наступлении. Единицей информации при использовании логарифма по основанииявляется бит. Теперь если переносить идею собственной информации в парадигму рекомендательных систем, то получается, что чем менее популярен объект, тем более вероятно, что он будет новым для пользователя. А значит мера информации у такого объекта будет выше. Для каждого рекомендованного объектасчитаем вероятность, с которой его порекомендуют случайному пользователю:, где– количество пользователей, которым был показан-й объект, а– общее число пользователей. Для заданного пользователя усредняем значение собственной информации по списку его рекомендацийи получаем итоговое значение метрики:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Хорошие свойства рекомендательных систем",
    "url": "https://education.yandex.ru/handbook/ml/article/horoshie-svojstva-rekomendatelnyh-sistem",
    "section_title": "Разнообразие (Diversity)",
    "text": "Разнообразие – это способность модели рекомендовать разные по содержанию объекты. Такое свойство очень важно для долгосрочного успеха сервисов, основанных на рекомендательных системах. Действительно, если модель постоянно рекомендует похожие друг на друга объекты, то рано или поздно пользователю наскучат такие рекомендации. Разнообразие можно рассчитывать на основе комбинаций метрик полноты и новизны. Также мерой разнообразия может быть дисперсия рекомендаций за заданный промежуток времени. Помимо этого популярны подходы, использующие эмбединги объектов для оценки попарной похожести объектов и расчёта на основе неё значения разнообразия. Одна из таких метрик – Intra List Similarity (ILS). Чтобы ее посчитать, нужно иметь эмбединги объектов рекомендаций, находящиеся в едином векторном пространстве. Для расчёта разнообразия для одного пользователя нужно усреднить попарную схожестьмежду рекомендованными объектами: где– это набор рекомендованных пользователю объектов. Для того чтобы добиться большего разнообразия, метрику нужно минимизировать. Мера схожести должна бытьбольшедля более похожих объектов. Чаще всего используется косинусная близость (cosine similarity).",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Хорошие свойства рекомендательных систем",
    "url": "https://education.yandex.ru/handbook/ml/article/horoshie-svojstva-rekomendatelnyh-sistem",
    "section_title": "Serendipity",
    "text": "Одно из самых желанных свойств для любой рекомендательной системы. У слова serendipity нет четкого перевода, в 2008 году оно дажепопало в список самых неподдающихся переводу слов в мире. На русский иногда оно переводится как «интуитивная прозорливость». Serendipity – это способность рекомендовать такие объекты, которые не только релевантны для пользователя, но ещё и существенно отличаются от того, с какими объектами пользователь взаимодействовал в прошлом. Serendipity – довольно субъективное свойство и его сложно формализовать. Более того рекомендации, удовлетворяющие этому свойству, встречаются редко, что усложняет интерпретацию и измерение serendipity. Нет консенсуса о том, какой метрикой можно оценить его. Мы расскажем о способе, предложенном в статье T. Murakami, K. Mori, R. Orihara, Metrics for evaluating the serendipity of recommendation lists, in: New Frontiers in Artificial Intelligence, Vol. 4914, Springer Berlin Heidelberg, Berlin, Heidelberg, 2008, pp. 40–46. Пусть– список рекомендаций для пользователя,– предсказание модели, для каждого объекта из списка, а– предсказание примитивной модели (в качестве примитивной можно брать модель на основе эвристик без машинного обучения или простую неперсональную модель), а– известная релевантность объекта для пользователя. Тогда Serendipity рассчитывается следующим образом: Значение метрики можно усреднить по всем пользователям тестовой выборки. Чем больше значение, тем больше модель удовлетворяет свойству Serendipity. Ключевая идея формулы такова: если уверенность персонализированной модели в том, что пользователю понравится-ый айтем, больше, чем уверенность неперсональной модели (примитивной), это значит, что данному пользователю может особенно понравиться-й айтем. Отдельный вопрос – как оптимизировать Serendipity. Нужно улучшать способность модели к персонализации: добавлять больше фичей для пар (пользователь, объект); взвешивать таргеты, чтобы более тонко учитывать необычные клики/просмотры; писать кастомные функции потерь, которые будут поощрять модель за буст неожиданныйх объектов (которые в большей степени удовлетворяют свойству serendipity). Кроме того, имеет смысл оптимизировать модель по метрике serendipity на офлайн тестовой выборке.",
    "source_type": null,
    "useful_links": [
      {
        "text": "попало в список самых неподдающихся переводу слов в мире",
        "url": "http://www.todaytranslations.com/blog/most-untranslatable-word/"
      }
    ]
  },
  {
    "document_title": "Хорошие свойства рекомендательных систем",
    "url": "https://education.yandex.ru/handbook/ml/article/horoshie-svojstva-rekomendatelnyh-sistem",
    "section_title": "Заключение",
    "text": "В этом разделе мы рассмотрели ключевые свойства рекомендательных систем и метрики для их оценки. Рекомендательные системы – сложная область, где нет готовых рецептов оценки качества. Ключевые метрики всегда идут от продуктовых деталей применения рекомендательной системы. Полезно смотреть на несколько метрик одновременно, чтобы оценить разные свойства моделей. В какой момент нужно начинать следить за метриками из данного раздела? Несмотря на их ценность, на начальном этапе стоит концентрироваться на более простых и интуитивно понятных с точки зрения бизнеса метриках: конверсии, среднем времени визита и так далее. А вот как только базовые метрики будут на удовлетворительном уровне, стоит начинать мониторить и оптимизировать метрики, разобранные в этом разделе.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Bias-variance decomposition",
    "url": "https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition",
    "section_title": "Вывод разложения bias-variance для MSE",
    "text": "Рассмотрим задачу регрессии с квадратичной функцией потерь. Представим также для простоты, что целевая переменная— одномерная и выражается через переменнуюкак: где— некоторая детерминированная функция, а— случайный шум со следующими свойствами: В зависимости от природы данных, которые описывает эта зависимость, её представление в виде точнойи случайнойможет быть продиктовано тем, что: данные на самом деле имеют случайный характер; измерительный прибор не может зафиксировать целевую переменную абсолютно точно; имеющихся признаков недостаточно, чтобы исчерпывающим образом описать объект, пользователя или событие. Функция потерь на одном объектеравна Однако знание значения MSE только на одном объекте не может дать нам общего понимания того, насколько хорошо работает наш алгоритм. Какие факторы мы бы хотели учесть при оценке качества алгоритма? Например, то, что выход алгоритма на объектезависит не только от самого этого объекта, но и от выборки, на которой алгоритм обучался: Кроме того, значениена объектезависит не только от, но и от реализации шума в этой точке: Наконец, измерять качество мы бы хотели на тестовых объектах— тех, которые не встречались в обучающей выборке, а тестовых объектов у нас в большинстве случаев более одного. При включении всех вышеперечисленных источников случайности в рассмотрение логичной оценкой качества алгоритмакажется следующая величина: Внутреннее матожидание позволяет оценить качество работы алгоритма в одной тестовой точкев зависимости от всевозможных реализацийи, а внешнее матожидание усредняет это качество по всем тестовым точкам. Замечание.Записьв общем случае обозначает взятие матожидания по совместному распределениюи. Однако, посколькуинезависимы, она равносильна последовательному взятию матожиданий по каждой из переменных:, но последний вариант выглядит несколько более громоздко. Попробуем представить выражение дляв более удобном для анализа виде. Начнём с внутреннего матожидания: Из общего выражения длявыделилась шумовая компонента. Продолжим преобразования: Таким образом, итоговое выражение дляпримет вид где —смещениепредсказания алгоритма в точке, усреднённого по всем возможным обучающим выборкам, относительно истинной зависимости; —дисперсия (разброс)предсказаний алгоритма в зависимости от обучающей выборки; — неустранимыйшумв данных. Смещение показывает, насколько хорошо с помощью данного алгоритма можно приблизить истинную зависимость, а разброс характеризует чувствительность алгоритма к изменениям в обучающей выборке. Например, деревья маленькой глубины будут в большинстве случаев иметь высокое смещение и низкий разброс предсказаний, так как они не могут слишком хорошо запомнить обучающую выборку. А глубокие деревья, наоборот, могут безошибочно выучить обучающую выборку и потому будут иметь высокий разброс в зависимости от выборки, однако их предсказания в среднем будут точнее. На рисунке ниже приведены возможные случаи сочетания смещения и разброса для разных моделей: Синяя точка соответствует модели, обученной на некоторой обучающей выборке, а всего синих точек столько, сколько было обучающих выборок. Красный круг в центре области представляет ближайшую окрестность целевого значения. Большое смещение соответствует тому, что модели в среднем не попадают в цель, а при большом разбросе модели могут как делать точные предсказания, так и довольно сильно ошибаться. Полученное нами разложение ошибки на три компоненты верно только для квадратичной функции потерь. Для других функций потерь существуют более общие формы этого разложения (Domigos, 2000,James, 2003) с похожими по смыслу компонентами. Это позволяет предполагать, что для большинства основных функций потерь имеется некоторое представление в виде смещения, разброса и шума (хоть и, возможно, не в столь простой аддитивной форме). Попробуем вычислить разложение на смещение и разброс на каком-нибудь практическом примере. Наши обучающие и тестовые примеры будут состоять из зашумлённых значений целевой функции, гдеопределяется как В качестве шума добавляется нормальный шум с нулевым средним и дисперсией, равной во всех дальнейших примерах 9. Такое большое значение шума задано для того, чтобы задача была достаточно сложной для классификатора, который будет на этих данных учиться и тестироваться. Пример семпла из таких данных: Посмотрим на то, как предсказания деревьев зависят от обучающих подмножеств и максимальной глубины дерева. На рисунке ниже изображены предсказания деревьев разной глубины, обученных на трёх независимых подвыборках размера 20 (каждая колонка соответствует одному подмножеству): Глядя на эти рисунки, можно выдвинуть гипотезу о том, что с увеличением глубины дерева смещение алгоритма падает, а разброс в зависимости от выборки растёт. Проверим, так ли это, вычислив компоненты разложения для деревьев со значениями глубины от 1 до 15. Для обучения деревьев насемплируем 1000 случайных подмножествразмера 500, а для тестирования зафиксируем случайное тестовое подмножество точектакже размера 500. Чтобы вычислить матожидание по, нам нужно несколько экземпляров шумадля тестовых лейблов: Положим количество семплов случайного шума равным 300. Для фиксированныхиквадратичная ошибка вычисляется как Взяв среднее отпо,и, мы получим оценку для, а оценки для компонент ошибки мы можем вычислить по ранее выведенным формулам. На графике ниже изображены компоненты ошибки и она сама в зависимости от глубины дерева: По графику видно, что гипотеза о падении смещения и росте разброса при увеличении глубины подтверждается для рассматриваемого отрезка возможных значений глубины дерева. Правда, если нарисовать график до глубины 25, можно увидеть, что разброс становится равен дисперсии случайного шума. То есть деревья слишком большой глубины начинают идеально подстраиваться под зашумлённую обучающую выборку и теряют способность к обобщению: Код для подсчёта разложения на смещение и разброс, а также код отрисовки картинок можно найти в данномноутбуке.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Domigos, 2000",
        "url": "https://www.researchgate.net/publication/221345426_A_Unifeid_Bias-Variance_Decomposition_and_its_Applications"
      },
      {
        "text": "James, 2003",
        "url": "http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=193A2D240404AB056822F188BAB09F94?doi=10.1.1.95.4138&rep=rep1&type=pdf"
      },
      {
        "text": "ноутбуке",
        "url": "https://github.com/yandexdataschool/ML-Handbook-materials/blob/main/chapters/ensembles/bias_variance.ipynb"
      }
    ]
  },
  {
    "document_title": "Bias-variance decomposition",
    "url": "https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition",
    "section_title": "Bias-variance trade-off: в каких ситуациях он применим",
    "text": "В книжках и различных интернет-ресурсах часто можно увидеть следующую картинку: Она иллюстрирует утверждение, которое в литературе называетсяbias-variance trade-off: чем выше сложность обучаемой модели, тем меньше её смещение и тем больше разброс, и поэтому общая ошибка на тестовой выборке имеет вид-образной кривой. С падением смещения модель всё лучше запоминает обучающую выборку, поэтому слишком сложная модель будет иметь нулевую ошибку на тренировочных данных и большую ошибку на тесте. Этот график призван показать, что существует оптимальная сложность модели, при которой соблюдается баланс между переобучением и недообучением и ошибка при этом минимальна. Существует достаточное количество подтверждений bias-variance trade-off для непараметрических моделей. Например, его можно наблюдать для методаближайших соседей при ростеи для ядерной регрессии при увеличении ширины окна(Geman et al., 1992): Чем больше соседей учитывает-NN, тем менее изменчивым становится его предсказание, и аналогично для ядерной регрессии, из-за чего сложность этих моделей в некотором смысле убывает с ростоми. Поэтому традиционный график bias-variance trade-off здесь симметрично отражён по оси. Однако, как показывают последние исследования, непременное возрастание разброса при убывании смещения не является абсолютно истинным предположением. Например, для нейронных сетей с ростом их сложности может происходить снижение и разброса, и смещения. Одна из наиболее известных статей на эту тему — статьяБелкина и др. (Belkin et al., 2019), в которой, в частности, была предложена следующая иллюстрация: Слева — классический bias-variance trade-off: убывающая часть кривой соответствует недообученной модели, а возрастающая — переобученной. А на правой картинке — график, называемый в статьеdouble descent risk curve. На нём изображена эмпирически наблюдаемая авторами зависимость тестовой ошибки нейросетей от мощности множества входящих в них параметров (). Этот график разделён на две части пунктирной линией, которую авторы называют interpolation threshold. Эта линия соответствует точке, в которой в нейросети стало достаточно параметров, чтобы без особых усилий почти идеально запомнить всю обучающую выборку. Часть до достижения interpolation threshold соответствует «классическому» режиму обучения моделей: когда у модели недостаточно параметров, чтобы сохранить обобщающую способность при почти полном запоминании обучающей выборки. А часть после достижения interpolation threshold соответствует «современным» возможностям обучения моделей с огромным числом параметров. На этой части графика ошибка монотонно убывает с ростом количества параметров у нейросети. Авторы также наблюдают похожее поведение и для «древесных» моделей: Random Forest и бустинга над решающими деревьями. Для них эффект проявляется при одновременном росте глубины и числа входящих в ансамбль деревьев. В качестве вывода к этому разделу хочется сформулировать два основных тезиса: Bias-variance trade-off нельзя считать непреложной истиной, выполняющейся для всех моделей и обучающих данных. Разложение на смещение и разброс не влечёт немедленного выполнения bias-variance trade-off и остаётся верным и для случая, когда все компоненты ошибки (кроме неустранимого шума) убывают одновременно. Этот факт может оказаться незамеченным из-за того, что в учебных пособиях часто разговор о разложении дополняется иллюстрацией с-образной кривой, благодаря чему в сознании эти два факта могут слиться в один.",
    "source_type": null,
    "useful_links": [
      {
        "text": "(Geman et al., 1992)",
        "url": "http://doursat.free.fr/docs/Geman_Bienenstock_Doursat_1992_bv_NeurComp.pdf"
      },
      {
        "text": "Белкина и др. (Belkin et al., 2019)",
        "url": "https://arxiv.org/pdf/1812.11118.pdf"
      }
    ]
  },
  {
    "document_title": "Bias-variance decomposition",
    "url": "https://education.yandex.ru/handbook/ml/article/bias-variance-decomposition",
    "section_title": "Список литературы",
    "text": "Блог-постпро bias-variance отЙоргоса Папахристудиса Блог-постпро bias-variance от Скотта Фортмана-Роу Статьи отДомингоса (2000)иДжеймса (2003)про обобщённые формы bias-variance decomposition Блог-постот Брейди Нила про необходимость пересмотра традиционного взгляда на bias-variance trade-off СтатьяГемана и др. (1992), в которой была впервые предложена концепция bias-variance trade-off СтатьяБелкина и др. (2019), в которой был предложен double-descent curve",
    "source_type": null,
    "useful_links": [
      {
        "text": "Блог-пост",
        "url": "https://link.medium.com/X5Cpg1WITjb"
      },
      {
        "text": "Блог-пост",
        "url": "http://scott.fortmann-roe.com/docs/BiasVariance.html"
      },
      {
        "text": "Домингоса (2000)",
        "url": "https://www.researchgate.net/publication/221345426_A_Unifeid_Bias-Variance_Decomposition_and_its_Applications"
      },
      {
        "text": "Джеймса (2003)",
        "url": "http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=193A2D240404AB056822F188BAB09F94?doi=10.1.1.95.4138&rep=rep1&type=pdf"
      },
      {
        "text": "Блог-пост",
        "url": "https://www.bradyneal.com/bias-variance-tradeoff-textbooks-update#double-descent"
      },
      {
        "text": "Статья",
        "url": "http://doursat.free.fr/docs/Geman_Bienenstock_Doursat_1992_bv_NeurComp.pdf"
      },
      {
        "text": "Статья",
        "url": "https://arxiv.org/pdf/1812.11118.pdf"
      }
    ]
  },
  {
    "document_title": "Подбор гиперпараметров",
    "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
    "section_title": "Grid Search",
    "text": "Самый естественный способ организовать перебор наборов гиперпараметров — сделать перебор по сетке (Grid Search): для каждого гиперпараметра фиксируется несколько значений; перебираются все комбинации значений различных гиперпараметров, на каждой из этих комбинаций модель обучается и тестируется; выбирается комбинация, на которой модель показывает лучшее качество. Примеры: для метода ближайших соседей можно, например, перебирать по сетке число соседей (например, от 1 до 20) и метрику, по которой будет измеряться расстояние между объектами выборки (евклидова, манхэттенская и так далее); для решающих деревьев можно перебирать по сетке сочетания значений максимальной глубины дерева и различные критерии ветвления (критерий Джини, энтропийный критерий). Перебор некоторых значений гиперпараметров можно вести по логарифмической шкале, так как это позволяет быстрее определить правильный порядок параметра и в то же время значительно уменьшить время поиска. Так можно подбирать, например, значение learning rate для градиентного спуска, значение константы регуляризации для линейной регрессии или метода SVM. Сразу же видно естественное ограничение данного метода: если комбинаций параметров слишком много либо каждое обучение / тест длится долго, алгоритм не завершится за разумное время.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Подбор гиперпараметров",
    "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
    "section_title": "Random Search",
    "text": "Если у вас возникает очень большое количество комбинаций параметров, вы можете какими-то способами пытаться справляться с этой проблемой: можно взять меньше значений каждого гиперпараметра, но тогда есть шансы пропустить наилучшую комбинацию; можно уменьшить число фолдов в кросс-валидации, но оценка параметров станет более шумной; можно оптимизировать параметры последовательно, а не перебирать их комбинации, но снова есть шанс получить неоптимальное решение; можно перебирать не все комбинации гиперпараметров, а только случайное подмножество. Последний способ называетсяRandom Search. Для каждого гиперпараметра задаётся распределение, из которого выбирается его значение, и комбинация гиперпараметров составляется семплированием из этих распределений (хорошие советы по поводу выбора распределений можно найти вдокументации sklearn). Таким образом, благодаря случайному выбору очередной комбинации гиперпараметров вы можете найти оптимальную комбинацию за меньшее число итераций. Вот это изображение хорошо иллюстрирует отличия поиска по сетке от случайного поиска: То есть: качество нашей модели в зависимости от гиперпараметров — это функция многих переменных с некоторой нетривиальной поверхностью. Но эта поверхностьможет зависетьот одной из своих переменных сильно меньше, чем от другой. Если бы мы знали, какой гиперпараметр важнее для перформанса модели, мы бы рассмотрели больше его возможных значений, но часто у нас нет такой информации, и мы рассматриваем некоторое наперёд заданное число значений для каждого гиперпараметра. Random Search может за то же число итераций, что и Grid Search, рассмотреть более разнообразные значения гиперпараметров. Тем самым он с большей вероятностью найдёт те значения, которые больше всего влияют на качество модели, а значит, с большей вероятностью найдёт наилучшую комбинацию значений гиперпараметров. Естьещё однодовольно интересное объяснение, почему Random Search работает хорошо. Рассмотрим случай, когда у нас конечная сетка гиперпараметров (каждому гиперпараметру сопоставлено конечное число значений). В этой сетке выделим группу размераот общего числа наборов гиперпараметров, на которой модель достигает лучшего качества (можно мысленно отранжировать все наборы по качеству в некоторый список и взять топэтого списка). Тогда некоторый набор гиперпараметров не попадает в эту группу с вероятностью. Если мы насемплировалинаборов, то каждый из них не попал в эту группу с вероятностью, и, соответственно, вероятность того, что хотя бы один насемплированный набор попал в лучшую группу, равна. Мы можем решить неравенство и выяснить, что примы попадём в топ 5% с вероятностью, не меньшей. Это в большинстве случаев значительно быстрее, чем перебор всех комбинаций гиперпараметров с помощью Grid Search. Если в рассуждении выше у нас некоторым гиперпараметрам соответствует непрерывное распределение, то всегда можно предположить, что мы уже насемплировали из этих распределений некоторое конечное число значений (равное числу итераций Random Search), а дальше считать, что мы работаем с конечной сеткой. Конечно, остаётся наша зависимость от самой сетки гиперпараметров, и не всякая сетка обязана содержать в себе глобальный максимум перформанса модели или даже гиперпараметры из интервала вокруг него.",
    "source_type": null,
    "useful_links": [
      {
        "text": "документации sklearn",
        "url": "https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-search"
      },
      {
        "text": "может зависеть",
        "url": "https://medium.com/rants-on-machine-learning/smarter-parameter-sweeps-or-why-grid-search-is-plain-stupid-c17d97a0e881#.pkwq17od8"
      },
      {
        "text": "ещё одно",
        "url": "https://web.archive.org/web/20160701182750/http://blog.dato.com/how-to-evaluate-machine-learning-models-part-4-hyperparameter-tuning"
      }
    ]
  },
  {
    "document_title": "Подбор гиперпараметров",
    "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
    "section_title": "Exploration vs exploitation",
    "text": "В машинном обучении достаточно часто встречаются такие термины, какexplorationиexploitation. Суть этих терминов хорошо поясняет следующий пример из реальной жизни. Допустим, перед вами стоит выбор, в какой ресторан пойти сегодня. Пусть ваш любимый ресторан находится прямо за углом. Вы ходите туда каждый день и поэтому достаточно уверены в том, насколько вкусным будет ваш обед. Но при этом не рассматриваете никакие другие опции и, возможно, упускаете возможность поесть гораздо вкуснее в другом месте. Если же вы будете обедать каждый раз в новом месте, то очень часто будете не удовлетворены результатом. В описанных далее методах подбора гиперпараметров будет так или иначе происходить поиск баланса между exploration и exploitation. Одно из основных отличий всех методов, которые будут описаны далее, от Grid Search и Random Search — возможность учитывать результаты предыдущих вычислений. Одна из возможных стратегий выбора точки для следующей итерации —exploration: исследование тех областей, в которых у нас мало семплов на текущей итерации, что даёт нам возможность с меньшей вероятностью пропустить оптимальное значение. Другая стратегия —exploitation: выбирать больше семплов в областях, которые мы достаточно неплохо изучили и где, как мы считаем, с большой вероятностью находится оптимум.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Подбор гиперпараметров",
    "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
    "section_title": "Байесовская оптимизация",
    "text": "Байесовская оптимизация — это итерационный метод, позволяющий оценить оптимум функции, не дифференцируя её. Кроме того, на каждой итерации метод указывает, в какой следующей точке мы с наибольшей вероятностью улучшим нашу текущую оценку оптимума. Это позволяет значительно сократить количество вычислений функции, каждое из которых может быть довольно затратным по времени. Подбор гиперпараметров тоже можно сформулировать в виде задачи, которая может решаться с помощью байесовской оптимизации. Пусть, например, наша функция — значение валидационных метрик в зависимости от текущего сочетания гиперпараметров. Её вычисление затратно по времени (нужно натренировать и провалидировать модель), и мы не можем вычислить градиенты этой функции по её переменным (нашим гиперпараметрам). Байесовская оптимизация имеет две основные компоненты: вероятностную модель, которая приближает распределение значений целевой функции в зависимости от имеющихся исторических данных (часто в качестве такой модели выбираютгауссовские процессы); функцию, которая позволяет по некоторым статистикам текущей вероятностной модели функцииуказать, в какой следующей точке нужно вычислить значение. Эта функция называетсяacquisition function. Она должна балансировать междуexplorationиexploitationв следующем смысле:exploration— исследовать те точки, в которых дисперсия нашей вероятностной модели велика;exploitation— исследовать те точки, где среднее нашей модели велико (и может служить оценкой максимума). exploration— исследовать те точки, в которых дисперсия нашей вероятностной модели велика; exploitation— исследовать те точки, где среднее нашей модели велико (и может служить оценкой максимума). Простой пример acquisition function — сумма среднего вероятностной модели и стандартного отклонения с некоторым весом: где— точка из пространства, в котором мы оптимизируем целевую функцию (в нашем контексте это вектор значений гиперпараметров). На картинке ниже изображены обе компоненты, из которых складывается данная acquisition function, — среднее вероятностной модели(синий график) и доверительный интервал, ширина которого в каждой точке пропорциональна стандартному отклонению вероятностной модели (жёлтая область). Среднее моделистремится приблизить искомую функциюи в точности равнов тех точках, где значенияизвестны. Доверительный интервал имеет переменную ширину, так как чем дальше находится некоторая точка от тех, значения в которых известны, тем более модель не уверена в том, какое значение функции в этой точке, и тем шире доверительный интервал. Наоборот, в точках, где значения известны, доверительный интервал имеет нулевой радиус. Байесовская оптимизация в общем случае представляет из себя следующий алгоритм. Пусть— множество предыдущих наблюдений целевой функции:, а— некоторая acquisition function. На итерациивычисляется точка, в которой нужно провести следующее вычисление целевой функции: Вычисляется значение, и обновляется множество наблюдений. Обновляется статистическая модель. Чтобы такой алгоритм работал эффективно,должна быть легко вычислимой и дифференцируемой. На рисунке ниже изображены три итерации этого алгоритма. Здесь пунктирная линия — это целевая функция, сплошная линия — график среднего вероятностной модели, жёлтым цветом обозначен доверительный интервал модели. Серый график снизу — это график acquisition function. Её значения велики там, где вероятностная модель предсказывает большие значения целевой функции (exploitation), и там, где велика неуверенность вероятностной модели (exploration). На каждой итерации находится точка максимума acquisition function (чёрный крестик), и следующая итерация произойдёт в этой точке (серый кружок на графике функции). На нижнем графике побеждает exploitation, так как acquisition function верно предсказала, что наблюдения из неизвестных областей слабо повлияют на нашу текущую оценку максимума. Байесовская оптимизация хорошо работает, когда нужно оптимизировать небольшое число гиперпараметров, так как в наивной реализации алгоритм не поддаётся распараллеливанию. При большой размерности пространства гиперпараметров скорость сходимости не лучше, чем у обычного Random Search (как утверждается в этой статье). Байесовская оптимизация в изначальной постановке предполагалась для работы с непрерывными гиперпараметрами, а для работы с категориальными гиперпараметрами ей нужны некоторые трюки: Если нужно найти оптимальное значение только одного гиперпараметра и этот параметр категориальный, то можно, например, использовать Thompson sampling (как тут вразделе «Bernoulli bandit»). Вообще, проблему выбора наилучшего значения категориального гиперпараметра можно переформулировать какmulti-armed bandit problemи использовать любой известный способ решения этой задачи. Если категориальных гиперпараметров больше одного и кроме них есть некатегориальные, то: можно попробовать использовать специальные виды ядер в гауссовских процессах,как, например, сделано здесь; можно заменить гауссовские процессы на Random Forest (подробнее можно посмотреть здесь вразделе «Random Forests»).",
    "source_type": null,
    "useful_links": [
      {
        "text": "гауссовские процессы",
        "url": "https://krasserm.github.io/2018/03/19/gaussian-processes/"
      },
      {
        "text": "как утверждается в этой статье",
        "url": "https://arxiv.org/pdf/1603.06560.pdf"
      },
      {
        "text": "разделе «Bernoulli bandit»",
        "url": "https://www.borealisai.com/en/blog/tutorial-8-bayesian-optimization/"
      },
      {
        "text": "multi-armed bandit problem",
        "url": "https://lilianweng.github.io/lil-log/2018/01/23/the-multi-armed-bandit-problem-and-its-solutions.html"
      },
      {
        "text": "как, например, сделано здесь",
        "url": "https://www.cs.toronto.edu/~duvenaud/thesis.pdf"
      },
      {
        "text": "разделе «Random Forests»",
        "url": "https://www.borealisai.com/en/blog/tutorial-8-bayesian-optimization/"
      }
    ]
  },
  {
    "document_title": "Подбор гиперпараметров",
    "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
    "section_title": "Tree-structured Parzen Estimator (TPE)",
    "text": "Алгоритм TPE, как и алгоритм байесовской оптимизации, итерационный: на каждой итерации принимается решение о том, какие следующие значения гиперпараметров нужно выбрать, исходя из результатов предыдущих итераций. Но идейно имеет довольно сильные отличия. Предположим сначала, что мы хотим сделать поиск оптимального значения дляодногогиперпараметра. На нескольких первых итерациях алгоритму требуется «разогрев»: нужно иметь некоторую группу значений данного гиперпараметра, на которой известно качество модели. Самый простой способ собрать такие наблюдения — провести несколько итераций Random Search (количество итераций определяется пользователем). Следующим шагом будет разделение собранных во время разогрева данных на две группы. В первой группе будут те наблюдения, для которых модель продемонстрировала лучшее качество, а во второй — все остальные. Размер доли лучших наблюдений задаётся пользователем: чаще всего это 10-25% от всех наблюдений. Картинка ниже иллюстрирует такое разбиение: Далее некоторым образом строятся оценки распределениялучших наблюдений и распределениявсех остальных в пространстве значений рассматриваемого гиперпараметра. На следующем шаге алгоритма мы семплируем несколько значений-кандидатов из распределения(количество таких семплирований тоже задаётся пользователем, можно задать их число равным, например, 1000). Из насемплированных кандидатов мы хотим найти тех, кто с большей вероятностью окажется в первой группе (состоящей из лучших наблюдений), чем во второй. Для этого для каждого кандидатавычисляетсяExpected Improvement: Замечание: На самом деле стоит отметить, что воригинальной статьевеличинаимеет более общее определение. Но там же доказывается, что максимизацияв исходном определении эквивалентна максимизации отношения выше. Кандидат с наибольшим значениембудет включён в множество рассматриваемых гиперпараметров на следующей итерации: После того как было выбрано значение-кандидат, максимизирующее, обучается модель с этим значением гиперпараметра. После обучения мы замеряем её качество на валидационной выборке и в соответствии с этим результатом обновляем распределенияи: снова ранжируем всех имеющихся кандидатов по качеству модели с учётом последнего, из топ 10-25% формируется обновлённое, из остальных —. Так происходит столько раз, сколько итераций алгоритма мы задали. Теперь опишем, как алгоритм работает в общем случае, когда гиперпараметровболее одного. Алгоритм работает с гиперпараметрами, представляя их в форме дерева (отсюда «tree» в названии). Например, в документацииHyperoptможно увидеть такой пример: Скопировать код1from hyperopt import hp23space = hp.choice('classifier_type', [4{5'type': 'naive_bayes',6},7{8'type': 'svm',9'C': hp.lognormal('svm_C', 0, 1),10'kernel': hp.choice('svm_kernel', [11{'ktype': 'linear'},12{'ktype': 'RBF', 'width': hp.lognormal('svm_rbf_width', 0, 1)},13]),14},15{16'type': 'dtree',17'criterion': hp.choice('dtree_criterion', ['gini', 'entropy']),18'max_depth': hp.choice('dtree_max_depth',19[None, hp.qlognormal('dtree_max_depth_int', 3, 1, 1)]),20'min_samples_split': hp.qlognormal('dtree_min_samples_split', 2, 1, 1),21},22]) На рисунке ниже изображено дерево, соответствующее данному примеру: Корень дерева— фиктивная вершина, введённая для удобства. Здесь первый уровень дерева — выбор классификатора (наивный байес, SVM, решающее дерево). Дальнейшие уровни — гиперпараметры самих классификаторов и зависящие уже от них гиперпараметры (например, SVMkernelRBFwidth). Движение по дереву во время итераций алгоритма происходит по некоторому пути от корня к листу и обратно вдоль пройденного пути (этот процесс подробнее описан ниже). Под некоторыми вершинами записан набор гиперпараметров в скобках (например,kernelиCпод SVM). Это означает, что при приходе в эту вершину значения всех гиперпараметров, перечисленных в скобках, должны так или иначе быть выбраны. Каждой вершине дерева, в которой будет происходить семплирование значений, сопоставляется своя параис учётом значений, насемплированных на этапе «разогрева». Каждому гиперпараметру, перечисленному в скобках, соответствует своя собственная пара. Если из названия гиперпараметра не идут стрелки (например,Cу SVM иmin_samples_splitу Decision Tree), то это означает, что от его значения не зависят значения никаких других гиперпараметров. Поэтому либо будет выбрано его значение, максимизирующеедля соответствующих емуи, либо уже ничего не нужно семплировать (как, например, в вершинахlinearилиgini). Если же из гиперпараметра идут стрелки на следующий уровень, то с помощью максимизациибудет выбрано, в каком направлении сделать переход. Например, из корнявыбирается, какой классификатор рассмотреть на следующем этапе, а из параметраkernelможно перейти либо кRBF, либо кlinear. Теперь опишем сам алгоритм. Сначала так же, как и в одномерном случае, происходит «разогрев»: проводится некоторое количество итераций Random Search с теми изначальными распределениями, которые были заданы для гиперпараметров (в примере из Hyperopt эти распределения задаются какhp.qlognormal,hp.lognormalи так далее). Затем начинается итерационное обновление дерева гиперпараметров. Обновление дерева на каждой итерации происходит в два этапа: Сначала алгоритм идёт из корня дерева до некоторого листа. В каждой вершине для каждого соответствующего ей гиперпараметра он находит значение, максимизирующее. Если выбор значения для некоторого гиперпараметра означает переход на следующий уровень дерева, он идёт в ту вершину, которая соответствует максимизации. Так он идёт до тех пор, пока не упрётся в какой-то лист. Пройденный путь от корня до листа задаёт полный набор значений гиперпараметров для модели, и её с этими значениями можно провалидировать. После того как модель, полученная на предыдущем этапе, была провалидирована, распределения в вершинах дерева нужно обновить в соответствии с информацией о полученном качестве. Для этого алгоритм поднимается из листа наверх, обновляя распределения во всех вершинах дерева вдоль своего пути. В каждой вершине для каждого гиперпараметра процедура обновления та же, что была описана для одного гиперпараметра: имеющиеся значения гиперпараметров переранжируются по качеству с учётом результата последнего кандидата (этот результат общий для всех вершин вдоль пути), по топ 10-25% оценивается, по остальным —. В качестве окончательного ответа алгоритм выдаёт набор гиперпараметров (или, как в примере выше, не только гиперпараметры, но даже саму модель), на котором было получено лучшее качество за все итерации. Число итераций алгоритма задаётся пользователем. За дальнейшими деталями о процедуре обновления дерева для алгоритма TPE можно обратиться кэтой статьеи кисходному кодуалгоритма TPE из библиотеки Hyperopt. Стоит заметить, что если гиперпараметры не лежат вместе ни в одном пути в дереве, то TPE считает их независимыми. Это — недостаток данного алгоритма, так как некоторые гиперпараметры, находящиеся по смыслу в разных путях в дереве, зависят от друг от друга. Например, с регуляризацией мы можем тренировать нейросеть большее число эпох, чем без регуляризации, потому что без регуляризации сеть на большом числе эпох может начать переобучаться. В этом конкретном примере можно использовать такой трюк: Скопировать код1hp.choice('training_parameters', [2{3'regularization': True,4'n_epochs': hp.quniform('n_epochs', 500, 1000, q=1),5}, {6'regularization': False,7'n_epochs': hp.quniform('n_epochs', 20, 300, q=1),8},9]) Но если внутренние зависимости между гиперпараметрами вам неизвестны, то алгоритм не сможет найти их сам. Критерийпозволяет методу TPE балансировать междуexplorationиexploitation. Семплирование из распределения— это, с одной стороны, exploitation, так как гиперпараметры, семплируемые из него, близки к оптимуму, но это же привносит элемент exploration, так как семплируемые гиперпараметры не равны оптимуму в точности.",
    "source_type": null,
    "useful_links": [
      {
        "text": "оригинальной статье",
        "url": "https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf"
      },
      {
        "text": "Hyperopt",
        "url": "https://github.com/hyperopt/hyperopt/wiki/FMin#22-a-search-space-example-scikit-learn"
      },
      {
        "text": "этой статье",
        "url": "https://arxiv.org/pdf/1208.3719.pdf"
      },
      {
        "text": "исходному коду",
        "url": "https://github.com/hyperopt/hyperopt/blob/master/hyperopt/tpe.py#L662"
      }
    ]
  },
  {
    "document_title": "Подбор гиперпараметров",
    "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
    "section_title": "Population Based Training (PBT)",
    "text": "Этот метод использует идеи из теорииэволюционных стратегийи с самого начала включает в себя параллельные вычисления. Методы, описанные выше, имеют свои сильные и слабые стороны. Grid Search и Random Search:отлично параллелизуются;не используют результаты предыдущих итераций. отлично параллелизуются; не используют результаты предыдущих итераций. БО и TPE:трудно параллелизуются;используют результаты предыдущих итераций, при сходимости результаты лучше, чем у Random Search и Grid Search. трудно параллелизуются; используют результаты предыдущих итераций, при сходимости результаты лучше, чем у Random Search и Grid Search. В алгоритме PBT была сделана попытка объединить сильные стороны обеих групп, что проиллюстрировано на картинке ниже: В процессе работы алгоритм обучает не одну модель, а целуюпопуляциюмоделей — набор моделей одинакового типа, отличающихся только набором гиперпараметров: гдеи— веса и гиперпараметры моделисоответственно. Предполагается также, что модели обучаются как-то итерационно, например градиентным спуском (но могут использоваться и безградиентные методы, такие как эволюционные стратегии). Изначально каждая модель в популяции имеет случайные веса и гиперпараметры. Каждая модель из популяции тренируется параллельно с остальными, и периодически качество каждой модели замеряется независимо от остальных. Как только какая-то модель считается «созревшей» для обновления (например, прошла достаточное число шагов градиентного спуска или преодолела некоторый порог по качеству), у неё появляется шанс быть обновлённой относительно всей остальной популяции: процедураexploit(): если у модели низкое качество относительно популяции, то её веса заменяются на веса модели с более высоким качеством; процедураexplore(): если веса модели были перезаписаны, шагexploreдобавляет случайный шум в параметры модели. При таком подходе только лучшие пары моделей и гиперпараметров выживут и будут обновляться, что позволяет добиться более высокой утилизации ресурсов. Стоит отметить, что наиболее оптимальный размер популяции, выявленный авторами в результате экспериментов, — от 20 до 40, что довольно много и не реализуется на обычном ноутбуке. Красивая гифка с демонстрацией работы алгоритма:",
    "source_type": null,
    "useful_links": [
      {
        "text": "эволюционных стратегий",
        "url": "https://lilianweng.github.io/lil-log/2019/09/05/evolution-strategies.html"
      }
    ]
  },
  {
    "document_title": "Подбор гиперпараметров",
    "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
    "section_title": "Open-source-библиотеки",
    "text": "В библиотекеScikit-learnесть реализации Grid Search и Random Search, что очень удобно, если вы используете модели из sklearn. Примеры их использования можно найтиздесь. В библиотекеHyperoptреализованы три метода оптимизации гиперпараметров: Random Search TPE Adaptive TPE У них есть небольшойтуториалпо тому, как начать пользоваться библиотекой. Кроме того, у них есть обёртка над sklearn, позволяющая работать с моделями оттуда:Hyperopt-sklearn. В библиотекеOptunaреализованы те же методы оптимизации, что и в Hyperopt, но по многим параметрам она оказывается удобнее. Хорошее сравнение Optuna и Hyperopt можно найтиздесь. В библиотекеScikit-Optimizeреализованы алгоритмы байесовской оптимизации и Random Search. Кроме самих методов оптимизации библиотека предоставляет отличный инструментарий для различныхвизуализаций. Хорошее описание возможностей библиотеки можно найтитут. БиблиотекаKeras Tunerпозволяет подбирать гиперпараметры для нейросеток, написанных на TensorFlow 2.0, и для обычных моделей из Scikit-learn. Доступные методы оптимизации — Random Search иHyperband. Хороший гайд по использованию данной библиотеки можно найтитут.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Scikit-learn",
        "url": "https://scikit-learn.org/stable/index.html"
      },
      {
        "text": "здесь",
        "url": "https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-optimization"
      },
      {
        "text": "Hyperopt",
        "url": "http://hyperopt.github.io/hyperopt/"
      },
      {
        "text": "Adaptive TPE",
        "url": "https://github.com/electricbrainio/hypermax"
      },
      {
        "text": "туториал",
        "url": "https://github.com/hyperopt/hyperopt/wiki/FMin"
      },
      {
        "text": "Hyperopt-sklearn",
        "url": "https://github.com/hyperopt/hyperopt-sklearn"
      },
      {
        "text": "Optuna",
        "url": "https://optuna.org/"
      },
      {
        "text": "здесь",
        "url": "https://neptune.ai/blog/optuna-vs-hyperopt"
      },
      {
        "text": "Scikit-Optimize",
        "url": "https://scikit-optimize.github.io/stable/index.html"
      },
      {
        "text": "визуализаций",
        "url": "https://neptune.ai/blog/scikit-optimize#8"
      },
      {
        "text": "тут",
        "url": "https://neptune.ai/blog/scikit-optimize"
      },
      {
        "text": "Keras Tuner",
        "url": "https://keras-team.github.io/keras-tuner/"
      },
      {
        "text": "Hyperband",
        "url": "https://arxiv.org/pdf/1603.06560.pdf"
      },
      {
        "text": "тут",
        "url": "https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html"
      }
    ]
  },
  {
    "document_title": "Подбор гиперпараметров",
    "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
    "section_title": "Summary",
    "text": "Список описанных методов не исчерпывает все существующие на данный момент методы оптимизации гиперпараметров: остались за кадром такие алгоритмы, какASHA,Hyperband,BOHB. Хороший сравнительный обзор этих трёх алгоритмов можно найтиздесь. Мы собрали все описанные выше алгоритмы в таблицу, чтобы вам было удобнее сравнивать их между собой. А к некоторым оставили дополнительные комментарии. Grid Search. Хорошо работает, когда у вас совсем мало гиперпараметров либо вы смогли распараллелить его работу. Сильные стороны:самый простой для понимания и реализации;тривиально распараллеливается. самый простой для понимания и реализации; тривиально распараллеливается. Слабые стороны:не использует результаты других итераций;ограничен в выборе заданной сеткой;долго работает, если делает последовательный перебор по сетке. Нет гарантий на необходимое число итераций. не использует результаты других итераций; ограничен в выборе заданной сеткой; долго работает, если делает последовательный перебор по сетке. Нет гарантий на необходимое число итераций. В защиту этого метода хочется сказать, что часто на практике приходится делать перебор гиперпараметров вообще вручную (если один инстанс вашей модели учится недели две и использует много ресурсов) либо по очень небольшой сетке. Так что метод вполне в ходу 😃 Random Search. Метод представляет собой небольшое усложнение над Grid Search, но при этом оказывается намного более эффективным. Сильные стороны:случайный перебор по сетке позволяет находить оптимальные гиперпараметры более эффективно, чем Grid Search, в частности из-за того, что непрерывные параметры можно задать в виде распределения, а не перечислять значения заранее;тривиально распараллеливается;допускает усиление за счётиспользования квазислучайных распределенийпри семплировании. случайный перебор по сетке позволяет находить оптимальные гиперпараметры более эффективно, чем Grid Search, в частности из-за того, что непрерывные параметры можно задать в виде распределения, а не перечислять значения заранее; тривиально распараллеливается; допускает усиление за счётиспользования квазислучайных распределенийпри семплировании. Слабые стороны:не использует результаты других итераций;ограничен в выборе заданной сеткой, хотя и в некоторых случаях менее жёстко, чем Grid Search. не использует результаты других итераций; ограничен в выборе заданной сеткой, хотя и в некоторых случаях менее жёстко, чем Grid Search. Байесовская оптимизация Сильные стороны:использует результаты предыдущих итераций;может моделировать внутренние зависимости между гиперпараметрами (за счёт работы с ними в едином подмножестве, где— число гиперпараметров);может расширять заданные изначально границы множества поиска гиперпараметров;достигает более высокого качества, чем Random Search, если удалось провести достаточное количество итераций. использует результаты предыдущих итераций; может моделировать внутренние зависимости между гиперпараметрами (за счёт работы с ними в едином подмножестве, где— число гиперпараметров); может расширять заданные изначально границы множества поиска гиперпараметров; достигает более высокого качества, чем Random Search, если удалось провести достаточное количество итераций. Слабые стороны:паралеллится нетривиально;в нераспараллеленном случае работает долго, так как для каждой итерации ему приходится заново строить вероятностную модель. В случае если такая модель — гауссовские процессы, сложность получается порядка, где— число гиперпараметров;для работы с категориальными гиперпараметрами нужны нетривиальные хаки. паралеллится нетривиально; в нераспараллеленном случае работает долго, так как для каждой итерации ему приходится заново строить вероятностную модель. В случае если такая модель — гауссовские процессы, сложность получается порядка, где— число гиперпараметров; для работы с категориальными гиперпараметрами нужны нетривиальные хаки. Tree-structured Parzen Estimator Сильные стороны:использует результаты предыдущих итераций;может работать с зависимостями между гиперпараметрами, в которых один гиперпараметр не будет рассматриваться, если другой не примет какое-то определённое значение (например, число нейронов во втором слое нейросети нужно перебирать, если параметр «число слоёв» имеет значение не менее двух);имеет линейную сложность по числу гиперпараметров (в отличие от БО);не требует специальных хаков для работы с категориальными признаками, так как каждый гиперпараметр в этом алгоритме имеет своё отдельное одномерное распределение, и не нужно строить сложное совместное распределение всех гиперпараметров (как в БО);достигает высоких результатов по качеству, довольно часто используется в соревнованиях. использует результаты предыдущих итераций; может работать с зависимостями между гиперпараметрами, в которых один гиперпараметр не будет рассматриваться, если другой не примет какое-то определённое значение (например, число нейронов во втором слое нейросети нужно перебирать, если параметр «число слоёв» имеет значение не менее двух); имеет линейную сложность по числу гиперпараметров (в отличие от БО); не требует специальных хаков для работы с категориальными признаками, так как каждый гиперпараметр в этом алгоритме имеет своё отдельное одномерное распределение, и не нужно строить сложное совместное распределение всех гиперпараметров (как в БО); достигает высоких результатов по качеству, довольно часто используется в соревнованиях. Слабые стороны:не может моделировать неявные зависимости между гиперпараметрами (те, которые юзер не задал с помощью дерева);хотя сложность и меньше, чем у БО, может работать довольно медленно даже на не очень большом числе гиперпараметров. не может моделировать неявные зависимости между гиперпараметрами (те, которые юзер не задал с помощью дерева); хотя сложность и меньше, чем у БО, может работать довольно медленно даже на не очень большом числе гиперпараметров. Population Based Training Сильные стороны:параллельный by design;может использовать результаты предыдущих итераций. параллельный by design; может использовать результаты предыдущих итераций. Слабые стороны:для эффективной работы нужно много воркеров (от 20 до 40), что нетривиально для реализации. для эффективной работы нужно много воркеров (от 20 до 40), что нетривиально для реализации.",
    "source_type": null,
    "useful_links": [
      {
        "text": "ASHA",
        "url": "https://arxiv.org/pdf/1810.05934.pdf"
      },
      {
        "text": "Hyperband",
        "url": "https://arxiv.org/pdf/1603.06560.pdf"
      },
      {
        "text": "BOHB",
        "url": "https://arxiv.org/abs/1807.01774"
      },
      {
        "text": "здесь",
        "url": "https://neptune.ai/blog/hyperband-and-bohb-understanding-state-of-the-art-hyperparameter-optimization-algorithms"
      },
      {
        "text": "использования квазислучайных распределений",
        "url": "http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html#random-search"
      },
      {
        "text": "использования квазислучайных распределений",
        "url": "http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html#random-search"
      }
    ]
  },
  {
    "document_title": "Подбор гиперпараметров",
    "url": "https://education.yandex.ru/handbook/ml/article/podbor-giperparametrov",
    "section_title": "Почитать по теме",
    "text": "Примерыиспользования Grid Search от sklearn. Примерыиспользования Random Search от sklearn. Хороший блог-пост о гиперпараметрах, в первом разделе которого есть интересные рассуждения про усиление Random Search с помощью квазислучайных распределений. Блог-постот DeepMind про предложенный ими алгоритм Population Based Training. Оригинальная статья, где был предложен алгоритм. Блог-постпро эволюционные стратегии. А если вам интересно как следует разобраться в байесовской оптимизации (в частности, рассмотреть больше примеров вероятностных моделей и разных acquisition function), то вот полезный контент: Отличный туториалпо различным методам оптимизации гиперпараметров, в частности по байесовской оптимизации. Статья-обзор, подробно объясняющая математические детали методов байесовской оптимизации и содержащая примеры их применения в ресёрче и индустрии. ВидеолекцияЕвгения Бурнаева на летней школе Deep | Bayes. Оригинальная статья, в которой были предложены методы TPE и байесовская оптимизация. Пример использования skopt (Scikit-Optimize)— нахождение лучших параметров для SVM с помощью байесовской оптимизации. Реализацияалгоритма байесовской оптимизации и примеры использования библиотечных реализаций. Про гауссовские процессыс хорошими визуализациями. Более формально про гауссовские процессы, но с хорошими примерами на питоне. Для дальнейшего изучения метода TPE можно использовать следующие источники: Оригинальная статья, в которой были предложены методы TPE и байесовская оптимизация. Блог-постпро TPE и остальные методы тюнинга гиперпараметров от NeuPy. Там же можно найти пример применения TPE изHyperopt. Отличное объяснениетого, что такое Parzen window density estimation. Отличный туториалпо различным методам оптимизации гиперпараметров (который уже был упомянут выше в разделе про байесовскую оптимизацию).",
    "source_type": null,
    "useful_links": [
      {
        "text": "Примеры",
        "url": "https://scikit-learn.org/stable/modules/grid_search.html#exhaustive-grid-search"
      },
      {
        "text": "Примеры",
        "url": "https://scikit-learn.org/stable/modules/grid_search.html#randomized-parameter-optimization"
      },
      {
        "text": "Хороший блог-пост о гиперпараметрах",
        "url": "http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html#random-search"
      },
      {
        "text": "Блог-пост",
        "url": "https://deepmind.com/blog/article/population-based-training-neural-networks"
      },
      {
        "text": "Оригинальная статья",
        "url": "https://arxiv.org/pdf/1711.09846.pdf"
      },
      {
        "text": "Блог-пост",
        "url": "https://lilianweng.github.io/lil-log/2019/09/05/evolution-strategies.html"
      },
      {
        "text": "Отличный туториал",
        "url": "https://www.borealisai.com/en/blog/tutorial-8-bayesian-optimization/"
      },
      {
        "text": "Статья-обзор",
        "url": "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7352306"
      },
      {
        "text": "Видеолекция",
        "url": "https://www.youtube.com/watch?v=PgJMLpIfIc8"
      },
      {
        "text": "Оригинальная статья",
        "url": "https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf"
      },
      {
        "text": "Пример использования skopt (Scikit-Optimize)",
        "url": "https://scikit-optimize.github.io/stable/auto_examples/sklearn-gridsearchcv-replacement.html"
      },
      {
        "text": "Реализация",
        "url": "https://colab.research.google.com/github/krasserm/bayesian-machine-learning/blob/master/bayesian_optimization.ipynb"
      },
      {
        "text": "Про гауссовские процессы",
        "url": "http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html"
      },
      {
        "text": "Более формально про гауссовские процессы",
        "url": "https://krasserm.github.io/2018/03/19/gaussian-processes/"
      },
      {
        "text": "Оригинальная статья",
        "url": "https://proceedings.neurips.cc/paper/2011/file/86e8f7ab32cfd12577bc2619bc635690-Paper.pdf"
      },
      {
        "text": "Блог-пост",
        "url": "http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html"
      },
      {
        "text": "Hyperopt",
        "url": "https://github.com/hyperopt/hyperopt"
      },
      {
        "text": "Отличное объяснение",
        "url": "https://stats.stackexchange.com/questions/244012/can-you-explain-parzen-window-kernel-density-estimation-in-laymans-terms"
      },
      {
        "text": "Отличный туториал",
        "url": "https://www.borealisai.com/en/blog/tutorial-8-bayesian-optimization/"
      }
    ]
  },
  {
    "document_title": "Сходимость SGD",
    "url": "https://education.yandex.ru/handbook/ml/article/shodimost-sgd",
    "section_title": "Доказательство сходимости",
    "text": "Зададимся следующим вопросом: с какой скоростью и в каком смысле SGD сходится к решению и сходится ли? Во-первых, как и во многих работах по стохастической оптимизации, нас будет интересовать сходимость метода в среднем, т.е. оценки наили, где— решение задачи (для простоты будем считать, что оно единственное). Во-вторых, чтобы SGD сходился в указанном смысле, необходимо ввести дополнительные предположения. Действительно, например, если дисперсия стох. градиента не ограничена, тои никаких разумных гарантий доказать не удаётся. Поэтому дополнительно к несмещённости часто предполагается, что дисперсия равномерно ограничена: предположим, что существует такое число, что для всехвыполнено Данное предположение выполнено, например, для задачи логистической регрессии (поскольку в данной задаче норма градиентов слагаемых ограничена), но в то же время является весьма обременительным. Его можно заменить на более реалистичные предположения, что мы немного затронем далее. Однако при данном предположении анализ SGD является очень простым и полезным для дальнейших обобщений и рассуждений. Для простоты везде далее мы будем считать, что функцияявляется-гладкой и-сильно выпуклой, т.е. для всехвыполнены неравенства Теорема. Предположим, чтоявляется-гладкой и-сильно выпуклой, стох. градиентимеет ограниченную дисперсию, и размер шага удовлетворяет. Тогда для всехвыполняется неравенство Доказательство.Используя выражение для, мы выводим Далее мы берём условное матожиданиеот левой и правой частей и получаем: Следующий шаг в доказательстве состоит в оценке второго момента. Используя предположение об ограниченности дисперсии стох. градиента, мы выводим: Чтобы оценить сверху, мы используем следующий факт, справедливый для любой выпуклой-гладкой функции(см. книгу Ю. Е. Нестерова \"Методы выпуклой оптимизации\", 2010): Беря в этом неравенстве,и используя, получаем Далее мы подставляем эту оценку в выражение для: Остаётся оценить скалярное произведение в правой части неравенства. Это можно сделать, воспользовавшись сильной выпуклостью функции: из следует Используя это неравенство в выведенной ранее верхней оценке на, мы приходим к следующему неравенству: где в последнем неравенстве мы воспользовались неотрицательностью, что следует изи. Чтобы получить результат, заявленный в теореме, нужно взять полное мат. ожидание от левой и правой частей полученного неравенства (воспользовавшись при этом крайне полезным свойством условного мат. ожидания — tower property:) а затем, применяя это неравенство для,,,, получим что и требовалось доказать. Данный результат утверждает, что SGD с потоянным шагом сходится линейно к окрестности решения, радиус которой пропорционален. Отметим, что чем больше размер шага, тем быстрее SGD достигает некоторой окрестности решения, в которой продолжает осциллировать. Однако чем больше размер шага, тем больше эта окрестность. Соответственно, чтобы найти более точное решение, необходимо уменьшать размер шага в SGD. Этот феномен хорошо проиллюстрированздесь. Теорема выше доказана при достаточно обременительных предположениях: мы предположили, что функция является сильно выпуклой,-гладкой и стох. градиент имеет равномерно ограниченную дисперсию. В практически интересных задачах данные условия (в данном виде) выполняются крайне редко. Тем не менее, выводы, которые мы сделали из доказанной теоремы, справедливы для многих задач, не удовлетворяющих введённым предположениям (во многом потому, что указанные свойства важны лишь на некотором компакте вокруг решения задачи, что в свою очередь не так и обременительно). Более того, если мы сделаем немного другое предположение о стохастических градиентах, то сможем покрыть некоторые случаи, когда дисперсия не является равномерно ограниченной на всём пространстве. Предположим теперь, что, гдепросэмплировано из некоторого распределениянезависимо от предыдущих итераций,иявляется выпуклой и-гладкой для всех(данное предположение тоже можно ослабить, но для простоты изложения остановимся именно на такой формулировке). Будем называть данные условия предположением о выпуклых гладких стохастчиеских реализациях. Они выполнены, например, для задач линейно регрессии и логистической регрессии. В таком случае, для точек, сгенерированных SGD, справедливо, что SGD с потоянным шагом сходится линейно к окрестности решения, радиус которой пропорционален. Отметим, что чем больше размер шага, тем быстрее SGD достигает некоторой окрестности решения, в которой продолжает осциллировать. Однако чем больше размер шага, тем больше эта окрестность. Соответственно, чтобы найти более точное решение, необходимо уменьшать размер шага в SGD. Этот феномен хорошо проиллюстрированздесь. Теорема. Предположим, чтоявляется-гладкой и-сильно выпуклой, стохастчиеские реализации являются выпуклыми и гладкими, и размер шага удовлетворяет, где. Тогда для всехвыполняется неравенство где. Доказательство. Аналогично предыдущей доказательству предыдущей теоремы, получаем Посколькуявляется выпуклой и-гладкой, имеем (см. книгу Ю. Е. Нестерова \"Методы выпуклой оптимизации\", 2010): Применяя это неравенство для,, получаем где во втором переходе мы воспользовались стандартным фактом:для любых. Подставим полученное неравенство в выражение для, доказанное ранее: Остаётся оценить скалярное произведение в правой части неравенства. Это можно сделать, воспользовавшись сильной выпуклостью функции: из следует Используя это неравенство в выведенной ранее верхней оценке на, мы приходим к следующему неравенству: где в последнем неравенстве мы воспользовались неотрицательностью, что следует изи. Действуя по аналогии с доказательством предыдущей теоремы, получаем требуемый результат. Выводы, которые можно сделать из данной теоремы, очень похожи на те, что мы уже сделали из прошлой теоремы. Главные отличия заключаются в том, чтоможет быть гораздо больше, т.е. максимальный допустимый размер шагав данной теореме может быть гораздо меньше, чем в предыдущей. Однако размер окрестности теперь зависит от дисперсии стох. градиента в решении, что может быть значительно меньше. Рассмотрим важный частный случай — задачи минимизации суммы функций: Обычноимеет смысл функции потерь на-м объекте датасета. Предположим, что— выпуклая и-гладкая функция. Тогда выполняется предположение о выпуклых гладких стохастчиеских реализациях: действительно, достаточно задатькак случайное число из, имеющее равномерное распределение. Тогда справедлив результат предыдущей теоремы си. Для любогоможно выбрать шаг в SGD следующим образом: где. Тогда из доказанного выше результата следует (см. Лемму 3 изстатьи С. Стиха), что послеитераций Таким образом, чтобы гарантировать, SGD требуется итераций/подсчётов градиентов слагаемых. Чтобы гарантировать то же самое, градиентному спуску (GD) необходимо сделать подсчётов градиентов слагаемых, поскольку каждая итерация GD требуетподсчётов градиентов слагаемых (нужно вычислять полный градиент). Можно показать, что, поэтому в худшем случае полученная оценка для SGD заведомо хуже, чем для GD. Однако в случае, когда, однозначного вывода сделать нельзя: при большомможет доминировать первое слагаемое в оценке сложности SGD, поэтому в таком случае SGD будет доказуемо быстрее, чем GD (если пренебречь логарифмическими множителями). Иными словами, чтобы достичь не очень большой точности решения, выгоднее использовать SGD, чем GD. В ряде ситуаций небольшой точности вполне достаточно, но так происходит не всегда. Поэтому возникает ествественный вопрос: можно ли так модифицировать SGD, чтобы полученный метод сходился линейно асимптотически к точному решению (а не к окрестности как SGD), но при этом стоимость его итераций была сопоставима со стоимостью итераций SGD? Оказывается, что да и соответствующие методы называются методами редукции дисперсии.",
    "source_type": null,
    "useful_links": [
      {
        "text": "здесь",
        "url": "https://fa.bianp.net/teaching/2018/COMP-652/stochastic_gradient.html"
      },
      {
        "text": "здесь",
        "url": "https://fa.bianp.net/teaching/2018/COMP-652/stochastic_gradient.html"
      },
      {
        "text": "статьи С. Стиха",
        "url": "https://arxiv.org/pdf/1907.04232.pdf"
      }
    ]
  },
  {
    "document_title": "Сходимость SGD",
    "url": "https://education.yandex.ru/handbook/ml/article/shodimost-sgd",
    "section_title": "Методы редукции дисперсии",
    "text": "Перед тем, как мы начнём говорить о методах редукции дисперсии, хотелось бы раскрыть подробнее причину того, что SGD не сходится линейно асимптотически к точному решению. Мы рассмотрели анализ SGD в двух предположениях, и в обоих случаях нам требовалось вывести некоторую верхнюю оценку на второй момент стох. градиента, т.е. на. В обоих случаях эта оценка содержала некоторый константный член (или— зависит от рассматриваемого предположения), который потом возникал и в финальной оценке на, препятствуя тем самым линейно сходимости метода. Конечно, это рассуждение существенно опирается на конкретный способ анализа метода, а потому не является строгим объяснением, почему SGD не сходится линейно. Однако важно отметить, что оценка надостаточно точно отражает поведение метода вблизи решения: даже если точкаоказалась по какой-то причине близка к решению(или даже просто совпала с решением), тои, в частности,будут порядкаили. Следовательно, при следующем шаге метод с большой вероятностью отдалится от/выйдет из решения, посколькуили. Из приведённых выше рассуждений видно, что дисперсия стох. градиента мешает методу сходится линейно к точному решению. Поэтому хотелось бы как-то поменять правило вычисления стох. градиента, чтобы выполнялись 3 важных свойства: (1) новый стох. градиент должен быть не сильно дороже в плане вычислений, чем подсчёт стох. градиента в SGD (градиента слагаемого), (2) новый стох. градиент должен быть несмещённой оценкой полного градиента, и (3) дисперсия нового стох. градиента должна уменьшаться в процессе работы метода. Например, можно рассмотреть следующий стох. градиент: гдевыбирается случайно равновероятно из множестваи. В таком случае, будет выполнено свойство (2) из списка выше. Чтобы достичь желаемой цели, необходимо как-то специфицировать выбор случайного вектора. Исторически одним из первых способов выборабыл, где точкаобновляется раз витераций: Данный метод называется Stochastic Variance Reduced Gradient (SVRG). Данный методы был предложен и проанализирован вNeurIPS статье Джонсона и Жанга в 2013 году. Теперь же убедимся, что метод удовлетворяет всем трём отмеченным свойствам. Начнём с несмещённости: Далее, вычислениеподразумевает 2 подсчёта градентов слагаемых прииподсчёта градентов слагаемых при. Таким образом, запоследователльных итераций SVRG происходит вычислениеградиентов слагаемых, в то время как SGD требуетсяподсчётов градиентов слагаемых. Если(стандартный выбор параметра), тоитераций SVRG лишь в 3 раза дороже, чемитераций SGD. Иными словами, в среднем итерация SVRG не сильно дороже итерации SGD. Наконец, если мы предположим, что метод сходится(а он действительно сходится, см., например, доказательство воттут), то получим, что, а значити. Но тогда в силу Липшицевости градиентовдля всехимеем: а значит, дисперсиястремится к нулю. Приведённые выше рассуждения не являются формальным доказательством сходимости метода, но частично объясняют, почему метод сходится и, самое главное, объясняют интуицию позади формул, задающих метод. Строгое доказательство можно прочитать воттут. Мы же здесь приведём результат о сходимости немного другого метода — Loopless Stochastic Variance Reduced Gradient (L-SVRG), который был предложен в2015 годуи переоткрыт в2019 году. Основное отличие от SVRG состоит в том, что точкатеперь обновляется на каждой итерации с некоторой маленькой вероятностью: Иными словами, L-SVRG имеет случайную длину цикла, в которомне обновляется. Вся интуиция и все наблюдения приведённые для SVRG выше, справедливы и для L-SVRG. Можно доказать следующий результат. Теорема. Предположим, чтоявляется-гладкой,-сильно выпуклой и имеет вид суммы, функцииявляются выпуклыми и-гладкими для всех, и размер шага удовлетворяет, где. Тогда для всехдля итераций L-SVRG выполняется неравенство где,. Замечание. В частности, еслии, то Следовательно, чтобы гарантировать, L-SVRG требуется итераций/подсчётов градиентов слагаемых (в среднем). Напомним, что чтобы гарантировать то же самое, градиентному спуску (GD) необходимо сделать подсчётов градиентов слагаемых, поскольку каждая итерация GD требуетподсчётов градиентов слагаемых (нужно вычислять полный градиент). Можно показать, что, поэтому в худшем случае полученная оценка для L-SVRG не лучше, чем для GD. Однако в случае, когда, L-SVRG имеет сложность значительно лучше, чем GD (если пренебречь логарифмическими множителями). В заключение этого раздела, хотелось бы отметить, что существуют и другие методы редукции дисперсии. Одним из самых популярных среди них являетсяSAGA. В отличие от SVRG/L-SVRG, в методе SAGA хранится набор градиентов. Здесь точкаобозначает точку, в которой в последний раз был подсчитан градиент функциидо итерации. Формально это можно записать следующим образом: Основное преимущество SAGA состоит в том, что не требуется вычислять полный градиент всей суммы по ходу работы метода, однако в начале требуется посчитать градиенты всех слагаемых (отмечаем здесь, что эта операция может быть гораздо дороже по времени, чем вычисление полного градиента) и, более того, требуется хранитьвекторов, что может быть недопустимо для больших датасетов. В плане теоретических гарантий SAGA и L-SVRG не отличимы. Ниже приведён график с траекториями SGD (с постоянным шагом), L-SVRG и SAGA при решении задачи логистической регрессии. Как можно видеть из графика, SGD достаточно быстро достигает не очень высокой точности и начинает осциллировать вокруг решения. В то же время, L-SVRG и SAGA достигают той же точности медленнее, но зато не осциллируют вокруг решения, а продолжают сходится (причём линейно). Сравнение работы SGD, L-SVRG и SAGA при решении задачи логистической регрессии на датасете gisette из библиотекиLIBVSM.",
    "source_type": null,
    "useful_links": [
      {
        "text": "NeurIPS статье Джонсона и Жанга в 2013 году",
        "url": "https://proceedings.neurips.cc/paper/2013/hash/ac1dd209cbcc5e5d1c6e28598e8cbbe8-Abstract.html"
      },
      {
        "text": "тут",
        "url": "http://proceedings.mlr.press/v108/gorbunov20a/gorbunov20a-supp.pdf"
      },
      {
        "text": "тут",
        "url": "http://proceedings.mlr.press/v108/gorbunov20a/gorbunov20a-supp.pdf"
      },
      {
        "text": "2015 году",
        "url": "https://proceedings.neurips.cc/paper/2015/hash/effc299a1addb07e7089f9b269c31f2f-Abstract.html"
      },
      {
        "text": "2019 году",
        "url": "http://proceedings.mlr.press/v117/kovalev20a/kovalev20a.pdf"
      },
      {
        "text": "SAGA",
        "url": "https://proceedings.neurips.cc/paper/2014/hash/ede7e2b6d13a41ddf9f4bdef84fdc737-Abstract.html"
      },
      {
        "text": "LIBVSM",
        "url": "https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html"
      }
    ]
  },
  {
    "document_title": "Нейросети для облаков точек",
    "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-oblakov-tochek",
    "section_title": "Сенсоры для получения облаков точек",
    "text": "Один из самых популярных сенсоров для получения облаков точек — это LiDAR. Принцип его действия состоит в следующем: посылается луч, он отражается от поверхности и возвращается на детектор. Зная скорость света и время, за которое луч вернулся, мы можем посчитать расстояние до объекта. Благодаря используемой технологии у каждой точки помимо позициибудет известна ещё интенсивность. Она показывает, насколько сильным был отклик от поверхности. Например, от стекол или снега мы можем ожидать околонулевой мощности отражения, в то время как от дорожных знаков отражение будет очень сильным. Таким образом, интенсивность может оказаться важным признаком при построении предсказательной модели над облаками. Большим преимуществом лидара является способность получать отклик на расстоянии 200 метров и больше при сохранении высокой точности. RGB-D камера — это камера, которая способна возвращать глубину каждого пикселя помимо RGB значения. Зная глубину и математическую модель камеры, мы можем восстановить облако точек. Большим преимуществом такого сенсора является наличие цвета для каждой точки. Это может быть полезно при построении моделей сегментации, детекции и так далее. RGB-D камеры, как правило, обладают меньшей точностью, чем LiDAR. Также такие сенсоры не позволяют оценивать глубину дальше 10-15 метров. Облако точек можно получить и с помощью обычной камеры, если воспользоваться алгоритмами компьютерного зрения для вычисления глубины. Существуют алгоритмы оценки глубины по одному кадру (monocular depth estimation), оценки глубины по нескольким кадрам (multi view stereo), восстановление облака точек окружающих объектов с помощью движения камеры (Structure From Motion). В зависимости от алгоритма, камеры и среды качество итоговых облаков может различаться. В каждом отдельном практическом приложении нужно смотреть, насколько тот или иной сенсор (или метод получения облака точек) подходит для задачи.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Нейросети для облаков точек",
    "url": "https://education.yandex.ru/handbook/ml/article/nejroseti-dlya-oblakov-tochek",
    "section_title": "Архитектуры для обработки облаков точек",
    "text": "В этой части мы рассмотрим различные подходы к построению нейросетей для работы с облаками точек. Мы обсудим детали архитектур, их минусы и плюсы, а также варианты использования этих архитектур в приложениях. Давайте подумаем как, именно мы можем обрабатывать облака точек. Во-первых мы можем применять некоторую функцию, например, MLP (полносвязную нейросеть) к вектору признаков каждой точки нашего облака. Проблема с таким подходом в том, что мы работаем не с облаком, а с отдельными точками. У такой архитектуры не будет пространственного контекста. В терминах CNN, receptive field каждой точки будет равен 1 — это эквивалентно свёрточной архитектуре, где все ядра размера 1x1. Значит нам нужен некий механизм, с помощью которого точки смогут обмениваться информацией друг с другом. Таких механизмов можно придумать много: это и построение графа над облаком, и пересылка сообщений между вершинами, это может быть механизм внимания. Авторы архитектурыPointNetпредложили максимально простой механизм: имея для каждой точки некоторый вектор признаков, давайте применим к этим векторам некоторую глобальную агрегацию AGGR, например, GlobalAveragePooling или GlobalMaxPooling: Таким образом из набора векторов для точек мы получим общий вектор признаков, описывающий всё облако. Полученный вектор описывает облако в целом, но точки при таком подходе по-прежнему не обмениваются информацией: ни одна из них не «знает», что происходит вокруг. Чтобы исправить недостатки двух описанных выше подходов, объединим их, рассмотрев следующий базовый «слой» преобразования облака: Агрегируем векторы признаков точек, получаем общий вектор признаковдля облака в целом; Для каждой точки конкатенируем её вектор признаков с вектором признаков облака и строим новый вектор признаков; Применим MLP к вектору признаков каждой точки:. Такие слои можно применять последовательно, формируя сколь угодно глубокую архитектуру. Теперь, если мы хотим решить задачу классификации над облаком, мы можем взять очередной вектор, полученный после агрегации всех векторов признаков точек, применить к нему MLP, получить логиты и обучать полученную сеть на cross-entropy loss. Если же мы хотим решить задачу сегментации (то есть классификации для каждой точки), мы можем точно после очередного слоя применить MLP с необходимыми размерами к каждому векторуи получить логиты. Авторы архитектуры PointNet предложили ещё одно небольшое усложнение описанной выше архитектуры. Давайте внимательно посмотрим на схему из статьи: Синий прямоугольник наверху соответствует одному описанному выше «слою», но вместо одного MLP здесь последовательность двух MLP, между которыми вставлена операция feature transform. Эта операция состоит в следующем: с помощью дополнительной сети по облаку в целом строим матрицу; эта матрица умножается на вектор признаков каждой из точек. Тем самым точки дополнительно обмениваются информацией. Во многих последующих статьях эту часть не включают, и практика показывает, что для PointNet это не ключевой элемент архитектуры, и им можно пренебречь. PointNet — это достаточно простая архитектура. Она использует геометрию облака, потому что координаты точек входят в векторы признаков, но работает не с локальной окрестностью точки, а со всем облаком в целом. Если мы обратимся к аналогиям с изображениями, то такая архитектура будет эквивалентна CNN со свёртками размера всего изображения. Такая архитектура с трудом улавливает локальные паттерны и детали, и именно это будет основным направлением дальнейшего улучшения этой архитектуры. Продолжением статьи PointNet стала статьяPointNet++от той же научной группы. Новая архитектура развивает идею локальности, о который мы писали в предыдущем параграфе. Давайте подумаем, каким образом мы можем получить локальные, зависящие только от окрестности точки операции над облаком точек. Первым делом нам необходимо понять, что такое локальность. В облаке точек очевидным решением кажется определить окрестность точки исходя из евклидового расстояния между точками — как шар некоторого радиуса — и проводить операции внутри этого шара. Какие операции мы будем проводить внутри шара? У нас уже есть PointNet, который по произвольному набору точек может построить вектор, описывающий этот набор в целом. С его помощью мы можем описать многослойную архитектуру, напоминающую энкодер свёрточной сети, каждый слой которой будет выглядеть следующим образом: сэмплируемключевых точек в облаке, гдеменьше размера облака (как правило в несколько раз); вокруг каждой ключевой точки фиксируем шар радиуса; для каждого шара находим все точки, которые в нём лежат; запускаем PointNet с одними и теми же весами для каждого шара; получаем новое облако източек, где каждой точке присвоен вектор признаков, полученный из PointNet. Далее мы можем повторять эту процедуру, пока у нас не останется одна точка, то есть один вектор признаков для всего облака в целом. Полученный эмбединг можно использовать для решения различных задач. Обсудим детали реализации этой архитектуры. В качестве алгоритма сэмплирования предлагается Farthest Point Sampling (FPS). Он заключается в том, что мы жадно сэмплируем точку, которая максимально удалена от текущего насэмплированного множества. Этот процесс мы повторяем, пока не наберём достаточное количество точек. Благодаря FPS мы можем в некоторой степени гарантировать, что покроем равномерно все облако и не пропустим какие-то мелкие, но удалённые от основного облака объекты. В этом ценное отличие FPS от случайного сэмплирования, при котором детали, содержащие мало точек, могут быть легко потеряны. Выбор радиуса шара зависит, как правило, от плотности облака. Стоит посмотреть, сколько примерно точек попадает в каждую окрестность, и исходя из этого фиксировать радиус. Также этот параметр можно подобрать с помощью валидации. Для удобства реализации фиксируют не только радиус, но и максимальное количество объектов внутри шара. Это делается для того, чтобы при реализации архитектуры можно было манипулировать тензорами, избегая итерации по всем точкам каждого шара. Например, мы фиксируем количество шаров, количество точек внутри шараи размерность вектора признаков для каждой точки. Тогда размер тензора будет:. Если в окрестности шара оказалось больше точек, чем мы заранее определили, то возьмем ближайшие. В случае, если точек в тензоре меньше, чем, тензор паддится нулями до нужного размера. Внутри каждого слоя веса PointNet одинаковы для всех шаров. На окрестностях с одинаковой локальной структурой мы хотим получать одинаковые результаты, поэтому мы не можем использовать абсолютные значения. В этом плане мы хотим, чтобы наши слои были похожи на свёртки, результат работы которых тоже не зависят от положения пикселя на изображении. Чтобы этого добиться, координатыкаждой точки преобразуются в локальные координаты, где— координаты центра шара. Отдельно стоит обсудить, как получить поточечные признаки для решения задачи сегментации. Нам предстоит обратить энкодер и получить архитектуру декодера. Для этого каждый раз, когда мы делаем downsampling облака, то есть переход от вектора для каждой точки к общему вектору для некоторой окрестности, мы будем запоминать, какие точки принадлежали к какому шару. В процессе upsampling, то есть перехода от вектора окрестности к поточечным векторам, мы будем конкатенировать вектор окрестности с исходными векторами признаков точек. После каждой операции upsampling мы можем запускать MLP, чтобы точка, получив информацию с более глубокого уровня, могла извлечь оттуда информацию. Мы разобрали архитектуру PointNet++, которая построена на обработке локальных окрестностей точек, определённых исходя из евклидового расстояния. У этой архитектуры есть свои проблемы. Во-первых, поиск ближайших соседей и FPS — это медленные процедуры. В результате могут возникнуть проблемы, когда мы захотим использовать такую сеть в real-time приложениях. Во-вторых, в зависимости от расстояния до сенсора у нас может меняться паттерн разреженности: если вблизи сенсора в шаре радиусамы можем найти в среднем 100 точек, то, как правило, чем больше расстояние до наблюдателя — тем меньше точек мы будем находить в таком же объёме. Это усложняет обучение и может привести к тому, что с расстоянием качество будет сильно деградировать. Давайте попробуем напрямую применить свёрточные нейронные сети в нашей задаче. Идея следующая: возьмём прямоугольный параллелепипед, который накрывает интересующую нас область пространства. Далее разобьём этот прямоугольный параллелепипед на значительно меньшие прямоугольные параллелипипеды одинакового размера. Назовем эти прямоугольные параллелепипедывокселями. В результате внутри каждого вокселя окажется некоторый набор точек. Нам нужно каким-то образом превратить точки внутри каждого вокселя в один вектор. После этого мы можем применить обычные свёрточные сети и решать любые задачи. Чтобы из набора точек внутри вокселя получить вектор признаков, мы можем просто применить PointNet. Таким образом, мы получим тензор размера, где первые три размерности пространственные, а последняя размерность — размерность вектора признаков. Далее мы можем использовать 3D-свёртки для того, чтобы обработать этот тензор. Но проблема в том, что ядро в 3D-свёртках имеет на одну размерность больше, чем в 2D-свёртках, что делает их дорогими для вычисления. В статьях были предложены различные подходы для того, чтобы ускорить эту архитектуру. Часто размерность по высоте и размерность признаков объединяют в одну: тензор размерностипревращается в тензор размерности, как будто мы смотрим на него сверху (bird’s eye view). Для работы с ними мы можем использовать 2D-свёртки. Ещё одним популярным трюком является использование высокой степени разреженности этого тензора: большое количество «столбиков» не содержат ни одной точки. Давайте возьмём все «столбики», содержащие хотя бы одну точку; предположим, что ихштук. Соберём из них тензор размераи применим к нему линейный слой, который уменьшит число каналов, то есть высоту «столбиков». Получится тензордля выбранного нами. Его столбцы мы снова расставим на их исходные места, получив тензор. «Столбики» этого тензора, которые соответствуют пустым «столбикам» исходного тензора, мы заполним нулями. Воксельный подход очень популярен в задаче детекции, потому что позволяет напрямую переиспользовать некоторые подходы к 2D детектированию. Но у него есть и недостатки. Например, нельзя сколько угодно плотно покрыть вокселями сколь угодно большой объём, потому что это напрямую влияет на размер тензора, а значит — на время работы, что может быть критично в real-time приложениях. В итоге мы можем потерять какие-то важные удалённые объекты или не справиться с мелкими деталями. Основная проблема воксельных архитектур — это неспособность обрабатывать облака произвольного размера и дальности. У вас может быть самый лучший LiDAR в мире, который видит на 300 метров во все стороны, но если ваша архитектура не будет способна обрабатывать полученное облако точек в режиме реального времени, то такой сенсор бесполезен. Чтобы преодолеть эту проблему, мы можем воспользоваться тем фактом, что лидар сканирует окрестность из одной точки. Давайте окружим сенсор виртуальным цилиндром и спроецируем все точки на этот цилиндр. Далее цилиндр можно развернуть в прямоугольник и получить представление с которым могут работать свёрточные сети. Обычно точки параметризуют двумя углами: pitch — наклон по вертикали, yaw — угол по горизонтали. Мы можем дискретизовать эти углы и таким образом получить для каждой точки координаты пикселя, в который она должна быть помещена. В каналы нашего тензора мы можем записать: расстояние до точки, интенсивность сигнала, абсолютную высоту точки. Далее такое представление может быть обработано любой 2D архитектурой. Важно отметить, что такое представление не будет работать для других методов получения облаков точек. Лидар сканирует окрестность из одной точки, и потому в направлении каждого луча у нас будет только одна точка. Это означает, что мы не видим за препятствиями. В то время облака, полученные, например, с помощью Structure from Motion, в направлении одного луча могут содержать несколько точек, что лишает нас возможности без потерь спроецировать всё облако на 2D холст. Такое представление снимает проблему с производительностью, так как размер обрабатываемых данных не зависит от разброса облака. Но, к сожалению, появляются новые проблемы. Во-первых, объекты, которые находятся далеко друг от друга в трёхмерном пространстве, могут оказаться рядом в этой проекции — в итоге, информация о таких объектах будет смешиваться, и в результате границы в задаче сегментации могут получиться размытыми. Воксельные- или PointNet-архитектуры не имеют этой проблемы — в них далёкие друг от друга объекты не будут так сильно взаимодействовать. Во-вторых, объекты при таком представлении будут иметь разные размеры в зависимости от расстояния, и модели придётся адаптироваться к этому. Воксельные и PointNet архитектуры, опять же, лишены этой проблемы, так как их представления инвариантны к переносу. Обе эти проблемы могут приводить к существенной деградации качества. Именно поэтому архитектуры, построенные на цилиндрической проекции, часто проигрывают другим архитектурам по качеству. В некоторых приложениях у нас может быть несколько различных сенсоров: например, лидар и камера. Тогда возникает задача: построить архитектуру, которая использует информацию с обоих сенсоров. Конечно, мы бы могли отдельно подготовить архитектуру для работы с изображением, отдельно архитектуру для работы с облаком и затем каким-то образом объединить результаты. Минус такого подхода в том, что нам требуется в два раза больше вычислительных мощностей, а нейронные сети никак не делятся информацией на промежуточных слоях. Возможно, нейронная сеть могла бы извлечь более богатые представления из объединенных данных. Например, разрешить некоторую неопределённость в облаке с помощью изображений. Оказывается, что задача смешивания различных сенсоров очень непростая, и в литературе долгое время не могли для задачи 3D детекции получить результаты, которые бы превосходили только лидарный подход. Мы обсудим идеи, как именно можно смешивать изображения и 3D информацию. Прежде чем мы перейдем к описанию подходов, давайте обсудим одну важную техническую деталь. Смешивание информации с разных сенсоров всегда предполагает, что сенсоры скалиброваны. Это означает что нам известна матрица перехода из системы координат одного сенсора в систему координат другого. Таким образом, у нас есть необходимая информация, для того, чтобы спроецировать лидарную точку на плоскость изображения. Архитектура, которая первой показала действительно значительный прирост качества при смешивании сенсоров, называетсяPointPainting. Идея была следующей: Делаем сегментацию изображения; Для каждой лидарной точки найдём соответствующий ей пиксель на изображении и присвоим этой точке соответствующий класс из сегментации; Для архитектуры, которая работает с облаком точек, этот класс будет еще одним дополнительным признаком на входе. Важно отметить, что сопоставление точки класса не будет идеальным, например, из-за того, что камера и лидар находятся не в одной точке. Идея очень простая, но при этом позволяет сильно улучшить метрики. Проблема в том, что данный подход не решает проблему возросших вычислений при обработке данных с двух сенсоров. Более того, мы передаем в 3D архитектуру лишь одно число для каждой точки и теряем много информации об изображении. Другой подход был описан в статьеLaserNet++. Авторы используют цилиндрическую проекцию для обработки облака. Перед началом обработки они пропускают изображение через небольшую свёрточную сеть, получая в результате некоторый вектор признаков в каждом пикселе. Далее для каждой лидарной точки находим соответствующий пиксель на изображении и добавляем его признаки к признакам точки. Отличие от PointPainting в том, что в данном подходе обе нейронные сети обучаются end-to-end. Это позволяет нам извлечь более богатое представление из изображения. В статье авторы сообщают о росте метрик на in-house наборе данных. К сожалению, на открытых данных этот подход не смог продемонстрировать превосходства над lidar-only моделями. В этом параграфе мы разобрали основные идеи работы с облаками точек. Верхнеуровнево все архитектуры можно разделить на следующие группы: Облако как граф (PointNet и многие другие архитектуры); Вокселизация (VoxelNet, PointPillars и другие); Проекция лидарного облака на 2D поверхность (RangerNet, LaserNet, LaserNet++ и другие). Каждый подход имеет свои плюсы и минусы и выбор конкретного подхода должен быть обусловлен решаемой задачей.",
    "source_type": null,
    "useful_links": [
      {
        "text": "PointNet",
        "url": "https://arxiv.org/pdf/1612.00593.pdf"
      },
      {
        "text": "PointNet++",
        "url": "https://arxiv.org/pdf/1706.02413.pdf"
      },
      {
        "text": "PointPainting",
        "url": "https://arxiv.org/pdf/1911.10150.pdf"
      },
      {
        "text": "LaserNet++",
        "url": "https://arxiv.org/pdf/1904.11466.pdf"
      }
    ]
  },
  {
    "document_title": "Многомерные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
    "section_title": "Дискретные многомерные распределения",
    "text": "Пусть, например, эксперимент состоит из двух фаз: сначала подбрасывается монетка, а затем кубик. Тогда вероятностная масса сосредоточена в точках,,. Вероятность каждого исхода можно записать в виде таблицы Результат подбрасывания монеты моделирует бернуллиевская случайная величина, а результат броска кубика — равномерно распределённая на множествеслучайная величина. Содержимое таблицы вероятностей каждого исхода можно также представить матрицей которая задаётсовместное распределениеслучайных величини:. Пару случайных величинв таком контексте называют такжеслучайным вектором. Элементы матрицыне обязаны совпадать; например, монета может быть несимметричной с вероятностью «успеха», и тогда таблица вероятностей примет вид Контрольный вопрос. Какая таблица вероятностей соответствует эксперименту, в котором результат подбрасывания монеты «портит» кубик следующим образом: на нём могут равновероятно выпасть только значенияилив случае «неудачи» и,илив случае «успеха»? В общем случае дискретное-мерное распределение задаётся многомерным тензором из неотрицательных чисел, суммирующихся в единицу. Такие тензоры используются для задания совместного распределения вероятностей случайного вектораиз дискретных случайных величин:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Многомерные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
    "section_title": "Непрерывные многомерные распределения",
    "text": "Непрерывное распределение на плоскости задаётся плотностью; при этом вероятность событияравна при условии, что этот интеграл имеет смысл. Простейший пример — равномерное распределение на единичном квадрате: его плотность равна, и Именно так на единичном квадрате формально определяется геометрическая вероятность. Плотность непрерывного распределения вявляется неотрицательной функцией видасо свойством Говорят, что случайный векторимеетсовместную плотность, если для всех достаточно «хороших» (измеримых по Лебегу) множеств.",
    "source_type": null,
    "useful_links": [
      {
        "text": "измеримых по Лебегу",
        "url": "https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%80%D0%B0_%D0%9B%D0%B5%D0%B1%D0%B5%D0%B3%D0%B0"
      }
    ]
  },
  {
    "document_title": "Многомерные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
    "section_title": "Маргинальные распределения",
    "text": "Из совместного распределения можно получить распределение в пространстве меньшей размерности путём суммирования или интегрирования по части переменных. Например, если матрицазадаёт совместное распределение случайных величини,, то каждый из наборов чисел неотрицателен и суммируется в единицу: Таким образом, числаизадают некоторые распределения вероятностей, называемыемаргинальными. Упражнение. Найдите маргинальные распределения, если совместное распределение задано матрицей В непрерывном случае ситуация похожая: если случайный вектор имеет совместную плотность, то функции являются плотностями маргинальных распределений. Для-мерных распределений можно находить маргинальные распределения, суммируя или интегрируя по любым наборам переменных с индексами; в результате получится маргинальное распределение по оставшимсяпеременным.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Многомерные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
    "section_title": "Независимость случайных величин",
    "text": "Случайные величиныиназываютсянезависимыми, если совместное распределение случайного векторараспадается на произведение одномерных. Точнее говоря, дискретные случайные величиныинезависимы, еслидля всех возможныхи; непрерывные случайные величиныинезависимы, если их совместная плотность. Если случайные величиныинезависимы, то распределение каждой из них является маргинальным распределением их совместного распределения, поскольку и Случайные величинынезависимы в совокупности, если их совместное распределение (совместная плотность) распадается в произведение одномерных распределений (плотностей). Пример. Рассмотримгауссовских случайных величинс плотностями Совместную плотность случайного вектораопределим как произведение плотностей его компонент: Случайный векторс такой плотностью имеетмногомерное нормальное (гауссовское) распределениеc независимыми в совокупности компонентами. Любое маргинальное распределение случайного вектораобладает плотностью того же вида, и поэтому также является гауссовским.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Многомерные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
    "section_title": "Характеристики случайных векторов",
    "text": "Математическое ожидание случайного вектораявляется вектором той же размерности и вычисляется покомпонентно: Каждая компонента случайного вектора — это обычная случайная величина, и её среднее можно вычислить стандартными методами: в дискретном случае; в непрерывном случае. Математическое ожидание перестановочно с линейным преобразованием случайного вектора:, где— фиксированная матрица. Вместо дисперсии у случайного вектораестьматрица ковариаций: Матрица ковариаций симметрична и состоит из попарных ковариаций компонент случайного вектора: Упражнение. Докажите, что ковариационная матрица любого случайного вектора неотрицательно определена. Если случайные величинынезависимы в совокупности, то, и ковариационая матрица случайного векторадиагональна: Например, матрица ковариации гауссовского случайного векторас плотностью равна, поскольку компоненты векторанезависимы в совокупности и имеют нормальное распределение. Аналогом ковариации в многомерном случае служит матрица ковариаций между случайными векторамии: Матрицу ковариаций можно также вычислить по формуле Упражнение. Пусть случайный векторполучен из случайного векторалинейным преобразованием:. Как связаны между собой их ковариационные матрицы?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Многомерные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
    "section_title": "Преобразования плотностей случайных векторов",
    "text": "Нередко приходится иметь дело не с самими случайными векторами, а с функциями от них. Но как найти плотность случайного вектора, зная плотность? Предположим, что— гладкая обратимая функция. Тогда для измеримогоимеем Чтобы перейти к интегралу по, сделаем замену переменной. По формуле замены координат в кратном интеграле получаем где– якобиан преобразования, т.е. определитель матрицы Якоби.Таким образом, Упражнение. Пусть– случайный вектор с плотностью. Какова плотность случайного вектора, где– постоянный вектор, а– постоянная обратимая матрица?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Многомерные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
    "section_title": "Распределение суммы независимых случайных величин",
    "text": "В дискретном случае найти распределение суммы двух независимых случайных величин несложно. В самом деле, В силу независимости случайных величинипоследняя сумма равна Полученная формула называетсяформулой свёртки. Пусть теперьи– независимые непрерывные случайные величины с плотностямиисоответственно. Сам собой напрашивается аналог формулы свёртки с плотностями вместо вероятностей, но чтобы достаточно строго вывести его и не запутаться, мы немного схитрим. А именно, мы рассмотрим случайный вектори его (обратимое!) преобразование Обратное к нему будет иметь вид Тогда по правилу преобразования плотности где в последнем равенстве мы воспользовались независимостьюи. Распределение случайной величины– это маргинальное распределение, которое вычисляется следующим образом: Эта формула также называетсяформулой свёртки.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Многомерные распределения",
    "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya",
    "section_title": "Примеры многомерных распределений",
    "text": "Рассмотрим несколько популярных распределений случайных векторов. Биномиальное распределениемоделирует-кратное подбрасывание монеты с вероятностями «успеха»и «неудачи».Мультиномиальное распределениеобобщает этот эксперимент: теперь подбрасывается кубик сгранями, и вероятность выпадения-й грани равна,. Обозначим черезколичество выпадений-й грани в серии избросков. Тогда случайный векторимеет мультиномиальное распределение, при котором Примультиномиальное распределение превращается вкатегориальное, известное также под названиемmultinoulli. Категориальное распределение моделирует случайный выбор одного изклассов с заданными вероятностями. Многомерное нормальное (гауссовское) распределениезадаётся функцией плотности где,— невырожденная симметричная матрица размера. Такое распределение обозначается. Если случайный вектор, то,; таким образом, параметры гауссовского распределения — это его среднее и матрица ковариаций. Упражнение.Пустьи. Докажите, что. Важный частный случай случайного гауссовского вектора с независимыми компонентами был рассмотрен в примере из секции пронезависимость случайных величин. Такое распределение получается, если матрицадиагональна,. Тогда,, и поэтому Отсюда снова получаем формулу совместной плотности которую можно переписать в виде откуда следует независимость в совокупности компонент вектора. Если ковариационная матрицане является диагональной, то отдельные компоненты случайного векторазависимы. Тем не менее, всегда найдётся линейное (и даже ортогональное) преобразование, которое превратит векторв гауссовский вектор с независимыми компонентами. Для этого достаточно найти ортогональную матрицусо свойством и далее воспользоваться формулой плотности линейного преобразования гауссовского вектора. По тем же соображениям облако точек, сгенерированных из распределения, будет напоминать эллипсоид с полуосями, пропорциональными вектору. Линии уровня плотностизадаются уравнениями вида, а такое равенство эквивалентно квадратичной форме гдеи– некоторые константы. С помощью описанной выше ортогональной замены эта квадратичная форма может быть приведена к главным осям: в координатах это выглядит как Мы получили практически каноническое уравнение-мерного эллипсоида. Вэто будут эллипсы, сплюснутые тем сильнее, чем дальше от единицы отношениесобственных значений матрицы. Нормальным будет и всякое маргинальное распределение многомерного гауссовского вектора. Упражнение. Пусть случайный векторимеет гауссовское распределение с параметрами где,,,,.Докажите, что случайный вектор, полученный маргинализацией по компонентам вектора, является гауссовским с параметрамии. Распределение Дирихлесосредоточено на-мерном симплексе Плотность распределения Дирихлеравна где– вектор положительных параметров, а– многомерная бета-функция. Если,то",
    "source_type": null,
    "useful_links": [
      {
        "text": "независимость случайных величин",
        "url": "https://education.yandex.ru/handbook/ml/article/mnogomernye-raspredeleniya#nezavisimost-sluchajnyh-velichin"
      }
    ]
  },
  {
    "document_title": "Кросс-валидация",
    "url": "https://education.yandex.ru/handbook/ml/article/kross-validaciya",
    "section_title": "Hold-out",
    "text": "Методhold-outпредставляет из себя простое разделение на train и test: Такое разделение очень легко реализовать с помощью библиотекиsklearn: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimporttrain_test_split34X, y = np.arange(1000).reshape((500,2)), np.arange(500)5X_train, X_test, y_train, y_test = train_test_split(6X, y,7test_size=0.2,8random_state=429) Чтобы оценить модель, вы обучаете её на тренировочном множестве, а результаты измеряете на тестовом. У sklearn по дефолту выставлен параметрshuffle=True, то есть перед разделением на тренировочное и тестовое множества происходит перемешивание семплов (и для воспроизводимости такого разбиения нужно фиксироватьrandom_state). А что будет, если не перемешать данные? Если обучение модели не зависит от порядка подачи в неё примеров (что верно, например, для k-NN или решающего дерева), то перемешивание данных влияет только на то, кто в итоге окажется в train и test. Если данные шли какими-то группами, например сначала 800 картинок с кошками, а за ними 200 картинок с собаками, аtrain_test_splitбыл совершён в пропорции 0.8, то модель просто не увидит собак в трейне. А в случае когда модель обучается с помощью градиентного спуска или его вариации (про различные модификации SGD подробно рассказывается впараграфео нейросетях), отсутствие перемешивания данных может влиять более интересным образом. Вот пример из практики Yandex.Research — как вы думаете, что не так с графиком обучения данной модели? Продолжим. Если у вас достаточно данных, лучше всегда предусматривать также валидационное множество: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimporttrain_test_split34X, y = np.arange(1000).reshape((500,2)), np.arange(500)5X_train, X_test, y_train, y_test = train_test_split(6X, y,7test_size=0.2,8random_state=429)10X_train, X_val, y_train, y_val = train_test_split(11X_train, y_train,12test_size=0.1,13random_state=4214) Если вы перебираете какие-то модели для вашей задачи, то оптимизировать их качества стоит на валидационном множестве, а окончательное сравнение моделей проводить на тестовом множестве. Оптимизация качеств модели может включать в себя подбор гиперпараметров, подбор архитектуры (в случае нейросетей) или подбор оптимального трешхолда для максимизации значений целевой метрики (например, вы делаете двуклассовую классификацию, а модель выдаёт непрерывные значения от 0 до 1, которые нужно бинаризовать так, чтобы получить максимальный скор по F1) и так далее. Если же оптимизировать качества моделей и проводить их сравнение на одном и том же множестве, то можно неявно заложить в модели информацию о тестовом множестве и получить результаты хуже ожидаемых на новых данных. Немного прервёмся например— к чему может привести неявное использование моделью тестового множества Представьте, что вы хотите обучить модель одномерной линейной регрессии для предсказания ваших данных: гдеи— искомые параметры вашей модели. Однако представьте, что параметрвам кто-то запретил обучать на тренировочном множестве и для вас у этой модели всего один параметр. Пусть на первой итерации у вас задано какое-то фиксированное, вы с ним подобрали на трейне лучшеепри данноми замерили качество получившейся модели на тестовом множестве. На следующей итерации вы взяли новое значение, повторили с ним предыдущий шаг и так далее. Теперь пришло время выбирать модель, и из всех них вы выбрали ту, которая показала лучший результат на тестовом множестве. Вам может показаться, что ваша модель содним параметромобучена на трейне и всё хорошо, но на самом деле вы использовали оба множества, чтобы обучить модель сдвумя параметрами, и теперь ваша тестовая оценка качества модели завышена. Может показаться, что этот пример довольно искусственный, но он на самом деле легко переносится на модели любой сложности. Просто представьте себе, что часть обучаемых весов вашей сложной модели вам запретили обучать на трейне и вы начинаете так же, как и выше, оценивать их на тесте, то есть по фактуучитьна тесте. А чем такая ситуация отличается от подборагиперпараметровмодели (которые вы уже действительно не можете обучить на трейне) сразу на тестовом множестве? Вообще говоря, ничем. Продолжим. Для окончательного применения найденную лучшую модель можно обучить на всех имеющихся данных. Правда, вы не сможете оценить качество получившейся модели, так как у вас уже не будет тестового множества. Чтобы примерно оценить, как будет вести себя модель при добавлении новых данных, вы можете построитькривые обучения: графики качества модели на трейне и на тесте в зависимости от числа поданных семплов на вход. Кривые обучения могут выглядеть следующим образом (код для отрисовки таких кривых можнонайтив документации библиотеки sklearn): Если графики подсказывают, что качество модели по валидационным метрикам продолжает расти, имеет смысл добавить новые данные. На картинке выше приведены кривые обучения двух моделей на одном и том же датасете. Модель слева показала итоговые результаты явно хуже модели справа — плюс график качества на валидации у неё близок к плато, хотя и продолжает расти, — а качество модели справа могло бы ещё вырасти при добавлении дополнительных семплов (качество на трейне константно высокое, а на валидации возрастает). При простом случайном разделении на тренировочное и тестовое множества (как в примерах выше) может случиться так, что их распределения окажутся не такими, как у всего исходного множества. Проиллюстрируем такую ситуацию на примере случайного разбиения датасетаIrisна трейн и тест. Распределение классов в данном датасете равномерное: Setosa Versicolor Virginica Случайное разбиение, в котором две трети цветов (100) отправились в трейн, а оставшаяся треть (50) отправилась в тест, может выглядеть, например, так: трейн: 38Setosa, 28Versicolor, 34Virginica (распределение) тест: 12Setosa, 22Versicolor, 16Virginica (распределение) Если распределение цветов в исходном датасете отражает то, что в природе они встречаются одинаково часто, то мы только что получили два новых датасета, не соответствующих распределению цветов в природе. Распределения обоих датасетов вышли не только несбалансированными, но ещё и разными: самый частый класс в трейне соответствует наименее частому классу в тесте. На помощь в такой ситуации может прийтистратификация: разбиение на трейн и тест, сохраняющее соотношение классов, представленное в исходном датасете. В библиотеке sklearn такое разбиение можно получить с помощью параметраstratify: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimporttrain_test_split34X, y = np.arange(1000).reshape((500,2)), np.random.choice(4, size=500, p=[0.1,0.2,0.3,0.4])5X_train, X_test, y_train, y_test = train_test_split(6X, y,7test_size=0.2,8random_state=42,9stratify=y10) В целом на достаточно больших датасетах (порядка хотя бы 10 тысяч семплов) со сбалансированными классами можно не очень сильно беспокоиться об описанной выше проблеме и использовать обычный random split. Но если у вас очень несбалансированные данные, в которых один класс встречается сильно чаще другого (как, например, в задачах фильтрации спама или сегментации осадков на спутниковых снимках), стратификация может довольно сильно помочь.",
    "source_type": null,
    "useful_links": [
      {
        "text": "sklearn",
        "url": "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
      },
      {
        "text": "параграфе",
        "url": "https://academy.yandex.ru/handbook/ml/article/nejronnye-seti"
      },
      {
        "text": "пример",
        "url": "https://www.johndcook.com/blog/2015/03/17/a-subtle-way-to-over-fit/"
      },
      {
        "text": "найти",
        "url": "https://scikit-learn.org/stable/auto_examples/model_selection/plot_learning_curve.html"
      },
      {
        "text": "Iris",
        "url": "https://archive.ics.uci.edu/ml/datasets/iris"
      }
    ]
  },
  {
    "document_title": "Кросс-валидация",
    "url": "https://education.yandex.ru/handbook/ml/article/kross-validaciya",
    "section_title": "k-Fold",
    "text": "Методk-Foldчаще всего имеют в виду, когда говорят о кросс-валидации. Он является обобщением метода hold-out и представляет из себя следующий алгоритм: Фиксируется некоторое целое число(обычно от 5 до 10), меньшее числа семплов в датасете. Датасет разбивается наодинаковых частей (в последней части может быть меньше семплов, чем в остальных). Эти части называютсяфолдами. Далее происходититераций, во время каждой из которых один фолд выступает в роли тестового множества, а объединение остальных — в роли тренировочного. Модель учится нафолде и тестируется на оставшемся. Финальный скор модели получается либо усреднениемполучившихся тестовых результатов, либо измеряется на отложенном тестовом множестве, не участвовавшем в кросс-валидации. Этот метод есть в sklearn: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimportKFold34X = np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])5y = np.array([1,2,3,4])6kf = KFold(n_splits=2)78fortrain_index, test_indexinkf.split(X):9print(\"TRAIN:\", train_index,\"TEST:\", test_index)10X_train, X_test = X[train_index], X[test_index]11y_train, y_test = y[train_index], y[test_index]12'''13result:14TRAIN: [2 3] TEST: [0 1]15TRAIN: [0 1] TEST: [2 3]16''' В коде выше получилось два фолда: в первый вошли объекты с индексами 2 и 3, во второй — объекты с индексами 0 и 1. На первой итерации алгоритма фолд с индексами 2 и 3 будет тренировочным, а на второй — фолд с индексами 0 и 1. В sklearn есть также методcross_val_score, принимающий на вход классификатор, данные и способ разбиения данных (либо число фолдов) и возвращающий результаты кросс-валидации: Скопировать код1fromsklearn.model_selectionimportcross_val_score23clf = svm.SVC(kernel='linear', C=1, random_state=42)4scores = cross_val_score(clf, X, y, cv=5)5print(scores)6'''7result:8array([0.96..., 1. , 0.96..., 0.96..., 1. ])9''' Интересный вопрос состоит в том, какую модель брать для сравнения с остальными на отложенном тестовом множестве (если оно у вас есть) либо для окончательного применения в задаче. После применения k-Fold для одной модели у вас на руках останетсяэкземпляров (инстансов) этой модели, обученных на разных подмножествах трейна. Возможные варианты: делать предсказание с помощью усреднения предсказаний этихинстансов; из этихинстансов выбрать тот, который набрал лучший скор на своём тестовом фолде, и применять дальше его; заново обучить модель уже на всехфолдах и делать предсказания уже этой моделью. Выбирать, какой способ лучше, нужно в зависимости от конкретной задачи и имеющихся вычислительных возможностей. Метод k-Fold даёт более надёжную оценку качества модели, чем hold-out, так как обучение и тест модели происходят на разных подмножествах исходного датасета. Однако проведениеитераций обучения и теста может быть вычислительно затратным, и поэтому метод обычно применяют либо когда данных достаточно мало, либо при наличии большого количества вычислительных ресурсов, позволяющих проводить всеитераций параллельно. В реальных задачах данных зачастую достаточно много для того, чтобы hold-out давал хорошую оценку качества модели, поэтому k-Fold в больших задачах применяется не очень часто. Методleave-one-out (LOO)— частный случай метода k-Fold: в нём каждый фолд состоит ровно из одного семпла. LOO тоже есть в библиотеке sklearn: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimportLeaveOneOut34X = np.array([[1,2], [3,4], [5,6]])5y = np.array([1,2,3])6loo = LeaveOneOut()78fortrain_index, test_indexinloo.split(X):9print(\"TRAIN:\", train_index,\"TEST:\", test_index)10X_train, X_test = X[train_index], X[test_index]11y_train, y_test = y[train_index], y[test_index]12'''13result:14TRAIN: [1 2] TEST: [0]15TRAIN: [0 2] TEST: [1]16TRAIN: [0 1] TEST: [2]17''' Этот метод может понадобиться в случае, если у вас очень мало данных, — например, в задаче сегментации клеток на изображениях с оптического микроскопа, — и вы хотите использовать максимальное их количество для обучения модели. Для валидации на каждой итерации методу требуется всего один семпл, однако и итераций будет столько, сколько семплов в данных, поэтому метод неприменим для средних и больших задач. Методstratified k-Fold— это метод k-Fold, использующий стратификацию при разбиении на фолды: каждый фолд содержит примерно такое же соотношение классов, как и всё исходное множество. Такой подход может потребоваться в случае, например, очень несбалансированного соотношения классов, когда при обычном random split некоторые фолды могут либо вообще не содержать семплов каких-то классов, либо содержать их слишком мало. Этот метод также представлен в sklearn: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimportStratifiedKFold34X = np.array([[1,2], [3,4], [1,2], [3,4]])5y = np.array([0,0,1,1])6skf = StratifiedKFold(n_splits=2)78fortrain_index, test_indexinskf.split(X, y):9print(\"TRAIN:\", train_index,\"TEST:\", test_index)10X_train, X_test = X[train_index], X[test_index]11y_train, y_test = y[train_index], y[test_index]12'''13result:14TRAIN: [1 3] TEST: [0 2]15TRAIN: [0 2] TEST: [1 3]16''' Существует такая задача, как прогнозирование временных рядов. На практике она часто возникает в форме «Что будет с показателями нашего продукта в ближайший день / месяц / год?». При этом имеются какие-то исторические данные этих показателей за предыдущее время, которые можно визуализировать в виде некоторого графика по времени: Этот график — пример графика временного ряда, и наша задача — спрогнозировать, как будет выглядеть данный график в будущие моменты времени. Кросс-валидация моделей для такой задачи осложняется тем, что данные не должны пересекаться по времени: тренировочные данные должны идти до валидационных, а валидационные — до тестовых. С учётом этих особенностей фолды в кросс-валидации для временных рядов располагаются вдоль временной оси так, как показано на следующей картинке: В sklearn реализована такая схема кросс-валидации: Скопировать код1importnumpyasnp2fromsklearn.model_selectionimportTimeSeriesSplit3X = np.array([[1,2], [3,4], [1,2], [3,4], [1,2], [3,4]])4y = np.array([1,2,3,4,5,6])5tscv = TimeSeriesSplit()6print(tscv)78fortrain_index, test_indexintscv.split(X):9print(\"TRAIN:\", train_index,\"TEST:\", test_index)10X_train, X_test = X[train_index], X[test_index]11y_train, y_test = y[train_index], y[test_index]1213'''14result:15TRAIN: [0] TEST: [1]16TRAIN: [0 1] TEST: [2]17TRAIN: [0 1 2] TEST: [3]18TRAIN: [0 1 2 3] TEST: [4]19TRAIN: [0 1 2 3 4] TEST: [5]20'''",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Кросс-валидация",
    "url": "https://education.yandex.ru/handbook/ml/article/kross-validaciya",
    "section_title": "Когда стоит заподозрить, что оценка качества модели завышена?",
    "text": "Ваша модель показала очень высокое качество на тестовых данных, вы радостно откидываетесь на спинку кресла и достаёте шампанское... Или пока рано? Перед тем как информировать коллег о своих высоких результатах, проверьте, что вы не допустили какую-то из следующих ошибок: ваши данные не были перемешаны (вспоминаем пример выше с тензорбордом курильщика); вы подбирали гиперпараметры на тестовом множестве и на нём же оценивали качество модели; у вас в данных есть фича, которая в некотором смысле является «прокси» к таргету (proxy for the target). Это такая фича, которая почти равна таргету, хотя формально им не является и так же, как и таргет, не будет доступна на момент реального применения модели; вы проводили feature engineering на всём датасете, а не только на трейне. Например, вы строилиtf-idfфичи илиbag-of-wordsна всех данных, а не только на трейне, тем самым заложив в свои тренировочные данные информацию о тестовых данных; вы применялистандартизациюданных на всём датасете, а не только на трейне. Например, в случаеStandardScalerтестовое множество повлияет на используемые этим методом оценки среднего и стандартного отклонения; вы смешали трейн с тестом. Последний пункт может звучать очень банально, но на практике часто оказывается, что правильно разделить данные на тренировочные и тестовые не так просто даже с учётом всех описанных выше техник. Об этом в следующих разделах. Ваши данные зависят от времени, а вы при разбиении на трейн и тест это не учли. Например, вы применили обычный random split при работе с временными рядами, передав тем самым вашей модели информацию из будущего. Или вы предсказываете погоду на несколько часов вперёд, а у вас данные из одного и того же дня находятся и в трейне, и в тесте. У вас есть датасет с картинками, и вы решили увеличить количество семплов в нём с помощьюаугментаций(примерами аугментаций могут служить симметричные отражения, повороты, растяжения). При этом вы взяли весь датасет, применили к нему аугментации и только после этого разделили на трейн и тест. В таком случае преобразования какой-то одной картинки могут попасть в оба множества, и вы получите пересечение трейна и теста. Вы решаете задачу рекомендации статей или постов пользователям на основании их комментариев и прочтений, при этом в трейне и тесте у вас одни и те же пользователи. Вы решаете какую-то задачу, где происходит работа с видеоданными. Например, распознаёте движение по видео или предсказываете фамилию актёра, попавшего в кадр. При этом в трейн и тест у вас попадают различные кадры из одного и того же видео. У вас есть спутниковые снимки, и вы хотите по ним предсказывать рельеф местности. При этом у вас в трейне и тесте есть кропы снимков над одними и теми же географическими координатами (хоть и в разное время). Вы обучаете голосового ассистента в звуковом потоке распознавать момент, когда к нему обращаются (например, «Слушай, Алиса», «Ok, Google»). При этом у вас в трейне и тесте одни и те же люди. Это, на первый взгляд, не очень страшная проблема, но на самом деле достаточно большая нейронка может запомнить интонации и манеру речи конкретного человека и будет использовать эти сведения для тестовых записей с этим человеком. При этом на новых людях распознавание будет работать сильно хуже. Вы хотите расширить тренировочный датасет какими-то дополнительными данными из другого датасета, но при этом оказывается, что другой датасет содержит в себе часть тестового множества вашего исходного датасета. Например, есть два публичных датасета:ImageNet LSVRC 2015, в котором 1000 классов и чуть больше миллиона изображений, иImageNet, в котором 21 тысяча классов и чуть больше 14 миллионов изображений. При этом первый полностью содержится во втором, поэтому использование ImageNet для расширения обучающей выборки из ImageNet LSVRC 2015 может закончиться тем, что в трейне окажутся примеры из тестового множества, сформированного из ImageNet LSVRC 2015. Пример заимствованотсюда. Допустим, что вы должны обучить модель, предсказывающую тему новостной статьи по её тексту. Если отсортировать статьи по дате их публикации, то ваши данные могут выглядеть, например, так: Здесь форма и цвет фигуры соответствуют новости, которой посвящена статья. Почему случайное разбиение данных на трейн и тест может привести к проблемам в этой задаче? На самом деле новостные статьи с одной и той же тематикой появляются кластерами во времени, так как статьи о новом событии выходят, как правило, порциями в то же время, когда произошло событие. Если разбить данные случайно, то тренировочное и тестовое множества с большой вероятностью будут содержать статьи на одни и те же наборы тем: Такое разбиение не соответствует тому, как потом модель будет применяться в реальной задаче: при нём модель будет ожидать равномерного распределения тем, предложенных ей в трейне, тогда как в реальности ей на вход будут приходить всё те же кластеры, и они, вообще говоря, не обязаны были быть в её тренировочном множестве. Простым решением будет при разбиении на трейн и тест учитывать время, когда была опубликована статья: Тут нужно, однако, учитывать, что в реальности кластеры историй по времени выражены не столь чётко и могут пересекаться. Поэтому если трейн и тест расположены слишком близко друг от друга по времени, то они могут пересечься. В принципе, это не так плохо с учётом того, что новости о каких-то событиях могут продолжать выходить в течение некоторого растянутого промежутка времени. Но если хочется избежать такой ситуации, то можно оставить между трейном и тестом некоторый временной зазор: тренироваться, например, на апрельских публикациях, а тестироваться на второй неделе мая, оставив, таким образом, недельный промежуток между двумя множествами.",
    "source_type": null,
    "useful_links": [
      {
        "text": "tf-idf",
        "url": "https://ru.wikipedia.org/wiki/TF-IDF"
      },
      {
        "text": "bag-of-words",
        "url": "https://en.wikipedia.org/wiki/Bag-of-words_model"
      },
      {
        "text": "стандартизацию",
        "url": "https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing"
      },
      {
        "text": "StandardScaler",
        "url": "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
      },
      {
        "text": "аугментаций",
        "url": "https://www.tensorflow.org/tutorials/images/data_augmentation?hl=en"
      },
      {
        "text": "ImageNet LSVRC 2015",
        "url": "https://academictorrents.com/collection/imagenet-lsvrc-2015"
      },
      {
        "text": "ImageNet",
        "url": "http://image-net.org/"
      },
      {
        "text": "отсюда",
        "url": "https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/example"
      }
    ]
  },
  {
    "document_title": "Кросс-валидация",
    "url": "https://education.yandex.ru/handbook/ml/article/kross-validaciya",
    "section_title": "Почитать по теме",
    "text": "Оригинальный текстописанного выше примера. Ещё один классный пример, когда случайное разбиение данных может испортить ML-модель. Отличный блог-постот Neptune про различные методы кросс-валидации. Раздел нашего учебника, посвящённый сравнению и оценке качества моделей. Большая статья-обзорпро методы сравнения моделей и оценки их качества. Секция Model Selectionот sklearn. Блог-постпро различные «умные» способы получить завышенные оценки качества моделей. Отличныйгайдо том, как читать графики обучающих кривых в разных случаях. Статья про временные рядыиз курса «Открытый курс машинного обучения» от ODS Библиотека Prophet от Facebookдля прогнозирования временных рядов, у которой есть свояимплементация кросс-валидациис дополнительными фичами (таблицы с результатами кросс-валидации, красивые графики). Здесьможно почитать статью с теоретическим обоснованием метода Prophet. Отличное видео про лики в данныхот DataRobot. Блог-постна эту же тему от них же. Статьяпро методики разбиения данных в рекомендательных системах.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Оригинальный текст",
        "url": "https://developers.google.com/machine-learning/data-prep/construct/sampling-splitting/example"
      },
      {
        "text": "Ещё один классный пример",
        "url": "https://developers.google.com/machine-learning/crash-course/18th-century-literature"
      },
      {
        "text": "Отличный блог-пост",
        "url": "https://neptune.ai/blog/cross-validation-in-machine-learning-how-to-do-it-right"
      },
      {
        "text": "Раздел нашего учебника",
        "url": "https://academy.yandex.ru/handbook/ml/article/metriki-klassifikacii-i-regressii"
      },
      {
        "text": "Большая статья-обзор",
        "url": "https://arxiv.org/pdf/1811.12808.pdf"
      },
      {
        "text": "Секция Model Selection",
        "url": "https://scikit-learn.org/stable/model_selection.html"
      },
      {
        "text": "Блог-пост",
        "url": "https://hunch.net/?p=22"
      },
      {
        "text": "гайд",
        "url": "https://www.ritchieng.com/applying-machine-learning/#2c-learning-curves"
      },
      {
        "text": "Статья про временные ряды",
        "url": "https://habr.com/ru/company/ods/blog/327242/"
      },
      {
        "text": "Библиотека Prophet от Facebook",
        "url": "https://facebook.github.io/prophet/docs/quick_start.html##python-api"
      },
      {
        "text": "имплементация кросс-валидации",
        "url": "https://facebook.github.io/prophet/docs/diagnostics.html"
      },
      {
        "text": "Здесь",
        "url": "https://facebook.github.io/prophet/"
      },
      {
        "text": "Отличное видео про лики в данных",
        "url": "https://community.datarobot.com/t5/sessions/data-cheats-how-target-leakage-affects-models/ba-p/8220"
      },
      {
        "text": "Блог-пост",
        "url": "https://community.datarobot.com/t5/blog/what-is-target-leakage-and-how-do-i-avoid-it/ba-p/1973"
      },
      {
        "text": "Статья",
        "url": "https://arxiv.org/pdf/2007.13237.pdf"
      }
    ]
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Модель скользящего среднего MA()",
    "text": "Модель скользящего среднего порядкаили просто MA() предполагает следующую зависимость данных: где— стационарный ряд со средним, а— гауссовский белый шум, то естьи независимы. По сути наш рядвыражается через сумму некоторого фиксированного среднего, значения белого шума в текущий момент времении не болеепредыдущих значений белого шума, домноженных на некоторые коэффициенты, которые являются параметрами модели. Рассмотрим некоторые свойства модели MA(). Как уже было упомянуто выше, рядбудет являтьcя стационарным со средним. Найдем также. Воспользовавшись свойством независимости для, можем заключить, что Посчитаем автоковариационную функцию для ряда, то есть найдем значение. Легко понять, что если, то= 0, т.к.независимы. Если же, то тогда Записав более компактно, можем получить: где. Из посчитанных значений для дисперсии и ковариационной функции, можете попробовать получить выражение и для автокорреляционной функции. Ее особенностью будет как раз равенство нулю на лаге, превосходящим. Посмотрим на визуализацию:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Модель авторегрессии AR()",
    "text": "Модель авторегрессии для временного ряда можно записать следующим образом: где— стационарный ряд, а— гауссовский белый шум, то естьи независимы. Отметим, что, вообще говоря, для стационарности нужны некоторые условия на коэффициенты. По сути наш рядвыражается через сумму некоторого фиксированного числа, значения белого шума в текущий момент времении не болеепредыдущих значений этого же ряда, домноженных на некоторые коэффициенты, которые являются параметрами модели. Другими словами, модель AR() — это модельдля которой Таргет:— значение ряда в момент времени Признаки:— значения ряда в предыдущие моменты времени Введем— оператор сдвига, обладающий следующими свойствами: применениек ряду дает предыдущее значение этого же ряда: применениек белому шуму дает предыдущее значение шума: применениек константе — это константа: Операториногда называют такжелаговымоператором. Можно рассматривать функции от оператора сдвига, например, кратное применение оператора:или. Для записей некоторых моделей временных рядов будет удобно использовать лаговый многочлен: Обратным к операторуназывают оператортакой, что: Так, например, дляможно заключить, что: Рассмотрим модель AR(): С помощью оператора сдвига ее можно представить в следующем виде: где— характеристический полином. Сформулируем пару важных утверждений: Любой стационарный (в широком смысле) процесс представим в виде, то есть в виде модели скользящего среднего с неограниченным количеством слагаемых (конечное или бесконечное число). Этот результат так же известен кактеорема Волдао декомпозиции временного ряда. Модельзадает стационарный временной рядвсе комплексные корнилежат вне единичного круга. Приведем пояснение второго утверждения. В самом деле, пусть— все его комплексные корни (их ровнос учетом кратности), тогда справедливо представление: Тогда при представлении временного ряда в виде и дальнейшего его разложения на простые дроби возникнут слагаемые вида Если при этомлежит внутри единичного круга или на его границе, то соответствующий ряд будет расходящимся. На самом деле, случаймы в дальнейшем учтем. В качестве примера рассмотрим подробнее модель.Зависимость имеет вид, где. Для данного ряда можно выписать следующие свойства: Уравнение, имеет корень. Тем самым,стационарен. Кроме того, чем меньше, тем предыдущее значение ряда вносит меньший вклад в текущее значение. Если ряд стационарен, то:. . Разберем первое равенство, остальные получаются аналогично. Возьмем математическое ожидание в уравнении ряда Поскольку ряд стационарен, то его математическое ожидание не меняется во времени, а для белого шума математическое ожидание равно нулю. Тем самым мы получаем уравнение на, откуда следует доказываемая формула. Таким образом, в зависимости от значениямы можем получить следующие результаты: Если, то— представление ряда в виде MA(). Если, то— это случайное блуждание. Если, то— экспоненциально растущий процесс. Посмотрим на визуализацию. В первом случае мы имеем модель, отрицательный коэффициент является следствием больших колебаний ряда. Во втором случае модель, большой положительный коэффициент делает ряд менее шумным. В третьем случае показано несколько рядов вида случайного блуждания, что соответствует случаю. В четвертом случае показан экспоненциальный процесс, на графике шум уже не заметен из-за масштаба. На немного вернемся к модели MA(). Чуть выше мы выяснили, что при некоторых условиях на коэффицентывременной ряд модели AR() будет стационарным, а значит имеет представление в виде MA(). На самом деле, модель скользящего среднего порядкатоже можно представить с помощью оператораследующим образом: где—характеристический многочлен. Для простоты изложения пусть. Важным при такой записи оказывается понятие обратимости, то есть представления в виде которое означает, что ряд можно представить в виде бесконечной авторегрессионной модели.Здесь, как и в рассуждениях выше, можно заключить, что временной рядобратим, если все комплексные корнилежат вне единичного круга.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Модель ARMA()",
    "text": "Модель ARMA() по сути является суммой моделейи, иначе говоря, модель есть сумма нескольких предыдущих значений ряда и нескольких предыдущих значений белого шума с некоторым коэффициентами. Эквивалентную запись ряда в терминах оператора сдвига можно получить, рассмотрев два многочлена или гдеи.Заметим, что во втором представлении константазаменена на. На самом деле, стационарность такого ряда будет определяться только его AR() компонентой, то есть значениями коэффициентов, так ряд в модели MA() всегда является стационарным.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Модель ARIMA()",
    "text": "Модель ARIMA() — это расширение моделей типа ARMA на нестационарные временные ряды, которые однако могут стать стационарным после применениея процедуры дифференцирования ряда. Модель ARIMA() для рядаопределяется как модель ARMA() для ряда разностей порядкаряда. Разность порядка 1:. Разность порядка 2:. Получаем формулу модели ARIMA: или То есть многочленимеетединичных корней.Тем самым такая модель позволяет учесть нестационарности, в частности, тренд. В качестве примера рассмотрим процесс случайного блуждания: где— белый шум. Как уже упомяналось ранее, такой ряд не является стационарным. Однако, если мы применим операцию дифференцирования, то можем перейти к новому, уже стационарном ряду, который можно записать в виде:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Частичная автокорреляция",
    "text": "Для модели скользящего среднего порядкамы выяснили, что значения автокорреляционной функции для такого ряда оказывается равной нулю после лага. Эта особенность позволяет использовать автокорреляционную функцию для определения порядка модели скользящего среднего. Возникает разумный вопрос, как оценить порядокдля модели AR()? Здесь оказывается полезным понятие частичной (частной) автокорреляционной функции. Частичная автокорреляция (PACF)— корреляция ряда с собой после снятия линеной зависимости от промежуточных значений ряда. Иначе говоря, мы хотим как-то учесть опосредованного влияние промежуточных значений ряда и оценить непосредственное влияниена. Чуть более формально частичную автокорреляцию можно записать следующим образом: где— линейная регрессия на: Пример для: где— МНК-оценка в модели. Можно показать, что значение частиной автокорреляции для модели авторегресии AR() будет ненулевой для лагови равняться нулю для лагов. Имеет место быть полная аналогия с автокорреляционной функцией и моделью MA(). Таким образом, исследование поведения автокорреляционной и частичной автокорреляционной функции может быть использовано для определения порядкамодели скользящего среднего и порядкамодели авторегрессии соответсвтенно.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Оценка коэффициентов в ARIMA",
    "text": "Пусть гиперпараметрыфиксированы.&tab;В предположении, что— гауссовский белый шум, в нашей модели мы можем выписать функцию правдоподобиягде— соместная плотность. Из-за того, чтоимеют нормальное распределение, она будет иметь разумный вид. Соответственно, в качестве оценок параметров берется оценка максимального правдоподобия. Для поиска начальных приближение для параметровивоспользуемся автокорреляционной и частичной автокорреляционной функцией. Начальное приближение: последний значимый пик у PACF. Начальное приближение: последний значимый пик у ACF. Далее обычно используется поиск по сетке вокруг подобранных значений, минимизируя информационный критерий: — критерий Акаике; — критерий Акаике (короткие ряды); — Байесовский информационный критерий или критерий Шварца, где— логарифм функции правдоподобия,— длина временного ряда. Приведем некоторый план при применению модели ARIMA для прогнозирования временных рядов. Анализ выбросов: замена нерелевантых выбросов наNAили усреднение по соседним элементам. Стабилизация дисперсии (преобразования). Дифференцирование, если ряд не стационарен. Выбор пилотныхипо PACF и ACF. Вокруг этих параметров подбираем оптим. модель по/. Пошаговое построение прогноза:— для:;— для:;— для:. Построение предсказательного интервала:— если остатки модели нормальны и гомоскедастичны (дисперсия постоянна), то строится теоретический предсказательный интервалгде— горизонт прогнозирования,— оценка на дисперсию шума,— коэф. для ряда при его представлении в виде бесконечного процесса скользящего среднего. И, имогут быть выражены через оценки на параметрыи.— иначе интервалы строятся с помощью бутстрепа.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели вида ARIMA",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-vida-arima",
    "section_title": "Модели SARIMA и ARIMAX",
    "text": "Рассмотрим некоторые расширение модели ARIMA. Обобщение модели ARIMA на ряды с наличием сезонной составляющей назвается SARIMA. Пусть— известная сезонность ряда. Добавим в модель ARIMA() компоненты, отвечающие за значения в предыдущие сезоны. Тогда модель SARIMAможет быть записана следующим образом: где Параметр сезонного дифференцирования, а также параметрыподбираются из тех же соображений, что и для, но только с поправкой, что делается это с учетом сезонности. ARIMAX — обобщение модели ARIMA, которая учитывает некоторые экзогенные факторы. Пусть— ряд регрессоров,известный до начала прогноза. Простой вариант: Общий случай: Пример: Вышеуказанные модели можно объединить и получить SARIMAX: Проведем аналогию с линейной регрессией. Это линейная по признакам модель, в которой Отклик:— значение ряда в моменты времени Признаки:— значения ряда в предыдущие моменты времениЗначение ряда за предыдущие сезоныЗначения признаков в предыдущие моменты времениЗначения признаков в предыдущие сезоны — значения ряда в предыдущие моменты времени Значение ряда за предыдущие сезоны Значения признаков в предыдущие моменты времени Значения признаков в предыдущие сезоны Ошибка:сумма шума за предыдущие моменты времени и предыдущие сезоны.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Априорное знание",
    "text": "Начнём с простого вопроса: как нам внести в модель априорные знания. Представьте, что мы обучаем модель линейной регрессии,. С помощью MLE мы получили некоторую оценкуна веса— всякие ли их значения мы встретим с покорностью и смирением? Наверное, мы удивимся, если какие-то компоненты векторабудут очень большими по сравнению с элементами: пожалуй, наша физическая интуиция будет бунтовать против этого, мы задумаемся о том, что из-за потенциальных ошибок сокращения вычисление предсказанийокажутся неточным — в общем, хотелось бы по возможности избежать этого. Но как? Будь мы приверженцами чисто инженерного подхода, мы бы сделали просто: прибавили бы к функции потерь слагаемое, или, или ещё что-то такое — тогда процедура обучения стала бы компромиссом между минимизацией исходного лосса и этой добавки, что попортило бы слегка близость, но зато позволило бы лучше контролировать масштаб. Надо думать, вы узнали в этой конструкции старую добрую регуляризацию. Но наша цель — зашить наше априорное знание о том, что компонентыне слишком велики по модулю, в вероятностную модель. Введение в модель априорного знания соответствует введению априорного распределения на. Какое распределение выбрать? Ну, наверное, компонентыбудут независимыми (ещё нам не хватало задавать взаимосвязи между ними!), а каждая из них будет иметь какое-то непрерывное распределение, в котором небольшие по модулю значения более правдоподобны, а совсем большие очень неправдоподобны. Мы знаем такие распределения? Да, и сразу несколько. Например, нормальное. Логично было бы определить где— какая-то дисперсия, которую мы возьмём с потолка или подберём по валидационной выборке. Отметим, что выбор нормального распределение следует и из принципа максимальной энтропии: ведь у него наибольшая энтропия среди распределений на всей числовой оси с нулевым матожиданием и дисперсией. Контроль масштаба весов — это, вообще говоря, не единственное, что мы можем потребовать. Например, мы можем из каких-то физических соображений знать, что тот или иной вес в линейной модели непременно должен быть неотрицательным. Тогда в качестве априорного на этот вес мы можем взять, например, показательное распределение (которое, напомним, обладает максимальной энтропией среди распределений на положительных числах с данным матожиданием).",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Оцениваем не значение параметра, а его распределение",
    "text": "Раз уж мы начали говорить о распределении на веса, то почему бы не пойти дальше. Решая задачу классификации, мы уже столкнулись с тем, что может быть важна не только предсказанная метка класса, но и вероятности. Аналогичное верно и для задачи регрессии. Давайте рассмотрим две следующих ситуации, в каждой из которых мы пытаемся построить регрессию: Несмотря на то, что в каждом из случаев «точная формула» или градиентный спуск выдадут нам что-то, степень нашей уверенности в ответе совершенно различная. Один из способов выразить (не)уверенность — оценить распределение параметров. Так, для примеров выше распределения на параметрмогли бы иметь какой-то такой вид: Дальше мы постараемся формализовать процесс получения таких оценок.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Построение апостериорного распределения",
    "text": "Давайте ненадолго забудем про линейную регрессию и представим, что мы подобрали с пола монету, которая выпадает орлом с некоторой неизвестной пока вероятностью. До тех пор, пока мы не начали её подкидывать, мы совершенно ничего не знаем о, эта вероятность может быть совершенно любой — то есть априорное распределение наявляется равномерным (на отрезке): Теперь представим, что мы подкинули еёраз, получив результаты(— решка,— орёл), среди которыхрешек иорлов. Определённо наши познания о числестали точнее: так, еслимало, то можно заподозрить, что иневелико (уже чувствуете, запахло распределением!). Распределение мы посчитаем с помощью формулы Байеса: в нашем случае: В этом выражении нетрудно узнать бета-распределение:. Давайте нарисует графики его плотности для нескольких конкретных значенийи: Как можно заметить, с ростоммы всё лучше понимаем, каким может быть, при этом если орёл выпадал редко, то пик оказывается ближе к нулю, и наоборот. Ширина пика в каком-то смысле отражает нашу уверенность в том, какими могут быть значения параметра, и не случайно чем больше у нас данных — тем уже будет пик, то есть тем больше уверенности. Распределениепараметра, полученное с учётом данных, называетсяапостериорным. Переход от априорного распределения к апостериорному отражает обновление нашего представления о параметрах распределения с учётом полученной информации, и этот процесс является сердцем байесовского подхода. Отметим, что если нам придут новые данные, в которыхрешек иорлов, мы сможем ещё раз обновить распределение по той же формуле Байеса: Вопрос на подумать. Пусть— нормальное распределение с фиксированной дисперсией, а для параметрав качестве априорного выбрано также нормальное распределение. Каким будет апостериорное распределение при условии данных?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Сопряжённые распределения",
    "text": "В двух предыдущих примерах нам очень сильно повезло, что апостериорные распределения оказались нашими добрыми знакомыми. Если же взять случайную пару распределенийи, результат может оказаться совсем не таким приятным. В самом деле, нет никакой проблемы в том, чтобы посчитать числитель формулы Байеса, но вот интеграл в знаменателе может и не найтись. Поэтому выбирать распределения нужно с умом. Более того, поскольку апостериорное распределение само станет априорным, когда придут новые данные, хочется, чтобы априорное и апостериорное распределения были из одного семейства; пары (семейств) распределенийи, для которых это выполняется, называютсясопряжённыминазываетсясопряжённымк. Полезно помнить несколько наиболее распространённых пар сопряжённых распределений: — распределение Бернулли с вероятностью успеха,— бета распределение; — нормальное с матожиданиеми фиксированной дисперсией,также нормальное; — показательное с параметром,— гамма распределение; — пуассоновское с параметром,— гамма распределение; — равномерное на отрезке,— Парето; Возможно, вы заметили, что почти все указанные выше семейства распределений (кроме равномерного и Парето) относятся к экспоненциальному классу. И это не случайность! Экспоненциальный класс и тут лучше всех: оказывается, что дляиз экспоненциального класса можно легко подобрать сопряжённое. Давайте же это сделаем. Пустьимеет вид Положим где— множитель, обеспечивающий равенство единице интеграла от этой функции. Найдём апостериорное распределение: Это распределение действительно из того же семейства, что и, только с новыми параметрами: Пример. Пустьподчиняется распределению Бернулли. Напомним, что оно следующим образом представляется в привычном для экспоненциального класса виде: Предлагается брать априорное распределение вида Тогда апостериорное распределение будет иметь вид (проверьте, посчитав по формуле Байеса!) Превратив логарифм частного в сумму, а экспоненту суммы в произведение, легко убедиться, что получается то самое бета распределение, которое мы уже получали выше.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Оценка апостериорного максимума (MAP)",
    "text": "Апостериорное распределение — это очень тонкий инструмент анализа данных, но иногда надо просто сказать число (или же интеграл в знаменателе не берётся и мы не можем толком посчитать распределение). В качестве точечной оценки логично выдать самое вероятное значение(интеграл в знаменателе отне зависит, поэтому на максимизацию не влияет): Это число называетсяоценкой апостериорного максимума (MAP). Если же в формуле выше перейти к логарифмам, то мы получим кое-что, до боли напоминающее старую добрую регуляризацию (и не просто так, как мы вскоре убедимся!): Пример. Рассмотрим снова распределение Бернуллии априорное распределение. Тогда MAP-оценка будет равна Дифференцируя пои приравнивая производную к нулю, мы получаем В отличие от оценки максимального правдоподобиямы здесь используем априорное знание: параметрыиработают как «память о воображаемых испытаниях», как будто бы до того, как получить данные, мы уже имелиуспехов инеудач.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Связь MAP- и MLE-оценок",
    "text": "Оценка максимального правдоподобия является частным случаем апостериорной оценки. В самом деле, если априорное распределение является равномерным, то естьне зависит(если весавещественные, могут потребоваться дополнительные усилия, чтобы понять, как такое вообще получается), и тогда",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Байесовские оценки для условных распределений",
    "text": "В предыдущих разделах мы разобрали, как байесовский подход работает для обычных, не условных распределений. Теперь вернёмся к чему-то более близкому к машинному обучению, а именно к распределениям вида, и убедимся, что для них байесовских подход работает точно так же, как и для обычных распределений. Имея некоторое распределение, мы подбираем для него априорное распределение на веса(и да, оно не зависит от: ведь априорное распределение существует ещё до появления данных) и вычисляем апостериорное распределение на веса: Вычислять его мы будем по уже привычной формуле Байеса: Повторим ещё разок, в чём суть байесовского подхода: у нас было некоторое априорное представлениео распределении весов, а теперь, посмотрев на данные, мы уточняем своё понимание, формулируя апостериорное представление. Если же нам нужна только точечная оценка, мы можем ограничиться оценкой апостериорного максимума (MAP): что уже до неприличия напоминает регуляризованную модель",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Пример: линейная регрессия с-регуляризацией как модель с гауссовским априорным распределением на веса",
    "text": "В модели линейной регрессии,введём априорное распределение на веса вида Тогда— точка минимума следующего выражения: Получается, что а это же функция потерь для линейной регрессии с-регуляризацией! Напомним на всякий случай, что у этой задачи есть «точное» решение Для этого примера мы можем вычислить и апостериорное распределение. В самом деле, из написанного выше мы можем заключить, что Таким образом,— это квадратичная функция от, откуда следует, что апостериорное распределение является нормальным. Чтобы найти его параметры, нужно немного преобразовать полученное выражение: Таким образом, Как видим, от априорного распределения оно отличается корректировкой как матожидания, так и ковариационной матрицы. Отметим, что— это, с точностью до численного множителя, оценка ковариационной матрицы признаков нашего датасета (элементы матрицы— это скалярные произведения столбцов, то есть столбцов значений признаков). Иллюстрация. Давайте на простом примере (датасет с двумя признаками) посмотрим, как меняется апостериорное распределениес ростом размера обучающей выборки: Как видим, не только мода распределения, то естьприближается к своему истинному значению, но и дисперсия распределения постепенно уменьшается. Ещё иллюстрация. Теперь рассмотрим задачу аппроксимации неизвестной функции одной переменной (чьи значения в обучающей выборке искажены нормальным шумом) многочленом третьей степени. Её, разумеется, тоже можно решать, как задачу линейной регрессии на коэффициенты многочлена. Давайте нарисуем, как будут выглядеть функции, сгенерированные из распределениядля разного объёма обучающей выборки: Тут тоже видим, что функции не только становятся ближе к истинной, но и разброс их уменьшается.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Пример: линейная регрессия с-регуляризацией как модель с лапласовским априорным распределением на веса",
    "text": "Другое распределение, которое тоже может кодировать наше желание, чтобы небольшие по модулю значениябыли правдоподобными, а большие не очень, — распределение Лапласа. Посмотрим, что будет, если его взять в качестве априорного распределения на веса. Проводя такое же вычисление, получаем, что а это же функция потерь для линейной регрессии с-регуляризацией!",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Как делать предсказания",
    "text": "Все изложенные выше рассуждения проводились в ситуации, когда— обучающая выборка. Для неё мы можем посчитать и точечную апостериорную оценку. А теперь пусть нам дан новый объект. Какой таргетмы для него предскажем? Было бы естественным, раз уж мы предсказываем распределение для, и длятоже предсказывать распределение. Делается это следующим образом: Надо признать, что вычисление этого интеграла не всегда посильная задача, поэтому зачастую приходится «просто подставлять». В вероятностных терминах это можно описать так: вместо сложного апостериорного распределениямы берём самое грубое на свете приближение где— дельта-функция, которая не является честной функцией (а является тем, что математики называют обобщёнными функциями), которая определяется тем свойством, чтодля достаточно разумных функций. Если не мудрствовать лукаво, то это всё значит, что Пример. Пусть,— модель линейной регрессии с априорным распределениемна параметры. Тогда, как мы уже видели раньше, Попробуем для новой точкипосчитать распределение на. Рекомендуем читателю попробовать самостоятельно посчитать интеграл или же обратиться к пункту 7.6.2 книжки «Machine Learning A Probabilistic Perspective» автора Kevin P. Murphy, убедившись, что что, очевидно, более содержательно, чем оценка, полученная с помощью приближения: Собственно, видно, что в этом случае Пример в примере. Рассмотрим полюбившуюся уже нам задачу приближения функции многочленом степени не выше(в которой мы строим модели с). Длямы получали такую картинку: Если оценить по приведённым выше формуламдля разных, то можно убедиться, что модель в большей степени уверена в предсказаниях для точек из областей, где было больше точек из обучающей выборки:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Байесовский подход и дообучение моделей",
    "text": "До сих пор мы в основном рассуждали о моделях машинного обучения как о чём-то, что один раз обучается и дальше навсегда застывает в таком виде, но в жизни такое скорее редкость. Мы пока не будем обсуждать изменчивость истинных зависимостей во времени, но даже если истина неизменна, к нам могут поступать новые данные, которые очень хотелось бы использовать для дообучения модели. Обычные, не байесовские вероятностные модели не предоставляют таких инструментов. Оценку максимального правдоподобия придётся пересчитывать заново (хотя, конечно, можно схитрить, использовав старое значение в качестве начального приближения при итеративной оптимизации). Байесовский же подход позволяет оформить дообучения в виде простой и элегантной формулы: при добавлении новых данныхимеем",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Байесовский подход к выбору модели: мотивация",
    "text": "Нам часто приходится выбирать: дерево или случайный лес, линейная модель или метод ближайших соседей; да, собственно, и внутри наших вероятностных моделей есть параметры (скажем, дисперсия шумаи), которые надо бы подбирать. Но как? В обычной ситуации мы выбираем модель, обученную на выборкев зависимости от того, как она себя ведёт на валидационной выборке(сравниваем правдоподобие или более сложные метрики) — или же делаем кросс-валидацию. Но как сравнивать модели, выдающие распределение? Ответим вопросом на вопрос: а как вообще сравнивать модели? Назначение любой модели — объяснять мир вокруг нас, и её качество определяется именно тем, насколько хорошо она справляется с этой задачей. Тестовая выборка — это хороший способ оценки, потому что она показывает, насколько вписываются в модель новые данные. Но могут быть и другие соображения, помогающие оценить качество модели. Аналитик Василий опоздал на работу. Своему руководителю он может предложить самые разные объяснения — и это будет выработанная на одном обучающем примере модель, описывающая причины опоздания и потенциально позволяющая руководителю принять решение о том, карать ли Василия. Конечно, руководитель мог бы принять изложенную Василием модель к сведению, подождать, пока появятся другие опоздавшие, и оценить её, так скажем, на тестовой выборке, но стоит ли? Давайте рассмотрим несколько конкретных примеров: Модель «Василий опоздал, потому что так получилось», то есть факт опоздания — это просто ни от чего не зависящая случайная величина. Такая модель плоха тем, что (а) не предлагает, на самом деле, никакого объяснения тому факту, что Василий опоздал, а его коллега Надежда не опоздала и (б) совершенно не помогает решить, наказывать ли за опоздание. Наверное, такое не удовлетворит руководителя. Модель «Василий опоздал, потому что рядом с его домом открылся портал в другой мир, где шла великая битва орков с эльфами, и он почувствовал, что просто обязан принять в ней участие на стороне орков, которых привёл к победе, завоевав руку и сердце орочьей принцессы, после чего был перенесён обратно в наш скучный мир завистливым шаманом». Чем же она плоха? Битва с эльфами — это, безусловно, важное и нужное дело, и на месте руководителя мы бы дружно согласились, что причина уважительная. Но заметим, что в рамках этой модели можно объяснить множество потенциальных исходов, среди которых довольно маловероятным представляется наблюдаемый: тот, в котором Василий не погиб в бою, не остался со своей принцессой и не был порабощён каким-нибудь завистливым шаманом. Отметим и другой недостаток этой модели: её невозможно провалидировать. Если в совершенно случайной модели можно оценить вероятность опоздания и впоследствии, когда накопятся ещё примеры, проверить, правильно ли мы её посчитали, то в мире, где открываются порталы и любой аналитик может завоевать сердце орочьей принцессы, возможно всё, и даже если больше никто не попадёт в такую ситуацию, Василий всё равно сможет бить себя в грудь кулаком и говорить, что он избранный. Так что, наверное, это тоже не очень хорошая модель. Модель «Василий опоздал, потому что проспал» достаточно проста, чтобы в неё поверить, и в то же время даёт руководителю возможность принять решение, что делать с Василием. Обратимся к примеру из машинного обучения. Сравним три модели линейной регрессии: Даже и не запрашивая тестовую выборку, мы можем сделать определённые выводы о качестве этих моделей. Средняя (квадратичная) явно лучше левой (линейной), потому что она лучше объясняет то, что мы видим: тот факт, что облако точек обучающей выборки выглядит вогнутым вниз. А что с правым, почему мы можем утверждать, что он хуже? Есть много причин критиковать его. Остановимся вот на какой. На средней картинке у нас приближение квадратичной функцией, а на правой — многочленом довольно большой степени (на самом деле, десятой). А ради интереса: как выглядит график квадратичной функции и как — многочлена десятой степени со случайно сгенерированными коэффициентами? Давайте сгенерируем несколько и отметим их значения в точках обучающей выборки: Обратите внимание на масштаб на графиках справа. И какова вероятность, что нам достался именно тот многочлен десятой степени, у которого значения в обучающих точках по модулю в пределах сотни? Очевидно, она очень мала. Поэтому мы можем сказать, что выбор в качестве модели многочлена десятой степени не очень обоснован. Слишком простая модель плохо объясняет наблюдаемые нами данные, тогда как слишком сложная делает это хорошо, но при этом описывает слишком многообразный мир, в котором имеющиеся у нас данные оказываются уже слишком частным случаем. В каком-то смысле наш способ выбора модели оказывается переформулировкойбритвы Оккама: из моделей, пристойно описывающих наблюдаемые явления, следует выбирать наиболее минималистичную.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Байесовский подход к выбору модели: формализация",
    "text": "Пусть у нас есть некоторое семейство моделейи для каждогозадана какая-то своя вероятностная модель. В духе байесовского подхода было бы оценить условное распределение моделей и в качестве наилучшей модели взять её моду. Если же считать все модели равновероятными, то мы сводим всё к максимизации только лишь: Величинаназываетсяобоснованностью(evidence, marginal likelihood) модели. Отметим, что такое определение вполне согласуется с мотивацией из предыдущего подраздела. Слишком простая модель плохо описывает наблюдаемые данные, и потому будет отвергнута. В свою очередь, слишком сложная модель способна описывать гораздо большее многообразие явлений, чем нам было бы достаточно. Таким образом, компромисс между качеством описания и сложностью и даёт нам оптимальную модель. Вернёмся к нашей любимой задаче аппроксимации функции одной переменной многочленом небольшой степени по нескольким точкам, значение в которых было искажено нормальным шумом. Построим несколько моделей, приближающих многочленом степени не выше некоторого(будет принимать значения 1, 3 и 6), положив в вероятностной модели. Мы не будем приводить полный вывод обоснованности для задачи регрессии, а сразу выпишем ответ: Посмотрим, какой будет обоснованность для разного числа обучающих точек: Можно убедиться, что для регрессии по двум точкам наиболее обоснованная — линейная модель (и неудивительно), тогда как с ростом числа точек более обоснованной становится модель с многочленом третьей степени; слишком сложная же модель шестой степени всегда плетётся в хвосте. Точно вычислить обоснованность может быть трудной задачей (попробуйте проделать это сами хотя бы для линейной регрессии!). Есть разные способы посчитать её приближённо; мы рассмотрим самый простой. Напомним, что Воспользуемсяприближением Лапласа, то есть разложим(как функцию от) вблизи своего максимума, то есть вблизив ряд Тейлора: где линейный член отсутствует, поскольку разложение делается в точке локального экстремума, а— знакомая нам матрица Фишера. Далее,мы можем с точностью до второго порядка приблизить. Получается, что Несмотря на то, чтои, сгруппированные нами во «всякие штуки», существенным образом зависят от модели, при большихони вносят в показатель гораздо меньше вклада, чем первые два слагаемых. Таким образом, мы можем себе позволить вместо трудновычисляемыхиспользовать для сравнения модели",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Байесовский подход к оцениванию",
    "url": "https://education.yandex.ru/handbook/ml/article/bajesovskij-podhod-k-ocenivaniyu",
    "section_title": "Фреквентисты против байесиан: кто кого?",
    "text": "Мы с вами познакомились с двумя парадигмами оценивания: фреквентистской(frequentist, от слова \"frequency\", частота) — в которой считается, что данные являются случайным (настоящая случайность!) семплом из некоторого фиксированного распределения, которое мы стараемся оценить по этому семплу, и байесовской— в которой данные считаются данностью и в которой мы используем данные для обновления наших априорных представлений о распределении параметров (здесь случайности нет, а есть лишь нехватка знания). У обеих есть свои достоинства и недостатки, поборники и гонители. К недостаткам байесовской относится, безусловно, её вычислительная сложность: возможно, вы помните, в пучину вычислений сколь мрачных нас низвергла банальная задача линейной регрессии, и дальше становится только ещё трудней. Если мы захотим байесовский подход применять к более сложным моделям, например, нейросетям, нам придётся прибегать к упрощениям, огрублениям, приближениям, что, разумеется, ухудшает наши оценки. Но, если простить ему эту вынужденную неточность, он логичнее и честней, и мы продемонстрируем это на следующем примере. Одно известное свойство оценки максимального правдоподобия —асимптотическая нормальность. Если оценивать наши весапо различным наборам изобучающих примеров, причём считать, что наборы выбираются случайно (не будем уточнять, как именно), то оценкатоже превращается в случайную величину, которая как-то распределена. Теория утверждает, что при где— истинное значение весов, а— матрица информации Фишера, которая определяется как что при некоторых не слишком обременительных ограничениях равно При этом поскольку, матрица тоже распадается в сумму, и получается, что, то есть с ростомковариацияоценки максимального правдоподобия стремится к нулю. На интуитивном уровне можно сказать, что матрица информации Фишера показывает, сколько информации о весахсодержится в. Поговорим о проблемах. В реальной ситуации мы не знаеми тем более не можем посчитать матрицу Фишера, то есть мы с самого начала вынуждены лукавить. Ясно, что вместоможно взять просто, а вместо— матрицу, которую можно даже при желании определить как безо всякого математического ожидания. Итак, хотя мы можем теперь построить доверительный интервал для оцениваемых параметров, по ходу нами было сделано много упрощений: мы предположили, что асимптотическая оценка распределения уже достигнута, отперешли к, а для полноты чувств ещё и избавились от математического ожидания. В байесовском подходе мы такого себе не позволяем.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Тонкости обучения",
    "url": "https://education.yandex.ru/handbook/ml/article/tonkosti-obucheniya",
    "section_title": "Инициализируем правильно",
    "text": "Как вы уже успели заметить, нейронные сети — достаточно сложные модели, чувствительные к изменениям архитектуры, гиперпараметров, распределения данных и другим вещам. Поэтому значительную роль играет начальная инициализация весов вашей сети. Стоит отметить, что здесь речь идет именно о начальной инициализации параметров сети, вопрос дообучения (и использования предобученных сетей в качестве backbone) в данном параграфе рассматриваться не будет. Нейронные сети включают в себя различные преобразования, и инициализация по-хорошему также должна зависеть от типа используемого преобразования. На практике вопрос часто остается без внимания, так как в большинстве современных фреймворков уже реализованы методы инициализации, зависящие от используемой функции активации и гиперпараметров слоя, и пользователь может не задумываться об этом. Но всё же важно понимать, какие соображения привели к появлению тех или иных стратегий инициализации. Давайте разберём несколько методов инициализации и обсудим их свойства. Казалось бы, инициализация параметров слоя нулями — это достаточно просто и лаконично. Но инициализация нулём (как и любой другой константой) ведёт к катастрофе! Вот пример того, что может получиться: Стоит, впрочем, отметить, что из-за численных ошибок значения параметров могут всё-таки сдвинуться с мёртвой точки, и тогда нейросеть что-нибудь выучит: Здесь также стоит привести цитату из замечательной Deep Learning book (страница 301): Скопировать код1Perhaps the only property known with complete certainty is that the initial parameters need to “break symmetry” between different units. If two hidden units with the same activation function are connected to the same inputs, then these units must have different initial parameters. If they have the same initial parameters, then a deterministic learning algorithm applied to a deterministic cost and model will constantly update both of these units in the same way. Если константная инициализация не подходит, можно инициализировать нейросеть случайными числами. Допустим, веса пришли из распределения с нулевым средним и дисперсией, например, из нормального распределения. Пусть теперь на вход линейному слою с весамиразмерностипришел вектораналогичной размерности. Замечание. Можем считать, что мы рассматриваем лишь одну компоненту следующего промежуточного представления. Все компонентыраспределены одинаковым образом и обладают нулевым средним. Тогда дисперсия ихпроизведенияимеет вид: Первое и второе слагаемые равны нулю так как математические ожидание и весов, и значенийравны нулю. Замечание. Стоит заметить, что это будет верно и для промежуточных слоев в случае использования симметричной относительно нуля функции активации, например,tanh. Поскольку все веса пришли из одного распределения, можно выразить дисперсию результата следующим образом: где— это дисперсия любой компоненты(как было оговорено ранее, они распределены одинаково), а— дисперсия компоненты. Следовательно, дисперсия результата линейно зависит от дисперсии входных данных с коэффициентом. Увеличение дисперсии промежуточных представлений с каждым новым преобразованием (слоем) может вызвать численные ошибки или насыщение функций активации (таких какtanhиsigmoid), что не лучшим образом скажется на обучении сети. Снижение дисперсии может привести к почти нулевым промежуточным представлениям (плюс «линейному» поведениюtanhиsigmoidв непосредственной близости от нуля), что тоже негативно повлияет на результаты обучения. Поэтому для начальной инициализации весов имеет смысл использовать распределение, дисперсия которого позволила бы сохранить дисперсию результата. Например,или же в общем случае Данный подход часто упоминается какcalibrated random numbers initialization. Если обратиться к предыдущему подходу, можно обнаружить, что все выкладки верны как для «прямого» прохода (forward propagation), так и для обратного (backward propagation). Дисперсия градиента при этом меняется враз, где— размерность следующего запромежуточного представления. И если мы хотим, чтобы сохранялись дисперсии и промежуточных представлений, и градиентов, у нас возникают сразу два ограничения: и Легко заметить, что оба этих ограничения могут быть выполнены только в случае, когда размерность пространства не меняется при отображении, что случается далеко не всегда. ВработеUnderstanding the difficulty of training deep feedforward neural networks за авторством Xavier Glorot и Yoshua Bengio в качестве компромисса предлагается использовать параметры из распределения с дисперсией Подробный вывод данного результата можно найти в оригинальной статье в формулах 2-12. Обратите внимание: эта инициализация хорошо подходит именно дляtanh, так как в выводе явно учитывается симметричность функции активации относительно нуля. В случае использования равномерного распределениядля инициализации весов с учетом описанных выше ограничений мы получимnormalized Xavier initialization: Замечание. Здесь используется тот факт, что дисперсия непрерывного равномерного распределения. Сравнение подобной инициализации для поведения промежуточных представлений (сверху) и градиентов (снизу) проиллюстрированы ниже (иллюстрации изоригинальной статьи): Вы могли обратить внимание, что Xavier initialization во многом опиралась на поведение функции активацииtanh. Данный тип инициализации и впрямь лучше подходит для нее, но само использование гиперболического тангенса приводит к некоторым сложностям (например, к затуханию градиентов). В 2015 году вработеDelving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification за авторством Kaiming He, Xiangyu Zhang, Shaoqing Ren и Jian Sun были рассмотрены особые свойства функции активацииReLU, в частности, существенно смещенная относительно нуля область значений. Пусть представление на входе было получено после применения данной функции активации к предыдущему представлению: где, в свою очередь, — это выход предыдущего линейного слоя с нулевым средним для каждой компоненты весов, то есть, в частности, В таком случае дисперсия выхода следующего линейного слоя примет вид: В данном случае первый член не может быть проигнорирован, так какReLUимеет ассиметричную область значений, а значит, распределениябудут смещёнными. С учетом того, что, выражение выше примет итоговый вид: С учётом поведенияReLUи того, что, можно сказать, что то есть Получается, что использованиеReLUприводит к необходимости инициализировать веса из распределения, чья дисперсия удовлетворяет следующему ограничению: Например, подходит нормальное распределение. Данный способ инициализации (и его сравнение с Xavier initialization) проиллюстрирован ниже: Рассмотренные способы инициализации используют достаточно много предположений, но все-таки они работают и позволяют нейронным сетям в некоторых случаях значительно быстрее сходиться. Понимание принципов работы даже таких небольших механизмов – ключ к глубокому освоению области глубокого обучения 😃",
    "source_type": null,
    "useful_links": [
      {
        "text": "произведения",
        "url": "https://href.li/?http://en.wikipedia.org/wiki/Variance#Product_of_independent_variables"
      },
      {
        "text": "работе",
        "url": "https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf"
      },
      {
        "text": "оригинальной статьи",
        "url": "https://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf"
      },
      {
        "text": "работе",
        "url": "https://arxiv.org/abs/1502.01852v1"
      }
    ]
  },
  {
    "document_title": "Тонкости обучения",
    "url": "https://education.yandex.ru/handbook/ml/article/tonkosti-obucheniya",
    "section_title": "Методы оптимизации в нейронных сетях",
    "text": "Так как мы договорились, что нейросети представляют собой параметризованные дифференцируемые функции и для каждого параметра мы можем посчитать градиент, то, так же как и линейные модели, их можно настраивать с помощью градиентных методов. Впараграфепро линейные модели мы под этим подразумевали обычно стохастический градиентный спуск на батчах, и это совершенно подходящий способ и для нейросетей тоже. Но существует множество модификаций и эвристик, позволяющих ускорить его сходимость, познакомиться с которыми вы можете в специальномпараграфе, посвящённом методам оптимизации.",
    "source_type": null,
    "useful_links": [
      {
        "text": "параграфе",
        "url": "https://academy.yandex.ru/handbook/ml/article/linejnye-modeli"
      },
      {
        "text": "параграфе",
        "url": "https://academy.yandex.ru/handbook/ml/article/optimizaciya-v-ml"
      }
    ]
  },
  {
    "document_title": "Тонкости обучения",
    "url": "https://education.yandex.ru/handbook/ml/article/tonkosti-obucheniya",
    "section_title": "Регуляризация нейронных сетей",
    "text": "Смысл терминарегуляризация(англ.regularization) гораздо шире привычного вам прибавления- или-нормы вектора весов к функции потерь. Фактически он объединяет большое количество техник для борьбы с переобучением и для получения более подходящего решения с точки зрения эксперта. Каждая из них позволяет навязать модели определённые свойства, пусть даже и ценой некоторого снижения качества предсказания на обучающей выборке. Например, уже знакомая читателю- или-регуляризация в задаче линейной регрессии (регуляризация Тихонова) позволяет исключить наименее значимые признаки (для линейной модели) или же получить устойчивое (хоть и смещённое) решение в случае мультиколлинеарных признаков. В нейронных сетях техники регуляризации можно разделить на три обширные группы: связанные с изменением функции потерь; связанные с изменением структуры сети; связанные с изменением данных. Рассмотрим каждую из них подробнее. Изменение функции потерь — классический способ получить решение, удовлетворяющее определённым условиям. В глубинном обучении часто используется техника Weight Decay, очень близкая к регуляризации Тихонова. Она представляет собой аналогичный штраф за высокие значения весов нейронной сети с коэффициентом регуляризации: Данная техника регуляризации была совмещена с методом градиентной оптимизации Adam, в результате чего был получен метод AdamW (описанный в параграфепараграфепро методы оптимизации). Также достаточно часто в качестве регуляризационного члена встречается энтропия распределения, предсказанного нейронной сетью. Представьте, что вы рекомендуете пользователю товары по истории его взаимодействия с сервисом, семплируя товары для показа в соответствии с распределением предсказанной релевантности. Вам может быть важно, чтобы рекомендации не были фиксированными (менялись при обновлении страницы), ведь это повысит вероятность того, что пользователь найдёт что-то интересное, а вы узнаете о нём что-нибудь новое. В такой ситуации при обучении модели вы можете потребовать, чтобы распределение предсказаний не сходилось к вырожденному, и в качестве дополнительной штрафной функции может выступать энтропия этого распределения. Энтропия дифференцируема, как и сами предсказанные величины, и может быть использована в качестве регуляризационного члена. Для задачи классификации он будет выглядеть следующим образом: где— коэффициент регуляризации,— предсказанные вероятности. Тем самым эксперт привносит своё знание непосредственно в процесс обучения модели в подходящей математической форме: «предсказания должны быть разнообразными» —>«распределение не должно быть вырожденным» —>«энтропия не должна быть слишком низкой». Внесение подходящих преобразований в структуру сети также может быть хорошим способом добиться желаемых результатов. Огромное влияние на развитие нейронных сетей оказали техникиdropout (2014)иbatch normalization (2015), позволившие сделать нейронные сети более устойчивыми к переобучению и многократно ускорить их сходимость соответственно. Dropout Обратимся к простым полносвязным (FC/Dense) сетям из нескольких слоёв. Каждый из слоёв порождает новое признаковое описаниеобъекта, который пришёл на вход: Но как можно гарантировать, что модель будет эффективно использовать все доступные параметры, а не переобучится под использование лишь небольшого их подмножества, поделив для себя внутреннее представление на сигнал и шум? Для этого можно было бы случайным образом «выключать» доступ к некоторым координатам внутренних представлений на этапе обучения. Тогда при выключении «полезных» координат произойдёт резкое изменение предсказаний модели, что приведёт к увеличению ошибки, а полученные градиенты этой ошибки укажут, как её исправить с использованием (и изменением) других координат. Сравнение тока информации по исходной модели и по модели с «выключенными» координатами внутренних представлений можно проиллюстрировать с помощью классической картинки: Обратите внимание: «выключать» можно как оригинальные признаки, так и признаки, возникающие на любом другом уровне представления объектов. С точки зрения-го слоя нейронной сети данные приходят откуда-то извне: при— из реального мира, а при— с предыдущих слоёв. Технически это осуществляется следующим образом: некоторые координаты внутреннего представления домножаются на ноль. То есть добавляется ещё одно преобразование, которое представляет собой домножение выхода предыдущего слоя на маску из нулей и единиц. где(вероятность обнуления координаты) — это гиперпараметр слоя. Отметим, что во многих фреймворках для глубинного обучения в качестве параметра слоя указывается именно вероятность обнуления, а не выживания. Данная маска участвует и при подсчёте градиентов: Как правило, маска генерируется независимо на каждом шаге градиентного спуска. Важно отметить, что на этапе предсказания dropout ничего не меняет, то есть. Множительнужен для того, чтобы распределениена этапе предсказания совпадало с распределением на этапе обучения. В самом деле, если даже математическое ожиданиебыло равно нулю, выборочная дисперсияниже, чем у: ведь часть значений обнулилась. На этапе предсказания dropout «выключается»: внутренние представления используются как есть, без умножения на маску. А чтобы слой знал, обучается он сейчас или предсказывает, в нейросетевых библиотеках в классе слоя обычно реализовано переключение между этими режимами (например, булев флагtrainingв pytorch-модулях). Стоит отметить, что dropout может применяться и к входным данным (то есть слой dropout может стоять первым в сети), и это может приводить к получению более качественных результатов. Например, если в данных множество мультикоррелирующих признаков или присутствует шум, наличие dropout позволит избежать обусловливания модели на лишь их подмножество и позволит учитывать их все. Так, подобный подход может быть использован, если данные представляют собой сильно разреженные векторы высокой размерности (скажем, сведения об интересе пользователя к тем или иным товарам). Batch normalization Появление техники batch normalization привело к значительному ускорению обучения нейронных сетей. В данном параграфе мы рассмотрим лишь основные принципы работы batch normalization. Дискуссия о свойствах и причинах эффективности batch normalization всё ещё ведётся, рекомендуем обратить внимание настатьюс NeurIPS 2018. Нам, впрочем, кажется, что, несмотря на активную критику в его адрес, полезно знать и предложенное авторами подхода объяснение необходимости batch normalization. Использование batch normalization гарантирует, что каждая компонента представления на выходе будет иметь контролируемое среднее и дисперсию. Достигается это следующим образом: Сперва идёт собственно слойbatch normalization, на котором текущий батч приводится к нулевому среднему и единичной дисперсии: гдеи— среднее и дисперсия признаков по обрабатываемому батчу, а— гиперпараметр слоя, небольшое положительное число, добавляемое для улучшения численной устойчивости. Отметим, чтои, будучи функциями от, тоже участвуют в вычислении градиентов. В ходепредсказания(или, как ещё говорят,инференса, от английскогоinference) используются фиксированные значенияи, которые были получены в ходе обучения как скользящее среднее всехи. Более точно: на каждой итерации forward pass мы вычисляем гдетакже является гиперпараметром слоя. Далее идёт слойchannelwise scaling, который позволяет выучить оптимальное шкалирование для всех признаков: гдеи— обучаемые параметры, позволяющие настраивать в ходе обучения оптимальные значения матожидания и дисперсии выходного слоя. Ниже приведён алгоритм из оригинальноqстатьи2015 года за авторством Сергея Иоффе и Кристиана Сегеди: Причина популярности batch normalization заключается в значительном ускорении обучения нейронных сетей и в улучшении их сходимости в целом. Рассмотрим график из оригинальной статьи: Как видно на иллюстрации выше, использование batch normalization позволило ускорить обучение в несколько раз и даже добиться лучших результатов, чем SotA-подход 2014 года Inception (структура которого была приведена на одной из иллюстраций в начале этого параграфа). Значительное ускорение достигается в том числе благодаря использованию более высокого learning rate: благодаря нормировке связь между слоями не нарушается столь сильно. Стоит заметить, что причины столь эффективной работы batch normalization до сих пор являются поводом для дискуссий и строгого теоретического объяснения эффекта от batch normalization ещё нет. Несмотря на это, он перевернул область глубинного обучения и вошёл в стандартный инструментарий при обучении нейронных сетей. Примечание: стоит заметить, что в настоящее время существуют и другие способы нормировать промежуточные представления: instance normalization, layer normalization и так далее. В завершение рекомендуем ознакомиться состатьёйо работе метода обратного распространения ошибки в слое batch normalization. Внесение изменений в данные (аугментация данных) также является популярной техникой регуляризации. Рассмотрим её на примере. Пусть перед нами фотография самолёта. Добавим мелкодисперсный шум к изображению. Мы всё ещё сможем увидеть на фотографии самолёт, но, с точки зрения модели машинного обучения (в данном случае — нейронной сети), полученное изображение является новым объектом! Повернём изображение самолёта на 10 градусов по часовой стрелке. В нашем распоряжении ещё одно изображение с известной целевой меткой (например, меткой класса «самолёт»), в котором присутствует поворот. Таким образом, внесение новых данных позволяет дать модели понять, какие преобразования над данными являются допустимыми, и она уже будет более устойчивой к наличию небольшого шума в данных или к поворотам (к которым чувствительна операция свёртки). Вдобавок аугментации позволяют значительно увеличить объём обучающей выборки. Особую популярность аугментации приобрели в области компьютерного зрения. В качестве примера приведём отличнуюбиблиотеку, позволяющую производить аугментацию изображений. Стоит обратить внимание, что используемые аугментации должны быть адекватны решаемой задаче. Инвертирование цветов на фотографии, внесение значительного количества шумов или переворот изображения могут привести и к негативным результатам (по сути, просто сделают выборку более зашумлённой или даже заставят сеть учиться на данных, которые она никогда не встретит в реальности), так как обобщающая способность сети ограниченна. Можно сказать, что аугментированные данные должны принадлежать к той же генеральной совокупности, что и оригинальный датасет. Итак, эксперт может привнести своё понимание задачи и на уровне аугментации данных: если данное преобразование является допустимым (то есть преобразованный объект мог бы попасть в обучающую выборку и самостоятельно — как фотография с другого устройства или запись речи другого человека с опечаткой), то модель должна быть устойчива к данным с подобными преобразованиями.",
    "source_type": null,
    "useful_links": [
      {
        "text": "параграфе",
        "url": "https://academy.yandex.ru/handbook/ml/article/optimizaciya-v-ml"
      },
      {
        "text": "dropout (2014)",
        "url": "https://jmlr.org/papers/v15/srivastava14a.html"
      },
      {
        "text": "batch normalization (2015)",
        "url": "https://arxiv.org/abs/1502.03167"
      },
      {
        "text": "статью",
        "url": "https://arxiv.org/abs/1805.11604"
      },
      {
        "text": "статьи",
        "url": "https://arxiv.org/abs/1502.03167"
      },
      {
        "text": "статьёй",
        "url": "https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html"
      },
      {
        "text": "библиотеку",
        "url": "https://github.com/albumentations-team/albumentations"
      }
    ]
  },
  {
    "document_title": "Введение в рекомендательные системы",
    "url": "https://education.yandex.ru/handbook/ml/article/intro-recsys",
    "section_title": "Где можно встретить рекомендательные системы?",
    "text": "С рекомендательными системами можно столкнуться там, где есть большое множество товаров и пользователей, которые хотят найти нужные для себя товары. Рекомендательные системы помогают отобрать наиболее релевантные для пользователя объекты, тем самым экономя его время. Приведём несколько примеров: YouTube рекомендует пользователям видео; На сайтах интернет-магазинов можно встретить блоки с рекомендациями товаров; Музыкальные сервисы наподобие Spotify или Яндекс.Музыки рекомендуют музыкальные треки. Что такое «релевантные для пользователя товары» – это нетривиальный вопрос, который решается отдельно для каждой задачи исходя из бизнес-логики. Отметим, что, хотя задачи поиска и рекомендаций кажутся похожими и, как мы увидим, могут использовать схожие методы, у них есть одно важное отличие: в задаче поиска есть сформулированный запрос от пользователя, а в задаче рекомендаций явного запроса нет, есть только история взаимодействий пользователя с объектами и наша надежда на то, что мы верно распознали его скрытые желания. Это различие объясняет некоторые особенности дизайна рекомендательных систем, которые мы подробнее обсудим в конце этого параграфа, при разборе классического пайплайна рекомендательной системы.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Введение в рекомендательные системы",
    "url": "https://education.yandex.ru/handbook/ml/article/intro-recsys",
    "section_title": "Формализация задачи",
    "text": "Введём ряд обозначений. Пусть у нас есть множество пользователейи множество объектов. Для каждого пользователяесть множество объектов, с которыми он взаимодействовал и которым поставил рейтинги. Рейтинг (его также называют фидбеком) – это некоторая характеристика взаимодействия пользователя с объектом; про него можно думать, как про некоторый таргет, который мы выбрали для оптимизации рекомендательной системы. Таким образом, задачу рекомендательных систем можно переформулировать в следующем виде: для каждого пользователянеобходимо оценить значениедляи выбрать несколько товаров с наибольшим. Иными словами, надо научиться среди непоказанных пользователю товаров находить те, которые заинтересовали бы его больше всего. Приведем несколько примеров фидбека: Для товара – факт добавления в корзину; Для музыки – дослушали ли трек до конца; Для статьи – лайк/дизлайк; Для видео – время его просмотра или факт просмотра, например, наполовину. Как правило, фидбек разделяют на два типа – explicit и implicit. Из-за различия для каждого фидбека есть разные техники обработки и использования, которые будут обсуждаться в параграфе проматричные факторизации. Explicit, или явный фидбек– это такие действия пользователя, по которым точно можно понять, понравился ли ему объект. Это может быть оценка, поставленная, фильму, лайк/дизлайк к видео или рецензия на купленный товар. Такого фидбека очень мало, но он наиболее точно характеризует отношение пользователя к товару. Implicit, или неявный фидбек– это любая другая информация о действиях пользователя на сайте. Он выступает в качестве прокси к явному фидбеку. Например, факт того, что пользователь досмотрел видео до конца, не говорит о том, понравилось ли оно ему, однако можно сделать предположение, что большинству досмотревших видео до конца оно понравилось. Приведем основные примеры неявного фидбека: клик на статью, время просмотра видео, покупка товара. Обычно такого сигнала в разы больше, чем явного, однако он более шумный, и не стоит доверять ему так же, как явному. Например, при оптимизации кликов на статью может получиться так, что рекомендательная система научится находить кликбейт, а не интересные пользователю статьи – это может плохо отразиться на сервисе в долгосрочной перспективе. Задачу построения рекомендательной системы можно формулировать в качестве задачи классификации (клик/не клик) или регрессию (сколько звёзд пользователь поставит объекту), но это не самые распространённые стратегии. Обратим внимание, что нам на самом деле не обязательно уметь точно оценивать рейтинги. Достаточно уметь для пользователя и набора объектов генерировать перестановку этих объектов в порядке убывания рейтинга. Модель, решающую данную задачу, называютранжирующей. Опишем классический пайплайн применения ранжирующей модели для одного пользователя. На вход подаются признаки пользователя и объекта, и для пары пользователь-объект на основе этих признаков выдается некоторое число, ответ модели. Далее мы сортируем объекты в порядке его убывания. Из полученной перестановки обычно берут несколько первых объектов для показа пользователю. Более подробно о том, как решается задача ранжирования, вы можете прочитать в соответствующем параграфе.",
    "source_type": null,
    "useful_links": [
      {
        "text": "матричные факторизации",
        "url": "https://academy.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya"
      }
    ]
  },
  {
    "document_title": "Введение в рекомендательные системы",
    "url": "https://education.yandex.ru/handbook/ml/article/intro-recsys",
    "section_title": "Коллаборативная фильтрация",
    "text": "Рассмотрим матрицу взамодействий пользователя, приведённую выше. Что можно порекомендовать Кате, исходя из исторических данных? Можно заметить, что взаимодействия Кати похожи на взамодействия Пети (так как они оба лайкали объекты 1 и 8). Иными словами, их интересы в чём-то похожи, поэтому Кате можно порекомендовать, например, объект 3 (так как он понравился Пете). Можно проделать аналогичное упражнение с Петей и сделать вывод, что ему не стоит рекомендовать объект 10. Можно решать и транспонированную задачу: для лайкнутого пользователем объекта искать похожие, то есть те, которые пользователи достаточно часто лайкали вместе с ним. Например, объекты 1 и 8 похожи друг на друга, так как их лайкали одни и те же пользователи, и точно так же похожи 1 и 3. Проиллюстрированный выше подход называютколлаборативной фильтрацией. Он объединяет семейство методов рекомендаций, использующих сходство по истории взаимодействия между пользователем и товаром. Рассмотрим конкретные простые методы коллаборативной фильтрации. Введём меру похожести двух пользователей, которая тем больше, чем выше сходство междуи. Для пользователярассмотрим множество похожих на него пользователейгде– настраиваемый гиперпараметр, в чём-то аналогичный порогу бинарного классификатора. Допустим, мы хотим теперь оценить рейтинг, который пользовательпоставил бы объекту. Сделаем это, опираясь на рейтинги, которые ставили похожие напользователи. Например, можно взять взвешенное среднее: Модуль добавляется для того, чтобы корректно обработать непохожих пользователей, то есть пары с отрицательной похожестью, которая может возникнуть, если при построениивзять достаточно маленькое. Можно пойти дальше и усовершенствовать метод оценивания. У пользователей могут быть разные диапазоны оценок: кто-то ставит почти всегда в диапазоне 1-3, а кто-то предпочитает ставить 4-5. Иными словами, для разных пользователей оценка «нормально» (и соответственно, оценки «хорошо» и «плохо») могут соответствовать разным значениям рейтинга. Для устранения этой проблемы, можно брать не сырой рейтинг пользователя, а его отклонение от среднего всех оценок пользователя:. Таким образом, мы учитываем только разброс вокруг среднего и итоговая оценка будет выглядеть так: Можно пойти еще дальше и учесть дисперсию оценок пользователей: где– множество объектов, с которыми взаимодействовал пользователь. В заключение приведём несколько вариантов оценки схожести пользователей: Мера Жаккара:где– множество понравившихсяайтемов; Скалярное произведение общих рейтингов:; Корреляция Пирсона: Дисконтированная корреляция Пирсона. Так как айтемов в пересечениив действительности не всегда может быть достаточно много, можно дисконтировать похожести, посчитанные по небольшому множеству айтемов, домножая корреляцию на. Теперь попробуем решать транспонированную задачу. Введем меру похожести объектов. Если нам нужно оценить рейтинг, который пользовательпоставил бы ещё не виденному им объекту, то мы можем рассмотреть множествоблизких кобъектов и оценитьаналогично user2user подходу: Меру схожести объектов можно задать как adjusted cosine: где– множество пользователей, оценивших товар. Обратите внимание, что– это средняя оценка пользователя, а не объекта, то есть это не корреляция Пирсона – на практике данный подход обычно работает лучше. Выделим ключевые особенности методов, основанных на коллаборативной фильтрации, о которых следует помнить при разработке рекомендательных систем: Они не опираются ни на какую дополнительную информацию кроме матрицы оценок, предполагая, что этого должно быть достаточно для улавливания качественного сигнала о схожести пользователей и товаров; Предложенные методы не применимы для новых объектов и пользователей – для них просто нет истории или она недостаточно информативна для того, чтобы методы могли давать более-менее точные оценки; Так как методы коллаборативной фильтрации основаны только на истории прошлых взаимодействий, рекомендательная система, построенная исключительно на их основе будет постепенно вгонять пользователя в информационный пузырь: эти методы не предполагают открытия новых интересов у пользователя, они способны только эксплуатировать уже имеющиеся.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Введение в рекомендательные системы",
    "url": "https://education.yandex.ru/handbook/ml/article/intro-recsys",
    "section_title": "Content-based рекомендации",
    "text": "Также помимо коллаборативной фильтрации существует content-based подход для построения рекомендаций: измерение похожести между объектами на основе их содержания. Например, две статьи про то, как заменить колесо на велосипеде можно считать похожими с точки зрения содержания. Иными словами, входом для content-based модели являются разные контентные признаки и характеристики товара (например, текст статьи, время публикации, картинки), а выходом является некоторое числовое представление объекта (эмбеддинг). Отметим, что никакую коллаборативную информацию такие модели не используют, они ничего не знают про других пользователей и про их взаимодействие с объектами. Например, Bert является чисто контентной моделью – он переводит текст в эмбеддинг. Пусть у нас есть некоторый контентные эмбеддингидля каждого товара – например, мы применили обученный Bert для получения векторных представлений статей. Тогда мы можем посчитать скалярное произведение (или косинусное расстояние) до оценённых пользователем объектов и оценить рейтинги, как: где– скалярное произведение или косинусное расстояние между двумя векторами,– множество оценённых пользователем объектов, а– гиперпараметр. Таким образом, высокие рейтинги получат объекты, похожие на те, что понравились пользователю – мы получили простую ранжирующую модель. Плюс контентного подхода в том, что, в отличие от чисто коллаборативного подхода, он одинаково хорошо работает на новых и старых айтемах, так как контентные модели основаны только на статичной контентной информации, которая всегда доступна. Из минусов можно отметить, что похожесть по контенту может ещё больше загонять пользователя в информационный пузырь: например, контентная модель вряд ли сможет к кофемашине порекомендовать кофейные зерна, в то время как коллаборативный подход получит сигнал о том, что товары являются дополняющими напрямую из действий других пользователей. Отметим, что существуют гибридные модели, совмещающие в себе коллаборативный и контентный сигналы. Например, такой моделью является DSSM. Подробнее о контентных моделях вы узнаете в соответствующем параграфе.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Введение в рекомендательные системы",
    "url": "https://education.yandex.ru/handbook/ml/article/intro-recsys",
    "section_title": "Классический пайплайн рекомендательной системы",
    "text": "Мы разобрали несколько классических подходов к построению рекомендаций, теперь нужно обсудить, как это скомпоновать в единую рекомендательную систему. Для начала сформулируем ряд свойств, которыми должна обладать хорошая рекомендательная система: При ранжировании товаров в порядке убываниянам хотелось бы учитывать как можно больше сигналов/фичей (как пользователя, так и объекта); Рекомендательная система должна работать достаточно быстро; Должен быть несложный механизм, позволяющий понятно учитывать «бизнес-логику» (например, если при прочих равных мы больше хотим показывать свежие статьи). Для соблюдения первого пункта, очевидно, нужна ранжирующая модель. В качестве самой модели часто применяют бустинг – на табличных данных он, как правило, cправляется лучше, плюс он быстрее нейронных сетей с точки зрения времени применения. Здесь не будет лишним упомянуть про feedback loop. Для обучения ранжирующей модели мы обычно берем прошлую историю взаимодействия пользователей с показанными ему объектами, считаеми составляем на основе этих оценок обучающий датасет. Таким образом, обучая новую модель, мы с некоторыми оговорками будем учиться предсказывать старую модель. Поэтому есть риск, что она застрянет в локальном оптимуме, из которого сложно выбраться. В качестве решения этой проблемы можно, например, подмешивать в выдачу случайные объекты и давать им больший вес в функции потерь. Таким образом, у нас появляется некоторое подмножество объектов, которые не были смоделированы нашей моделью. В качестве дополнительного плюса такого подхода мы в какой-то степени будем выбивать пользователя из его информационного пузыря, показывая объекты из категорий, которыми он еще не интересовался. В реальной рекомендательной системе обычно от нескольких миллионов товаров и хотя бы несколько сотен тысяч пользователей в день (а чаще несколько миллионов). Обученная CatBoost модель на 5000 объектов отрабатывает где-то за 100-125ms на CPU. Фичи пользователей и объектов постоянно меняются, поэтому на каждый запрос пользователя мы должны заново скорить все объекты. Но тогда только на скоринг мы будем тратить порядка 25 секунд, а если это не CatBoost, а, например, нейронная сеть, то, скорее всего, ещё больше. Это очень существенные и необоснованные затраты. В действительности, пользователю наверняка интересна лишь небольшая часть имеющихся у нас товаров. Можно попытаться сузить множество до потенциально интересных пользователю объектов и уже для них применить «тяжёлую» ранжирующую модель, которая определит финальную выдачу. Этот подход называетсяотбором кандидатов. К отбору кандидатов предъявляют два требования: он должен быть быстрым; он должен иметь хорошую полноту поиска подходящих пользователю объектов, то есть в полученной после отбора кандидатов подмножестве должны в избытке находиться интересные пользователю статьи/фильмы/продукты; Приведем несколько подходов к отбору кандидатов: Эвристики: самые популярные товары, популярные запоследних дней, популярные среди жителей этого города, недавно опубликованные; Коллаборативные: item2item или user2user рекомендации. Мы можем в оффлайне предподсчитывать все необходимые статистики и строить таблички из пользователя в множество подходящих айтемов или из айтема в айтемы. Также есть более сложные подходы на основе матричных разложений, о которых будет рассказано в соответствующем параграфе; Контентные методы: берём content-based эмбеддинги объектов и строим быстрый индекс для поиска ближайших объектов (например, HNSW). Подробнее о быстром поиске ближайших соседей вы можете почитать в параграфе про метрические методы. Далее, можем взять понравившиеся пользователю товары и найти похожие на них. Обычно отбор кандидатов состоит из набора разных источников кандидатов, где каждый источник по смыслу пытается покрыть какой-то пользовательский аспект. Двухступенчатая рекомендательная система уже обладает двумя хорошими свойствами, осталось предложить механизм, который позволит учитывать бизнес-логику. Под бизнес-логикой здесь понимается некоторое качество рекомендательной системы, которое хотелось бы иметь, но которое достаточно нетривиально, чтобы мы не стали зашивать его в саму ранжирующую модель. Приведем примеры возможных пожеланий: Реже показывать старые видео в ленте; Реже показывать слишком длинные видео или видео, снятые в плохом качестве; Обеспечить разнообразную для пользователя выдачу. Например, если пользователь интересуется кошками и машинами, А ранжирующая модель всем видео про кошек дала большую оценку, чем любому видео про машины, то получится, что лента пользователя будет состоять только из кошек, хотя ему также интересны и машины. Все эти свойства подразумевают под собой небольшое переупорядочивание объектов после применения ранжирующей формулы. Этот механизм называетсяпереранжированием(реранкингом).",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Генеративно-состязательные сети (GAN)",
    "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
    "section_title": "Введение",
    "text": "Генеративно-состязательные сети (Generative Adversarial Networks, GAN) – это большой класс генеративных моделей, общая черта которых заключается в том, что они обучаются одновременно с другой сетью, которая старается отличить сгенерированные объекты от настоящих. В этом параграфе мы рассмотрим основы основ GAN-ов, интуитивное объясним принципы их работы, а также детально погрузимся в многочисленные приёмы и модификации оригинального подхода, которые применяются в наиболее успешных моделях. Мы также приведём примеры нескольких типов практических задач, в которых применяются генеративно-состязательные сети. Генеративно-состязательные сети — это неявная генеративная модель. То есть она не восстанавливает плотность данных в явном виде, но умеет сэмплировать из распределения данных. Самый простой и эффективный дизайн генеративных моделей, которые умеют только сэмплировать, но не умеют оценивать плотность, – это отображение одних случайных величин в другие. Подобного вида модель после обучения работает следующим образом: пусть– случайная величина, обозначающая сэмпл из распределения нужных нам данных (например, картинок с нарисованными цифрами), а– сэмпл из какого-то распределения, который нам легко получить (например, каждая его компонента берётся из стандартного нормального). Тогда, если у нас есть обученная функция, которая переводит сэмплы изв сэмплы из, то процесс генерации происходит в два этапа: сначала мы случайным образом получаем вектор, а затем отображаем его в: Ключевым вопросом в таких моделях является соотношение размерностейи. Есть генеративные модели, где. Примером таких подходов являются, например, нормализующие потоки. В случае генеративных состязательных сетей (как и другого класса популярных генеративных моделей, вариационных автоэнкодеров),. Поэтому работу этих моделей можно рассматривать как поиск многообразия размерностисреди всех случайных примеров из домена, на котором определяется. Например, в случае генерации цифр это соответствует поиску в домене, где– это ширина картинки, а– её высота, подмножества, в котором каждый элемент изображает какую-либо цифру. Таким образом, задача обучения генеративных состязательных сетей может рассматриваться как задача компрессии данных в низкоразмерное представление.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Генеративно-состязательные сети (GAN)",
    "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
    "section_title": "Основы обучения GAN-ов",
    "text": "Классическая аналогия того, как учатся GANы — это фальшивомонетчик и полицейский. Задача фальшивомонетчика — научиться создавать купюры, которые полицейский не сможет отличить от реальных. Задача полицейского — научиться отличать купюры фальшивомонетчика от настоящих. Чтобы понять, как обучаются GANы, надо представить себе следующий мысленный эксперимент. Допустим, фальшивомонетчик и полицейский — друзья, которые решили поучиться друг у друга. Фальшивомонетчик создаёт несколько фальшивых купюр и показывает полицейскому. Полицейский говорит фальшивомонетчику, какие из его купюр, по его мнению, поддельные, а какие — настоящие. Фальшивомонетчик запоминает отзыв полицейского и в следующий раз улучшит свои купюры на основе отзыва от полицейского. Сам полицейский при этом тоже учится: он запоминает, что купюры, которые он видел — поддельные. В нашем мысленном эксперименте представим, что фальшивомонетчик взаимодействует с полицейским много раз. Что получается в результате? С каждым разом купюры фальшивомонетчика всё труднее отличить от настоящих. И с каждым разом умение выявлять поддельные купюры у полицейского выше. Важный вопрос для понимания работы GANов: в какой момент мы можем утверждать, что фальшивомонетчик хорошо подделывает купюры? Ответ:Когда фальшивомонетчик сможет обманывать сильного полицейского. В начале нашего эксперимента полицейский плохо отличает подделку от оригинала. Поэтому обмануть его можно купюрами плохого качества. Нам же интересно получить фальшивомонетчика, который будет выдавать купюры, неотличимые от оригинала даже профессионалом. Рассмотрим задачу обучения более формально. Пусть у нас есть генератор(фальшивомонетчик) с параметрами, и дискриминатор(полицейский) с параметрами. Генератор отображает векторыв, распределение которых приближает реальное распределение данных. Дискриминатор каждому реальному сэмплуи фейковомуставит в соответствие вероятность, которая оценивает степень принадлежностик реальным данным, т.е. он решает задачу бинарной классификации. Самый простой способ это сделать – при помощи минимизации бинарной кросс-энтропии: Учитывая обозначение, и то, что мы пытаемся максимизировать вероятность принадлежности к реальным данным, как её оценивает дискриминатор, задачу, которую решает генератор, можно расписать следующим образом (используя свойство выпуклости логарифма): Это равенство позволяет записать задачи, которые решают генератор и дискриминатор, вместе. (Мы также избавимся от лишних минусов, сделав так, чтобы дискриминатор решал задачу максимизации.) Получается, что на самом деле генератор и дискриминатор пытаются оптимизировать одну функцию: генератор её минимизирует, а дискриминатор максимизирует. Обозначим эту функцию (минус бинарную кросс-энтропию) как. Тогда эту задачу оптимизации можно записать в сокращённом виде: По параметрам дискриминатора минимум бинарной кросс-энтропии (или минимумпо) достигается на следующей функции – оптимальном дискриминаторе для фиксированного генератора: Её оптимальность нетрудно проверить, используя выпуклость логарифма. Учитывая это, и формулу для, интуицию работы метода обучения GANов со стороны генератора можно сформулировать следующим образом: Мы замеряем, насколько реалистичными являются сгенерированные сэмплы, используя для этого оптимальный дискриминатор. Мы хотим увеличить отклик дискриминатора на каждом сэмпле, т.е. пытаемся модифицировать каждый предсказанный элементтак, чтобы на нём стало выше значение. Ещё более простую интуицию для этой задачу можно сформулировать следующим образом. Как нужно модифицировать плотность, чтобы она стала ближе к, если к плотности распределения мы имеем доступ только через сэмплы из него? Визуализацию желаемых градиентов по случайным сэмплам для задачи сопоставления двух гауссиан можно видеть на графике ниже, где. Направленные вниз стрелки показывают, насколько нужно уменьшить координаты точек из распределения, чтобы получилось нечто максимально похожее на. То есть на самом деле точки будут сдвигаться на то же самое расстояние влево. Формализуем эту интуицию, и заодно поймём, почему вообще такой метод должен работать. Подставив выражение для оптимального дискриминатора в, мы можем избавиться от внутренней максимизации в исходной задаче и оставить только внешнюю минимизацию по параметрам генератора. Тем самым, мы получим в явном виде функцию потерь, которую минимизирует генератор (обозначим её за). Для неё мы распишем математическое ожидание через интеграл и упростим дроби: Упростим выражение дляещё раз, прибавив и отняв константу, а также учитывая, чтои: Здесьозначает, как обычно, KL-дивергенцию которая показывает, насколько два распределения отличаются друг от друга. Черезобозначает ещё один вид дивергенции (её называют дивергенцией Йенсена-Шеннона). Получается, что при оптимальном дискриминаторе генератор, решая внешнюю задачу оптимизации, уменьшает расстояние между распределениями реальных и фейковых данных, действительно приближая их друг к другу! Исходя из этого, и в предположении достаточной capacity генератора и дискриминатора (т.е. предполагая, что их параметризация позволяет достичь оптимума), мы можем сформулировать первый, наивный алгоритм обучения генеративно-состязательных сетей. Решить внутреннюю задачу максимизации по, повторяя шаги ниже до сходимости по параметрам дискриминаторак оптимальному значению:— Составить мини-батч сэмплов шумаиз.— Составить мини-батч сэмплов данныхиз.— Обновить дикриминатор, сделав шаг вверх по его градиенту: Сделать шаг SGD для внешней задачи минимизации по:— Составить мини-батч сэмплов шумаиз.— Обновить генератор, сделав шаг вниз по его градиенту:где черезмы для краткости обозначили. Какие у этого наивного подхода могут быть недостатки? Во-первых, он очень медленный, потому что необходимо обучать дискриминатор до сходимости, чтобы сделать всего один шаг по градиенту генератора. Но вторая проблема намного серьёзнее: функция потерь генератора может насыщаться и выдавать близкие к нулю градиенты. Проиллюстрируем это на примере обучения простой модели, которая будет сэмплировать из одномерной гауссианы с заданными параметрами. Распределениев этом случае известно, а распределениемы можем получить с помощью методов оценки плотности по сэмплам. Визуализируем эти плотности, а также градиент по сэмплам из генератора (a). Видно, что в случае, когда пики распределений плохо пересекаются друг с другом, градиент будет равен нулю на большинстве сэмплов, которые выдаёт генератор, т.е. они никак не будут использоваться для обучения. Чтобы понять причину происходящего, давайте посмотрим на градиент функции потерь генератора. На точках, далёких от основной «массы», дискриминатор выдаёт что-то близкое к нулю, то есть знаменатель градиента практически не будет ни на что влиять, а в числителе тоже будет практически ноль: ведь если мы немного поменяем параметры генератора, то «плохие» точки по-прежнему будут далеки от, так что изменение лосса будет пренебрежимо малым, и градиент тоже. Это приводит к тому, что обучение происходит недостаточно эффективно: мы тратим время на вычисление сэмплов, которые не делают никакой вклад в обновление параметров генератора. Но более существенная проблема возникает в вырожденном случае: если изначально два распределения практически не пересекаются своими плотностями (b): в этом случае процесс обучения практически не идёт. Часто ли встречается такая вырожденная ситуация на практике? Довольно часто! Достаточно представить себе ситуацию, когда мы хотим генерировать реалистичные изображения лиц, а генератор в начале обучения вместо этого выдаёт случайный шум. Из-за наличия такой проблемы описанная выше функция потерь генератора называется «сатурирующей». В оригинальном подходе по обучению генеративно-состязательных сетей было предложено два решения этой проблемы. Во-первых, мы можем обучать дискриминатор на каждой итерации не до сходимости, а с небольшим фиксированным числом шагов(на практике чаще всего используется). Это позволяет существенно улучшить исходную ситуацию с переобучением дискриминатора. Также мы могли бы улучшить функцию потерь для генератора, сделав так, чтобы она сглаживала выходы дискриминатора около нуля. В качестве такой функции изначально был предложен логарифм. Нетрудно видеть, что оптимум улучшенной функции потерь («несатурирующий лосс») совпадает с исходной, что позволяет сохранить все описанные выше теоретические гарантии: Точка минимума у новой функции потерь та же, что у исходной, а градиенты оказываются ненулевыми на всех сгенерированных сэмплах. Помимо этого, на практике вместо обычного метода стохастического градиентного спуска используются его модификации, которые учитывают и первые, и вторые моменты градиентов например, Adam. Вообще, GAN-ы – довольно капризные модели, и настоятельно рекомендуется использовать готовые реализации с GitHub, оставляя большую часть гиперпараметров без изменений. Наиболее критичными среди них являются learning rate и расписание (то есть количество обновлений дискриминатора на одно обновление генератора).",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Генеративно-состязательные сети (GAN)",
    "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
    "section_title": "Метрики качества",
    "text": "После успешного обучения генератора хотелось бы также понять, насколько хорошо он работает. Для этого рассмотрим на примере задачи генерации изображений типовые ошибки, которые может совершать GAN. Наиболее частая проблема – плохое качество или наличие артефактов – вызвана ограничениями, связанными с capacity генератора и несовершенством самих методов обучения. Здесь всё просто: наша генеративная модель плохо работает, и мы это видим на сгенерированных сэмплах. Более скрытым видом ошибок является так называемыйmode collapse: обученный генератор выдаёт реалистично выглядящие картинки, но они не покрывают всё разнообразие распределения. Например, если наша модель учится генерировать изображения с животными, то она может проигнорировать более редкие виды, а научиться генерировать только наиболее часто встречающиеся. Более экстремальная форма подобного поведения – это когда модель вообще выдаёт вариацию одной картинки. Иногда в литературе общее качество результатов работы нейросети, по аналогии с задачей классификации, измеряется точностью метода (precision), а отсутствие mode collapse измеряется полнотой (recall). Самый простой и действенный способ измерить как precision, так и recall – сгенерировать данные и посмотреть на них, дав экспертную оценку уровня их реализма. Не стоит им пренебрегать! Формализовать этот подход в метрику можно в виде эксперимента, который в литературе называется user study. Например, мы можем сделать опрос экспертов, которым будем показывать два примера, настоящий и сгенерированный, и попросить их угадать, где фейк. Тогда процент неправильных ответов будет являться метрикой качества для нашего метода. Такой опрос в основном показывает степень реализма полученных результатов: есть ли в них какие-то заметные артефакты, соответствуют ли они реальным примерам по своей структуре, и так далее. Отчасти он также замеряет разнообразие примеров: то, насколько они хорошо покрывают носитель распределения. Если обученная модель генерирует очень похожие друг на друга примеры (то есть имеет место существенный mode collapse), то эксперт через несколько примеров научится определять ненастоящие. С другой стороны, если сэмплы в целом разнообразные, но всё равно не полностью покрывают основу целевого распределения, то user study не позволит обнаружить эту проблему. Есть метрики, с помощью которых можно автоматически проводить тестирование, похожее на user study. Для изображений наиболее используемой является Frechet Inception Distance (FID). Чтобы её посчитать, нам в идеале понадобится нейросеть, предобученная на датасете, который мы генерируем, но на практике во всех случаях используется модель Inception v3, предобученная на датасете ImageNet (отсюда слово Inception в названии метрики). Для того, чтобы понять идею этой метрики, рассмотрим следующий пример: если выходом нейросети является класс (число), то его вероятность можно смоделировать мультиномиальным распределением. Гипотетически, чтобы сравнить два распределения картиноки, нам достаточно измерить расстояние между двумя мультиномиальными распределениями, построенными на выходах предобученного классификатора после прогона датасетов реальных и сгенерированных данных. Если в распределениипримеров из каких-то классов будет меньше или больше, чем в, то такая метрика будет отличная от нуля. Понятно, что это слишком грубое приближение расстояния между двумя распределениями, т.к. оно практически никак не учитывает реализм получаемых картинок. Поэтому вместо выходов нейросети в FID было предложено использовать признаки с её глубоких слоёв. Они кодируют высокоуровневую семантику изображений, потому что по этим признакам модель предсказывает вероятность принадлежности картинки к тому или иному классу. При этом в них остаётся довольно много информации об исходном изображении и свойств локальных признаков (текстур), которые могут помочь распознать артефакты. Метрика FID работает таким образом, что сравнивает два распределения высокоуровневых признаков для реальных и сгенерированных картинок, используя в качестве их приближения многомерные гауссианы (каждая размерность соответствует одному каналу). Для измерения расстояния между этими двумя распределениями используется метрика Вассерштейна: гдеи– это среднее и матрица ковариаций глубоких признаков, которые считаются по выборке изреальных картинок. При этом как средние, так и матрицы ковариаций считаются по объединению всех признаков со всех картинок без учёта пространственной размерности, т.е. по второй размерности матрицы. То же самое делается для сгенерированных картинок, для них средние и ковариации обозначены каки. Минимум этой метрики равен нулю, и достигается в случае, когда статистики, посчитанные по двум распределениям, совпадают. На практике эта метрика используется как для измерения реализма изображений, так и для детектирования mode collapse. Ещё один способ измерения качества, который мы рассмотрим, напрямую связан с тем, что генеративно-состязательные модели эффективно занимаются кодированием потенциально высокоразмерных данных в низкоразмерное представление. Но как для нейросети с большим числом параметров проверить, занимается ли она реальным кодированием или простым запоминанием выборки? Рассмотрим следующий пример. Пусть наша генеративная модель к случайным векторамприменяет их функцию распределения и отображает векторы в равномерно распределённые на отрезкечисла. Упорядочим наш датасет. В качестве случайного сэмпла пусть наша модель выдаёт ту картинку, чей индекс, поделённый на размер датасета, ближе всего к. Другими словами, наша генеративная модель будет выдавать случайные картинки из датасета вместо генерации новых картинок. Методы оценки качества, которые мы описали выше, пропустят эту проблему: ведь «сгенерированные» картинки будут в точности совпадать с настоящими. Поэтому для полной проверки качества работы генеративной модели важно понимать, действительно ли она производит сжатие выборки в низкоразмерное представление или просто запоминает обучающие примеры. Одним из тестов на подобное поведение является интерполяция между сгенерированными примерами. Возьмём два случайных вектораииз. Рассмотрим все векторы, которые лежат между ними. К каждому такому векторуприменим наш генератор и получимдля промежуточных векторов идляи. Для правильно обученного GANа мы должны увидеть следующую картинку: при изменении коэффициентаизображениедолжно плавно меняться и перетекать изв. При этом каждая промежуточная картинка должна быть так же реалистичным сэмплом. Качество такой интерполяции сложно измерить численно, но если мы видим, что промежуточные результаты меняются случайно без какой-либо связи с семантикой интерполируемых примеров, то это говорит о плохом качестве генератора. Стоит упомянуть, что для сэмплов из нормального распределения, которое обычно имеют векторы, намного лучше работаетинтерполяция по сфере (Slerp), потому что в многомерном пространстве векторыпрактически всегда будут лежать в объёме вокруг сферы диаметра, где– размерность вектора. Интерполяция в скрытом пространстве с недавних пор стала использоваться для генерации анимаций и видео. Ведь анимация — это последовательность кадров, плавно переходящих друг в друга. И если у нас есть обученный GAN для генерации картинок, то нам нужно лишь найти путь в скрытом пространстве таким образом, чтобы набор сгенерированных картинок складывался в анимацию. Более того, в скрытом пространстве можно находить различные интерпретируемые пути. Например, путь, при движении по которому размывается задний фон или меняется причёска. Почитать подробнее про это можнотут. Ещё одним способом проверить, не запомнил ли генератор датасет, является поиск ближайших соседей по датасету. Для этого следует сгенерировать несколько изображений. Для каждого изображения нужно найти несколько ближайших соседей из датасета. В качестве признаков для картинок можно взять признаки с последних слоёв сети Inception. На соседей стоит посмотреть глазами. Если мы увидим, что ближайшие соседи из датасета визуально совпадают со сгенерированными сэмплами, то это значит, что генератор запомнил сэмплы из датасета.",
    "source_type": null,
    "useful_links": [
      {
        "text": "интерполяция по сфере (Slerp)",
        "url": "https://en.wikipedia.org/wiki/Slerp"
      },
      {
        "text": "тут",
        "url": "http://proceedings.mlr.press/v119/voynov20a/voynov20a.pdf"
      }
    ]
  },
  {
    "document_title": "Генеративно-состязательные сети (GAN)",
    "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
    "section_title": "Базовые модели",
    "text": "Чтобы лучше понимать современные модели, давайте сначала рассмотрим более базовые модели. Хотя они редко используются напрямую, многие идеи из них легли в основу современных моделей. Наиболее простая версия генеративной модели для изображений — это DCGAN (Deep Convolutional GAN, 2015 год). Её до сих пор можно иногда встретить как в литературе, так и на практике. В основе DCGAN лежит простая идея: нейросети, основанные на свёртках, отлично подходят для распознавания изображений, а значит вполне могут подойти и для их генерации. Единственное отличие, которое требуется – это постепенно увеличивать внутри нейросети пространственный размер признаков, а не уменьшать. Для этого в современных нейросетях делается операцияnearest upsampling, очень похожая на max pooling. В nearest upsampling пространственное разрешение карты признаков увеличивается за счёт того, что каждый вектор повторяетсяраз по горизонтали и по вертикали. К примеру, после увеличения таким образом карты признаков, состоящей из одной единицы, мы получим квадрат размераиз единиц. На практике увеличение размерности происходит по аналогии с размерами пулинга в свёрточных дискриминативных сетях и почти всегда равно. Таким образом, генератор в случае DCGAN является последовательностью свёрток, слоёв батч нормализации, нелинейностей и слоёв upsampling, а дискриминатор – обычной классификационной нейросетью. При этом первым слоем в генераторе является линейный слой, который отображает вектор шумав карту признаков с начальным разрешением (как правило, размера). Хотя результаты работы DCGAN довольно смазанные, эта модель показала большие перспективы генеративных нейросетей для изображений. Допустим, что в нашем датасете есть изображения, относящиеся к разным классам, и мы хотели бы уметь генерировать изображение заданного класса. В этом случае речь идёт обусловной генерации. В качестве условия может выступать не только метка класса, но и объект любой природы. Например, когда вы можете захотеть сгенерировать изображение по текстовому описанию. Далее будем обозначать условие как. Наша задача — построить генератор, который бы моделировал. Самый основной метод условной генерации — конкатенация условия с вектором шума, который генератор принимает на вход. Встатье Conditional GAN2014 года, где предложили этот метод, рекомендовалось подавать условие не только в генератор, но и в дискриминатор. Если мы генерируем векторные данные, то вектор на вход дискриминатора подаётся конкатенированным с. При этом если если— это метка класса, то стоит её закодировать с помощью one-hot encoding. Если же мы работаем с изображениями, то нам из вектора условия следует сделать изображение. Например, если картинки из датасета имеют размер, то следует размножить вектор, создав из него тензор размера, где— размерность вектора. Далее полученное «изображение» конкатенируется с входным изображением.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Deep Convolutional GAN",
        "url": "https://arxiv.org/pdf/1511.06434.pdf"
      },
      {
        "text": "статье Conditional GAN",
        "url": "https://arxiv.org/pdf/1411.1784.pdf"
      }
    ]
  },
  {
    "document_title": "Генеративно-состязательные сети (GAN)",
    "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
    "section_title": "Современные модели",
    "text": "Теперь на примере наиболее успешных моделей мы расскажем об улучшениях, которые во многом отходят от оригинального подхода к обучению GAN-ов и при этом значительно улучшают практические результаты, а значит расширяют практическую применимость. В этом разделе мы рассмотрим state-of-the-art систему генерации изображений StyleGAN, методы еёобращения(т.е., поиска векторов шума, соответствующих произвольной картинке), а также методы манипуляции семантикой изображений. После этого мы рассмотрим несколько примеров условных генеративных моделей, которые вместо шума принимают на вход изображения. Такие модели используются как для задачи повышения разрешения (super resolution), так и стилизации (например, превращение пейзажей в картины Моне). Мы сфокусируемся на изображениях, так как в этой области сконцентрирован как основной прогресс, так и наиболее впечатляющие применения генеративных моделей. Самой известной генеративно-состязательной моделью, работающей с изображениями, по праву считается StyleGAN, который до сих пор активно развивается и имеет большое количество расширений (например, существуют разнообразные методы его обращения). Архитектура StyleGAN переняла progressive growing из моделиProgressive Growing of GANs. Суть данной техники заключается в том, чтобы не сразу генерировать изображение высокого разрешения, а постепенно. Давайте рассмотрим это подробнее. Мы хотим получить генератор, который генерирует изображения размера 1024x1024. Обучить такой генератор очень сложно. Поэтому мы начинаем с разрешения 4x4. У генератора мы оставляем только первый блок слоёв, который позволяет из шума получить изображение размера 4x4. У дискриминатора мы оставим, наоборот, только последний, который принимает на вход изображение размером 4x4. Такой GAN мы обучаем на изображениях из датасета (предварительно уменьшив их в размере). Спустя сколько-то итераций мы понимаем, что сеть уже умеет генерировать маленькие изображения. В этот момент мы добавляем к генератору один блок, чтобы на выходе у неё получалось изображение размера 8x8. Так же мы добавляем один блок в начало дискриминатора, чтобы он на вход принимал изображения размера 8x8. Теперь генератор и дискриминатор состоят из двух блоков, которые мы и обучаем. Такой процесс мы повторяем несколько раз, пока в итоге не дойдём до нужного нам разрешения 1024x1024. Эта схема в итоге показала себя действенным способом генерации реалистичных изображений высокого разрешения. Ключевой частью StyleGAN является используемый в нём способ подачи шумав нейросеть, и именно из-за него метод и получил своё название. Для того чтобы понять, что конкретно в нём особенного, давайте подробнее посмотрим на архитектуру сети (рисунок из предыдущего раздела, модель StyleGAN справа). Во-первых, вместо того, чтобы подавать вектор шуматолько в самом начале генератора, нейросеть обуславливают на него много раз на разных разрешениях признаков. Исторически, впервые похожим методом решалась задача переноса стиля одной картинки на другую, отсюда и название: a style-based generator. В качестве метода обуславливания используются так называемые адаптивные слои. Это модификация обычных слоёв нейросетей, в которых часть параметров предсказывается другой нейросетью. Вообще говоря, адаптивным можно сделать любой вид нормализации, включая батч нормализацию, но наиболее известным примером такого слоя являетсяадаптивная инстанс нормализация(adaptive instance normalization), и именно она использовалась в первой версии StyleGAN. Вспомним, как именно работает неадаптивная версия этого слоя. Пусть у нас есть батч, элементы которого будем обозначать как. Здесьобозначает размер мини-батча,– количество признаков, аи– высоту и ширину. Тогда внутри слоя инстанс нормализации выполняется следующая операция: Здесьиобозначают матрицы средних и стандартных отклонений, которые считаются отдельно для каждого элемента мини-батча и для каждого признака: При этомиявляются параметрами слоя, которые настраиваются в процессе обучения. Особенностью этого слоя является то, что, в отличие от батч нормализации, он применяется одинаковым образом как при обучении, так и во время инференса. То есть вместо того, что приближать средние и стандартные отклонения по батчу при помощи скользящих средних, как это делается в батч нормализации, мы честно каждый раз считаем эти статистики для каждой новой картинки отдельно от всех остальных. Это делает инстанс нормализацию очень популярной в области обработки и генерации изображений, где зачастую бывает невозможным обучение с большим размером мини-батча, а значит и использование батч нормализации. Адаптивной инстанс нормализацией (AdaIN) называется слой, гдеиявляются не обучаемыми параметрами, а нейросетями, которые предсказывают эти векторы из какого-то общего для всех слоёв адаптивной инстанс нормализации входа (обозначим его через): Это означает, что вместо оптимизации по векторамибудет происходить оптимизация по параметрам этих двух нейросетей. Также это означает, что у адаптивной инстанс нормализации добавляется ещё один вход помимо набора признаков, который определяет её поведение: некоторый вектор, который также называют вектором стиля. Как правило, в качествеииспользуется нейросеть с одним линейным слоем или неглубокий персептрон. Нетрудно видеть, что если в качестве вектораподавать сгенерированный шум, то это будет хорошим способом многократного обуславливания нашего генератора на вектор шума. Это позволило бы глубоким слоям нейросети выучивать лишь часть той информации о выходном изображении, которая содержится в векторе, например, глобальные признаки картинки. А информация о локальных признаках выходного изображения (текстурах) может появляться уже ближе к последним слоям на более высоком разрешении промежуточных признаков. Таким образом, у генератора нет необходимости хранить во всех своих картах признаков всю информацию о сгенерированной картинке, как это происходит в случае DCGAN: он может декодировать её напрямую из вектора шума по мере необходимости, что существенно облегчает обучение таких моделей и улучшает качество результатов. Авторы StyleGAN пошли даже дальше: в качестве дополнительной регуляризации они специально заставляли нейросеть использовать информацию из вектора шума частями. А именно, во время обучения все слои адаптивной нормализации случайным образом делятся на две последовательно идущие группы: первая группа обуславливается при помощи одной части вектора шума, а вторая – при помощи другой части. На практике это приводит к следующему эффекту: нейросеть учиться декодировать часть признаков изображения, используя вектор, а часть – используя. Это позволяет после обучения напрямую манипулировать выходами нейросети, смешивая разные векторы стилей. Второе ключевое открытие авторов StyleGAN связано с задачей поиска семантически значимого редактирования векторов из выученного низкоразмерного многообразия. Зачем это нужно на практике мы уже упоминали ранее: на этом низкоразмером многообразии значительно проще семантически редактировать изображения, чем на уровне пикселей. Например, для задачи генерации лиц на многообразииза изменение возраста или гендера может отвечать простой аддитивный сдвиг векторана. Если же мы попытаемся приблизить такую операцию в пространстве пикселей, то для этого уже понадобится большая нейросеть с сотнями тысяч или даже миллионами параметров. При этом, как правило, мы хотим использовать наиболее простые операции редактирования. В идеале, мы бы хотели ограничить класс преобразований редактирования (а) сдвигами на какой-то вектор и (б) линейной (или сферически-линейной) интерполяцией двух векторов. С одной стороны, кажется, что так задача редактирования векторов существенно усложняется: этот класс преобразований даже менее выразителен, чем линейные операции. Но, с другой стороны, для таких простых преобразований легче гарантировать, что они не выведут нас за пределы многообразия, в котором у распределениябольшая «масса», т.е. того множества векторов, которые генератор чаще всего видел во время обучения. Для нормального распределения, как было сказано ранее, это многообразие можно приблизить сферой радиуса. Но будет ли легко найти хорошо работающие преобразования на многообразии случайных векторов, взятых из нормального распределения? Авторы StyleGAN обнаружили, что если сначала пропустить векторычерез многослойный персептрон, и подавать на вход свёрточного генератора его выходы, то редактировать латентные векторы на выученном многообразиистанет намного проще. Это объясняется тем, что функцияимеет возможность выучить достаточно сложное распределение для переменной, которое упростило бы задачу генерации картинки для свёрточной части генератора. И на практике оказывается, что такое выученное представлениеулучшает не только качество генерируемых картинок, но и качество результатов для семантического редактирования векторов. Последняя важная деталь, которая тем не менее очень сильно помогла авторам StyleGAN получить настолько хорошие результаты – это так называемый truncation trick. Он был впервые предложен в более ранних работах и продолжает оказывает огромное влияние на качество результатов. Его суть состоит в том, чтобы после обучения сэмплировать те примеры из латентного пространства, которые чаще всего видел генератор во время обучения. Например, если мы во время обучения брали векториз нормального распределения, то при использовании truncation trick после обучения мы бы его сэмплировали из нормального распределения с обрезанными хвостами. Тем самым, интуитивно, мы убираем из сгенерированной выборки те примеры входных векторов, которые генератор реже видел во время обучения. Однако, нетрудно заметить что такая процедура приводит к потере разнообразия в выходных картинках. Например, если мы обрежем нормальное распределение вплоть до его среднего значения, то тогда нейросеть сможет выдавать лишь один пример. При всём при этом потеря разнообразия выходов – не такая большая проблема, т.к. обученный генератор всё ещё может часто ошибаться и выдавать маргинальные примеры. Фильтрация таких плохих примеров по какому-то выставленному порогу – в этом и есть суть применения truncation trick. В случае StyleGAN, авторам хотелось бы применять этот трюк непосредственно на распределении в выученном латентном пространстве. Для этого они применяют простой трюк: сначала считают центр масс, усредняя векторыдля большой выборки сэмплов: а затем сдвигают каждый сгенерированный векторпо направлению к этому центру: где– это параметр, который задаёт trade-off между качеством результатов и их разнообразием. Хотя работа StyleGAN показала довольно хорошие результаты, авторы статьи про StyleGAN-2Analyzing and Improving the Image Quality of StyleGANзаметили, что в некоторых случаях она может выдавать некачественные изображения. В частности, StyleGAN в некоторых случая может выдавать изображения с артефактами. Основной причиной этих артефактов оказалась адаптивная нормализация. Изначально, адаптивная нормализация состояла из двух частей: нормализация (на рисунке обозначена как Norm) и модуляция (на рисунке обозначена как Mod). В нормализации мы вычитали среднее и делили на стандартное отклонение. В модуляции мы умножали на новое выученное стандартное отклонение и прибавляли новое выученное среднее. Авторы StyleGAN2 предложили несколько модификаций для этапа нормализации. Каждое изменение в статье добавляли последовательно, следя за изменением общего качества генерации. Как из нормализации, так и из модуляции убрали вычитание/прибавление среднего. Нормализация и модуляция теперь выполняются независимо друг от друга и были перемещены в начало/конец стилевых блоков (см рисунок ниже, (c) Revised architecture). Нормализацию из предыдущего пункта заменили на демодуляцию весов. По сути это та же нормализация, только теперь нормализуются веса свёрток, а не входные данные (см рисунок ниже, (d) Weight demodulation. Обратите внимание на). В StyleGAN используется техникаprogressive growing(см раздел про StyleGAN). Из-за этого StyleGAN появляются артефакты, возникающие при исследовании латентного пространства с помощью интерполяций. Некоторые объекты лиц (глаза, зубы), которые должны вращаться при вращении головы, оставались на месте. Чтобы побороть эти артефакты, вместо progressive growing в StyleGAN2 стали использовать residual connections. Эти изменения позволили улучшить качество генерируемых изображений и избавиться от артефактов StyleGAN. Вот, например, некоторые примеры сгенерированных изображений модели StyleGAN2: Следующий шаг в развитии архитектуры StyleGAN — это статьяStyleGAN-ADA. ADA расшифровывается какAdaptiveDiscriminatorAugmentation. В данной статье авторы предложили механизм аугментации данных, который позволяет стабилизировать обучение и избежать переобучения дискриминатора. Всего в статье использовали 18 разных аугментаций. В статье также предложили некоторую эвристику того, как понимать, насколько переобучился дискриминатор. Эвристика нужна для того, чтобы адаптивно контролировать параметр аугментациив зависимости от степени переобучения. Основная идея алгоритма контроляв процессе обучения следующая. Изначально этот параметр равен нулю. Его значение изменяется на фиксированную величину каждые четыре мини-батча (авторы пишут, что частота обновлений не влияет на результат). Если наблюдается, что дискриминатор слишком переобучился, то параметрувеличивается. И наоборот, при низкой степени переобучении дискриминатора значениеуменьшается. Аугментация, как показали авторы, действительно помогает стабилизировать обучение при маленьком количестве данных. Однако, большой набор реальных данных всегда будет выигрывать у аугментации. Большинство современных моделей, которые показали впечатляющие результаты для генерации изображений, работают по схеме text to image. То есть текст является входом для нейросети, изображение — выходом. Обычно текст на входе называют prompt. По такой схеме работают модели Stable Diffusion, DALLE 2, Midjourney. Все эти модели являются диффузионными. Однако, пока что списывать GANы со счетов не стоит. Хотя качество у GANов не такое высокое, как у диффузионных моделей, а обучать их сложнее, у них есть неоспоримое преимущество — быстрая генерация изображений. На момент написания этого параграфа самая свежая статья про генерацию изображений с помощью GANов —StyleGAN-T. Её авторы решили на основе StyleGAN сделать модель для генерации изображений из текста. Архитектура модели StyleGAN-T очень похожа на архитектуру модели StyleGAN (за основу авторы взялиStyleGAN-XL— версию StyleGAN для больших обучающих выборок). В качестве кодировщика текста была использована предобученная модельCLIP. На что стоит обратить внимание в данной архитектуре: Текст, закодированный CLIP text encoder, подаётся на вход как генератору, так и дискриминатору. Дискриминатор в данном случае классифицирует не отдельное изображение, а пару текст/изображение. Сгенерированное изображение пропускается через фиксированный кодировщик изображений, также взятый из модели CLIP (CLIP image encoder на рисунке архитектуры). Полученное представление изображения должно быть близко с представлением текста, полученным с помощью CLIP text encoder. Это достигается за счёт добавление CLIP guidance loss в общую функцию потерь. Для разрешения выше 64x64 авторы берут случайные кропы размера 64x64 на изображении, чтобы посчитать CLIP guidance loss. Основное новшество модели StyleGAN-T — это лучшая GAN-модель для генерации изображений из текста. До этого большинство хорошо работающих моделей позволяли генерировать изображения для заданного класса или вообще без условий. Связать текст с изображением — гораздо более сложная задача. Поскольку на вход модель принимает не только шум, но и закодированный текст, она позволяет делать интерполяции по пространству текста. Примеры сгенерированных изображений и интерполяций по текстовому пространству вы можете видеть на рисунке ниже. Качество изображений StyleGAN-T отстаёт от диффузионных моделей, таких как Stable Diffusion или DALLE 2, о чём пишут сами авторы. Однако данная модель сильно выигрывает по скорости: на одной и той же видеокарте Stable Diffusion генерирует изображение за 3.7 секунды, в то время как StyleGAN-T за 0.02 секунды. Выше были перечислены лишь основные особенности данного класса генеративных моделей, на которые стоит обратить внимание. Эти соображения нашли применение в других задачах помимо генерации картинок из шума. На самом деле, список трюков и нюансов, необходимых для успешного обучения такой модели, намного обширнее. На практике для генеративных моделей настоятельно рекомендуется отталкиваться от готовых кодовых баз, внося минимальные и контролируемые изменения в процесс обучения. Особенно чувствительны генеративные модели бывают к архитектуре генератора и дискриминатора, к параметрам оптимизации (learning rate, количество обновлений весов дискриминатора на одно обновление генератора, и т.д.), а также к значениям весов лоссов (например, к весу R1 регуляризации, которую мы тут не обсуждали).",
    "source_type": null,
    "useful_links": [
      {
        "text": "Progressive Growing of GANs",
        "url": "https://arxiv.org/abs/1710.10196"
      },
      {
        "text": "Analyzing and Improving the Image Quality of StyleGAN",
        "url": "https://arxiv.org/abs/1912.04958"
      },
      {
        "text": "progressive growing",
        "url": "https://arxiv.org/pdf/1710.10196.pdf"
      },
      {
        "text": "StyleGAN-ADA",
        "url": "https://arxiv.org/abs/2006.06676"
      },
      {
        "text": "StyleGAN-T",
        "url": "https://arxiv.org/abs/2301.09515"
      },
      {
        "text": "StyleGAN-XL",
        "url": "https://arxiv.org/abs/2202.00273"
      },
      {
        "text": "CLIP",
        "url": "https://arxiv.org/abs/2103.00020"
      }
    ]
  },
  {
    "document_title": "Генеративно-состязательные сети (GAN)",
    "url": "https://education.yandex.ru/handbook/ml/article/generativno-sostyazatelnye-seti-(gan)",
    "section_title": "Применения генеративных состязательных нейросетей",
    "text": "До этого мы рассмотрели основные особенности генеративных состязательных нейросетей, а также их применение в задаче генерации изображений. В этом разделе мы рассмотрим, какие ещё задачи можно решать с помощью таких моделей. Отметим, что задачи, которые мы рассмотрим ниже, можно решать и другими способами без ГАНов. Зачастую диффузионные модели (MidJourney, Stable Diffusion) показывают лучшие результаты в этих задачах. Тем не менее в данном же разделе мы рассмотрим именно методы на основе генеративных состязательных нейросетей. Представьте, что вы хотите удалить с фотографии людей на заднем плане. Встаёт вопрос, чем их заменить? Для этого существует задача инпеинтинга (inpainting). Она заключается в том, чтобы восстановить часть изображения, которая была выделена маской. Если выделить людей или объекты на фотографии маской, то нейросеть для инпеинтинга будет способна зарисовать эти участки чем-то подходящим для конкретной фотографии. Обычно генератор модели GANs для инпеинтинга представляют собой image-to-image модели. То есть изображение подаётся как на вход, так и на выход. То, что происходит внутри генератора, зависит от архитектуры модели. Как правило, используются U-Net-подобные архитектуры с какими-то дополнениями. Так, например, в одной из последних работ по инпеинтигу на основе GANsResolution-robust Large Mask Inpainting with Fourier Convolutionsиспользуются Fast Fourier Convolutions. Чтобы обучить модель инпеинтинга, нужно подготовить данные в формате пар <изображение с маской, изображение без маски >. Сделать это не сложно. Достаточно на существующем наборе изображений случайным образом выделить участки для удаления, после чего обучать нейросеть их восстанавливать. Задачу inpainting можно так же превратить в задачу outpainting, то есть дорисовки изображения по краям. Для этого нужно в качестве маски подать пиксели, которые находятся за рамками изображения. При этом само исходное изображение можно уменьшить, если того требуют размерности нейросети. Задача outpainting может быть полезна, когда хочется расширить изображение, например, чтобы увеличить его разрешение. До этого мы рассматривали, как можно редактировать латентное пространство обученной состязательной модели, чтобы это отражалось на сгенерированных изображениях. В 2023 году вышла работаDrag Your GAN, которая основана на этом принципе, и позволяет редактировать изображения перетаскиванием одной точки в другую. Пример работы Drag Your GAN.cсылка на источник изображения Метод Drag Your GAN основан на модели StyleGAN2. Ему на вход подаётся набор изначальных точек и набор конечных точек. Внутри метода поочерёдно выполняются следующие два шага: Обновление латентного пространства и обновления изображения с помощью оптимизации; Обновление координат точек (трекинг точек). Изначально метод работает только со сгенерированным изображениями. Однако, нет проблем в том, чтобы добавить кодировщик, который бы переводил реальные изображения в латентное пространство модели. В таком случае можно будет редактировать и реальные изображения. Демо Drag Your GAN доступно поссылке.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Resolution-robust Large Mask Inpainting with Fourier Convolutions",
        "url": "https://arxiv.org/abs/2109.07161"
      },
      {
        "text": "Drag Your GAN",
        "url": "https://vcai.mpi-inf.mpg.de/projects/DragGAN/"
      },
      {
        "text": "cсылка на источник изображения",
        "url": "https://vcai.mpi-inf.mpg.de/projects/DragGAN/"
      },
      {
        "text": "ссылке",
        "url": "https://huggingface.co/spaces/DragGan/DragGan"
      }
    ]
  },
  {
    "document_title": "Сети бесконечной ширины",
    "url": "https://education.yandex.ru/handbook/ml/article/seti-beskonechnoj-shiriny",
    "section_title": "Применение NTK-анализа",
    "text": "Нам удалось проинтегрировать динамику предсказаний в явном виде. Что это даёт? Во-первых, мы получаем достаточное условие на сходимость в глобальный минимум на обучающей выборке. Таким условием является положительная определённость матрицы Грама ядра:для некоторого. В самом деле, в этом случае, что даёт Во-вторых, раз явное решение известно, можно написать оценку на обобщающую способность. Оба этих результата опираются на то, что ядро постоянно. Как мы покажем ниже, постоянство нейрокасательного ядра нейронной сети можно гарантировать лишь в пределе бесконечной ширины. Тем не менее, если сеть конечна, но достаточно широка, можно показать, что её ядро достаточно близко к предельному, и оценки сохраняют силу. Например, для обоснования сходимости в глобальный минимум достаточно показать, что наименьшее собственное значение эмпирического ядра с высокой вероятностью остаётся отделённым от нуля в течение обучения:с вероятностьюдля. В самом деле, из этого следует, что а значит, Формальное доказательство вы можете найти в работеGradient Descent Provably Optimizes Over-parameterized Neural Networks, а также вконспекте лекцийавтора этого параграфа. Вот ещё несколько результатов, полученных в этом направлении: улучшенные оценки на минимальную ширину в работеQuadratic suffices for over-parametrization via matrix chernoff bound; оценки для случая глубоких сетей в работеGradient descent finds global minima of deep neural networks; оценки на обобщающую способность, полученные через близость ядра к предельному, в работеFine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks. Как мы увидим позже, NTK реальных, стандартно параметризованных, имеющих конечную ширину сетей может меняться за время обучения существенным образом: см. эмпирическую работуDeep learning versus kernel learningи теоретический анализ для сетей с одним скрытым слоемDynamically Stable Infinite-Width Limits of Neural Classifiers. Тем не менее, ядро в инициализации может выявить определённые патологии соответствующей нейронной сети. Рассмотрим один из примеров применения. В некоторых состоящих из однородных блоков архитектурах (скажем, ResNet) можно увеличивать (и даже устремлять к бесконечности) число слоёв или блоков, и логично задаться вопросом о том, как при этом будет вести себя процесс обучения. Необходимым условием обучаемости является хороший первый шаг обучения. Если он исчезающе мал, то сеть не обучится ни на первом, ни на каком-либо другом шаге. Если он слишком велик, то обучение разойдётся на первом же шаге. Как мы увидим ниже, индикатором проблем является плохая обусловленность NTK в инициализации. Например, его собственные значения могут с ростом глубины стремиться к нулю или, наоборот, к бесконечности. В первом случае какие-то из компонент выборки никогда не выучатся, во втором обучение невозможно ни при каком конечном темпе обучения. Чтобы в этом убедиться, рассмотрим разложение матрицы Грама ядра по собственным векторами: где, а векторыобразуют ортонормированный базис. Разложим предсказание сети по этому базису:. Так как базис ортонормированный, каждая из компонент эволюционирует независимо от других. В самом деле, для дискретного градиентного спуска с шагомимеем Таким образом, если, тоникогда не сойдётся к. Кроме того, для того, чтобы процесс сходился, шагдолжен убывать обратно пропорционально наибольшему собственному числу. Если последнее стремится к бесконечности, тостремится к нулю, а значит,будем мало для всех, для которыхконечен; соответствующие компоненты также никогда не сойдутся. Подробности см. в работеRapid training of deep neural networks without skip connections or normalization layers using Deep Kernel Shaping, а также в более ранних работахExponential expressivity in deep neural networks through transient chaos,Deep information propagation,Resurrecting the sigmoid in deep learning through dynamical isometry,Dynamical isometry and a mean field theory of cnns, в которых использовалась похожая идея, но не использовалось понятие NTK явно. См. также главу про инициализацию вконспекте лекций.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Gradient Descent Provably Optimizes Over-parameterized Neural Networks",
        "url": "https://arxiv.org/pdf/1810.02054.pdf"
      },
      {
        "text": "конспекте лекций",
        "url": "https://arxiv.org/pdf/2012.05760.pdf"
      },
      {
        "text": "Quadratic suffices for over-parametrization via matrix chernoff bound",
        "url": "https://arxiv.org/pdf/1906.03593v1.pdf"
      },
      {
        "text": "Gradient descent finds global minima of deep neural networks",
        "url": "https://arxiv.org/pdf/1811.03804.pdf"
      },
      {
        "text": "Fine-Grained Analysis of Optimization and Generalization for Overparameterized Two-Layer Neural Networks",
        "url": "https://arxiv.org/pdf/1901.08584.pdf"
      },
      {
        "text": "Deep learning versus kernel learning",
        "url": "https://arxiv.org/pdf/2010.15110.pdf"
      },
      {
        "text": "Dynamically Stable Infinite-Width Limits of Neural Classifiers",
        "url": "https://arxiv.org/pdf/2006.06574.pdf"
      },
      {
        "text": "Rapid training of deep neural networks without skip connections or normalization layers using Deep Kernel Shaping",
        "url": "https://arxiv.org/pdf/2110.01765.pdf"
      },
      {
        "text": "Exponential expressivity in deep neural networks through transient chaos",
        "url": "https://arxiv.org/pdf/1606.05340.pdf"
      },
      {
        "text": "Deep information propagation",
        "url": "https://arxiv.org/pdf/1611.01232.pdf"
      },
      {
        "text": "Resurrecting the sigmoid in deep learning through dynamical isometry",
        "url": "https://arxiv.org/pdf/1711.04735.pdf"
      },
      {
        "text": "Dynamical isometry and a mean field theory of cnns",
        "url": "https://arxiv.org/pdf/1806.05393.pdf"
      },
      {
        "text": "конспекте лекций",
        "url": "https://arxiv.org/pdf/2012.05760.pdf"
      }
    ]
  },
  {
    "document_title": "Сети бесконечной ширины",
    "url": "https://education.yandex.ru/handbook/ml/article/seti-beskonechnoj-shiriny",
    "section_title": "NTK и Ядровые методы",
    "text": "Предельное NTK нейронной сети можно использовать в любом ядровом методе, например, в SVM. Обсудим это поподробнее и заодно разберёмся, почему NTK вообще называют ядром. Рассмотрим задачу линейной регрессии: Эту же задачу можно эквивалентно переписать следующим образом: где– пространство линейных отображенийс некоторой нормойна нём. Сделаем линейное пространствоевклидовым, введя на нём следующее скалярное произведение. Дляиопределим Это скалярное произведение порождает норму, что и делает формулировку (5) эквивалентной формулировке (4). Пространство линейных моделей слишком узко, однако ничто не мешает нам рассмотреть задачу вида (5), в которойбудет произвольным нормированным пространством функций. Наиболее хорошо изучен случай, когда функции изявляются линейными моделями в некотором (возможно, бесконечномерном) гильбертовом пространстве признаков:, гдеотображаетв это пространство. Если последнее всё же конечномерно, то мы можем использовать матричную запись; элементыв этой записи обычно называют первичными переменными (primal variables). Пространство функцийтакже оказывается гильбертовым: соответствующее скалярное произведение имеет вид Таким образом,, если. Любому отображениюможно сопоставить симметричную положительно-определённую функцию; функции такого вида называются ядрами. В силуфундаментальной теоремы о представителелюбое решение задачи (4) принимает вид В отличие от, векторвсегда конечномерен: его размерность равна размеру обучающей выборки. Элементыназывают двойственными (dual) переменными. Упомянутый результат позволяет перейти от минимизациив бесконечномерном пространстве функций (или, что то же самое, минимизациив бесконечномерном пространстве признаков), к минимизации в конечномерном пространстве двойственных переменных: Если в качестве функции потерь взять квадратичную, то получим ядровую регрессию; если же взять hinge loss, то SVM. Заметим, что двойственная задача полностью сформулирована в терминах ядра: отображение в потенциально бесконечное пространство признаковболее нигде не возникает. Поэтому мы можем использовать в качествелюбую симметричную положительно определённую функцию двух переменных, не думая о том, для какого пространства признаков оно будет ядром (есть теорема, что такие функции всегда являются ядрами). Это может быть очень полезно. Так, если для эмпирического NTK в инициализацииимеем, но совершенно неочевидно, какое отображениесоответствует предельному NTK:. Таким образом, мы можем использоватьв качестве ядрав двойственной задаче (6) наряду с линейнымили гауссовским ядром. Такой подход привлекателен тем, что обучение ядровых методов более устойчиво и имеет меньше гиперпараметров. При этом можно надеяться, что результат обучения ядрового метода с NTK в качестве ядра будет близок к результату обучения соответствующей нейронной сети. Основная проблема ядровых методов в том, что они требуют вычисления матрицы Грама ядра на обучающем наборе данных. Её размер(где– размер выборки), так что применение ядровых методов на больших данных сильно усложняется. Более того, наивное вычисление динамикииз формулы (3) требует обращения матрицы Грама, которое занимаетвремени. Тем не менее, определённые оптимизации существуют. Так например, в работеKernel methods through the roofпредлагается способ приближённого вычисления () запамяти и времени. Другие подходы см. в работахFast Finite Width Neural Tangent KernelиNeural tangents: Fast and easy infinite neural networks in python. Так или иначе, на малых наборах данных выражение (3) можно вычислить точно, см. результаты в работеHarnessing the power of infinitely wide deep nets on small-data tasks. Существуют также примеры задач, в которых матрицу Грама ядра достаточно посчитать только для малых, см., например,Simple, Fast, and Flexible Framework for Matrix Completion with Infinite Width Neural Networks. Ещё одна проблема использования NTK в ядровых методах состоит в том, что явный подсчёт предельного NTK доступен только для сетей, состоящих из слоёв из определённого класса. В этот класс входят полносвязные и свёрточные слои, average pooling, ряд нелинейностей с одним аргументом (включая, например, ReLU и erf), layer norm, но не входят max pooling и batch norm, часто используемые в реальных архитектурах. Явный подсчёт предельного NTK для «хороших» сетей реализован вбиблиотеке NeuralTangents; часть явных формул для подсчёта можно найти в статьеOn exact computation with an infinitely wide neural net. Тем не менее, даже в тех случаях, когда посчитать предельное NTK не представляется возможным, в качестве ядра для ядрового метода можно использовать эмпирическое NTK в инициализации Такое ядро можно рассматривать как шумную и смещённую оценку предельного; для уменьшения шума можно использовать Монте-Карло оценку матожидания. Некоторые оптимизации подсчёта эмпирического ядра см. в работеNeural tangents: Fast and easy infinite neural networks in python. NTK не единственное ядро, которое можно сопоставить нейронной сети. Так, NNGP-ядро– это ядро гауссовского процесса, реализуемого сетью в пределе бесконечной ширины. Подробнее можно почитать в работахDeep Neural Networks as Gaussian Processes,Wide neural networks of any depth evolve as linear models under gradient descent,Random neural networks in the infinite width limit as Gaussian processesили вконспекте лекций. Можно показать, что оно соответствует NTK-ядру для сети, в которой учится лишь выходной слой. Так как, в отличие от NTK, для подсчёта NNGP-ядра не требуется обратный проход (backward pass), последнее более вычислительно эффективно;Towards nngp-guided neural architecture search– пример работы, в которой предпочтение отдаётся NNGP-ядру именно по этой причине.",
    "source_type": null,
    "useful_links": [
      {
        "text": "фундаментальной теоремы о представителе",
        "url": "https://en.wikipedia.org/wiki/Representer_theorem"
      },
      {
        "text": "Kernel methods through the roof",
        "url": "https://arxiv.org/pdf/2006.10350.pdf"
      },
      {
        "text": "Fast Finite Width Neural Tangent Kernel",
        "url": "https://arxiv.org/pdf/1806.07572.pdf"
      },
      {
        "text": "Neural tangents: Fast and easy infinite neural networks in python",
        "url": "https://arxiv.org/pdf/1912.02803.pdf"
      },
      {
        "text": "Harnessing the power of infinitely wide deep nets on small-data tasks",
        "url": "https://arxiv.org/pdf/1910.01663.pdf"
      },
      {
        "text": "Simple, Fast, and Flexible Framework for Matrix Completion with Infinite Width Neural Networks",
        "url": "https://arxiv.org/pdf/2108.00131.pdf"
      },
      {
        "text": "библиотеке NeuralTangents",
        "url": "https://github.com/google/neural-tangents"
      },
      {
        "text": "On exact computation with an infinitely wide neural net",
        "url": "https://arxiv.org/pdf/1904.11955.pdf"
      },
      {
        "text": "Neural tangents: Fast and easy infinite neural networks in python",
        "url": "https://arxiv.org/pdf/1912.02803.pdf"
      },
      {
        "text": "Deep Neural Networks as Gaussian Processes",
        "url": "https://arxiv.org/pdf/1711.00165.pdf"
      },
      {
        "text": "Wide neural networks of any depth evolve as linear models under gradient descent",
        "url": "https://arxiv.org/pdf/1902.06720.pdf"
      },
      {
        "text": "Random neural networks in the infinite width limit as Gaussian processes",
        "url": "https://arxiv.org/pdf/2107.01562.pdf"
      },
      {
        "text": "конспекте лекций",
        "url": "https://arxiv.org/pdf/2012.05760.pdf"
      },
      {
        "text": "Towards nngp-guided neural architecture search",
        "url": "https://arxiv.org/pdf/2011.06006.pdf"
      }
    ]
  },
  {
    "document_title": "Сети бесконечной ширины",
    "url": "https://education.yandex.ru/handbook/ml/article/seti-beskonechnoj-shiriny",
    "section_title": "Сходимость эмпирического ядра",
    "text": "Вы этом параграфе мы покажем, что при определённой параметризации эмпирическое NTK не зависит ни от времени, ни от инициализации. Мы начнём с иллюстративного примера, прежде чем формулировать строгую теорему. Рассмотрим сеть с одним скрытым слоем, скалярным выходом и гауссовской инициализацией весов; вход для простоты тоже положим скалярным: Здесь– ширина скрытого слоя. Следуя одной из стандартных схем инициализации из статьиDelving deep into rectifiers: Surpassing human-level performance on imagenet classification, дисперсия каждого слоя выбирается обратно пропорционально числу входных нейронов (подробнее см. в параграфе протонкости обучения нейросетей). Назовём описанную выше параметризацию стандартной. Для сходимости ядра нам придётся несколько её видоизменить: Назовём новую параметризацию NTK-параметризацией. Отметим, что распределение выходов нейронов в инициализации остаётся неизменным при переходе от стандартной к NTK-параметризации. Что меняется – это динамика градиентного спуска: Приприращения весов для такой параметризации имеют порядок, в то время как сами веса имеют порядокпри. Поэтомуипридля любого данногои. Другими словами, с ростом размера скрытого слоя градиент будет стремиться к нулю, и каждый из весов в пределе останется в начальной точке. Сравним с градиентным спуском в стандартной параметризации: В этом случае веса выходного слоя имеют порядокпри, но получают приращения порядкав этот момент времени, в то время как веса входного слоя имеют порядокпри, но получают в этот момент времени приращения порядка. В новой параметризации эмпирическое NTK выглядит следующим образом: Так какипридля любых заданныхи, выражение выше асимптотически эквивалентно а значит, сходится к прив силу закона больших чисел. Предельное ядроне зависит ни от времени, ни от инициализации. Мы будем называть это ядронейрокасательнымили простоNTK(его не стоит путать с эмпирическим NTK). Ещё раз подчеркнём, что это работает для NTK-параметризации, но не для стандартной. Для стандартной параметризации эмпирическое NTK в инициализации расходится с шириной: Подробнее мы поговорим об этом в одном из следующих параграфов. Для NTK-параметризации сходимость эмпирического ядра выполняется не только для сетей с одним скрытым слоем. Так, рассмотрим полносвязную сеть сслоями: Здесь,идля всех остальных. Положим, что веса инициализируются из стандартного нормального распределения. Поставим задачу оптимизации дифференцируемой функции потерь: где– объединение всех весовсети. Теорема ниже доказана воригинальной работе по NTK: Теорема. В предположениях выше, еслиизи липшицева иизи липшицева, тосходится кпо вероятности припоследовательно. Оказывается, что эта теорема верна не только для полносвязных сетей с гладкими активациями. Определимтензорную программукак начальный набор переменных определённых типов и последовательность команд. Каждая команда порождает новую переменную, действуя на уже имеющиеся. Переменные бывают трёх типов: :матрицы с независимыми элементами из; : вектора размерас асимптотически независимыми нормальными элементами; : образы-переменных относительно поэлементных нелинейностей. Для переменнойзаписьбудет означать, чтоимеет тип. Команды бывают следующие: trspop:(перевести переменную типасо значениемв переменную типасо значением); matmul:; lincomb:; nonlin:(здесь мы несколько выходных векторовагрегируем в один с помощью покоординатной, возможно, нелинейной функции). Формализм тензорных программ позволяет представить прямой и обратный проход широкого класса нейронных архитектур, который включает свёрточные сети, рекуррентные сети, сети с residual слоями. Хотя и ни одна из операций выше не может порождать новые-переменные (веса), любое наперёд заданное число шагов градиентного спуска можно представить в рамках одной тензорной программы (посредством «развёртывания» шагов градиентного спуска). Назовём величинушириной тензорной программы.Основная «предельная» теорема тензорных программ представлена ниже: Master theorem(G. Yang,Tensor programs III: Neural matrix laws). Рассмотрим тензорную программу с-величинами, удовлетворяющую определённым начальным условиям. Пусть все нелинейностии функцияполиномиально ограничены. Тогда почти наверное при, гдеимогут быть вычислены по некоторым рекурентным правилам. Оказывается, что если тензорная программа выражает прямой и обратной проход в некоторой нейронной сети, то NTK сети в инициализации всегда можно представить в видедля некоторой функции, см.Tensor programs II: Neural tangent kernel for any architecture.Таким образом, теорема выше доказывает существование и детерминированность предельного ядра в инициализации, а также даёт способ его вычисления. Более того, это верно и для ядра в любой фиксированный момент времени, см.Tensor Programs IIb. В качестве иллюстрации обратимся вновь к сети с одним скрытым слоем. Рассмотрим тензорную программу, вычисляющую прямой и обратный проходы на входахи. Такая программа порождает следующие-величины:,,и. Напомним, что эмпирическое NTK равно Положив получим выражение как раз в виде, требуемом Master Theorem.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Delving deep into rectifiers: Surpassing human-level performance on imagenet classification",
        "url": "https://arxiv.org/pdf/1502.01852.pdf"
      },
      {
        "text": "тонкости обучения нейросетей",
        "url": "https://academy.yandex.ru/handbook/ml/article/tonkosti-obucheniya"
      },
      {
        "text": "оригинальной работе по NTK",
        "url": "https://arxiv.org/pdf/1806.07572.pdf"
      },
      {
        "text": "Tensor programs III: Neural matrix laws",
        "url": "https://arxiv.org/pdf/2009.10685.pdf"
      },
      {
        "text": "Tensor programs II: Neural tangent kernel for any architecture",
        "url": "https://arxiv.org/pdf/2006.14548.pdf"
      },
      {
        "text": "Tensor Programs IIb",
        "url": "https://arxiv.org/pdf/2105.03703.pdf"
      }
    ]
  },
  {
    "document_title": "Сети бесконечной ширины",
    "url": "https://education.yandex.ru/handbook/ml/article/seti-beskonechnoj-shiriny",
    "section_title": "Стандартная параметризация и эволюция ядра",
    "text": "Как было отмечено в предыдущем параграфе, эмпирическое NTK двухслойной сети расходится с шириной при стандартной параметризации. При, так какнезависимы и имеют порядок, сумма расходится пропорционально.Так как для квадратичной функции потерь, предсказание модели в любой точкеполучает приращение порядкана первом же шаге обучения; для задачи регрессии такая модель теряет смысл. Однако для классификации величина предсказаний не играет роли: для бинарной классификации важен лишь знак, а для многоклассовой – индекс максимального логита. Таким образом, в этом случае, несмотря на расходящееся ядро, предел при бесконечной ширине имеет смысл, см.Dynamically Stable Infinite-Width Limits of Neural Classifiers. Рассмотрим нормализованное эмпирическое NTK. Его предел в инициализации равен. Назовём этот предел нормализованным NTK и обозначим. В отличие от ядра в NTK-параметризации, нормализованное NTK при стандартной параметризации зависит от времени: Напомним, как выглядит градиентный спуск в стандартной параметризации: При,, в то время как. Так каки, для любого, не зависящего от,,,и. Наивная оценка сумм даётдля любого, не зависящего от. Таким образом, нормализованное ядро зависит от времени даже в пределе бесконечной ширины. Экспериментальный анализ эволюции ядра реальной нейронной сети в стандартной параметризации см. в работеDeep learning versus kernel learning. Преимущество нейронных сетей над ядровыми методами, в том числе с NTK, может быть связано, в частности, с зависимостью предельного ядра от времени. В самом деле, ядро измеряет «похожесть» в некотором пространстве признаков. Для NTK это пространство фиксировано, в то время как нейронная сеть меняет своё ядро по ходу обучения, возможно, делая его более подходящим для задачи.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Dynamically Stable Infinite-Width Limits of Neural Classifiers",
        "url": "https://arxiv.org/pdf/2006.06574.pdf"
      },
      {
        "text": "Deep learning versus kernel learning",
        "url": "https://arxiv.org/pdf/2010.15110.pdf"
      }
    ]
  },
  {
    "document_title": "Модели с латентными переменными",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
    "section_title": "Зачем нужны модели с латентными переменными",
    "text": "Предположим, что мы делаем анализ данных для банка, и нам предоставили данные о годовых зарплатах клиентов. В этом графике заметны три моды, которым, наверное, соответствуют три кластера клиентов. Неопытный аналитик мог бы проигнорировать это и попытаться описать график в отчете для руководства с помощью двух чисел — средней зарплаты и стандартного отклонения зарплат. Однако данные с гистограммы ниже имеют точно такое же среднее и стандартное отклонение, как и мультимодальные данные выше. Распределение совсем другое, правда? Очевидно, что графики выглядят совершенно по-разному, и правильная интерпретация первого графика может принести бизнесу дополнительные деньги (скажем, если банк научится предлагать клиентам из каждого кластера более кастомизированные предложения). Так что не надо пытаться описывать мультимодальные данные с помощью унимодальных распределений. Проблема заключается в том, что нам неизвестно, к какому кластеру относится каждый клиент, и неизвестны характеристики кластеров — как же их тогда описать? Для каждого кластера можно попытаться задать свои параметры (среднее и дисперсию). Но как определить, из какого кластера конкретный клиент в выборке? Более того, один клиент может, например, «на 0.7» относиться к одному кластеру и «на 0.3» к другому. Как решать такую задачу «мягкой» кластеризации («мягкой», потому что один объект может относиться к нескольким кластерам)? Мы могли бы действовать итерационно. Сначала зададим начальное приближение на параметры распределений. Например, в нашем случае с клиентами банка из графика можно предположить, что среднее для первой кластера 30, для второго — 40, для третьей — 50, а стандартные отклонения у всех равняются, скажем, 10. Зная эти начальные параметры, мы можем для каждого клиента посчитать степень принадлежности к каждому из трёх кластеров (важно не забыть отнормировать эти числа, чтобы их сумма действительно равнялась единице). Дальше мы бы могли пересчитать наши средние и дисперсии, «взвешивая» вклад объектов пропорционально степени их принадлежности к каждому кластеру, и таким образом уточнить средние и дисперсии для всех трёх кластеров. Повторяя эти два шага последовательно, мы получили бы средние и дисперсии кластеров, а для каждого объекта — степени принадлежности к кластерам. Это — EM-алгоритм, подробнее о нём мы поговорим ниже. Кстати, оказывается, что и метод кластеризации K-средних во многом сродни EM-алгоритму (и на самом деле представляет собой его предельный случай). Действительно, мы сначала случайно расставляем центры кластеров. Затем мы для каждого объекта пересчитываем расстояние до центра каждого кластера, после чего получаем «вес» объекта в каждом кластере («вес» в том смысле, что чем ближе объект к центру кластера, тем больше этот объект учитывается при пересчете центра этого кластера) через нормировку расстояний. Теперь, если мы применяем настоящий метод K-средних, то приписываем объект к кластеру с самым большим «весом», после чего опять пересчитываем центры кластеров и потом опять измеряем вес для каждого объекта кластера. Строгое же применение EM-алгоритма даёт «мягкую» версию метода K-средних.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели с латентными переменными",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
    "section_title": "Смеси распределений",
    "text": "Говорят, что распределениеявляетсясмесью распределений, если его плотность имеет вид где: — число компонент; — вероятности компонент; — функции правдоподобия, то есть функции вероятности компонент (в дискретном случае) или их плотности (в абсолютно непрерывном случае). Проиллюстрируем это понятие на примере с банком. Будем считать, что распределения компонент смеси принадлежат некоторому параметрическому семейству:(например, гауссовскому с параметром). Мы можем говорить, что каждое из распределенийзадаёт свой кластер, причём каждый кластер имеет некоторую априорную вероятность. Если у нас нет дополнительных данных, разумно положить. Если же нам, к примеру, известно, что какой-нибудь кластер описывает сравнительно малочисленную группу людей, эти вероятности окажутся различными. Таким образом, мы проинтерпретировали нашумягкую кластеризациюв терминах смеси распределений.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели с латентными переменными",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
    "section_title": "Как генерировать из смеси распределений",
    "text": "Рассмотрим следующий эксперимент: сначала из дискретного распределениявыбирается номер, а затем из распределениявыбирается значение. Покажем, что распределение переменнойбудет представлять собой смесь. Введемскрытую переменную, отвечающую за то, к какой компоненте смеси будет относиться очередной. Пусть она представляет собой-мерный бинарный случайный вектор, ровно одна компонента которого равна единице: Вероятность того, что единице будет равна-я компонента, положим равной: Запишем распределение сразу всего вектора: Теперь, когда номер компоненты смеси известен, сгенерируемиз распределения: или, что то же самое, Проверим, чтоимеет нужное нам распределение. Запишем совместное распределение переменныхи: Чтобы найти распределение переменной, нужно избавиться от скрытой переменной: Суммирование здесь ведется по всем возможным значениям, то есть по всем-мерным бинарным векторам с одной единицей: Мы получили, что распределение сгенерированной переменнойв описанном эксперименте представляет собой смеськомпонент.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели с латентными переменными",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
    "section_title": "Модели со скрытыми переменными",
    "text": "Рассмотрим вероятностную модель с наблюдаемыми переменнымии параметрами, для которой задано правдоподобие. Предположим, что в модели также существуютскрытые переменные, описывающие её внутреннее состояние и, возможно, недоступные для непосредственного наблюдения (как то, к какому из кластеров относится клиент). Тогда правдоподобиеназываетсянеполным, а правдоподобие—полным. Они связаны соотношением Нашей основной целью будет создать хорошую модель, то есть оценить параметры. И оказывается, что с помощью введения скрытых переменных нередко удаётся существенно упростить правдоподобие и эффективно решить задачу. Рассмотрим пример со смесями распределений. В качестве наблюдаемых переменных здесь выступает выборка, в качестве скрытых переменных— номера компонент, из которых сгенерированы объекты (здесь каждый из—-мерный вектор), в качестве параметров — априорные вероятности и параметры компонент. Неполное правдоподобие выглядит так: Правдоподобие здесь имеет видлогарифма суммы. Если приравнять нулю его градиент, то получатся сложные уравнения, не имеющие аналитического решения. Данное правдоподобие сложно вычислять: оно не является выпуклым (а точнее, вогнутым) и может иметь много локальных экстремумов, поэтому применение обычных итерационных методов для его непосредственной максимизации приводит к медленной сходимости. Рассмотрим теперь полное правдоподобие: Оно имеет видсуммы логарифмов, и это позволяет аналитически найти оценки максимального правдоподобия на параметрыпри известных переменныхи. В общем случаетакже стараются выбирать таким способом, чтобы распределениеоказалось «лучше» исходного. В каком именно смысле, мы увидим дальше. Проблема, впрочем, заключается в том, что нам не известны скрытые переменные, поэтому их необходимо оценивать одновременно с параметрами, что никак не легче максимизации неполного правдоподобия. Осуществить это позволяетEM-алгоритм.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели с латентными переменными",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
    "section_title": "EM-алгоритм",
    "text": "EM-алгоритм решает задачу максимизации полного правдоподобия путём попеременной оптимизации по параметрам и по скрытым переменным. Опишем сначаланаивныйспособ оптимизации. Зафиксируем некоторое начальное приближение для параметров. При известных наблюдаемых переменныхи параметрахмы можем оценить скрытые переменные, найдя их наиболее правдоподобные значения: Зная скрытые переменные, мы можем теперь найти следующее приближение для параметров: Повторяя итерации до сходимости, мы получим некоторый итоговый вектор параметров. Данная процедура, однако, далека от идеальной — и ниже мы предложим решение, которое приводит к более качественным результатам. Воспользуемся байесовским подходом. Точечные оценки параметров несут меньше информации, чем их распределение; учтём это и будем оптимизировать не, а условное распределение. Как и прежде, зафиксируем вектор параметров, но вместо точечной оценки вычислим апостериорное распределение на скрытых переменных, которое будет в некотором смысле оптимальным образом описывать распределениепри известныхи. В этом заключаетсяE-шагEM-алгоритма. Отметим, что вычислитьаналитически возможно не для всех распределений, и скрытые переменные стоит подбирать так, чтобы это всё-таки получилось. Теперь мы должны произвести оптимизацию по. Для этого возьмём логарифм полного правдоподобияи усредним его по всем возможным значениям скрытых переменных: Формально говоря, мы нашли матожидание логарифма полного правдоподобия по апостериорному распределению на скрытых переменных. НаM-шагеновый вектор параметров находится как максимизатор данного матожидания: EM-алгоритм состоит в чередовании E-шага и M-шага. Можно показать, что такой итерационной процесс всегда не уменьшает правдоподобие и сходится. Не всегда получается подобрать латентные переменныетак, чтобыможно было выразить аналитически, то есть на E-шаге не удаётся минимизироватьпо. В такой ситуации иногда приходится брать оптимум не по всему пространству распределений, а только по некоторому семейству — например, параметрическому, в котором оптимизацию можно проводить градиентными методами. В максимально упрощённой ситуации мы возьмём семейство дельта-функций, то есть вместо распределения набудем брать просто точечную оценку. Такая модификация EM-алгоритма называетсяжёстким EM-алгоритмом. В начале параграфа мы упоминали кластеризацию методом K-средних и отмечали, что EM-алгоритм даёт «мягкую» версию алгоритма: на E-шаге мы не приписываем однозначно точку к какому-то из кластеров (то есть не берём точечную оценку скрытой переменной «номер кластера, к которому принадлежит точка»), а сопоставляем ей вероятности принадлежности каждому из кластеров (то есть распределение на скрытые переменные). Настоящий метод K-средних как раз таки соответствует жёсткому EM-алгоритму.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели с латентными переменными",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
    "section_title": "Разделение смеси гауссиан",
    "text": "Пусть теперь нам известно, чтоточек были семплированы из Kразныхгауссовских распределений и нам неизвестно, какая точка из какого распределения пришла в выборку. Нам нужно оценить параметры (,) для первого распределения, (,) для второго и, соответственно, (,) для-го распределения. Если мы знаем, что точкапришла из распределения, то её правдоподобие в равно: Напомним, что— это латентная переменная, обозначающая номер гауссианы (от 1 до), из которой была просемплирована точка. Например, если точкапросемплирована из распределения с номером 3, то в формулу вместо (,) нужно подставлять. Воспользуемся EM-алгоритмом для нахождения параметров (,). Сначала инициализируем их: Зная, выполним E-шаг: нужно найтиили что то же самое, для каждого объектанайти распределение на вероятности. Как найти апостериорную вероятность, если мы знаеми у нас есть приближение? Ответ — по формуле Байеса: где— априорная вероятность того, что объектаполучен из распределения с номером. На первом шаге априорную вероятность можно положить равнойдля всех гауссиан. Введём обозначение — правдоподобие того, что объектпришел из нормального распределения с параметрами. Тогда по формуле Байеса: Вот так для каждого объектапо начальному приближениюмы посчитаем распределение— с какими вероятностями объектприходит из той или иной компоненты смеси. Теперь выведем формулы для М-шага. Запишем производную и приравняем к, чтобы найти экстремум: Отсюда Мы получили конечную формулу для пересчетапои предыдущему значению. Причем у этой формулы есть простая интерпретация — каждый объект мы взвешиваем с его вероятностью принадлежности к этому классу. Теперь посчитаем производную по(обратите внимание, что именно по квадрату): Стало быть, Мы снова получили интерпретируемый результат: подсчитывая дисперсию для-ой гауссианы, мы учитываем вес каждого объекта при подсчете среднеквадратичноого отклонения. То есть веса — вероятности происхождения из той или иной компоненты смеси. Сравните эту формулу с формулой для подсчета выборочной дисперсии, где каждый изобъектов вносит одинаковый вклад в дисперсию с весом: Вы можете «пощупать» EM-алгоритм в задаче разделения вероятностной смеси с помощью интерактивной визуализации — попробуйте сделать E и M шаги и последить за изменениями параметров: после одной итераций алгоритма можно выбрать точку на графике и наблюдать за вероятностью её принадлежности к разным кластерам.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Модели с латентными переменными",
    "url": "https://education.yandex.ru/handbook/ml/article/modeli-s-latentnymi-peremennymi",
    "section_title": "Вероятностный PCA",
    "text": "Теперь давайте рассмотрим простой пример того, как введение латентных переменных может помочь выделять новые информативные признаки в данных. Предположим, что мы имеем выборку данных(вектор-строку), где каждый объект имеетпризнаков (предположим, что числоочень большое). Это достаточно типичная ситуация, например, при работе с текстами или изображениями. Теперь введём следующую вероятностную модель, где— латентный вектор-строка меньшей размерности, а, где— единичная матрица размером,— скаляр больший 0. Что означает эта модель? Она означает, что наши сложные многоразмерные данныемогут иметь более простое малоразмерное представление, а отображениелинейно с точностью до нормально распределенного шума. Заметим, что так как, отсюда следует, что. Зададим априорное распределение накак стандартное нормальноеи распишем совместное распределениечерез условное и априорное: Чтобы восстановить параметры,и латентные переменные, снова воспользуемся EM-алгоритмом. На E-шагемы оцениваем распределение напри фиксированныхи: По формуле Байеса распределение напри условии: С точностью до констант и слагаемых, которые не зависят от, логарифм правдоподобия равен: Обозначим, тогда Если теперь взять от этого экспоненту, увидим, что. M-шаг. Теперь мы оптимизировать пои: Приравняв производные к, можно найти: Вероятностный PCA хорош тем, что: как любая байесовская модель, может служить промежуточным участком в более сложной вероятностной модели; если в данных есть пропуски, то вероятностный PCA легко обобщается и на этот случай с добавлением дополнительных скрытых переменных; так как параметрыи оценки наполучаются через итерационный EM-алгоритм, то вероятностный PCA может быть вычислительно эффективнее. Так, в вычислениях и промежуточных формулах нигде не используется матрица, и все рассматриваемые матрицы имеют меньший размер. Связь с обычным PCA Как вероятностный PCA связан с обычным, который мы изучили в теме про разложение матриц? Напомним, что в обычном SVD-разложении мы полагали, что. Давайте опять положим, что разница междуиесть гауссовский шум с нулевым средним: или Если зададим априорное распределение накак стандартное нормальное, тогдаи соответственно. Теперь сделаем обратную заменуи убедимся, что оценка максимального правдоподобия в точности равна. (напомним, чтоиэто вектор-строки). Заметим, что число есть след матрицы, состоящей из этого числа, поэтому можно преобразовать вторую часть, как Отсюда следует, что Приравняв производную пок нулю, найдем: Оценка максимума правдоподобия на: Эту оценку можно интерпретировать как среднюю потерю дисперсии по всем проигнорированным сингулярным направлениям. Если же— константа, то приполучаем обычный PCA. Другой способ получить обычный PCA — это вместо обычного EM-алгоритма воспользоваться его жёсткой модификацией. Теперь предлагаем вам потренировать изученный материал на практике. Предлагаем вам выполнить лабораторную работу, которая покрывает большинство тем главы “Вероятностные модели”. Скачайтеноутбукс лабораторной работой. В нём вы найдете описания заданий и дополнительные материалы. Задания из лабораторной прикреплены к этому параграфу в виде задач в системе Яндекс Контест. Чтобы проверить себя, отправляйте решения по соответствующим задачам в систему. Успехов в практике!",
    "source_type": null,
    "useful_links": [
      {
        "text": "ноутбук",
        "url": "https://yastatic.net/s3/ml-handbook/admin/autohw_lm_probability_7de017bf61.ipynb?updated_at=2024-03-07T13:21:16.239Z"
      }
    ]
  },
  {
    "document_title": "Энтропия и семейство экспоненциальных распределений",
    "url": "https://education.yandex.ru/handbook/ml/article/entropiya-i-semejstvo-eksponencialnyh-raspredelenij",
    "section_title": "Энтропия",
    "text": "Представим, что вы пронаблюдали значениенекоторой случайной величины. Как измерить количество информации, которое вы при этом получили? Следующие соображения кажутся в этом плане вполне естественными: чем выше вероятность, тем более ожидаемо появление значенияи, соответственно, менее информативно; и наоборот, наблюдение маловероятного значенияобычно даёт обильную пищу для размышлений и повышает; при наблюдении двух независимых реализацийислучайной величинылогично складывать полученную информацию:. Указанные соображения наводят на мысль, что информацию следует считать убывающей функцией от вероятности:. Кроме того, функциядолжна превращать произведение в сумму, поскольку для независимых случайных величиниравенствовлечёт На самом деле выбор тут небогат. Единственная непрерывная функция, обладающая такими свойствами, — это логарифм:. Основание логарифма может быть любым числом больше единицы. Поскольку информацию измеряют в битах и байтах, в теории информации обычно предпочитают двоичные логарифмы. Однако для вычислений удобнее использовать натуральный логарифм, и по умолчанию мы будем подразумевать именно его (кстати, соответствующую единицу информации называют «нат»). Среднее количество информации, которое несёт в себе значение дискретной случайнойс распределением вероятностей, вычисляется по формуле Это так называемаяэнтропия(Шэннона). Пример. Рассмотрим схему Бернулли с вероятностью «успеха». Энтропия её результата равна Давайте посмотрим на график этой функции: Минимальное значение (нулевое) энтропия принимает приили. Исход такого вырожденного эксперимента заранее известен, и чтобы сообщить кому-то о его результате, достаточнобит информации. Иначе говоря, можно вообще ничего не передавать, и так всё предельно ясно. Максимальное значение энтропии достигается в точке, что вполне соответствует тому, что припредсказать исход эксперимента сложнее всего. Упражнение. Найдите энтропию геометрического распределения с вероятностью «успеха»:, Следующие свойства энтропии дискретной случайной величинывытекают прямо из определения: неотрицательность:; при некотором(нулевую энтропию имеют вырожденные распределения и только они); , если случайная величина имеет конечный носитель мощности. Последнее свойство выводится изнеравенства Йенсена. Применяя его к выпуклой вверх логарифмической функции, с учётом нормировки условияполучаем Вопрос на подумать. Итак, всякое распределение с носителемимеет энтропию не больше. А у какого распределения она в точности равна? Чтобы вычислить энтропию непрерывной случайной величины, надо, как водится, сумму заменить на интеграл, и получится формуладифференциальной энтропии: Замечание.В дальнейшем мы будем использовать одинаковый терминэнтропиякак для дискретных, так и для непрерывных случайных величин, для краткости опуская словодифференциальнаяв последнем случае. Кроме того, энтропию распределения, заданного через pmf или pdf, будем обозначать. Такое обозначение позволяет избежать привязки к случайной величине там, где это излишне. Если, то обозначенияиэквивалентны. Также отметим, что энтропию можно записать в виде математического ожидания: Пример. Найдём энтропию нормального распределения. Его плотность равна, следовательно, Делая в последнем интеграле замену, получаем, что По свойству гамма-функции. Таким образом, Как видно, энтропия гауссовского распределенияне ограничена ни сверху, ни снизу: И да, в отличие от энтропии дискретного распределения дифференциальная энтропия может быть отрицательной. Это связано с тем, что плотность может принимать значения больше единицы, и поэтому математическое ожидание её логарифма с обратным знаком может оказаться меньше нуля. В частности, с нормальным распределением так происходит, если. Упражнение. Найдите энтропию показательного распределения. В задачах машинного обучения истинное распределение, из которого приходят наблюдения, обычно неизвестно, и его пытаются приблизить распределениемиз некоторого класса модельных распределений.Дивергенция Кульбака-Лейблера(KL-дивергенция,относительная энтропия) позволяет оценить расстояние между распределениямии: в дискретном случае и в непрерывном. KL-дивергенцию можно представить в виде разности: Здесь вычитаемое – это уже знакомая нам энтропия распределения, которая показывает, сколько в среднем бит требуется, чтобы закодировать значение случайной величины. Уменьшаемое носит названиекросс-энтропиираспределенийи.Кросс-энтропию можно интерпретировать как среднее число бит для кодирования значения случайной величиныалгоритмом, оптимизированным для кодирования случайной величины. Иными словами, дивергенция Кульбака-Лейблера говорит о том, насколько увеличится средняя длина кодов для значений, если при настройке алгоритма кодирования вместоиспользовать. Подробнее об этом вы можете почитать, например, вданном посте. Дивергенция Кульбака-Лейблера в некотором роде играет роль расстояния между распределениями. В частности,, причём дивергенция равна нулю, только если распределения совпадают почти всюду (для дискретных и непрерывных распределений это означает, что они просто тождественны). Но при этом она не является симметричной: вообще говоря,. Упражнение. Пользуясь неравенством,, докажите неотрицательность KL-дивергенции. Пример.С помощью KL-дивергенции измерим расстояние между двумя гауссианамии. Подставляя явные выражения для плотностей находим Из свойств нормального распределения вытекает, что Таким образом, Как и должно быть, полученное выражение равно нулю, если гауссианы совпадают. При равных дисперсияхполучаем, что. Это выражение остаётся прежним, если поменять местамии, поэтому в этом случае. Если же, то выражение дляявно отличается от, что лишний раз показывает несимметричность KL-дивергенции. Упражнение. Найдите дивергенцию Кульбака-Лейблера двух показательных распределенийи. При определении KL-дивергенции мы уже встречались скросс-энтропией В зависимости от типа распределений кросс-энтропия вычисляется по формуле Поскольку задача минимизации KL-дивергенции между неизвестным распределением данныхи модельным распределениемэквивалентна задаче минимизации кросс-энтропии. Разница между ними равна энтропии распределения, которая, очевидно, не зависит от. В машинном обучении кросс-энтропию часто используют в качестве функции потерь в задаче классификации наклассов. Истинное распределение на каждом обучающем объекте задаётся с помощью one hot encoding и является вырожденным: Классификатор обычно выдаёт вероятности принадлежности каждому из классов, Функция потерь на одном объекте полагается равной кросс-энтропии между истинным и предсказанным распределениями: И это вполне логично: чем ближе модельное распределение к истинному, тем меньше наши потери. В идеале, если. Чтобы вычислить функцию потерь по обучающей выборке изобъектов с метками, обычно берут усреднённную кросс-энтропию",
    "source_type": null,
    "useful_links": [
      {
        "text": "неравенства Йенсена",
        "url": "https://ru.wikipedia.org/wiki/%D0%9D%D0%B5%D1%80%D0%B0%D0%B2%D0%B5%D0%BD%D1%81%D1%82%D0%B2%D0%BE_%D0%99%D0%B5%D0%BD%D1%81%D0%B5%D0%BD%D0%B0"
      },
      {
        "text": "данном посте",
        "url": "https://habr.com/ru/post/484756/"
      }
    ]
  },
  {
    "document_title": "Энтропия и семейство экспоненциальных распределений",
    "url": "https://education.yandex.ru/handbook/ml/article/entropiya-i-semejstvo-eksponencialnyh-raspredelenij",
    "section_title": "Принцип максимальной энтропии",
    "text": "Впараграфе про оценки параметровбыли описаны различные свойства параметрических оценок и методы их получения, например, метод моментов или метод максимального правдоподобия. В принципе, если мы уже выбрали для наших данныхнекоторое параметрическое семейство, моделирующее их распределение, восстановить его параметры чаще всего можно по выборочному среднемуи/или выборочной дисперсии. А теперь представим, что мы посчитали эти (или какие-то другие) статистики, а семейство распределений пока не выбрали. Как же совершить этот судьбоносный выбор? Давайте посмотрим на следующие три семейства и подумаем, в каком из них мы бы стали искать распределение, зная его истинные матожидание и дисперсию? Почему-то хочется сказать, что в первом. Почему? Второе не симметрично – но что нас может заставить подозревать, что интересующее нас распределение не симметрично? С третьим проблема в том, что, выбирая его, мы добавляем дополнительную информацию как минимум о том, что у распределения конечный носитель. А с чего бы? У нас такой инфомации вроде бы нет. Общая идея такова: мы будем искать распределение, которое удовлетворяет только явно заданным нами ограничениям и не отражает никакого дополнительного знания о нём. Таким образом, искомое распределение должно обладать максимальной неопределённостью при заданных ограничениях, или, говоря более научно, иметь максимально возможную энтропию. В самом деле, энтропия выражает нашу меру незнания о том, как ведёт себя распределение, и чем она больше – тем более «‎произвольное» распределение, по крайней мере, в теории. В этом и заключаетсяпринцип максимальной энтропиидля выбора модели машинного обучения. Как мы уже видели выше, среди распределений с конечным носителем максимальную энтропию имеет равномерное распределение. Примеры геометрического и нормального распределения показывают, что энтропия распределений с бесконечным носителем (счётным или континуальным) может быть сколь угодно большой, и среди них нет какого-то одного распределения с максимальной энтропией. Однако в более узком классе распределений с фиксированным средним и/или дисперсией найти распределение с максимальной энтропией, как правило, можно. Пример. Покажем, что среди распределений на множестве натуральных чисели математическим ожиданиеммаксимальную энтропию имеет геометрическое распределение. Для минимизации энтропиис учётом ограничений воспользуемсяметодом множителей Лагранжа, согласно которому требуется минимизировать функцию Лагранжа Приравняем к нулю частные производные по: Отсюда следует, что, так что распределение действительно получается геометрическое. Параметрыинайдём из уравнений Деля первое уравнение на второе, получаем, или. Далее из первого уравнения находим. Итак, а это и есть геометрическое распределение с параметром. У непрерывных распределений возможны более интересные комбинации из ограничений на носитель и параметры. И конечно же, первую скрипку среди распределений с максимальной энтропией играет гауссовское распределение. Пример. Докажем, что среди распределений наc математическим ожиданиеми дисперсиейнаибольшую энтропию имеет нормальное распределение. Пусть– некоторое распределение со средними дисперсией,. Как было показано выше,. Запишем дивергенцию Кульбака-Лейблера: Так как KL-дивергенция всегда неотрицательна, получаем, чтопри любом распределении, удовлетворяющем заданным ограничениям. Можно показать, что максимальную энтропию среди многомерных распределений с вектором среднихи матрицей ковариацийимеет также гауссовское распределение. Упражнение. Докажите, что среди распределений на отрезкемаксимальную энтропию имеет равномерное распределение. Упражнение. Докажите, что среди распределений на промежуткес математическим ожиданиеммаксимальную энтропию имеет показательное распределение. Как выяснилось, многие классические распределения имеют максимальную энтропию при весьма естественных ограничениях. Но как быть, если даны не эти конкретные, а какие-то другие ограничения? Есть ли какой-нибудь надёжный алгоритм вывода распределения с максимальной энтропией, позволяющий избежать случайных озарений и гаданий на кофейной гуще? Оказывается, что при некоторых не очень обременительных ограничениях ответ можно записать с помощью распределений экспоненциального класса.",
    "source_type": null,
    "useful_links": [
      {
        "text": "параграфе про оценки параметров",
        "url": "https://education.yandex.ru/handbook/ml/article/parametricheskie-ocenki"
      },
      {
        "text": "методом множителей Лагранжа",
        "url": "https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BC%D0%BD%D0%BE%D0%B6%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%B9_%D0%9B%D0%B0%D0%B3%D1%80%D0%B0%D0%BD%D0%B6%D0%B0"
      }
    ]
  },
  {
    "document_title": "Энтропия и семейство экспоненциальных распределений",
    "url": "https://education.yandex.ru/handbook/ml/article/entropiya-i-semejstvo-eksponencialnyh-raspredelenij",
    "section_title": "Экспоненциальное семейство распределений",
    "text": "Говорят, что параметрическое семейство распределений относится кэкспоненциальному классу, если его pdf (или pmf) может быть представлена в виде где – векторнатуральных параметровраспределения; — неотрицательная функция (base measure), часто равная единице; —нормализатор(partition), обеспечивающий суммируемость pmf или интегрируемость pdf в единицу: —log-partition; — вектордостаточных статистикраспределения. Пример. Покажем, что нормальное распределениепринадлежит экспоненциальному классу. Оно имеет два параметра, поэтому такую же размерность имеюти вектор-функция. Распишем плотность: Положим,, Остаётся выразить функциючерези. Упражнение. Выразите partitionи log-partitionчерези запишите плотность нормального распределения в экспоненциальном виде. Пример. Покажем, что распределение Бернуллипринадлежит экспоненциальному классу. Его pmfможно записать как Параметр здесь один, поэтому натуральный параметртоже один:. Такая функция отназывается функцией логитов и активно участвует в построении моделилогистической регрессии. Остальные функции положим равными,,. Остаётся выразить partition через: Итак,, и экспоненциальный вид распределения Бернулли записывается как Вопрос на подумать. Принадлежит ли к экспоненциальному классу семейство равномерных распределений на отрезках? Казалось бы, да, ведь В чём может быть подвох? К экспоненциальным семействам относятся многие непрерывные и дискретные распределения из часто встречающихся в теории и на практике, в том числе нормальное; распределение Пуассона; экспоненциальное; биномиальное; геометрическое; бета-распределение; гамма-распределение; распределение Дирихле. Как выглядят натуральные параметры, достаточные статистики и нормализаторы этих и других распределений из экспоненциального класса, можно посмотреть навикипедии. К экспоненциальным семействам не относятся, например, равномерное распределение,-распределение Стьюдента, распределение Коши, смесь нормальных распределений. Если распределениепринадлежит экспоненциальному классу, то моменты его достаточных статистикмогут быть получены дифференцированием функции. Утверждение.. Доказательство.По правилу дифференцирования сложной функции имеем Нормализаторзаписывается в виде интеграла который мы продифференцируем внесением градиента внутрь под знак интеграла: Таким образом, Если, то в соответствии с только что доказанным частная производнаядаёт-й момент распределения. Упражнение. Вычислите производные по натуральным параметрам от log-partition для распределения Бернуллии нормального распределенияи проверьте, что они совпадают со значениями соответствующих моментов. Кстати, можно продифференцировать ещё раз и доказать, что Возможно, вас удивил странный и на первый взгляд не очень естественный вид. Но всё не просто так: оказывается, что оценка максимального правдоподобия параметров распределений из экспоненциального класса устроена очень интригующе. Запишем функцию правдоподобия i.i.d. выборки: Её логарифм равен Дифференцируя по, получаем Приравниваяк нулю и пользуясь равенством, находим Таким образом, теоретические матожидания всех компонентдолжны совпадать с их эмпирическими оценками, а метод максимального правдоподобия совпадает с методом моментов дляв качестве моментов. И в следующем пункте выяснится, что распределения из экспоненциальных семейств обладают максимальной энтропией среди тех, что имеют заданные моменты. Теперь мы наконец готовы сформулировать одно из самых любопытных свойств семейств экспоненциального класса. В следующей теореме мы опустим некоторые не очень обременительные условия регулярности. Просто считайте, что для хороших дискретных и абсолютно непрерывных распределений, с которыми вы в основном и будете сталкиваться, это так. Теорема. Пусть параметрраспределениявыбран так, что для некоторого фиксированного. Тогда распределениеобладает наибольшей энтропией среди распределенийс тем же носителем, для которых. Выше мы уже находили обладающее максимальной энтропией распределение на множестве натуральных чисел с заданным математическим ожиданием. Таковым оказалось геометрическое распределение. Теорема Купмана—Питмана—Дармуа позволяет сделать это гораздо быстрее.В данном случае у нас лишь одна функция, которая соответствует фиксации математического ожидания. Искомое дискретное распределение имеет вид Это уже похоже на геометрическое распределение с параметром. Его математическое ожидание равно, что по условию должно равняться. Итак, наше распределение с максимальной этропией выглядит так: Пример. Среди распределений на всей вещественной прямой с заданным математическим ожиданиемнайдём распределение с максимальной энтропией.",
    "source_type": null,
    "useful_links": [
      {
        "text": "логистической регрессии",
        "url": "https://education.yandex.ru/handbook/ml/article/linear-models#linejnaya-klassifikaciya"
      },
      {
        "text": "википедии",
        "url": "https://en.wikipedia.org/wiki/Exponential_family#Table_of_distributions"
      }
    ]
  },
  {
    "document_title": "Обучение представлений",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-predstavlenij",
    "section_title": "Нейронные сети и выучивания представлений",
    "text": "Нейронные сети можно рассматривать, как механизм автоматического выучивания представлений, поэтому современные методы выучивания представлений существенно сконцентрированы на использовании нейросетей. Напомним, что нейронная сеть состоит из набора дифференцируемых преобразований, примененных друг за другом к объектудля получения предсказания целевой переменной. Обычно преобразования содержат обучаемые параметры, которые настраиваются в процессе обучения по данным. Преобразования в литературе часто называют слоями. Результат применения преобразования к его входу мы будем называть скрытыми представлениями или активациями. Активации любого слоя можно использовать как представления объекта. Представления с разной глубины нейронной сети будут обладать разными свойствами. Рассмотрим свёрточные нейронные сети для изображений. Активации первых слоёв обычно видят только маленькие части исходной картинки, другими словами, имеют маленькийreceptive field. Такие активации могут реагировать — принимать большие значения — только на низкоуровневые детали, маленькие фрагменты изображения. По мере увеличения глубины receptive field становится больше, а активации начинают реагировать на более высокоуровневые абстракции, такие как формы и части объектов. Активации последних слоёв имеют большой receptive field и реагируют на уже на объекты и группы объектов. На изображении ниже показаны части картинок (патчи), каждая группа из 9 изображений максимизирует значение определенной активации в обученной нейронной сети. Размер патча зависит от receptive field активации, а максимизация ведется по датасету реальных изображений: выбираем топ-9 патчей из датасета по значению активации. Для активаций, взятых с ранних слоев, нейроны реагируют на низкоуровневые детали. По мере увеличения глубины нейроны начинают реагировать на более высокоуровневые объекты. Большая часть методов, которые мы рассмотрим ниже, за исключением матричной факторизации (в зависимости от того, как на это взглянуть), будут использовать активации нейросети в качестве представлений. Поэтому, обучить представления и обучить нейросеть это почти синонимы. Большинство отличий будет состоять в том, как эти нейронные сети обучаются и какую архитектуру имеют. Нейронные сети можно обучать из случайной инициализации, а можно стартовать с вектора весов, обученного на внешнем датасете. К примеру, если вы решаете задачу классификации изображений, часто инициализация части вашей нейронной сети весами, предобученными на популярном датасете ImageNet, ускорит и улучшит обучение. Такой процесс называется fine-tuning («дообучение» / «файнтюнинг»): Как можно усложнять эту схему: Добавлять в модель много новых, обучающихся с нуля слоёв (на картинке мы добавляем один, но можно и больше); Не обязательно копировать все слои, можно копировать только сколько-то первых. Дообучать как все веса модели, так и какую-то часть. К примеру, можно заморозить скопированные слои и дообучать только новые части модели. Для файнтюнинга часто используют постепенное увеличение (warm-up) learning rate на первых эпохах обучения. Это позволяет сетке «привыкнуть» к новой задаче и архитектуре. Пример: В некотором смысле хорошая инициализация работает как праер на функции, которые могут быть выучены после дообучения. Поэтому дообучение часто требует в разы меньше данных, чем обучение со случайной инициализации.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обучение представлений",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-predstavlenij",
    "section_title": "Supervised обучение",
    "text": "Обучение представлений через решение supervised задач — это простой и популярный способ обучения представлений. Рассмотрим его на примере задачи поиска изображений (image retrieval) Задача: Рассмотрим задачу поиска изображений. Каждое изображение хочется закодировать вектором признаков (представлением) так, чтобы вектора признаков похожих изображений были близки. При чем тут обучение представлений?Image retrieval часто рассматривается как задача обучения представлений. Хочется получить алгоритм, который по изображению выдаст вектор (представление объекта) так, чтобы близость векторов по какой-то простой (скажем, евклидовой) метрике означала схожесть объектов. Идея: Возьмём активации с последнего слоя из нейросети, предобученной на большом размеченном датасете.Для задач зрения почти всегда имеется ввиду предобучение на задаче классификации. Также мы предполагаем, что высокоуровневая разметка собрана человеком. Почему такие представления могут адекватно решать задачу поиска изображений?Классификационная сеть будет неявно поощрять, чтобы у похожих изображений векторы активаций тоже были близки. К примеру, перед последнем слоем классификационной сети активации кошек и собак должны быть распознаны линейными классификаторами — активации картинок одного класса должны быть близки друг к другу. А за счет похожих паттернов визуально похожие коты будут находиться ближе друг к другу, чем непохожие. Для начала нам нужно обучить нейросеть на большом размеченном датасете картинок/текста/звука/... (pretext problem) Обычно лучше всего работает предобучение на задачах классификации. Почему так происходит? Пока непонятно. Возможно, это связано с тем, что для классификации удобнее собирать датасеты, а возможно это хорошие свойства задачи или CrossEntropy функции потерь. Для изображений часто используется предобучение на датасетеImageNet— классификация на 1000 классов, 1.3M изображений в обучающей выборке, ~ 150 GiB. Для текстов, обычно решают задачу языкового моделирования, на набирающем популярность датасетThe Pile~ 825 GiB. Затем мы дообучаем нейросеть на более похожем на нашу задачу размеченном датасете(если такой есть; если нет пропускаем этот шаг). После — оставляем только первыеслоёв. Aктивации слояберём в качестве представлений объектов Агрегируем активации по пространственным координатам, чтобы получитьвектордля каждого объекта. Часто используется покомпонентное среднее или максимум (скажем, глобальный пулинг для изображений). Наконец, используем признаки или предобученные веса для решения целевой задачи (downstream problem). Supervised подход можно применять для различных типов данных. Всё, что нужно — это большой размеченный датасет, хоть и отдалённо, но похожий на целевые данные. Для музыки это может быть задача классификации жанра, для видео — задача классификация действий, для текста — классификация тематик. 👍 Благодаря выученным представлениям мы сможем решать целевую задачу, не имея для неё большого датасета;👎 Нужен большой размеченный датасет, близкий для целевой задачи;👎 Оптимальные представления для датасета, на котором мы предобучаемся, могут сколь угодно плохо подойти для целевой задачи. К примеру, представления, полученные на ImageNet, плохо подойдут для медицинских изображений (Raghu2019). На рисунке ниже показан пример того, как представления помогают решать задачу поиска. Запрос находится в самом левом столбике. Зеленым отмечены верно найденные изображения, красным — неверно найденные, синим — изображения из стоп-листа. Как видно, система вполне неплохо решает задачу поиска изображений. Подробнее про такой подход для поиска изображений можно почитать в работах (Babenko 2014,Babenko 2015). СтатьяBig Transfer (BiT): General Visual Representation Learning (Kolesnikov at el. 2019) даёт ряд важных советов, о том, на что именно стоит обратить внимание при supervised обучении c целью переноса представлений и весов модели на новые задачи. Рассмотрим их подробнее. Большие и разнообразные датасеты: Увеличение размера pretex-датасета вносит существенный вклад в качество решения downstream задачи. Авторы продемонстрировали, что при предобучении переход от 1М изображений (ImageNet) к 14М изображений (ImageNet21k) к 300M изображений (JFT), стабильно улучшает качество дообучения на новой задаче с маленьким числом размеченных примеров. Да, тут мы заходим на территорию, когда ImageNet рассматривается как маленький датасет. Большие pretext модели: Увеличение датасета при недостаточном размере модели может навредить. Нужно одновременно иметь большие модели и большие датасеты. Одно из возможных объяснений такое: с увеличением датасета модель должна предсказывать правильные ответы на трейне для огромного числа точек. При этом нельзя работать очень плохо хоть на каких-то точках, ведь когда гибкости недостаточно, моделька настраивается «так себе» во многих областях пространства, что может ухудшить финальное качество алгоритма. Долгое обучение: Большие модели требуют много шагов оптимизации. Мотивация:После supervised обучения расстояния между эмбеддингами не обязаны хорошо отражать треубуемую для решения нашей задачи«похожесть». Поэтому хочется, чтобы«похожесть»моделировалась известным расстоянием (к примеру евклидовым). Для этого былапредложенатриплетная фунция потерь илиtriplet loss(Schroff at el. 2015). Триплетный лосс обучается на тройках объектов (якорный объект, негативный к якорному, позитивный к якорному). Информация о позитивных и негативных объектах – это один из видов разметки. Этот лосс может использоваться как для обучения с нуля, так и для дообучения. Отметим, что объекты не обязательно должны быть из одного домена: к примеру, якорный объект может быть картинкой, а позитивные и негативые объекты текстами. Таким образом, мы сможем находить «подходящие» тексты к картинкам и наоборот. рассмотрим тройки объектов, где— позитивный пример к,— негативный пример к будем притягиватьии отталкиватьи одним из популярных лоссов для решения такой задачи является triplet loss: представляется нейронной сетью — параметер зазора — в некотором смысле усложняет задачу:придостаточно, чтобы позитивный эмбединг был ближе якорному, чем негативный;с параметроммы начинаем требовать, чтобы позитивный был ближе, чем негативный, как минимум на. придостаточно, чтобы позитивный эмбединг был ближе якорному, чем негативный; с параметроммы начинаем требовать, чтобы позитивный был ближе, чем негативный, как минимум на. лоссоптимизируем по параметрам. Обучение с триплет лоссом сильно зависит от алгоритма формирования троек.Если формировать тройки случайно, то большинство троек будут слишком легкими, не информативными. Негативные объекты будет слишком легко отличить от позитивных, поэтому обучающего сигнала от таких троек будет мало. Поэтому хочется собрать наиболее сложные тройки из всех объектов в датасете или минибатче. Такой процесс называется hard negative/positive mining и часто используется для обучения с триплетной функцией потерь. 🧪Примеры: Диалоговая система:— фраза;— подходящий ответ;— ответ не в тему. — фраза; — подходящий ответ; — ответ не в тему. Верификация лица:— лицо которое хотим верифицировать;— тот же человек, что и в, но с других ракукрсов, в другом освещении, ...;— лица других людей. — лицо которое хотим верифицировать; — тот же человек, что и в, но с других ракукрсов, в другом освещении, ...; — лица других людей. 👍 Обучение метрических эмбедингов (metric learning), в отличие от supervised подхода, использует информацию о метрике, что позволяет выучить более релевантные представления для целевой задачи. 👎 Все еще требует разметки (на тройки объектов). 👎 Обучение с триплетным лоссом часто ведет себя нестабильно (еще нестабильнее, чем обучение нейросетей для других задач).",
    "source_type": null,
    "useful_links": [
      {
        "text": "ImageNet",
        "url": "https://www.image-net.org/"
      },
      {
        "text": "The Pile",
        "url": "https://pile.eleuther.ai/"
      },
      {
        "text": "Raghu2019",
        "url": "https://arxiv.org/abs/1902.07208"
      },
      {
        "text": "Babenko 2014",
        "url": "https://link.springer.com/content/pdf/10.1007/978-3-319-10590-1_38.pdf"
      },
      {
        "text": "Babenko 2015",
        "url": "https://openaccess.thecvf.com/content_iccv_2015/papers/Babenko_Aggregating_Local_Deep_ICCV_2015_paper.pdf"
      },
      {
        "text": "Статья",
        "url": "https://arxiv.org/abs/1912.11370"
      },
      {
        "text": "предложена",
        "url": "https://arxiv.org/abs/1503.03832"
      }
    ]
  },
  {
    "document_title": "Обучение представлений",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-predstavlenij",
    "section_title": "Self-supervised обучение",
    "text": "В этом разделе мы хотим показать, что нейронные сети и представления можно предобучать без рукотвороной разметки. МотивацияМы разобрали supervised предобучение нейронных сетей и их использование для извлечения признаков. Однако supervised подходы не всегда эффективны. Supervised обучение требует больших размеченных датасетов. Разметка данных — это трудоёмкий и дорогой процесс, на выходе от которого всё равно получается шумная, и зачастую смещенная разметка. Поэтому от ручной разметки данных хочется уйти или хотя бы постараться её минимизировать. Этого можно добиться, если научиться использовать неразмеченные данные для предобучения. Неразмеченные данные генерируются в огромном количестве, и их значительно проще собирать. Это позволит нам обучаться наогромныхколлекциях данных, размер которых был бы недостижим при необходимости сбора разметки. Также в каждом объекте, изображении, звуке или тексте содержитсяв разы больше информации, которую можно учитывать при обучении, чем закодировано в одном таргете. К примеру, один из тысячи классов можно закодировать всего десятью битами, а изображение содержит мегабайты внутренней полезной информации, котрую можно использовать для обучения. Поэтому подходы, которые могут обучаться без разметки, но с использованием внтурненнией информации, потенциально могут выучивать более хорошие представления, чем supervised подходы. 💡Основная идея self-supervised обучения — обучение через решение синтетических supervised задач (pretext problems), источником разметки в которых является сам объект (текст, изображение, или видео). Отсюда и приставка \"self\" в названии подхода. предсказание объекта по его компактному описанию; предсказание слова по контексту; предсказание закрытой части изображения по открытой; предсказание будущих кадров по прошлым. Если всё это кажется вам supervised-задачами, вы правы! Приставлка self- означает отсутствие внешней разметки. Признаки и веса, выученные для решения, казалось бы, бесполезных pretext задач, на практике работают как очень хороший претрейнинг для решения supervised задач (downstream problems). Это позволяет достигать отличного качества, используя в сотни раз меньше размеченных данных по сравнению с чисто supervised подходами. Осталось ответить на вопрос: какие pretext задачи использовать? Универсального ответа нет, но оказывается, что многие pretext задачи используют контекст для обучения. Подробнее об этом расскажем далее. Почему контекст так важен для обучения? Обучение людей, как и обучение алгоритмов, неразрывно связано с использованием контекста. При изучении иностранного языка часто прибегают к упражнениям вида «Вставте правильные слова в текст». Чтобы выполнить такое упражнение, человеку нужно учитывать контекст и предсказывать значения незнакомых слов, если это необходимо для понимания текста. Предложенная профессором Южно-Калифорнийского университетаСтивином Крашенйном«гипотезы входного материала» (input hypothesis) предполагают, что для эффективного изучения языка человеку нужно читать и слушать текст, который немного превышает его текущий уровень. Скажем, содержит 10-15% незнакомых слов, но при этом остается понятным. Такой способ обучения требует восстановления значения незнакомых слов из контекста. Визуальный контекст также широко используется при обучении детей. Вы можете помнить упражнения, в которых нужно было найти лишний предмет, закончить рисунок или раскрасить изображение. Такие задания требуют учета визуального контекста для решения задачи: важно уметь понимать принадлежность разных рисунков к одной группе, генерировать изображение, наблюдая только некоторую его часть и так далее. Self-supervised обучение представлений и моделей глубокого обучения использует похожие идеи обучения из контекста. К примеру, модель word2vec(Mikolov et al. 2013)и BERT(Devlin et al. 2018)выучивают эмбединги слов, решая задачу предсказания слов по контексту. С философией word2vec вы уже познакомились впараграфепро нейросети для работы с последовательностями. А некоторые модели для картинок решают пазлы(Doersch,Noroozi et al. 2017), дополняют изображения или звуки(van den Oord et al. 2018), раскрашивают фотографии(Zhang et al. 2016)и ищут похожие объекты(Chen et al. 2020). Последнюю из них — SimCLR – мы подробно разберём ниже. SimCLR — метод, который первым продемонстрировал, что self-supervised предобучение может достигать того же качества что и supervised обучение. Он основан на контрастивной функции потерь (contrastive loss), и в некотором смысле решает задачу поиска похожих объектов. Также мы разберем метод self-supervised предобучения для vision tranformer, который, в некотором смысле, дорисовывает картинку, а также демонстрирует, что методы self-supervised предобучения для изображений и текстов во многом похожи. Стоит отметить, что pretext задачи, которые мы будем обсуждать ниже, не являются «серебряной пулей». Известно, что такие задачи работают как хороший претрейнинг. Другими словами, позволяют получить хорошее качество для некоторых downstream задач (классификация, детекция, сегментация) после дообучения на небольшом количестве размеченных примеров. Хорошего понимания, почему эти методы работают, в области пока нет. Скорее всего, разные типы задач (downstream problems) будут требовать разных методов претрейнинга, но это мы поймём только в ближайшие несколько лет. SimCLR решает синтетическую задачу поиска похожих изображений. Вот как он работает на верхнем уровне: Для каждого изображения в минибатче генерируются две аугментации; Выбирается одно из изображений; одна из его аугментаций считается запросом, вторая — позитивным ответом, аугментации остальных объектов — негативными примерами; Цель модели — для каждого «запроса» найти позитивный пример. Выученные веса могут быть использованны для «дообучения»/«файнтюнинга» сети под финальную задачу. SimCLR оптимизирует контрастив лосс (contrastive loss), который фактически является кросс энтропией на positive-negative разметке: где— это косинусное расстояние, a лоссработает следующим образом: Контрастивная функция потерьпритягивает друг к другу эмбединги запросаи позитивного примера, в то же самое время отталкивая эмбединги негативных примеров; Максимумбудет достигается в точке, поэтому эмбединги аугментаций одной и той же картинки будут притягиваться; Знаменатель требует, чтобы негативные эмбединги были далеко от запроса. Интуиция: На контрастивную функцию потерь можно смотреть как на поиск ответа по запросу, который ведется только среди всех эмбедингов в текущем минибатче. Такая задача требует сохранения информации про контент на изображении (что, вообще говоря, не очень просто) и в то же время понижения размерности, так как эмбедингиобычно имеют сравнительно низкую размерность. Размер минибатча: Размер минибатча влияет на количество отрицательных примеров. Чем больше отрицательных примеров — тем более сложную задачу мы ставим перед нейросетью. Существует некоторый баланс между сложностью задачи и качеством выученных представлений. Слишком простые задачи (то есть маленькие батчи) обычно не позволяют выучить хороших представлений: простая задача может хорошо решаться даже с помощью «плохих» представлений. Поэтому SimCLR обучается хорошо только на очень больших мини-батчах (с тысячами примеров). неразмеченный датасет изображений операцию аугментации изображения энкодер(типичные значения M~2048) проекция(типичные значения K~128) ✍️ В примере сверху Семплируем мини-батч объектов; Для каждого объекта в минибатче:— Cемплируем две аугментации;— Вычисляем эмбединги;— Вычисляем проекции; Вычисляем contrastive loss, используя.— Вдва слагаемых из-за того, что в паре (изображение, аугментация), вообще говоря, любой элемент можно выбрать в качестве запроса (другой тогда будет позитивным примером). Тем самым из одного мини-батча картинок мы можем сделать два мини-батча для обучения SimCLR.— Функция потерьвычисляется для низкоразмерных проекций. Делаем шаг по градиенту, повторяем с шага 1 пока не сойдёмся; Используемдля генерации эмбедингов или файнтюнинга под supervised задачу. Точно никто не знает, но приведем следующую гипотезу: Контрастивная функция потерь требует различать аугментации разных изображений. При этом эмбеддинги должны содержать информацию о контенте изображения, чтобы осуществлять поиск аугментаций одинаковых изображений по ключу. Этот процесс позволяет создать представления изображений, сохраняющие достаточно много информации про контент, чтобы решать не только задачу поиска аугментаций, но и другие задачи. Претрейнинг, который мы обсудили выше, позволяет эффективно дообучать модели и получать качество, сравнимое с supervised обучением, используя в 100 раз меньше размеченных примеров. Оговорка в том, что эти результаты получены второй весрсией метода SimCLRv2(Chen at. el, 2020).SimCLRv2 TLDR; модели больше, глубже сеть проекции, улучшение качества происходит за счет дистиляции. Одна из самых популярных self-supervised задач в NLP — это предсказание замаскированных токенов (masked tokens predictionDevlin at el. 2019). При обучении такая модель (обычно transformer) видит текст, в котором некоторые токены заменены на специальный токен [MASK]; задача модели — правильно предсказать замаскированные токены по контексту. Оказывается, такой претрейнинг позволяет очень хорошо адаптировать модель для решения разных задач, таких как классификация текстов, используя при этом мало размеченных примеров. Можно ли использовать такой self-supervised подход для изображений? Оказывается, что да! В этом помогает vision transformer. В последнее время модели на основеvision transformer(ViT)(Dosovitskiy at el. 2020)бурно развиваются и компьютерного зрения. В supervised режиме для задачи классификации vision transformer обучается следующим образом: Изображение нарезается на квадратные патчи одинакового размера; Затем патчи вытягиваются в последовательность; Каждый патч вытягивается в столбец пикселей; Каждый стобец проецируется обучаемой матрицей; К каждому вектору с шага 4 добавляются positional encoding (без позиционных эмбеддингов трансформер не учитывает позицию токена в последовательности, а positional encoding кодирует позицию токена и позволяют трансформеру учитывать эту информацию); Векторы с шага 5 подаются в трансформер; Классификационный токен на выходе предсказывает распределение на классы; Вычисляется кросс-энтропия, делается шаг по её градиенту. ViT не используют локальные операции, такие как свёртки. Как следствие, такие модели требуют заметно больше данных и параметров для обучения (300M изображений по сравнению со стандартным размером размеченного датасета 1.3М). Но оказывается, чтоBERT-like self-supervised обучение применимо и для моделей vision transformer, и позволяет обучать их без использовния гиганских датасетов. Какие self-supervised задачи на замаскированных патчах решают авторы статьи: Предсказание среднего цвета в замаскированном патче; Предсказание патча низкого разрешения и одновременное предсказание цвета; Предсказание патча высокого разрешения разрешение с использованием-лосса. Во всех случаях обучается и файнтюнится вся сеть целиком. Этот интересный пример показывает, что pretext-задачи придуманные, для NLP-сетей могут быть применены и к задачам зрения.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Стивином Крашенйном",
        "url": "https://en.wikipedia.org/wiki/Stephen_Krashen"
      },
      {
        "text": "(Mikolov et al. 2013)",
        "url": "https://arxiv.org/abs/1301.3781"
      },
      {
        "text": "(Devlin et al. 2018)",
        "url": "https://arxiv.org/abs/1810.04805"
      },
      {
        "text": "параграфе",
        "url": "https://academy.yandex.ru/handbook/ml/article/beta-nejroseti-dlya-raboty-s-posledovatelnostyami"
      },
      {
        "text": "(Doersch",
        "url": "https://arxiv.org/abs/1505.05192"
      },
      {
        "text": "Noroozi et al. 2017)",
        "url": "https://arxiv.org/abs/1603.09246"
      },
      {
        "text": "(van den Oord et al. 2018)",
        "url": "https://arxiv.org/abs/1807.03748"
      },
      {
        "text": "(Zhang et al. 2016)",
        "url": "https://arxiv.org/abs/1603.08511"
      },
      {
        "text": "(Chen et al. 2020)",
        "url": "https://arxiv.org/abs/2002.05709"
      },
      {
        "text": "(Chen at. el, 2020)",
        "url": "https://arxiv.org/pdf/2006.10029.pdf"
      },
      {
        "text": "Devlin at el. 2019",
        "url": "https://arxiv.org/pdf/1810.04805.pdf"
      },
      {
        "text": "(Dosovitskiy at el. 2020)",
        "url": "https://arxiv.org/pdf/2010.11929.pdf"
      }
    ]
  },
  {
    "document_title": "Обучение представлений",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-predstavlenij",
    "section_title": "Послесловие",
    "text": "Глубинное обучение — в существенной степени наука о представлениях сложных объектов. В этом параграфе мы лишь слегка затронули несколько важных тем: supervised предобучение, self-supervised предобучение, и metric learning. Self-supervised предобучение — это важный новый раздел глубинного обучения, который, вероятно, поможет серьезно сократить количество необходимой разметки во многих приложениях. Генеративные модели VAE/inverse-GANs также широко используются для получения и обработки представлений. О них вы сможете прочитать в следующих параграфах.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обучение представлений",
    "url": "https://education.yandex.ru/handbook/ml/article/obuchenie-predstavlenij",
    "section_title": "Почитать по теме",
    "text": "Contrastive Representation Learning, Lilian Weng, May 2021. Self-Supervised Representation Learning, Lilian Weng, Nov 2019. Самообучение (Self-Supervision), Александр Дьяконов, Июнь 2020. Self-Supervised Learning | ICLR, Yann LeCun, May 2020. Self-Supervised Learning | UC Berkeley, CS294-158 Deep Unsupervised Learning, Aravind Srinivas, Spring 2020. Unsupervised Representation Learning | DeepMind x UCL.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Contrastive Representation Learning",
        "url": "https://lilianweng.github.io/lil-log/2021/05/31/contrastive-representation-learning.html"
      },
      {
        "text": "Self-Supervised Representation Learning",
        "url": "https://lilianweng.github.io/lil-log/2019/11/10/self-supervised-learning.html"
      },
      {
        "text": "Самообучение (Self-Supervision)",
        "url": "https://dyakonov.org/2020/06/03/%D1%81%D0%B0%D0%BC%D0%BE%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-self-supervision/"
      },
      {
        "text": "Self-Supervised Learning | ICLR",
        "url": "https://youtu.be/8TTK-Dd0H9U"
      },
      {
        "text": "Self-Supervised Learning | UC Berkeley, CS294-158 Deep Unsupervised Learning",
        "url": "https://youtu.be/dMUes74-nYY"
      },
      {
        "text": "Unsupervised Representation Learning | DeepMind x UCL",
        "url": "https://youtu.be/f0s-uvvXvWg"
      }
    ]
  },
  {
    "document_title": "Методы второго порядка",
    "url": "https://education.yandex.ru/handbook/ml/article/metody-vtorogo-poryadka",
    "section_title": "Метод Ньютона",
    "text": "Итак, наша задача – безусловная оптимизация гладкой функции Как и при оптимизации методом градиентного спуска, мы будем искать направление уменьшения функционала. Но в этот раз мы будем использовать не линейное приближение, а квадратичное: Формула Тейлора говорит нам брать. Приравняв к нулю градиент этой квадратичной аппроксимации, мы получаем направление спуска для метода Ньютона: Обозначим. В таком случае мы можем записать итеративный алгоритм спуска: В литературе методом Ньютона называется такой метод при, при другом размере шагеэтот метод называютдэмпированным(damped) методом Ньютона. Обсудим, в чем главная особенность метода Ньютона и в чем заключается выигрыш по сравнению с классическим градиентным спуском. Таких особенностей две. Первая связана со скоростью его сходимости. А именно – в окрестности решения он сходитсяквадратично. Теорема. Пусть функцияимеет достаточно гладкий гессиан и сильно выпукла в точке оптимума. Тогда, что для всякогодля метода Ньютона свернодля константызависящей только от. Второе приятное свойство заключается в устойчивости метода Ньютона к плохой обусловленности задачи (в отличие от метода градиентного спуска). Разберёмся, что это значит. Когда мы говорим о плохой обусловленности задачи, мы имеем в виду, что гессиан в точке оптимума плохо обусловлен, то есть отношение максимального и минимального собственных чисел является большим числом. Геометрически это значит, что линии уровня функции вблизи оптимума похожи на очень вытянутые эллипсоиды; мы уже обсуждали, что в такой ситуации градиентный спуск может работать медленно. А как справится метод Ньютона? Оказывается, намного лучше. И связано это с его инвариантностью к линейным преобразованиям. А именно, рассмотрим функциюдля некоторой невырожденной матрицы. Обозначим. Посмотрим, как связаны градиент и гессиан новой функции с градиентом и гессианом старой. Воспользуемся производной сложной функции: Рассмотрим теперь траекториюметода Ньютона, запущенного из точкидля поиска минимума функции, и траекториюметода Ньютона, запущенного для поиска минимума функции. Если, то для всехбудет верно, то есть траектории получаются одна из другой при помощи этого линейного преобразования, другими словами, траектории исходной и новой функции подобны. Вернёмся теперь к плохо обусловленной задаче минимизации функции. Рассмотрим линейное преобразованиеи функцию. Тогда для функциичисло обусловленности гессиана в точке оптимума равно в точность единице (проверьте это!), а траектории для этой новой, хорошо обусловленной функции, и старой, плохо обусловленной, подобны. В частности, метод Ньютона не будет, как градиентный спуск, долго метаться где-то на задворках вытянутой эллиптической «ямки» вокруг оптимума, а быстро ринется к центру. Можно сказать, что метод Ньютона правильно улавливает кривизну линий уровня функции и это позволяет ему быстрее сходиться к оптимуму. Эту идею стоит запомнить, она появляется в некоторых вдохновлённых методами второго порядка модификациях SGD. Также еще можно заметить, что свойства, которые мы требуем от функции в теореме о квадратичной сходимости, вообще говоря, не сохраняются при линейных преобразованиях: могут поменяться константы липшицевости и сильной выпуклости. Это простое замечание побудило исследователей ввести класс самосогласованных функций, более широкий и линейно инвариантный, для которого метод Ньютона также сходится. Подробнее об этом можно узнать вразделе 9.6 книги S. Boyd &L. Vandenberghe, Convex Optimization. От хорошего переходим к плохому: к слабостям метода Ньютона. Во-первых, мы имеем квадратичную скорость сходимости только вокрестностиоптимума. А если мы стартуем из произвольно удалённой точки, то нам, как и в случае градиентного спуска, требуется подбор шагапри помощи линейного поиска (что нам вряд ли по карману). Если подбирать шаг не хочется, можно прибегнуть к интересному теоретическому методу получения гарантий на глобальную сходимость – добавлению кубической регуляризации. Другая проблема кроется в формуле пересчета следующей итерации:вычисление и обращение гессиана. Конечно, вместо обращения гессиана можно честно решать систему линейных уравнений, но асимптотика остается прежней:, а от затрат памяти на хранение матрицывообще некуда деться. А это значит, что, например, решать линейную регрессию с ~10000 признаками методом Ньютона попросту невозможно. Есть и третья, малозаметная проблема: дословно метод Ньютона не работает для невыпуклых задач, посколькуне будет положительно опредленной иперестанет быть направлением спуска. Для решения этой проблемы можно немного «подпортить» нашу аппроксимацию и рассмотреть матрицу вида, такую чтостанет положительно определенной, и уже её подставлять в нашу квадратичную модель. Идея подмены гессиана на что-то более подходящее – это главная идея квазиньютоновских методов, обсуждаемых далее. Итак, общие выводы: Метод Ньютона – теоретически оптимальный метод, который автоматически улавливает кривизну функции в окрестности оптимума. Для размерностион уже не является эффективным, поскольку требует вычисления и хранения гессиана, а также решения системы линейных уравнений с его участием (что может быть в общем случае очень дорого).",
    "source_type": null,
    "useful_links": [
      {
        "text": "разделе 9.6 книги S. Boyd &L. Vandenberghe, Convex Optimization",
        "url": "https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf"
      }
    ]
  },
  {
    "document_title": "Методы второго порядка",
    "url": "https://education.yandex.ru/handbook/ml/article/metody-vtorogo-poryadka",
    "section_title": "Квазиньютоновские методы",
    "text": "Чтобы придумать, как бороться с проблемами метода Ньютона, нужно посмотреть на него с другой стороны, а для этого мы обратимся ненадолго к решению задачи нахождения нуля векторной функции. Итак, рассмотрим совершенно новую задачу. Пусть дана функцияи нужно найти её ноль, то есть такое, что. Связь с оптимизацией (по крайней мере в выпуклом случае) довольно проста: если взять, то корень уравненияи будет точкой оптимума. Сначала рассмотрим одномерный случай. Как найти ноль функции с помощью итеративной процедуры? Логично поступить следующим образом: проводим касательнуюк графику функции и находим точку, в которой линейная аппроксимация обнуляется: откуда получаем формулу пересчета Известно, что этот метод обладает квадратичной скоростью сходимости в одномерном мире, что очень перекликается с методом Ньютона для оптимизации – и не просто так. Если рассмотреть многомерный случай, то вычисление производной заменяется на вычисление якобиана векторнозначной функции. В случаенаш якобиан становится гессианом и получаем в точности обычный метод Ньютона для оптимизации: Пусть мы хотим найти такую точку, что. В одномерном случае мы можем подменить вычислениевычислением её приближения. Откуда получаем формулу пересчета: Графически, этот метод выглядит следующим образом: Скорость сходимости этого метода несколько ниже, чем у метода Ньютона (линейная, а не квадратичная), но зато мы теперь не должны вычислять производную! В текущем виде, используя просто подмену градиента на его конечно-разностную аппроксимацию, не очевидно, как обобщить этот метод на произвольную размерность. Но, если посмотреть на название метода и на картинку, как он работает, мы видим, что мы по сути проводим через два предыдущих приближения секущую, а затем выбираем ноль этой секущей в качестве следующей точки. В многомерном случае мы можем выписать соответствующее ей уравнение, где– матрица размера, которая должна удовлетворять так называемомууравнению секущей(secant equation): Теперь, чтобы выбрать следующую точку, нужно найти ноль секущей, то есть А теперь рассмотрими добавим в итеративную схему выше размер шага. Тогда мы получаем общую итеративную схему квазиньютоновских методов: При этом необходимо выбирать такие, чтобы они (а) были симметричными и положительно определенными и (б) удовлетворяли уравнению секущей Первое требование восходит к двум соображениям. Первое –должно приближать гессиан, а он в идеале в окрестности точки минимума как раз является симметричным и положительно определенным. Второе соображение проще: в противном случаепопросту не будет направлением спуска. Несмотря на эти два свойства, выбор по прежнему остается достаточно широким, откуда возникает большое разнообразие квазиньютоновских методов. Мы рассмотрим один классический и широко известный метод BFGS (Broyden, Fletcher, Goldfarb, Shanno). Сначала заметим, что в самом алгоритме в первую очередь используется обратная матрица к, которую мы обозначим. Тогда выбирать– это тоже самое, что выбирать. Введем еще два стандартных обозначения, чтобы можно было проще записывать все последующие формулы:и. В их терминах уравнение секущей длявыглядит максимально просто:. Теперь введем некоторое искусственное требование, которое гарантирует единственность– выберем ближайшую подходящую матрицу к, удовлетворяющую описанным выше условиям: Вообще говоря, при выборе разных норммы будем получать разные квазиньютоновские алгоритмы. Рассмотрим один достаточно общий класс норм (аналог взвешенныхнорм в матричном мире): где– это Фробениусова норма а– некоторая симметричная и положительно определенная матрица весов, которую мы выберем таким образом, что она будет сама по себе удовлетворять уравнению секущей. Сразу уточним, что матрица весов в таком случае меняется на каждой итерации и, по сути, на каждой итерации мы имеем разные задачи оптимизации, само же предположение задает дополнительную похожесть на обратный гессиан, поскольку можно взять в качестве весов усредненый гессиан Решив описанную выше оптимизационную задачу, мы получаем матрицу, не зависящую явным образом от матрицы весов: Эта формула как раз является ключевой в алгоритме BFGS. Чтобы заметить одно крайне важное свойство этой формулы, раскроем скобки: Отсюда мы видим, что нам в этой формуле достаточно умножать матрицу на вектор и складывать матрицы, что можно делать заопераций! То есть мы победили один из самых страшных минусов метода Ньютона. Воспользовавшись тем, чтои– числа, перепишем формулу в более computational friendly стиле: Общие выводы: Итерации BFGS вычислительно проще итераций метода Ньютона и не требуют вычисления гессиана; По скорости сходимости BFGS уступает методу Ньютона, но все равно является достаточно быстрым; По прежнему требуетсяпамяти, что по-прежнему вызывает проблемы при большой размерности (). Время выполнения итерациигораздо лучше, чемметода Ньютона, но всё ещё оставляет желать лучшего. Казалось бы, избавиться отнельзя принципиально, ведь нужно как-то взаимодействовать с матрицейразмера, а она не факт что разреженная. Но и в этом случае можно добиться улучшения до линейной сложности (как у градиентных методов!). При взаимодействии с матрицами существует два основных способа хранить их дешевле, чем «по-честному». Первый способ – пользоваться разреженностью матрицы, а второй – низкоранговыми разложениями или чем-то близким. Поскольку сейчас мы не хотим добавлять предположений на задачу, которую мы решаем, то единственный выход – это пользоваться структурой, возникающей в BFGS. Если внимательно взглянуть на формулы обновления, то их можно переписать в следующем виде: Для того, чтобы перейти отк, можно хранить не матрицу, а набор пар из k пари начальное приближение(например,для некоторого), чтобы «восстановить». Пользуясь такой структурой, мы можем хранить матрицупри помощи лишьчисел, а не. К сожалению, такая структура имеет довольно простую проблему: призатраты памяти становятся только выше. Возникает простая идея – а давайте хранить только последниеобновлений! Таким образом, мы получаем алгоритм L-BFGS, который имеет уже линейныезатраты памяти и, что немаловажно, такие же линейные затратына итерацию, ведь умножение матрицина вектор может осуществляться за линейное время. Общие выводы: L-BFGS обладает линеной сложностью итерации, линейными требованиями по дополнительной памяти и к тому же требует вычислять только градиенты! Производительность сильно зависит от константы, отвечающей за точность аппроксимации гессиана; Как и все методы из этого раздела, требует точного, а не стохастического вычисления градиентов.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Методы второго порядка",
    "url": "https://education.yandex.ru/handbook/ml/article/metody-vtorogo-poryadka",
    "section_title": "Практические аспекты",
    "text": "Из всех перечисленных в этом разделе методов важнее всего отметить L-BFGS как самый практичный. Он реализован в любой* библиотеке, которая имеет дело с оптимизацией чего-либо и может быть эффективным, если удаётся вычислить градиенты (и значения функций для линейного поиска размера шага). К сожалению, это получается не всегда: при больших размерах датасета вычисление честного градиента и значения для функционалов вида суммы не представляется возможным за разумное время. В таком случае мы вынуждены вернуться в мир стохастического градиентного спуска. Общая идея более тонкого учёта геометрии линий уровня функции потерь, в чём-то напоминающая происходящее в методе Ньютона, находит применение и в ряде вариаций SGD, но, конечно, порождает совершенно другие методы. Что же касается самого метода Ньютона, его можно несколько оптимизировать, если смириться с тем, что всё вычисляется неточно. Во-первых, обратную матрицу к гессиану матрицу на самом деле не нужно ни хранить, ни даже вычислять. Давайте разберёмся, почему. Умножитьна вектор– это то же самое, что решить систему с левой частьюи правой частью, а для решения систем уравнений существуют эффективные итеративные методы, не меняющие левой части системы, а требующие лишь уметь умножать её на разные векторы. При этом умножать гессиан на вектор можно при помощи автоматического дифференцирования. Кроме того, можно на кажом шаге неточно решать систему, получая таким образом неточный метод Ньютона. Теория предписывает решать систему все точнее с ростом номера итерации, но на практике нередко используют фиксированное и небольшое число шагов итеративных методов решения систем линейных уравнений.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Проксимальные методы",
    "url": "https://education.yandex.ru/handbook/ml/article/proksimalnye-metody",
    "section_title": "Проксимальная минимизация",
    "text": "Для того, чтобы подступиться к проксимальным методам, посмотрим на градиентный спуск с другой стороны. Для простоты рассмотрим константный размер шага. Перепишем шаг градиентного спуска следующим образом: Посмотрим на это уравнение по-другому. Рассмотрим функцию, равнуюпри(мы будем воспринимать, как некоторый временной параметр). Тогда при: Теперь слева не что иное, как аппроксимация производной! Если мы устремимк нулю, то получится так называемоеуравнение градиентного потока: Эта динамика в случае выпуклой функциисходится к точке минимумаиз любой начальной точки при. Сравнение между динамикой градиентного спуска и градиентного потока можно увидеть на следующем изображении: Первый состоит из дискретных шагов, второй же представляет из себя непрерывный процесс. Нетрудно осознать физический смысл динамики: маленькое тело скатывается по склону графика функции так, что в любой момент её скорость совпадает с антиградиентом, то есть оно катится по направлению наискорейшего спуска. Теперь представим, что мы сейчас занимается не машинным обучением, а численными методами. Перед нами есть обыкновенное дифференциальное уравнение (ОДУ), и его надо решить. Одним из численных методов решения ОДУ (более стабильным, чем обычная схема Эйлера) является обратная схема Эйлера (backward Euler scheme): В обратной схеме Эйлера мы делаем градиентный спуск, только градиент смотрим не в текущей точке (как было бы в обычной схеме Эйлера), абуквальнов будущей. Занятная идея, только вот напрямую выразитьиз этого уравнения не получится. Нужно поступить чуть хитрее. Заметим, что Это позволяет нам сказать, что весь векторявляется градиентом функции, посчитанном в точке. Тогда получаем, чтоудовлетворяет следующему условию: Если функциявыпуклая, тотоже выпуклая, и её стационарная точка будет точкой минимума. Стало быть,можно высчитывать по формуле Определимпрокс-операторследующим образом: Тогда, поскольку умножение навнутри арг-минимума не влияет на саму точку минимума, получаем следующую итеративную схему: Итеративный процессназываетсяметодом проксимальной минимизации. Вы можете спросить себя: зачем он нужен? Ведь теперь на каждом шаге мы должны решать задачу оптимизации: Есливыпуклая, нам есть, что ответить: наличие второго слагаемого гарантирует сильную выпуклость задачи, то есть она решается достаточно эффективно. Но еслине является выпуклой, то мы ничего не достигли этой модификацией. Чтобы понять, зачем нам понадобилась проксимальная оптимизация, рассмотрим оптимизацию функций вида где– это гладкая функция, а– это функция, для которой прокс-оператор считается аналитически. Воспользуемся следующим трюком: помы совершим градиентный шаг, а по– проксимальный. Получаем следующую итеративную процедуру: Эта процедура определяет так называемый проксимальный градиентный метод (Proximal Gradient Method, PGM), который может использоваться, например, для решения задачи регрессии с-регуляризацией. Теперь решим конкретную задачу-регрессии. Она выглядит следующим образом: Мы хотим применить PGM к этой задаче, для этого нужно научиться вычислять прокс-оператор для-нормы. Проделаем эту операцию: Заметим, что каждое слагаемое зависиттолько от одной координаты. Это значит, что каждую координату мы можем прооптимизировать отдельно и получитьодномерных задач минимизации вида Решение такой одномерной задачи записывается в виде функцииsoft thresholding: Тогда мы получаем следующий алгоритм для-регрессии, которые называются Iterative Shrinkage-Thresholding Algorithm (ISTA): Скопировать код1w = normal(0,1)# инициализация2repeat S times:# другой вариант: while abs(err) >tolerance3f = X.dot(w)# посчитать предсказание4delta = f - y# посчитать отклонение предсказания5grad =2* X.T.dot(delta) / n# посчитать градиент6w_prime = w - alpha * grad# считаем веса, которые отправим в прокс7foriinrange(d):8w[i] = soft_threshold(w_prime[i], alpha * llambda)# вычисляем прокс Заметим одну крутую особенность этого алгоритма -- мы явно видим, что решение получается разреженное, ведь какие-то координаты будут явно зануляться при применении soft threshold! Причем чем больше размер и шага, и параметра регуляризации, тем больше прореживается координат. Конкретно этот метод не применяется на практике, но используются его вариации. Например,статья, которая указана в параграфе пролинейные моделио том, как работало предсказание CTR в google в 2012 году, также базируется на вычислении soft threshold как прокс-оператора. Подытожим все вышесказанное: Проксимальные методы – теоретически интересная идея для выпуклой оптимизации, которая должна давать более численно стабильные алгоритмы. Проксимальные методы позволяют достаточно эффективно решать задачи композитной оптимизации, в частности,-регуляризованную задачу регрессии. Более того, используемые на практике решения задачи-регуляризованной регрессии так или иначе базируются на идее ISTA. Также есть попытки использовать проксимальные методы для более сложных моделей. Например,статья о применении их в нейросетях. Кроме того, имеются применения проксимальных методов для построения распределенных алгоритмов. Все подробности можно найти вмонографии Neal Parikh и Stephen Boyd, мы же только привели применение этих идей в машинном обучении.",
    "source_type": null,
    "useful_links": [
      {
        "text": "статья",
        "url": "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41159.pdf"
      },
      {
        "text": "линейные модели",
        "url": "https://academy.yandex.ru/handbook/ml/article/linejnye-modeli"
      },
      {
        "text": "статья о применении их в нейросетях",
        "url": "https://arxiv.org/abs/1706.04638"
      },
      {
        "text": "монографии Neal Parikh и Stephen Boyd",
        "url": "https://web.stanford.edu/~boyd/papers/prox_algs.html"
      }
    ]
  },
  {
    "document_title": "Дистилляция знаний",
    "url": "https://education.yandex.ru/handbook/ml/article/distillyaciya-znanij",
    "section_title": "Сжатие моделей",
    "text": "Задача сжатия моделей проистекает из следующего наблюдения. Неоднократно было замечено, что в широком диапазоне практически значимых задач машинного обучения точность предсказания модели существенно зависит от её размера. При этом зачастую данная зависимость выглядит достаточно тривиально: последовательное увеличение размеров модели позволяет последовательно улучшать точность её предсказаний. Однако такой безграничный рост приводит к ряду проблем, связанных с практическим применением итоговых моделей. Сюда относятся рост времени обучения больших моделей и повышенные аппетиты таких моделей к размерам и качеству обучающей выборки. Кроме того, большие модели нередко требуют более дорогостоящего вычислительного оборудования для эффективного применения, особенно если мы говорим об обработке большого количества запросов в сжатые сроки. А для некоторых сценариев, таких как предсказание в реальном времени и/или на мобильных устройствах, применение большой модели может оказаться вовсе невозможным. Эти проблемы породили каждая свою ветвь исследований. Так в последние годы де-факто стандартным способом обучения даже относительно компактных моделей стало использование mixed-precision training, которое позволяет ускорить обучение более или менее любых сетей на современных графических процессорах, при этом практически без потерь в итоговом качестве. Для борьбы с недостатком обучающих данных была предложена целая плеяда методов self-supervised pretraining, и новые появляются до сих пор. Сжатие моделей же концентрируется на решении проблем, связанных с этапом применения уже обученных моделей. Как можно догадаться из названия, задача сжатия моделей заключается в том, чтобы взять большую модель, и сжать её в как можно более компактную модель при этом по возможности минимально пожертвовав качеством предсказания. Исторически задачу сжатия моделей пытались решать множеством разных способов. Классическим примером здесь может служить прунинг, где модель обучается специальным образом (например, с использованием L2 регуляризации) так, чтобы часть весов в итоге можно было занулить и исключить из итоговой модели. Однако методы данного семейства, как правило, страдают от двух основных проблем. Во-первых, простое удаление части весов каждого из слоёв обычно показывает лишь незначительное ускорение в применении итоговой модели за исключением случаев использования специализированной аппаратуры Во-вторых, наивный прунинг нередко приводит к существенной просадке в качестве предсказания сжатой модели, причём соотношение степени сжатия и качества итоговой модели едва ли возможно контролировать. Чтобы обойти данные ограничения, и была предложена техника дистилляции знаний.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Дистилляция знаний",
    "url": "https://education.yandex.ru/handbook/ml/article/distillyaciya-znanij",
    "section_title": "Хинтоновская дистилляция знаний",
    "text": "Первой статьёй, в которой можно встретить дистилляцию знаний в современном виде являетсястатьяХинтона и др. 2014 года. В ней авторы рассматривают задачу классификации картинок и предлагают использовать предсказания большой заранее обученной модели-учителя в качестве новой,мягкой, разметки, которую будет пытаться повторить компактный ученик. Авторы предлагают использовать дивергенцию Кульбака-Лейблера между предсказаниями учителя и ученика в качестве дополнительного слагаемого к стандартной функции потерь — кросс-энтропии между предсказанием ученика ижёсткойразметкой: Здесь черезобозначена функция потерь для дистилляции знаний. Подподразумевается число объектов, а под— классов, представленных в обучающей выборке. Черезобозначена жёсткая разметка: Черезобозначены вероятности классов, предсказанные моделью-учеником, а через— моделью-учителем. Коэффициентпозволяет настраивать баланс между решением исходной задачи и повторением предсказаний учителя. В последнем переходе учтено, что логарифм частного раскладывается в разность логарифмов, после чего один из членов можно исключить, поскольку он не зависит от оптимизируемых значений. В дальнейшем для упрощения выкладок подбудет подразумеваться именно последнее выражение. Свой выбор функции потерь авторы мотивируют следующим образом. Широко известным фактом является то, что при классификации картинок на достаточно больших и разнообразных датасетах большие нейронные сети стабильно показывают лучшие результаты по сравнению с компактными. Однако также хорошо известно, что даже сравнительно небольшие нейронные сети способны приближать очень широкий спектр функций. В таком случае можно предположить, что проблема обучения компактных сетей заключается не в том, что компактная модель не способна приблизить ту же функцию, что и большая, а в том, что компактная модель не способна самостоятельно выучить данную функцию из исходных данных. В таком случае потенциально мы можем подтолкнуть компактную модель к выучиванию более информативного представления путем модификации функции потерь. Как этого добиться? Давайте возьмем заведомо более информативное представление, выученное большой моделью-учителем, и добавим в функцию потерь слагаемое, которое будет учить модель-ученика повторять его. В случае решения задачи классификации KL-дивергенция является именно таким слагаемым. Есть и другой способ взглянуть на хинтоновскую дистилляцию знаний. Минимизацияотличается от стандартного обучения, тем, что мы дополнительно минимизируем расстояние между предсказаниями ученика и учителя. От стандартной разметки такая целевая переменная отличается наличием так называемыхтеневых знаний(dark knowledge), которые состоят из вероятностей принадлежности объекта ко всем классам, помимо истинного. Благодаря теневым знаниям модели-ученику во время обучения доступна дополнительная информация о взаимоотношениях между представленными в обучающей выборке классами, а также схожести отдельных объектов и классов. Чтобы проверить данную гипотезу, авторы проводят следующий эксперимент. Сначала они обучают модель-учителя классифицировать картинки на датасетеMNIST. После этого авторы обучают компактную модель-ученика с помощью ранее полученного учителя на тех же данных, но опуская при этом все картинки цифры. После этого авторы показывают, что, если исправить коэффициент сдвига для данного класса в последнем слое сети-ученика с помощью небольшой валидационной выборки, сеть способна верно определитькартинок тройки, несмотря на то, что во время обучения она не видела ни одного примера. Также косвенным подтверждением данной гипотезы можно считать и тот факт, что при использовании довольно популярной сейчастехники сглаживания разметки (label smoothing), эффективность дистилляции знаний заметно падает. Именно теневые знания на данный момент являются де-факто стандартным объяснением эффекта Хинтоновской дистилляции знаний. В качестве дополнительной эвристики авторы также предлагают перед взятием KL-дивергенции сглаживать распределения учителя и ученика с помощью температуры, то есть вместоисчитать KL-дивергенцию междуи, где: Здесь с помощьюобозначены логиты классов, предсказанные моделью-учеником. Формула длявыглядит аналогично. Зачем нужна температура? Давайте рассмотрим формулу дополнительного слагаемого функции потерь. Для простоты выкладок я ограничусь функцией потерь для единственного объекта под номером, а также опущу постоянный множитель, который также не существенен для данного повествования. Вспомним, что коэффициентыприходят из предобученной модели-учителя, а значит являются константными с точки зрения процесса оптимизации. В таком случае несложно видеть, что мы имеем дело с чем-то очень близким к стандартной кросс-энтропийной функции потерь, но таргет— это уже не one-shot закодированные номера классов, а что-то более интересное. В таком случае компоненты предсказания ученика, которые отвечают классам, оценённым учителем, как наиболее вероятные, получат большие веса и сформируют каркас итоговой функции потерь. В то же время все прочие компоненты получат околонулевые коэффициенты и влияния на функцию потерь практически не окажут. В какой-то степени эффект от этого может быть позитивным. Действительно, так как для преобразования предсказания нейронной сети в распределение вероятностей мы используем, итоговая модель не может предсказать строго нулевую вероятность. Поэтому типичное предсказание обученной сети содержит в себе множество практически нулевых значений. При этом порядок между данными значениями определяется в первую очередь не похожестью объекта на представителей данных классов, а конкретным исходом стохастического процесса обучения данной модели. В таком случае нам вовсе не хотелось бы вынуждать ученика воспроизводить данный порядок, если ценой тому будет ухудшение точности предсказания истинного класса. С другой стороны, нейронные сети являются зачастую излишне уверенными в себе классификаторами: их предсказание часто содержит ярко выраженный максимум, вероятность которого близка к единице даже в тех случаях, когда модели стоило бы усомниться. К сожалению, для нас это значит, что при дистилляции знаний из такой модели мы рискуем попасть в ситуацию, что итоговые весанастолько малы для всех классов, кроме истинного, что наше дополнительное слагаемое по сути повторяет стандартную кросс энтропию и не способно внести хоть сколь-нибудь заметный вклад в обучение модели-ученика. Этот эффект можно нивелировать путем сглаживания предсказания учителя таким образом, чтобы сделать распределениеближе к равномерному, для чего, собственно и используется температура. В таком случае функция потерь задается следующим образом: Но в данную формулу незаметно закралась одна неприятная деталь. Давайте рассмотрим градиент второго слагаемого в скобках. Как и в прошлый раз, для простоты выкладок я ограничусь случаем единственного объекта под номероми опущу константный множитель: Здесь легко узнаётся формула кросс-энтропийной функции потерь, градиент которой по логитам считается следующим образом: Можно видеть, что при изменении температурыбаланс между слагаемыми функции потерь (качеством решения задачи и качеством повторения предсказания учителя) нарушается. Действительно, если раньше мы настраивали его путём выбора подходящего коэффициента, то теперь мы приходим к тому, что при изменении температуры коэффициентнеобходимо также менять: иначе при взятии градиента одно слагаемое функции потерь будет разделено на, а другое останется неизменным. Разумным кажется ввести множительв формулу дляявным образом. Однако прежде, чем мы сделаем это, давайте ещё раз внимательно посмотрим на получившийся градиент: где черезобозначены логиты, предсказанные моделью-учителем. Давайте теперь устремимк бесконечности. Раскладывая экспоненты в ряд Тейлора до первого слагаемого, получаем: Вспомним теперь, что результат применения преобразованияне зависит от сдвига на константу, поэтому на выходе из нейронной сети мы можем вычитать из логитов среднее значение таким образом, чтобы. В таком случае, предыдущая формула упрощается до: Из этой формулы следует два вывода. Во-первых, можно видеть, что для соблюдения баланса второе слагаемое вправильнее будет домножить не на, а на. Во-вторых, в данной формуле можно узнать градиент квадратичной функции потерь между векторами логитов. То есть при стремлении температурык бесконечности градиент второго слагаемого встремится к градиенту квадрата нормы разности между логитами модели-ученика и модели-учителя. Таким образом, мы приходим к финальной версии функции потерь: Описанная выше статья произвела настоящий фурор в 2014 году. Дистилляция знаний путем минимизации KL-дивергенции между предсказаниями ученика и учителя хорошо зарекомендовала себя на практике и породила целый ряд исследований, направленных на использование и усовершенствование предложенного подхода. Вместе с методом прижилось и понятие теневых знаний, и его довольно часто можно встретить в статьях, посвящённых данной тематике. Кроме того, зародилась традиция изучения дистилляции знаний на примере задачи классификации картинок. Дальше по ходу параграфа мы ещё не раз столкнёмся с тем, что авторы различных методов часто прилагают результаты экспериментов на таких датасетах, какCIFAR-10, CIFAR-100,ImageNetи так далее. Тем не менее, сети для работы с данными других модальностей тоже дистиллируют, и начнем мы с разбора статьи, которая использует предложенный метод для решения задачи языкового моделирования (language modelling). Одним из наиболее выдающихся примеров применения Хинтоновской дистилляции можно считать модельDistilBERT, которая сохраняет 97% качества модели BERT (согласно бенчмаркуGLUE), используя при этом на 40% меньше параметров и требуя на 60% меньше времени при применении. При этом столь выдающийся результат авторы получают, используя хинтоновский подход практически без изменений. По аналогии с тем, как это делалось для модели-учителя (в роли которого выступает BERT), авторы обучают свою модель решать задачу маскированного языкового моделирования. В дополнение к хинтоновской функции потерь использовалось ещё косинусное расстояние между итоговыми векторными представлениями токенов, полученными с помощью ученика и учителя,разворачиваяпредставлений ученика в сторону направлений, задаваемых представлениями модели-учителя. Ещё одна интересная деталь в этой статье — способ инициализации модели-ученика. Действительно, в качестве архитектуры для своей сети, авторы решили переиспользовать архитектуру самого BERT, но с уменьшенным вдвое числом слоёв для ускорения. Авторы замечают, что большинство операций, которые используются в трансформерах, уже достаточно хорошо оптимизированы во всех популярных библиотеках, поэтому изменение размера внутренних представлений оказывает существенно меньшее влияние на итоговое время применения сети, нежели изменение количества слоёв. Поэтому в статья фокусировалась на сжатии модели именно в глубину, оставляя ширину неизменной. Поскольку веса слоёв модели-ученика имеют при таком подходе такие же размерности, что и веса слоёв модели-учителя, последние можно использовать при инициализации. Ровно так авторы и поступают, копируя веса каждого второго слоя исходной модели для инициализации DistilBERT. Может показаться, что умная инициализация не критична и наихудшим следствием использования более примитивной стратегии будет всего лишь увеличение времени, требуемого для обучения модели-ученика. Но авторы провели ablation study и выяснили, что обучение без умной инициализации приводит к потере почтипроцентных пункта итоговой метрики (обученная без неё модель сохраняет лишькачества модели-учителя). Для сравнения, исключение из функции потерь кросс-энтропии между предсказанием ученика и истинной разметки приводит к потере лишьпроцентных пункта итоговой метрики, а исключение KL-дивергенции приводит к потерепроцентных пункта. Интересно, что двумя годами позднее вышла независимаястатья, авторы которой показали, что хинтоновская дистилляция — это очень сложная оптимизационная задача со множеством локальных минимумов, которые сильно усложняют поиск глобального. Поскольку статья была написана независимо другими авторами, конкретный пример DistilBERT там не изучается, однако в целом авторы приходят к выводу, что умная инициализация может быть ключевым элементом для успеха дистилляции знаний.",
    "source_type": null,
    "useful_links": [
      {
        "text": "статья",
        "url": "https://arxiv.org/abs/1503.02531"
      },
      {
        "text": "MNIST",
        "url": "http://yann.lecun.com/exdb/mnist/"
      },
      {
        "text": "техники сглаживания разметки (label smoothing)",
        "url": "https://arxiv.org/abs/1906.02629"
      },
      {
        "text": "CIFAR-10, CIFAR-100",
        "url": "https://www.cs.toronto.edu/~kriz/cifar.html"
      },
      {
        "text": "ImageNet",
        "url": "https://www.image-net.org"
      },
      {
        "text": "DistilBERT",
        "url": "https://arxiv.org/abs/1910.01108"
      },
      {
        "text": "GLUE",
        "url": "https://arxiv.org/abs/1804.07461"
      },
      {
        "text": "статья",
        "url": "https://arxiv.org/abs/2106.05945"
      }
    ]
  },
  {
    "document_title": "Дистилляция знаний",
    "url": "https://education.yandex.ru/handbook/ml/article/distillyaciya-znanij",
    "section_title": "Дополнительные источники знаний для дистилляции",
    "text": "Несмотря на широкий успех хинтоновского подхода, дистилляция знаний им не ограничивается. Одно из наиболее очевидных направлений улучшения предложенного метода — это использование дополнительных способов передачи знаний от модели-учителя к модели-ученику. Действительно, в хинтоновской постановке единственный канал передачи знаний — это выходы с последнего слоя модели-учителя. Однако в случае нейронных сетей это отнюдь не единственный доступный нам источник информации. Например, можно использовать веса модели-учителя для умной инициализации, как при обучении DistilBERT. К сожалению, поскольку дистилляция знаний практически всегда сопряжена со сжатием модели, не всегда получается непосредственно использовать веса учителя, и в каждом отдельном случае приходится изобретать специализированные трюки. По этой причине DistilBERT — это единственная известная автору этого параграфа модель, в которой удалось добиться улучшения результатов благодаря использованию весов модели-учителя для умной инициализации. Тем не менее, в нейронных сетях можно найти и другие источники информации. Хинтоновская дистилляция использует только выходы с последнего слоя сети. Почему бы нам дополнительно не использовать выходы промежуточных слоев? И действительно,исследования показывают, что использование выходов промежуточных слоев позволяет улучшить результаты дистилляции знаний. Для получения прироста качества авторы предлагают выбрать один или несколько промежуточных слоев модели-учителя, сопоставить каждому из них промежуточный слой модели-ученика, после чего использовать квадрат нормы разности выходов итоговых пар слоев в качестве дополнительного слагаемого к хинтоновской функции потерь. К сожалению, несмотря на кажущуюся прямолинейность данного подхода, здесь возникают две сложности. Мы явным образом предполагаем наличие заранее выбранных пар слоёв, оставляя за бортом вопрос о том, каким образом их собственно стоит выбирать. Поскольку дополнительные слагаемые функции потерь по сути обучают модель-ученика повторять промежуточные представления модели-учителя, разумным кажется сохранять порядок слоёв: слои из середины модели-учителя сопоставлять со слоями из середины модели-ученика, а слои, находящиеся ближе к концу модели-учителя, — со слоями, находящимися ближе к концу модели-ученика. В частности, авторы оригинальной статьи просто берут средний слой в каждой из моделей и используют их в качестве своей единственной пары, однако это в большей степени связано с тем, что статья была написана в 2014 году и рассматривала достаточно маленькие по современным меркам модели. Более свежие статьи, как правило, работают с более глубокими сетями, а потому используют большее количество пар слоёв. Так, авторы следующей работырассматриваютглубокие сверточные сети с промежуточными связями (residual connections) и предлагают разбивать каждую из моделей на группы блоков с промежуточной связью таким образом, чтобы итоговое количество групп совпало. Пример такой разбивки можно видеть на картинке ниже. Здесь к каждой группе относится по три блока в модели-учителе и по два блока в модели-ученике. После этого выходы каждой такой группы можно сопоставить друг другу и использовать для дистилляции знаний. После того, как пары слоёв были выбраны, перед нами может возникнуть и второе препятствие. Что, если выходы выбранных слоёв различаются по размерам? Такая ситуация запросто может случиться, ведь мы хотим, чтобы модель-ученик была поменьше, а один из способов сжатия — как раз уменьшение количества нейронов в полносвязных слоях. В таком случае авторы оригинальной статьипредлагаютиспользовать дополнительное преобразование, чтобы придать выходам модели-ученика нужные размеры (например, линейный слой). Такие слои обучаются совместно с моделью-учеником, а после исключаются из сети при применении. В более поздних работах встречаются и другие, более продвинутые преобразования. Несмотря на кажущуюся интуитивность дистилляции промежуточных выходов, практическое применение это метода, к сожалению, осложняется необходимостью выбора целого ряда гиперпараметров. Скажем, оптимальные тактики выбора пар слоёв для дистилляции или дополнительных преобразований для выравнивания размерностей выходов до сих пор являются предметами активных исследований, точно так же, как и функции потерь для оптимизации.",
    "source_type": null,
    "useful_links": [
      {
        "text": "исследования показывают",
        "url": "https://arxiv.org/abs/1412.6550"
      },
      {
        "text": "рассматривают",
        "url": "https://arxiv.org/abs/1612.03928"
      },
      {
        "text": "предлагают",
        "url": "https://arxiv.org/abs/1412.6550"
      }
    ]
  },
  {
    "document_title": "Дистилляция знаний",
    "url": "https://education.yandex.ru/handbook/ml/article/distillyaciya-znanij",
    "section_title": "Иерархия методов дистилляции знаний",
    "text": "Выше мы рассмотрели два подхода к дистилляции знаний: хинтоновскую дистилляцию и дистилляцию промежуточных представлений. Как мы уже упоминали ранее, в последние годы область применения дистилляции знаний сильно разрослась, и новые методы появляются день ото дня. Это породило довольно естественное желание систематизировать предложенные методы в некоторую иерархию. Мы рассмотрим две классификации методов: по режиму дистилляции, по области применения. Различные подходы к дистилляции знаний принято делить по так называемым режимам. Выделяют три основных режима дистилляции знаний: offline-, online- и самодистилляция. Все рассмотренные выше статьи так или иначе следуют некоторой общей схеме: в качестве учителя используется большая заранее обученная модель, знания из которой дистиллируются в ученика, в то время как сам учитель остается неизменным. Дистилляция в таком режиме получила название offline-дистилляции знаний. Но что делать, если большой предобученный учитель для вашей задачи не доступен? Что если модель-учитель не помещается на доступную нам видеокарту, из-за чего обучение или вовсе невозможно, или требует в десятки раз больше времени, по сравнению с обучением желаемой модели-ученика? Что, если набор данных, описывающий вашу задачу, невелик, и большая модель может переобучиться на нём, делая дистилляцию знаний как минимум неэффективной, а возможно и вредной для итогового качества ученика? Тут на помощь приходит online-дистилляция знаний. В качестве альтернативы авторыэтой статьипредлагают брать в качестве учителя модель такой же архитектуры, что и ученик, и обучать обе модели одновременно. То есть вместо одной модели мы случайно инициализируем две, после чего на каждом шаге обучения для каждой из моделей мы минимизируем, где в качестве учителя выступает другая модель. В таком случае в начале обучения градиент дистилляционного члена не будет иметь какого-то чёткого направления, а обучение обеих моделей будет происходить преимущественно за счет минимизации обычной функции потерь. На поздних же этапах обучения в дело включится и KL-дивергенция, что позволит дополнительно повысить качество каждой из моделей. Почему данный подход работает? Широко известно, что в ряде задач ансамблирование нескольких одинаковых нейронных сетей, одинаково обученных на одних и тех же данных, но из разных случайных инициализаций,дает прироств итоговой метрике. Этот факт подталкивает нас к выводу о том, что в зависимости от инициализации одна и та же нейронная сеть вычленяет из данных разные закономерности. Опираясь на данный вывод, авторы вышеупомянутой статьи утверждают, что в предложенной постановке каждая из моделей в процессе обучения может воспользоваться информацией, которая иначе была бы доступна только модели, стартовавшей из другой инициализации. Авторы проводят ряд экспериментов с моделями разных размеров, обучая их на датасетах CIFAR-100 иMarket-1501, и показывают, что использование даже одной дополнительной модели позволяет добиться заметного улучшения в качестве предсказаний обучаемой модели. Так на датасете CIFAR-100 совместное обучение ансамбля из двух моделей практически во всех экспериментах дает прирост впроцентных пункта к итоговой точности предсказания, причем метод позволяет достигнуть положительного эффекта даже для самой большой из рассмотренных моделей при её совместном обучении с самой малой моделью. Кроме того, авторы проводят ряд экспериментов, в которых сравнивают offline-дистилляцию большей модели в меньшую с их совместным обучением и показывают, что предложенный метод позволяет добиться лучших результатов. Online-постановка естественным образом обобщается на случай большего числа моделей в обучаемом ансамбле. В таком случае в качестве дистилляционного слагаемого авторы предлагают минимизировать среднее значение KL-дивергенций от текущей модели до предсказаний каждой из других моделей в ансамбле, поскольку минимизация KL-дивергенции до усредненных вероятностей приводит к худшему результату. При этом авторы в своих экспериментах показывают, что увеличение числа моделей в ансамбле приводит к улучшению результатов обучения. Кроме того авторы отмечают, что для ускорения обучения можно достаточно эффективно использовать несколько видеокарт, поскольку на каждом шаге между устройствами передавать необходимо только результаты предсказания. В качестве отдельного режима дистилляции знаний принято выделять также самодистилляцию (self distillation), при которой учитель и ученик являются одной и той же моделью. Самодистилляция включает в себя две основные группы методов. Первая группа методов направлена на использование информации, которая накапливается в модели во время обучения, для дополнительного улучшения качества предсказаний той же самой модели. Методы данной группы являются как бы продолжением идей online дистилляции знаний, поскольку учитель и ученик обучаются одновременно. Хороший пример метода из данной группы можно найти вэтой статье, где авторы пытаются заставить представления менее глубоких слоёв быть эквивалентными представлениям более глубоких слоёв. А именно, авторы предлагают разделить сеть на несколько частей (в статье) и после каждой такой части добавить небольшую предсказательную голову. Все такие головы обучаются путем минимизации суммы трёх слагаемых: кросс-энтропии с истинной разметкой; KL-дивергенции с предсказаниями полной сети; квадратичной функции потерь между промежуточными представлениями данной головы и выходом последней части сети. Таким образом авторы добиваются от ResNet50точности предсказания на тестовой выборке CIFAR-100 с минимальным замедлением обучения. Для сравнения, стандартное обучение такой же сети позволяет добиться лишьточности предсказания, а дистилляция из ResNet152 (которая, в свою очередь, показывает точность предсказания в) позволяет улучшить данный показатель лишь до. При этом обучение в предложенном режиме занимаетчасов (обычное обучение занимаетчаса), а дистилляция из ResNet152 занимает ужечасов без учета обучения модели учителя (что требует дополнительныхчасов). Вторая группа методов по сути заключается в offline дистилляции из обученной модели в новую модель такой же архитектуры. То есть мы выбираем некоторую архитектуру нейронной сети, обучаем одну модель стандартным образом, а затем обучаем точно такую же модель из новой случайной инициализации с использованием хинтоновской дистилляции из ранее обученной модели. Стоит заметить, что с хинтоновской точки зрения данное действие едва ли способно улучшить итоговое качество модели. Действительно, будучи точно такой же моделью, ученик обладает идентичной способностью к обучению, а значит учитель едва ли может предоставить ему какую-либо дополнительную информацию во время обучения. Поэтому такая самодистилляция изначально была предложена как метод изучения процесса хинтоновской дистилляции знаний, поскольку в такой постановке у задачи минимизации KL-дивергенции гарантированно есть глобальный минимум, причем мы даже знаем точку, в которой он достигается. В частности именно с помощью данного метода авторыранее упомянутой статьидемонстрируют, что хинтоновская дистилляция знаний является сложной оптимизационной задачей. Тем удивительнее, что авторы статьи 2018 годаобнаружили, что самодистилляция в предложенной выше постановке позволяет получить прирост в обобщающей способности итоговой модели. Так, они проводят ряд экспериментов с моделямиDenseNetиWide-ResNetна датасете CIFAR-100 и показывают, например, что самодистилляция DenseNet-112-33 позволяет повысить точность предсказания на тестовой выборке сдо. Вопрос об источнике прироста качества в данном случае до сих пор в значительной степени открыт. Авторы статьи приписывают данный эффект комбинации умного сглаживания разметки и внесения в обучение информации о взаимоотношении классов в датасете. Но на наш взгляд эксперименты, которые предъявляют в статье в качестве доказательства этих гипотез, едва ли можно назвать убедительными. Возможно, здесь в очередной раз проявляется то, что одинаковые модели могут вычленять из одних и тех же данных разные закономерности в зависимости от случайной инициализации, и дистилляция одной такой модели в другую позволяет ученику увидеть ранее недоступные ему связи. Также хочется обратить внимание на интереснуюстатью, вышедшую в 2020 году. В ней показывается, что в случае обучения с L2-регуляризацией предложенная выше самодистилляция производит неявный отбор признаков. Ну и раз мы проходили мимо самодистилляции, здесь никак нельзя не упомянутьстатью2019 года, которая в течении практически года держала почетный статус SOTA на датасете ImageNet. Её авторы предлагают подход, который во многом очень близок к описанному выше. Они обучают модель на исходном наборе данных, после чего используют её для разметки новых данных, взятых в данном случае из стороннего обширного набора данных JFT-300M (закрытый набор данных, который нередко упоминается в статьях от Google). После этого авторы отбрасывают картинки, для которых модель дает неуверенные предсказания, чтобы избежать данных out-of-domain. Кроме того, они выравнивают размеры классов, чтобы избежать связанных с этим спецэффектов (согласно авторам статьи, модели меньшего размера показали себя более чувствительными к данной оптимизации). Таким образом, авторы получают большое количество дополнительных шумно размеченных данных, на которых, совместно с основным набором, они обучают новую модель. Эту модель, в свою очередь, можно использовать для получения новой разметки для дополнительных данных, с помощью которых обучается следующая модель, и такие итерации можно продолжать произвольное количество раз. В качестве разметки авторы предлагают использовать мягкую разметку, задаваемую моделью-учителем, но и бинаризованная разметка показывает схожие результаты на данных in-domain. Ключевая деталь здесь — что предсказание на новых данных производится без аугментаций, в то время как ученик учится воспроизводить разметку уже с высоким уровнем аугментации данных, а также с применением других техник регуляризации, таких как dropout и stochastic depth. Авторы утверждают, что ученик обучается лучше переносить свои знания на новые данные. Предложенный метод позволил авторам добиться от моделиEfficientNet-L2точности предсказания вна тестовом наборе данных ImageNet, существенно улучшив результат исходной модели ви обновив мировой рекорд. Подавляющее большинство рассмотренных выше статей так или иначе ограничиваются задачей классификации картинок. Такой выбор, хоть и не является случайным, всё же несёт больше исторический, нежели практический характер. На самом деле, многие предложенные выше методы достаточно тривиально могут быть обобщены и на другие задачи машинного обучения. Например, метод дистилляции промежуточных представлений по сути вовсе никак не зависит от природы итоговых выходов модели, а потому может использоваться при сжатии практически любой модели. В частности данный метод может быть использован для сжатия генеративных состязательных сетей. Так авторы довольно популярной статьи в данной областидемонстрируют-,- и даже-кратное ускорение для ряда популярных pix2pix генеративных сетей, при этом не теряя в качестве генерации. Как уже упоминалось ранее, авторы используют дистилляцию промежуточных представлений: модель-ученик учится минимизировать L2-расстояние между своим промежуточным представлением и промежуточным представлением модели-учителя. Но, так как данные представления имеют различное количество каналов (ученик выучивает более сжатое представление) авторы используют дополнительную свертку 1х1 над представлением ученика для сопоставления тензоров друг с другом. Помимо дистилляции промежуточных представлений, авторы также пользуются наличием модели-учителя для того, чтобы получить парную картинку в случае обучения на неспаренных данных (как это происходит, например, в CycleGAN). Парная картинка используется для минимизации L1 нормы разности с предсказанием модели. Кроме того, авторы во время обучения минимизируют и стандартную для генеративных состязательных сетей функцию потерь, при этом для модели-ученика используется такой же дискриминатор, что и для модели-учителя, что позволяет авторам инициализировать веса с помощью весов оригинального дискриминатора. Таким образом авторы предлагают следующий рецепт для сжатия генеративных состязательных сетей. Сначала необходимо обучить модель-учителя. После этого нужно сконструировать сжатый генератор-ученика, скопировать (вместе с весами) дискриминатор и обучить получившуюся систему с помощью минимизации взвешенной суммы трёх функций потерь: Стандартной функции потерь генеративных состязательных сетей. L1-расстояния между предсказанием генератора и парной картинки. При этом если в данных парной картинки нет, вместо неё используется результат генерации моделью-учителем. L2-расстояния между промежуточными представлениями двух генераторов. Этот метод хорошо себя зарекомендовал на практике и получил широкое распространение в своей нише. Ещё одно интересное применение дистилляции знаний — улучшение результатов квантизации моделей. Техника квантизации нейронных сетей заключается в том, чтобы перевести часть весов или даже всю сеть из полной точности (как правило, float32) во float8 или даже float4. Помимо очевидной экономии памяти, такое представление нередко позволяет использовать специальные ядра современных графических ускорителей или специальные регистры процессоров для достижения существенного ускорения при применении квантизованных моделей. К сожалению, бесплатный сыр бывает только в мышеловке. Сжатое представление на то и называется сжатым, что является менее богатым, нежели полная точность. Поэтому большинство весов сети приходится изменять при сжатии, чтобы они попали на более грубую сетку. Разумеется изменения каждого отдельного веса может показаться незначительным, однако когда все веса сети незначительно изменяются, итоговый результат подсчетов может оказаться вовсе неузнаваемым. Чтобы смягчить данный эффект, модель принято доучивать после квантизации. И вот здесь на помощь приходит дистилляция знаний: например, из сети полной точности в квантизованного ученика. Ровно к такой схеме приходят авторыэтой статьи. Итоговая схема выглядит следующим образом: мы обучаем сеть в полной точности, квантизуем ее веса и доучиваем ее в квантизованном виде с использованием дистилляции знаний из сети в полной точности. Хочется отметить, что сжатие моделей — это хоть и основное, но всё же не единственное применение дистилляции знаний. Так, раньше в этом параграфе уже упоминалась самодистилляция, которая позволяет получать прирост в обобщающей способности обучаемой модели без использования моделей большего размера. Самодистилляцией, однако, примеры применения дистилляции знаний без сжатия модели не ограничиваются. Так, в 2020 году былпредложенметод BYOL-предобучения без учителя, основанный на дистилляции знаний. Метод BYOL направлен на предобучение моделей компьютерного зрения и основан на идее так называемого контрастивного предобучения (contrastive pretraining). Суть методов данного семейства заключается в том, чтобы обучать модель выдавать схожие представления для различных аугментаций одной и той же картинки. Действительно, случайные патчи, вырезанные из фотографии автомобиля, скорее всего также являются фотографиями автомобиля. При этом, если в наших данных присутствует достаточное количество фотографий различных автомобилей, мы можем надеяться на то, что модель выучит некоторое общее понимание концепта автомобиля даже несмотря на то, что мы можем вовсе не знать, на каких конкретно картинках автомобили присутствовали, а на каких - нет. Однако если мы хотим добиться от такой модели осмысленных представлений сначала нам необходимо преодолеть проблему коллапса представлений. Действительно, у предложенной выше задачи есть тривиальное решение, в котором выход обучаемой сети не зависит от ее входа. В таком случае представления для произвольных аугментаций любой картинки будут совпадать, то есть функция потерь окажется нулевой. Тем не менее сами представления при этом окажутся совершенно бесполезными. Поэтому различные методы контрастивного обучения отличаются в первую очередь как раз способами борьбы с проблемой коллапса представлений. Так, авторы метода BYOL часто сравнивают свои результаты с довольно свежим на момент написания статьи методомSimCLR, в котором предлагается обучать модель одновременно минимизируя расстояния между парами представлений для различных аугментаций одной картинки и максимизируя расстояния между представлениями для различных картинок. При этом, для повышения эффективности такого обучения, во время генерации батча данных авторы сначала выбирают некоторое количество картинок из набора данных, затем для каждой картинки производят две различные случайные аугментации, после чего полученные картинки используются для создания однойпозитивной пары, расстояние между представлениями которой будет минимизироваться, а также для создания множестванегативных парс аугментациями других картинок в батче, расстояния между представлениями которых будут максимизироваться. Авторы BYOL подвергают данный подход критике, показывая, что для эффективного обучения SimCLR требует большого размера батча, а также довольно агрессивных аугментаций. В противном же случае качество обучаемых представлений заметно падает. Авторы BYOL объясняют данный эффект тем, что сам подход использования негативных пар является субоптимальным, поскольку требует аккуратного выбора негативных примеров. Поэтому свой метод авторы конструируют таким образом, чтобы модель обучалась только на позитивных парах картинок. В таком случае каким образом авторам удается решить проблему коллапса представлений? Для этого, вместо минимизации расстояния между представлениями обучаемой сети для двух аугментаций одной картинки, авторы обучают свою модель минимизировать расстояние между представлением обучаемой (online) сети для одной аугментации и представлением для второй аугментации, которое задается уже другой, целевой (target) сетью. То есть в некотором смысле здесь происходит дистилляция знаний из целевой сети в обучаемую. Последней важной деталью является природа целевой сети. Авторы BYOL замечают, что даже использование произвольно инициализированной сети в качестве целевой для предложенного выше метода обучения приводит к выучиванию обучаемой моделью осмысленных представлений. Подробнее, линейный классификатор, обученный на основе выученных таким образом представлений картинок из набора данных ImageNet показываеттестовой точности предсказания, в то время как использование представлений задаваемых самой целевой сетью позволяет добиться лишьточности. Мотивированные данным наблюдением, авторы предлагают в качестве целевой использовать такую же сеть, что и обучаемая. При этом: градиенты не текут через целевую модель, и она не обновляется на шаге градиентного спуска; обучаемая модель заканчивается дополнительным двухслойным перцептроном, который используется для преобразования её финальных представлений в представления целевой модели; веса целевой модели не меняются на шаге градиентного спуска, а вместо этого они обновляются между шагами с помощью экспоненциального сглаживания весов обучаемой модели: где, следуя обозначениям из статьи, мы обозначили черезивеса целевой и обучаемой моделей соответственно, а— вещественный параметр. Предложенный метод позволяет авторам добиться ужетестовой точности от линейного классификатора на наборе данных ImageNet, заметно превосходя предложенные ранее методы self-supervised предобучения, и практически преодолевая разрыв между self-supervised и supervised обучением классификаторов на основе ResNet. Стоить заметить, что сценарии применения дистилляции знаний отнюдь не ограничиваются выше рассмотренными. На данный момент уже существует множество различных подходов и алгоритмов, так или иначе связанных с дистилляцией знаний, и их количество растет день ото дня. Данный параграф не ставит своей целью полный обзор таких методов. Вместо этого всем заинтересовавшимся я рекомендую обратить внимание на довольно исчерпывающийобзорот 2020 года. Здесь можно найти множество ссылок на актуальные к тому моменту статьи, в числе которых присутствует и большинство статей, упомянутых в этом параграфе. Завершим параграф упоминанием открытых проблем в области дистилляции знаний. Действительно, несмотря на впечатляющие результаты, дистилляция знаний всё же не является идеальным методом, и ряд вопросов до сих пор остаются без ответа. Например, с ростом популярности дистилляции знанийвыяснилось, что использование учителя с большей обобщающей способностью не всегда приводит к улучшению обобщающей способности ученика. В какой-то степени данный эффект можно списать на то, что компактная модель-ученик упирается в пределы своего качества предсказания, и тогда использование более умного учителя уже не приносит дополнительной пользы. Но это не объясняет, почему использование более точной модели в качестве учителя может приводить даже к ухудшению итоговой точности модели-ученика. В чём причина данного эффекта и как выбрать оптимального учителя для фиксированного ученика, до сих пор открытый вопрос. И как уже упоминалось ранее, дистилляция знаний из одной сети в точно такую же нередкоприводитк росту обобщающей способности ученика по сравнению со своим учителем. С точки зрения хинтоновской теории, которая является де-факто стандартным способом объяснения дистилляции знаний, это звучит абсурдно. Модель-ученик гарантированно способна приблизить ту же функцию, что и модель-учитель. Тем не менее, этого не происходит, а модель-ученик выучивает свое собственное представление, которое нередко качественно превосходит представление учителя. Данный факт уже сложно объяснить в парадигме передачи знаний от учителя к ученику, потому что здесь ученик оказывается в состоянии получить больше знаний, нежели учитель способен передать. Несмотря на то, что на данную тему написана уже не одна статья, исчерпывающего объяснения пока нет. Так или иначе, дистилляция знаний неоспоримо работает и является основным практическим подходом к сжатию нейросетевых моделей на данный момент.",
    "source_type": null,
    "useful_links": [
      {
        "text": "этой статьи",
        "url": "https://arxiv.org/abs/1706.00384"
      },
      {
        "text": "дает прирост",
        "url": "https://arxiv.org/abs/2012.09816"
      },
      {
        "text": "Market-1501",
        "url": "https://ieeexplore.ieee.org/document/7410490"
      },
      {
        "text": "этой статье",
        "url": "https://arxiv.org/abs/1905.08094"
      },
      {
        "text": "ранее упомянутой статьи",
        "url": "https://arxiv.org/abs/2106.05945"
      },
      {
        "text": "обнаружили",
        "url": "https://arxiv.org/abs/1805.04770"
      },
      {
        "text": "DenseNet",
        "url": "https://arxiv.org/abs/1608.06993"
      },
      {
        "text": "Wide-ResNet",
        "url": "http://www.bmva.org/bmvc/2016/papers/paper087/index.html"
      },
      {
        "text": "статью",
        "url": "https://arxiv.org/abs/2002.05715"
      },
      {
        "text": "статью",
        "url": "https://arxiv.org/abs/1911.04252"
      },
      {
        "text": "EfficientNet-L2",
        "url": "https://arxiv.org/abs/1905.11946"
      },
      {
        "text": "демонстрируют",
        "url": "https://arxiv.org/abs/2003.08936"
      },
      {
        "text": "этой статьи",
        "url": "https://arxiv.org/abs/1711.05852"
      },
      {
        "text": "предложен",
        "url": "https://arxiv.org/abs/2006.07733"
      },
      {
        "text": "SimCLR",
        "url": "https://arxiv.org/abs/2002.05709"
      },
      {
        "text": "обзор",
        "url": "https://arxiv.org/abs/2006.05525"
      },
      {
        "text": "выяснилось",
        "url": "https://arxiv.org/abs/1910.01348"
      },
      {
        "text": "приводит",
        "url": "https://arxiv.org/abs/1805.04770"
      }
    ]
  },
  {
    "document_title": "Параметрические оценки",
    "url": "https://education.yandex.ru/handbook/ml/article/parametricheskie-ocenki",
    "section_title": "Предельные теоремы",
    "text": "Как правило, чем больше размер выборки, тем более информативны параметрические оценки вида. Теоретические свойства таких оценок приустанавливаются с помощью предельных теорем теории вероятностей. Внимательный читатель мог обратить внимание, что в ряде примеров из предыдущих параграфов параметры некоторых распределений почему-то молчаливо подменялись средними значениями. Так мы поступили в задаче о показе рекламы, взяв в качестве параметра пуассоновского распределение среднее количество кликов пользователей. Фактически мы оценили неизвестный параметрасредним по выборке: В общем-то это кажется логичным, поскольку, если. Однако у такой оценки есть также мощное теоретическое обоснование. Теорема (Закон больших чисел, ЗБЧ). Пусть– последовательность попарно независимых одинаково распределенных случайных величин с конечным математическим ожиданием. Тогда для любого Таким образом, чем больше размер выборки, тем менее вероятно отклонениевыборочного среднегоот истинного среднегона любое число. Закон больших чисел особенно легко обосновать для случая конечных дисперсий:. Имеем Отсюда видно, что, поэтому при большихраспределение случайной величинывсё больше похоже на распределение, сосредоточенное в одной лишь точке. Формально же утверждение ЗБЧ получается с помощью неравенства Чебышева: Закон больших чисел допускает следующее усиление. Теорема (Усиленный закон больших чисел, УЗБЧ). Пусть– последовательность попарно независимых одинаково распределенных случайных величин с конечным математическим ожиданием. Тогда выборочное среднеепочти наверноесходится к, т.е.. Доска Гальтонаиллюстрирует биномиальное распределение. До поворота на ее дне лежит множество маленьких шариков. Сразу после переворота шарики проходят через 10 рядов гладких круглых препятствий. Преодоление каждого препятствия можно рассматривать как испытание Бернулли: с равными вероятностями шарик может пойти как налево, так и направо. Поэтому финальное положение шарика в одной из 10 корзин является приблизительной реализацией биномиального распределения. Уже прибиномиальное распределение напоминает нормальное. И действительно, чем больше, тем лучше дискретная случайная величинааппроксимируется непрерывной гауссианой. Теорема Муавра-Лапласа. Пусть,, тогда Из теоремы Муавра-Лапласа вытекает, что при большихвероятность попадания биномиальной случайной величиныв заданный интервал можно оценить как где— функция распределения стандартного нормального распределения. При выводе закона больших чисел мы видели, что выборочное среднееимеет среднееи дисперсию. Но как именно выглядит распределение случайной величиныпри увеличении? Оказывается, что оно становится всё больше похоже на. Вот как, например, выглядят нормализованные гистограммывыборочных средних, построенных по i.i.d. выборкамдля разных значений: Эти гистограммы и впрямь очень напоминают гауссианы, и это прямое следствие следующей теоремы. Центральная предельная теорема, ЦПТ. Пусть– последовательность попарно независимых одинаково распределенных случайных величин с конечным математическим ожиданиеми дисперсией. Тогда Точнее говоря,. Таким образом, случайная величинасходится по распределениюк:. Если применить центральную предельную теорему к бернуллиевским случайным величинам с вероятностью успеха, то вновь получим теорему Муавра-Лапласа.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Доска Гальтона",
        "url": "https://ru.wikipedia.org/wiki/%D0%94%D0%BE%D1%81%D0%BA%D0%B0_%D0%93%D0%B0%D0%BB%D1%8C%D1%82%D0%BE%D0%BD%D0%B0"
      }
    ]
  },
  {
    "document_title": "Параметрические оценки",
    "url": "https://education.yandex.ru/handbook/ml/article/parametricheskie-ocenki",
    "section_title": "Свойства параметрических оценок",
    "text": "Оценивать параметры можно по-разному, хочется делать это хорошо. Ценные свойства оценок, которые обычно желательны – этонесмещенностьисостоятельность. Каждый элемент i.i.d выборкиможно рассматривать как значение случайной величины из некоторого распределения с неизвестным параметром.А раз так, то всякую оценку этого параметратакже можно считать случайной величиной, у которой можно пытаться вычислять математическое ожидание, например. Оценкапараметраназываетсянесмещенной, если. Несмещённость оценки означает, что она в среднем будет равна истинному значению параметра. Интуитивно можно представлять себе несмещённость следующим образом: если мы нагенерим большое количество выборок,, и для каждой посчитаем оценку, то в среднем получится более или менее истинное значение параметра:. Простейший пример несмещённой оценки среднего значениядаёт выборочное среднее, поскольку Медианойвыборкиназывается средний членвариационного ряда, состоящего из отсортированных по возрастанию элементов выборки: Еслинечётно,, то есть ровно один элемент в середине вариационного ряда, именно он называется медианой:. При чётномв качестве медианы берут среднее двух центральных элементов вариационного ряда: Упражнение.Дана i.i.d. выборкаиз равномерного распределения. Докажите, что выборочная медиана даёт несмещённую оценку медианы распределения. В некоторых случаях оценкасмещена, но с ростомэто смещение нивелируется. Если, то оценканазываетсяасимптотически несмещённой. Упражнение.Пусть— i.i.d. выборка. Оценим параметркак максимальное значение выборки: Является ли эта оценка несмещённой? Асимптотически несмещённой? Оценканазываетсясостоятельной, если она сходится по вероятности к,, то есть Cостоятельность означает, что с ростом размера выборки всё менее вероятны хоть сколько нибудь значимые отклонения оценки от истинного значения параметра. Если i.i.d. выборкаполучена из распределения с конечным математическим ожиданием, то в силу закона больших чисел выборочное среднееявляется состоятельной оценкой для. Состоятельность оценки – независимое от несмещенности свойство: оценки могут быть состоятельными, но не несмещенными и наоборот. Например, оценкаиз предыдущего упражнения оказалась смещённой, однако, она состоятельна: Упражнение. Приведите пример несмещённой оценки, не являющейся состоятельной. Имея i.i.d. выборкуиз невырожденного распределения с конечным средним, оценим это среднее как. Эта оценка, очевидно, несмещённая:. Состоятельной, однако, она не является, ведь выражение никоим образом не зависит от. Следовательно, состоятельность оценкиозначала бы, чтодля любого. Такое возможно только для вырожденного распределения, сосредоточенного в одной лишь точке:. Смещение(bias) оценкиопределяется как Смещение показывает, насколько оценка в среднем отклоняется от истинного значения. Оценка несмещённая, если; асимптотически несмещённая, если. Среднеквадратичной ошибкой(mean squared error,MSE) оценки называется величина Смещение, дисперсия и среднеквадратичная ошибка связаны между собой следующим соотношением (bias-variance decomposition): Упражнение. Докажите, что оценкасостоятельная, если она асимптотически несмещённая и. Таким образом, если, то оценкапараметраасимптотически несмещённая и состоятельная. Стандартным отклонениемоценкипараметраназывается корень из дисперсии: Оценкаасимптотически нормальна, если, т.е. Согласно центральной предельной теореме выборочное среднее i.i.d. выборки из распределения с конечными средними дисперсиейявляется асимптотически нормальной оценкой параметра. Пустьи— несмещённые оценки параметра. Оценкаэффективнееоценки, если. Такое определение эффективности вполне логично, ведь чем меньше дисперсия несмещённой оценки, тем меньше у неё шансов удалиться куда-то далеко от истинного значения параметра. Пример. Пусть— i.i.d. выборка из распределения. Какая оценка параметраэффективнее: выборочное среднее или медиана? Несмещённость оценокиуже была показана выше. Найдём дисперсию наших оценок. Диспресия случайной величиныравна, следовательно,. Найти дисперсию медианы несколько сложнее. Ограничимся случаем. Тогда, и С помощью заменыотсюда находим, что Следовательно,, что прибольше, чем, так что выборочное среднее эффективнеемедианы (примерно враз при больших, если считать по отношению стандартных отклонений). Несмотря на то что в плане эффективности среднее оказалось предпочтительнее в этом примере,в статистике медиану любят за бОльшую устойчивость к выбросам. Ниже приведён scatter-plot, по которому можно наглядно оценить меру разброса среднего и медианы выборки из равномерного распределения на отрезкедля. Для построения этого графика были взятыi.i.d. выборок изразмера, и для каждогопосчитаны выборочное среднее и медиана. Эти статистики и задают координаты точки на графике. Разумеется, чем больше значение, тем кучнее локализованы точки вокруг среднего значения, совпадающего в данном случае с медианой. Как видно, облако точек сосредоточено вдоль прямой. Как мы уже убедились, выборочное среднеепредставляет собой несмещённую и состоятельную оценку для математического ожидания. Можно ли то же самое сказать провыборочную дисперсию в предположении, что i.i.d. выборкасостоит из реализаций случайной величиныс конечными моментамии? Прежде всего раскроем скобки и перепишемв виде где— выборочное среднее, построенное по выборке. Оно несмещённое, поэтому. Заметим также, что откуда в силу независимостииприполучаем Итак, Таким образом, оценка дисперсиисмещённая (хотя и асимптотически несмещённая). По этой причине для оценки дисперсии часто используют аналогичную несмещённую оценку которую также называют выборочной дисперсией. Обоснуем теперь состоятельность оценки. Согласно закону больших чисел,. Здесь нам потребуется пара свойств сходимости по вероятности. Упражнение. Пусть,. Докажите, что. Упражнение. Пусть. Докажите, что. Пользуясь результатами этих упражнений, заключаем, чтои, и, стало быть, оценкасостоятельна.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Параметрические оценки",
    "url": "https://education.yandex.ru/handbook/ml/article/parametricheskie-ocenki",
    "section_title": "Методы оценки параметров",
    "text": "До этого мы обсуждали разные приятные свойства оценок, а теперь рассмотрим некоторые методы, позволяющие систематически получать по выборке оценки параметров с нужными свойствами. Пусть выборкаполучена сэмплированием из некоторого семейства распределенийс параметрами.Метод моментовдля оценки этих параметров заключается в приравнивании выборочных моментов к теоретическим Решая полученную систему уравнений,, находим оценки параметров. Пример. Оценим параметры нормального распределенияс помощью метода моментов. Упражнение. Оцените по методу моментов параметрыидля выборкииз. При некоторых условиях на регулярность семейства распределенийоценка по методу моментов получается состоятельной и асимптотически нормальной. Пусть, как обычно, выборка.Правдоподобие(функция правдоподобия,likelihood) выборки— это просто её совместная pmf или pdf. Вне зависимости от типа распределения будем обозначать правдоподобие как Если выборка i.i.d., то функция правдоподобия распадается в произведение одномерных функций: Оценка максимального правдоподобия(maximum likelihood estimation,MLE) максимизирует правдоподобие: Поскольку максимизировать сумму проще, чем произведение, обычно переходят к логарифму правдоподобия (log-likelihood). Это особенно удобно в случае i.i.d. выборки, тогда Пример. В результатеподбрасываний монеты выпало«орлов» и«решек».Оценим вероятность выпадения «орла» методом максимального правдоподобия. Пусть— вероятность выпадения «орла», тогда правдоподобие равно Дифференцируя логарифм правдоподобия и приравнивая к нулю производную, находим Нетрудно убедиться, что это точка максимума. Итак, оценка максимального правдоподобиявероятности «успеха» в схеме Бернулли вполне ожидаемо оказалась равна доле «успехов» в серии изиспытаний. Упражнение. Пусть i.i.d. выборкавзята из пуассоновского распределения с параметром. Найдите его оценку максимального правдоподобия. Методом максимального правдоподобия можно оценить сразу несколько параметров. Пример. Найдём MLE-оценки параметров распределенияпо i.i.d. выборке. Запишем правдоподобие: Перейдём к log-likelihood: Приравняем частные производные поик нулю: откуда– выборочное среднее,– выборочная дисперсия. Упражнение. Пусть i.i.d. выборка. Найдите оценки максимального правдоподобия для параметрови. Свойства оценки максимального правдоподобия состоятельность:; инвариантность относительно параметризации: если— MLE-оценка для, то— MLE-оценка для; асимптотическая нормальность:; асимптотическая оптимальность: при достаточно большихоценкаимеет минимальную дисперсию.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Ландшафт функции потерь",
    "url": "https://education.yandex.ru/handbook/ml/article/landshaft-funkcii-poter",
    "section_title": "Все минимумы достаточно широкой нелинейной сети глобальны",
    "text": "Рассмотрим нейронную сеть с одним скрытым слоем: где функция активацииприменяется поэлементно. Рассмотрим набор данныхразмера, где, а. Применяя соотношения выше к этому набору, получим следующие значения выходов слоёв: Поставим задачу оптимизации квадратичной функции потерь где– норма Фробениуса. Теорема 1(On the local minima free condition of backpropagation learning) Еслианалитична, ограничена и не тождественно равна нулю, ширина скрытого слояне меньшеи все столбцы матрицыразличны, то все локальные минимумыглобальны. Доказательство. Пусть– локальный минимум, и пусть,– соответствующие ему скрытые представления. Тогда– локальный минимум. Задача оптимизациивыпуклая, поэтому– глобальный минимум. Если, то система, где– неизвестная матрица, гарантировано имеет решение для каждого. Следовательно, а значит,– глобальный минимум. Заметим, что для выполнения равенстванеобходимо. Пусть теперь. Если тем не менее, то– по-прежнему глобальный минимум. Пусть Докажем, чтоне может быть локальным минимумомдо тех пор, пока выполнены условия следующей леммы, которую мы докажем позже: Лемма 1. Если, функцияаналитична, ограничена и не тождественно равна нулю, а все столбцы матрицыразличны, то лебегова мера множестваравна нулю. Так каки– непрерывна как функция от, существует, для которого где черезмы обозначили-окрестность точкив пространстве весов. Из леммы 1 следует, что для любогонайдётся, для которого. Возьмём. Для соответствующегоимеем; при этом. Как было отмечено выше, задача минимизациивыпуклая, и оптимум её равен нулю, так как. Поэтому градиентный спуск, применённый ки стартующий в, сойдётся в некоторую точку, для которой. Мы знаем, что в нашей эпсилон-окрестности функция потерь положительна, значит, найденная точка находится вне её:. Таким образом, найдётсятакое, что для любыхсуществует паратакая, что градиентный спуск, примененный к, стартующий ви действующий только на, сходится в точку. Очевидно, что если «для любых» заменить на «для любых», утверждение выше останется верным. Это означает, что динамика градиентного спуска, действующего только на, не устойчива по Ляпунову в точке. Следовательно,не может быть точкой минимума (иначе градиентный спуск был бы устойчив), а значит, условиеневыполнимо в условиях леммы 1. Таким образом, все локальные минимумыглобальны.Теорема 1 доказана. Доказательство леммы 1. Пусть– наборов индексов издлины. Рассмотрим– подматрицу матрицы, состоящую из строк, проиндексированных набором. В терминахусловиеэквивалентно. Так каканалитична, а определитель – аналитическая функция элементов матрицы,– аналитическая функция отдля любого. Нам понадобится следующая лемма, доказательство которой вы можете найти вThe loss surface of deep and wide neural networks(лемма 4.3): Лемма 2.В условиях леммы 1, найдётся, для которого. Из леммы 2 и эквивалентности выше следует, что найдётся, такой что для некоторогоимеет место неравенство. Так как определитель– аналитическая функция, а всякая не тождественно нулевая аналитическая функция принимает значение ноль лишь на множестве меры ноль по Лебегу, то лебегова мера множестваравна нулю. Таким образом,лемма 1 доказана.",
    "source_type": null,
    "useful_links": [
      {
        "text": "On the local minima free condition of backpropagation learning",
        "url": "https://ieeexplore.ieee.org/document/410380"
      },
      {
        "text": "The loss surface of deep and wide neural networks",
        "url": "https://arxiv.org/pdf/1704.08045.pdf"
      }
    ]
  },
  {
    "document_title": "Ландшафт функции потерь",
    "url": "https://education.yandex.ru/handbook/ml/article/landshaft-funkcii-poter",
    "section_title": "Обобщения",
    "text": "При доказательстве теоремы 1 мы воспользовались следующими условиями: Все обучающие примеры (столбцы матрицы) различны; Число скрытых слоёвравно одному; Ширина (последнего) скрытого слоя не меньше числа примеров:; Функция активациианалитична, ограничена и не тождественно равна нулю; Функция ошибки квадратична. Можем ли мы ослабить какие-то из них? Если какие-то из примеров совпадают и соответствующие метки также одинаковы, теорема обобщается тривиально. Если же метки не совпадают, то нулевая ошибка, вообще говоря, недостижима. Тем не менее, доказательство меняется по большому счёту лишь в том, что вместобудет фигурировать число различных примеров. Рассмотрим сеть сскрытыми слоями, действующую на набор данныхразмера: Для обобщения теоремы 1 на глубокие сети с широким последним скрытым слоем, достаточно обобщить лемму 1. Например, можно воспользоваться следующим результатом (лемма 4.4 изThe loss surface of deep and wide neural networks) Лемма 3. Пустьаналитична, ограничена и не тождественно равна нулю, и пусть. Тогда еслии все строки матрицыразличны, то лебегова мера множестваравна нулю. Третье предположение можно попытаться ослабить с двух сторон. Во-первых, можно требовать меньшего числа нейронов в скрытом слое. В общем случае этот подход не работает: в статьеA note on connectivity of sublevel sets in deep learningдоказывается, что– это наименьшая ширина, при которой теорема выполняется для набора данных общего вида с различными примерами. Тем не менее, для реальных нейронных сетей градиентный спуск нередко находит глобальный минимум, хотя их ширина часто гораздо меньше размера набора данных, на которых они обучаются. Возможно, оценки на минимальную ширину удастся улучшить, если учесть структуру данных: например, если все примеры разбиваются на подмножества с элементами, находящимися близко друг к другу и имеющими одинаковые метки. Во-вторых, можно предположить, что самым широким является не последний скрытый слой, а один из промежуточных:для некоторого. Но тогда задачане выпукла, а значит, изне следует, что, и градиентный спуск, действующий на, не обязан сходиться в точку, в которой(он может застрять в локальном минимуме). Тем не менее, поставив ряд дополнительных условий, теорему 1 можно обобщить: Теорема 2. Пусть– локальный минимуми выполнены следующие условия: аналитична, ограничена, не тождественно равна нулю; производнаянигде не обращается в ноль; ; ; . Тогда– глобальный минимум. Условие 4 необходимо, чтобы изследовало. Отметим, что из условия 4 также следует, что, то есть нейронная сеть должна сужаться, начиная со следующего после самого широкого слоя. Условие 5 необходимо, чтобы в случаепостроить малое возмущение минимума, которое снова является минимумом, но для которого; невырожденный гессиан позволяет применить для этого теорему об обратной функции. Если функция активациине аналитична, то лемма 3 неверна. В самом деле, для однородной(например, для ReLU или leaky ReLU) паттерны активаций,, не меняются при малом возмущении весов. Значит, мы, вообще говоря, не можем найти такое малое возмущение, для которого рангбудет полным. Вместо малого возмущения в работеOn Connected Sublevel Sets in Deep Learningявно строятся пути в пространстве весов, на которых функция потерь не возрастает и достигает нуля. Если такой путь можно построить из произвольной точки, то все (строгие) локальные минимумы глобальны. Оказывается, что для построения такого пути аналитичность функции активации не требуется. Более того, при определённых условиях можно доказать, что из любых двух точек в пространстве весов можно построить соответствующие пути так, чтобы они сходились в одной точке. Это значит, чтомножество подуровнясвязно при любом– эффект, впервые эмпирически обнаруженный в работахLoss surfaces, mode connectivity, and fast ensembling of DNNsиEssentially No Barriers in Neural Network Energy Landscape. Связность множеств подуровня сильнее глобальности всех строгих минимумов. В самом деле, если бы существовал строгий локальный минимум уровня, то для достаточно малогоему бы соответствовала отдельная связная компонента множества подуровня. С другой стороны, если все локальные минимумы глобальны, но изолированы, то множество подуровнянесвязно для достаточно малого. Вместо того, чтобы строить пути, на которых функция потерь достигает нуля, можно строить пути, на которых функция потерь достигает сколь угодно малого значения. Это позволяет обобщить результат на функции потерь, для которых минимум по второму аргументу, ответу сети, не достигается. Пример такой функции – кросс-энтропия. Так мы приходим к следующей теореме: Теорема(On Connected Sublevel Sets in Deep Learning). Пусть выполнены следующие условия: ,строго монотонна и не найдётся ненулевыхс, таких что; выпукла по второму аргументу идля любого; Существует, для которогоидля всех. Тогда если, то Для каждогонайдутся веса, для которых; Множество подуровнясвязно для каждого.",
    "source_type": null,
    "useful_links": [
      {
        "text": "The loss surface of deep and wide neural networks",
        "url": "https://arxiv.org/pdf/1704.08045.pdf"
      },
      {
        "text": "A note on connectivity of sublevel sets in deep learning",
        "url": "https://arxiv.org/pdf/2101.08576.pdf"
      },
      {
        "text": "On Connected Sublevel Sets in Deep Learning",
        "url": "https://arxiv.org/pdf/1901.07417.pdf"
      },
      {
        "text": "Loss surfaces, mode connectivity, and fast ensembling of DNNs",
        "url": "https://arxiv.org/pdf/1802.10026.pdf"
      },
      {
        "text": "Essentially No Barriers in Neural Network Energy Landscape",
        "url": "https://arxiv.org/pdf/1803.00885.pdf"
      },
      {
        "text": "On Connected Sublevel Sets in Deep Learning",
        "url": "https://arxiv.org/pdf/1901.07417.pdf"
      }
    ]
  },
  {
    "document_title": "Нормализующие потоки",
    "url": "https://education.yandex.ru/handbook/ml/article/normalizuyushie-potoki",
    "section_title": "Введение",
    "text": "В главеГенеративный подход к классификациимы уже познакомились с типом моделей, которые оценивают совместное распределение. Такие модели называютгенеративными. Для простоты предположим, что мы имеем всего один класс, тогда задача моделированиясводится к задаче моделирования. Научившись моделировать это распределение, мы сможем: генерировать объекты, где– параметры модели; оценивать вероятность встретить данный объектсреди набора наблюдаемых данных; выучивать скрытые представления для объекта. Известными примерами генеративных моделей являются: Авторегрессионные модели: Вариационные автокодировщики: Но оба эти метода не позволяют одновременно: получать скрытые представления для объектов точно вычислять функцию правдоподобия Нормализующие потокиспособны решить обе эти задачи.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Генеративный подход к классификации",
        "url": "https://education.yandex.ru/handbook/ml/article/generativnyj-podhod-k-klassifikacii"
      }
    ]
  },
  {
    "document_title": "Нормализующие потоки",
    "url": "https://education.yandex.ru/handbook/ml/article/normalizuyushie-potoki",
    "section_title": "Мотивация",
    "text": "Пусть, гденеизвестно, а. Мы хотим найти отображение, для которогои. Отображениепреобразует базовую функцию плотностик более сложной. С его помощью мы можем генерировать сложный объект путем сэмплинга простого объекта(скрытой переменной) из распределенияи применения «генератора». Обратное отображение«нормализует» сложное распределение, приводя его к простому. Найдя такое отображение, мы сможем генерировать новые объекты, а оценить плотностьпоможет формула преобразования плотности случайной величины. Давайте её вспомним. Пусть,, при этом отображениедифференцируемо, обратимо и. Тогда: где– якобиан отображения.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Нормализующие потоки",
    "url": "https://education.yandex.ru/handbook/ml/article/normalizuyushie-potoki",
    "section_title": "Определение",
    "text": "Итак,нормализующий поток– это обратимое дифференцируемое отображение, которое переводит исходные представления объектов в скрытые:и. При этом функция правдоподобиявычисляется по формуле: Умея вычислять функцию правдоподобия, мы можем обучать нашу модельметодом максимума правдоподобия (ММП): где– выборка наблюдаемых данных из распределения. Обычно модель нормализующего потока составляет композицию изне очень сложных отображений, чтобы она была, с одной стороны, достаточно контролируемой, а с другой – достаточно выразительной: Тогда якобиан вычисляется по формуле: Но вычисление якобиана является очень затратной операцией. Для того, чтобы мы могли обучать модели эффективно на высокоразмерных данных (аудио, изображения), необходимо использовать такое отображение, подсчет якобиана которого был бы эффективен! Примером такого отображения являетсяпланарный поток(Planar Flow), где отображениепринадлежит следующему семейству функций: где– обучаемые параметры, а– гладкая нелинейная функция, например,. Якобиан такого отображения можно будет посчитать за. Обозначим Тогда",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Нормализующие потоки",
    "url": "https://education.yandex.ru/handbook/ml/article/normalizuyushie-potoki",
    "section_title": "Развитие идеи",
    "text": "В планарных потоках нам удалось быстро посчитать якобиан, потому что матрица имела специальный вид (сумма единичной и низкоранговой). Но мы знаем и другие случаи, когда определитель можно посчитать быстрее – треугольные матрицы. Их определитель равен произведению элементов на диагонали. Следующие модели активно использовали этот трюк. Авторы моделиNICEпредложили использовать в качествеследующее семейство преобразований: где, а– произвольная нейросеть свходами ивыходами. Такое преобразование называютаддитивным связыванием(additive coupling). Обратное преобразование вычисляется с такой же легкостью, а якобиан равен. То есть,, что является довольно сильным ограничением модели. Далее, из-за того, что первыеканалов векторасовпадают с координатами нормального шума, то есть моделирования этих каналовне происходит. Из-за этого выразительная способность модели NICE была относительно невысокой. Позже авторы NICE позже предложили использовать между слоями нормализующих потоков зафиксированные перестановки признаков/каналов, что стало основой работыRealNVP. Использование перестановок позволяет добиться того того, чтобы все выходные каналы оказались затронуты преобразованием; при этом градиент перестановки вычисляется легко. где– поэлементное умножение, а– нейросеть, которая может быть произвольной, но, как правило, выбирается такой же архитектуры, как и. Такое преобразование называютаффинным связыванием(affine coupling). Получившееся отображение тоже легко обращается, а его якобиан равен: Заметим, что, как и в случае аддитивного связывания, значительная часть каналов остается неизменной при использовании аффинного связывания. Для того, чтобы преобразованиемоделировало распределениево всех каналах, на разных слоях неизменными оставляют разные подмножества изканалов. Чтобы улучшить сходимость глубоких () нормализующих потоков, авторы предложили использовать Batch Normalization. Данное преобразование тоже является обратимым, а его якобиан вычисляется крайне просто. В результате, выразительная способность модели сильно повысилась, и она стала способна выучивать сложные распределения: Ссылка на статью Данный вид нормализующих потоков также обладает нижнетреугольным якобианом, но он использует другое семейство функций: гдеи– нейросети произвольной архитектуры. Как видно из формулы,напрямую зависит от. Таким образом, элементы генерируютсяавторегрессивно, что и дало название архитектуре. Якобиан такого преобразования вычисляется по следующей формуле: Таким образом, шаг генерации выглядит следующим образом: ... Однако вычисление скрытых переменныхне является авторегрессивным: Несмотря на то, что данная разновидность нормализующих потоков кажется более мощной моделью, её трудно применить на практике к данным высокой размерности. Это происходит из-за того, что генерация нового объекта осуществляется авторегрессивно по координатам, что становится слишком затратным при обучении на высокоразмерных данных, например, на изображениях. Ссылка на статью Чтобы быстро генерировать объекты из сложного распределения, мы можем избавиться от авторегрессивности на шаге генерации, поставив в авторегрессивную зависимость не наблюдаемые, а латентные переменные: Можем заметить, что проблема долгого вычисления авторегрессивных выражений никуда не уходит. Мы лишь изменяем построение модели таким образом, чтобы генерировать объектыбыстрее: Но вычисление, а значит и правдоподобия, становится долгим, и обучение занимает больше времени. Нормализующие потоки стали наиболее актуальны в задаче генерации звука, поскольку они обладают достаточно высокой выразительностью и эффективностью, чтобы быстро генерировать аудиозаписи высокого качества. В этом контексте, модель нормализующего потока должна генерировать аудио, получая на вход описание того, что ей необходимо сгенерировать. То есть модель обуславливается на дополнительные признаки. Нормализующие потоки могут быть обусловлены на входные данные путем использования дополнительных входных данных в качестве переменной, от которой зависят преобразования, применяемые к данным. Обусловливающей переменной может быть любая дополнительная информация, имеющая отношение к задаче генерации, такая как текстовые описания, изображения или другие характеристики данных. В контексте генерации аудио обуславливающей переменной обычно служитmel-спектрограмма, которая позволяет отобразить интенсивность различных частот аудио-сигнала в разные моменты времени. Нормализующий поток учится генерировать сигнал в виде waveform-а на основе спектрограммы путем обратного преобразования. Чтобы генерировать более длинные фрагменты звука, модель генерирует короткие звуковые кадры (фреймы) за раз, которые затем объединяются для формирования полного waveform-а. Теперь мы готовы узнать про применение нормализующих потоков в генерации аудио! Ссылка на статью Архитектура Inverse Autoregressive Flow (IAF) была изначально предложена для задачи генерации аудио. Она позволяет генерировать объекты крайне эффективно, но обучение методом максимального правдоподобия занимает много времени из-за авторегрессивности вычислений. Метод Probability Density Estimation позволяет решить эту проблему с помощью использования второй предобученной авторегрессивной модели в качестве учителя. IAF обучается в качестве модели-студента, минимизируя KL дивергенциюгдеи– распределения студента и учителя соответственно. Ключевым достижением данного подхода является то, что вычисление функции потерь требует вычисления кросс-энтропии между учителем и студентом, а не правдоподобия, что позволяет максимально распараллелить все вычисления ввиду отсутствия авторегрессивности в вычислениях. Вместе с тем в данной работе в качестве учителя выбирается не случайная модель, а оригинальная авторегрессивная модельWaveNet, которая в 2016 году позволила достичь state-of-the-art качества генерации аудио. Эта модель является не нормализующим потоком, а обыкновенной авторегрессивной моделью, которая обучается предсказывать следующий кусочек аудио (фрейм) длиной в несколько миллисекунд. Таким образом, с помощью IAF и Probability Density Distillation авторам удалось ускорить генерацию более чем в 1000 раз без потери качества! На картинке выше мы видим, что модель использует лингвистические признаки для генерации аудио. Эта задача является примеромзадачи условной генерации, где на вход модели подаетсяспектрограмма, сгенерированная отдельной моделью по тексту, а на выход ожидается речь в аудио-формате (waveform). О том, как модель использует дополнительную информацию для обуславливания, поговорим в главе проWaveglow Исследователи из OpenAI в 2018 году опубликовали работуGlow: Generative Flow with Invertible 1×1 Convolutions, которая значительно улучшает результаты модели RealNVP. Опишем два главых улучшения. Во-первых, для перемешивания каналов Glow используетобратимые свертки с ядром 1x1вместо фиксированной матрицы перестановок каналов в RealNVP; Это нововведение является по-настоящему красивым, так как в нем предлагается способ вычисления якобиана 2D-свертки за. А именно, логарифм якобиана такой 1x1-свертки с числом каналовдля тензора размераравен, где– матрица свёртки 1х1. Авторы предлагают использовать следующий вариант LU-разложения для матрицы: где– фиксированная матрица перестановок,– нижнетреугольная матрица с единицами на диагонали,– верхнетреугольная матрица с нулями на диагонали, а– обучаемый вектор. Нетрудно показать, что Благодаря этому авторам удалось снизить сложность вычислений якобиана сдо Кроме того, для улучшения сходимости использовали собственно разработанныйactnorm-слой(activation normalization). Поскольку нормализующие потоки требуют много вычислительных ресурсов, для обучения используются мини-батчи маленького размера, из-за чего батч-нормализация работает не очень хорошо. Авторы предлагают использовать следующий тип нормализации – actnorm: Нормализуем входной тензор (промежуточное изображение) по размерности каналов; Инициализируем параметры смещенияи разбросастатистиками спервого батча; Далее обучаем их в качестве обычных параметров. Таким образом, один блок нормализующего потока выглядит так: Ссылка на статью Вторым важным с практической точки зрения применением нормализующих потоков стала модельWaveGlow. Она представляет собой версию модели Glow, адаптированную для генерации речи по тексту. Как мы помним, эта задача также является примеромзадачи условной генерации: На практике это приводит к тому, что все распределения в нашей формуле становятсяусловными. Таким образом, при генерации мы также сэмплируем из условного распределения, а в слоях нормализующих потоков используем преобразования. В качестве обуславливающего факторадля WaveGlow мы имеем сгенерированную по текстуmel-спектрограмму, а на выходе ожидаем получить соответствующую тексту и спектрограмме аудио-запись. Как мы видим на изображении и в формулах ниже, mel-спектрограмма используется как дополнительный признак для нейросети, генерирующей параметры афинного преобразования. В качестве модели, которая производит параметры афинного преобразования, используется похожая на WaveNet архитектура с dilated-свертками. Правая часть схемы ниже более подробно показывает строение слоя affine coupling: Операцияразделяет тензорпополам на два тензора меньшей размерностиидля их последующего участия в слоеаффинного связывания(affine coupling). Пример генерации:Источник",
    "source_type": null,
    "useful_links": [
      {
        "text": "NICE",
        "url": "https://arxiv.org/abs/1410.8516"
      },
      {
        "text": "RealNVP",
        "url": "https://arxiv.org/abs/1605.08803"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://arxiv.org/abs/1705.07057"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://arxiv.org/abs/1606.04934"
      },
      {
        "text": "mel-спектрограмма",
        "url": "https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://arxiv.org/abs/1711.10433"
      },
      {
        "text": "WaveNet",
        "url": "https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio"
      },
      {
        "text": "спектрограмма",
        "url": "https://en.wikipedia.org/wiki/Mel_scale"
      },
      {
        "text": "Waveglow",
        "url": "#waveglow"
      },
      {
        "text": "Glow: Generative Flow with Invertible 1×1 Convolutions",
        "url": "https://arxiv.org/pdf/1807.03039.pdf"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://arxiv.org/pdf/1811.00002.pdf"
      },
      {
        "text": "mel-спектрограмму",
        "url": "https://en.wikipedia.org/wiki/Mel_scale"
      },
      {
        "text": "Источник",
        "url": "https://nv-adlr.github.io/WaveGlow"
      }
    ]
  },
  {
    "document_title": "Нормализующие потоки",
    "url": "https://education.yandex.ru/handbook/ml/article/normalizuyushie-potoki",
    "section_title": "Out-of-distribution detection",
    "text": "Может показаться, что способность точно и эффективно вычислять функцию правдоподобия может позволить без труда обнаруживать аномалии в данных, что может пригодиться во многих приложениях. Однако в работеKirichenko et al.на примере задачи генерации изображений было показано, что нормализующие потоки выучивают отображение картинок в латентное пространство, основываясь на локальных корреляциях пикселей и графических деталях, а не на семантическом контенте. Из-за этого правдоподобие OOD-объектов может быть выше, чем правдоподобие in-distribution сэмплов. Однако позже было предложено использовать ряд эвристик для того, чтобы улучшить способность к детекции аномалий за счет подсчета значения функции правдоподобия: Использовать значение правдоподобия второй модели потока, обученного на отличном от исходного датасете (например, ImageNet при исходном CelebA). А затем вычислять отношенение этих двух значений для вынесения вердикта об аномальности объекта.Schirrmeister et al. В работеSerrà et al.показали, что проблема качества нормализующих потоков в задаче детекции аномалий связана с чрезмерным влиянием сложности входных данных на значение функции правдоподобия. Поэтому авторы предложили использовать в качестве поправки размер сжатого изображения с помощью одного из алгоритмов компрессии (JPEG2000/PNG).",
    "source_type": null,
    "useful_links": [
      {
        "text": "Kirichenko et al.",
        "url": "https://arxiv.org/abs/2006.08545"
      },
      {
        "text": "Schirrmeister et al.",
        "url": "https://arxiv.org/abs/2006.10848"
      },
      {
        "text": "Serrà et al.",
        "url": "https://arxiv.org/abs/1909.11480"
      }
    ]
  },
  {
    "document_title": "Нормализующие потоки",
    "url": "https://education.yandex.ru/handbook/ml/article/normalizuyushie-potoki",
    "section_title": "Сравнение с другими типами генеративных моделей",
    "text": "Обратимся к статьеBond-Taylor et al., в которой приводится количественный анализ всех существующих семейств генеративных моделей в задаче генерации изображений из датасета CIFAR-10. В таблице выше указано, насколько представители каждого из популярных семейств генеративных моделей эффективны в следующих аспектах решения задачи: скорость обучения; скорость генерации; число обучаемых параметров; разрешение генерируемого изображения; ограничение на форму якобиана; возможность вычислять правдоподобие объекта; FID (Fréchet Inception Distance) тестовой выборки; Отрицательный логарифм правдоподобия тестовой выборки. За расшифровкой обратимся к таблице ниже: Подведя итог, можно сказать, что нормализующие потоки: требуют очень много времени на обучение, так как при обучении проводятся нетривиальные неоптимизированные вычисления; имеют скорость генерации, сравнимую с GAN-ами; менее эффективны по соотношению качество/число параметров, чем GAN-ы и диффузионные модели; позволяютбыстровычислять точное значение функции правдоподобия объекта; обладают сравнительно неплохим качеством генерации, проигрывающим GAN-ам и диффузионным моделям. Итак, нормализующие потоки явно выделяются среди других семейств генеративных моделей своими свойствами – обратимостью и способностью вычислять правдоподобие объекта. Но если для решения задачи они не требуются, то имеет смысл попробовать другие модели – в первую очередь, GAN-ы и диффузионные модели.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Bond-Taylor et al.",
        "url": "https://arxiv.org/abs/2103.04922"
      },
      {
        "text": "Fréchet Inception Distance",
        "url": "https://arxiv.org/abs/1706.08500"
      }
    ]
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "Введение",
    "text": "Допустим, мы работаем в сервисе рекомендаций фильмов и перед нами стоит задача подобрать для каждого пользователя набор наиболее релевантных фильмов. Пользователь может разными способами провзаимодействовать с фильмом: посмотреть его, оставить отзыв, поставить оценку (например, от 1 до 5). В этом параграфе мы будем строить рекомендации на основе матрицы оценок user-item. Её строки соответствуют объектам, а столбцы – пользователям. На-й позиции матрицы мы ставим либо пропуск, либо оценку, выставленную-му объекту-м пользователем. Разумеется, не все оценки нам известны: вряд ли каждый пользователь имел возможность ознакомиться с каждым объектом. В процессе решения задачи мы будем пытаться восстановить оценки на местах пропусков. Сделав это, мы сможем, например, порекомендовать пользователю те объекты, которые он ещё не смотрел, но предсказанная оценка которых для этого пользователя максимальна. Все типы взаимодействия пользователей с объектами мы можем рассматривать как пользовательский фидбек. Обычно различаютявный(explicit) инеявный(implicit) виды фидбека. Фидбек называется явным, если он отражает степень интереса пользователя к объекту. Например, к этому типу относят рейтинги, лайки и дизлайки. Такого фидбека обычно мало, он поступает только от тех пользователей, которые соглашаются нам его дать. Обычно гораздо больше информации имеется о неявных предпочтениях – просмотры, клики, добавление в закладки. Но если пользователь, например, посмотрел фильм, мы ещё не можем сделать вывод, что он ему понравился. Мы можем лишь утверждать, что до просмотра этот фильм казался ему достаточно интересным. Поэтому обычно неявная обратная связь более шумная, чем явная. Для начала научимся работать с явным фидбеком.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "Связь с задачей матричной факторизации",
    "text": "Вернёмся к задаче восстановления матрицы оценок и предположим, что каждый пользователь и объект можно закодировать набором изскрытых признаков, а оценка-го объекта-м пользователем равна скалярному произведению соответствующих векторов скрытых представленийи. Тогда если бы наша матрица оценок была заполнена полностью, её можно было бы представить в виде произведений двух матрици, составленных по столбцам из скрытых представлений пользователей и объектов: Правда, в таком случае нам бы и не требовалось ничего решать: мы могли бы просто рекомендовать пользователю объекты с самыми высокими оценками в соответствующей строке. Но суровая реальность такова, что зачастую матрица оценок сильно разрежена. Мы можем поступить следующим образом: восстановить латентные векторы для пользователей и объектов по имеющемуся набору оценок, после чего предсказать оценки для всех отсутствующих позиций. В параграфе, посвящённомматричной факторизации, мы уже обсуждали способы решения данной задачи с помощью SVD и стохастического градиентного спуска. У SVD есть существенные недостатки: из-за большого количества пропусков в матрице полученное решение будет слишком шумным, а кроме того, его придется каждый раз рассчитывать заново при добавлении новых пользователей или объектов. Градиентный спуск не имеет данных проблем, но тоже не очень практичен. В этом параграфе мы рассмотрим более эффективный алгоритм, называемыйAlternating Least Squares(ALS).",
    "source_type": null,
    "useful_links": [
      {
        "text": "матричной факторизации",
        "url": "https://academy.yandex.ru/handbook/ml/article/matrichnaya-faktorizaciya#ispolzovanie-svd-razdelyonnye-predstavleniya-i-rekomendatelnaya-sistema-dlya-bednyh"
      }
    ]
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "Постановка задачи",
    "text": "Пусть, как и раньше,– скрытые представления пользователей и объектов соответственно размерности. Запишем эти векторы по строкам в матрицыиразмераисоответственно, где– количество пользователей, а– количество объектов. Обозначим черезмножество таких парпользователей и объектов, для которых имеются явно проставленные оценки. Предсказывать рейтинги мы будем как скалярное произведение скрытых представлений: В результате мы приходим к следующей задаче оптимизации. Мы хотим научиться как можно лучше приближать известные рейтинги: Добавив регуляризацию получаем следующую функцию потерь:",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "Alternating Least Squares (ALS)",
    "text": "Оптимальные параметры можно найти с помощью хорошо знакомого нам градиентного спуска, но есть более быстрые и надёжные способы. Если мысленно заморозить параметры, соответствующие латентным факторам пользователей, задача оптимизации латентных представлений объектов сведётся к задаче наименьших квадратов, для которой мы знаем точное решение. Итоговый процесс оптимизации функции потерь будет иметь следующий вид. В цикле до сходимости: Фиксируем матрицу(скрытые представления пользователей); Решаем задачу L2-регуляризованной регрессии для каждого товара и находим оптимальную матрицу; Фиксируем матрицу(скрытые представления объектов); Решаем задачу L2-регуляризованной регрессии для каждого пользователя и находим оптимальную матрицу; Решение, получаемое путём попеременного вычисления точных аналитических решений, обычно точнее тех, что получаются с помощью наивного градиентного спуска. Более того, данное решение имеет эффективную реализацию, позволяющую использовать преимущества параллельных вычислений. Для лучшего понимания распишем каждый шаг данного алгоритма оптимизации: Раскроем квадратичный член: В первой сумме константы, они уходят. Из второй и третьей возьмём только те слагаемые, в которых участвует. Из четвёртой остается только член с, так как всенезависимы. Последняя сумма пропадает, так какинезависимы: В первой сумме индексфиксирован, поэтомуможно вынести за знак суммы: Объединим второй и третий члены формулы, вынесем умножение наза скобки: Теперь воспользуемся тем, что и выпишем ответ: Таким образом, мы получили аналитическое выражение для вычисления каждогона шаге алгоритма. Отметим, что каждый вектормы можем вычислить независимо от других. Данное наблюдение позволяет нам использовать всю мощь параллельных вычислений для эффективного решения оптимизационной задачи. Распределив данные так, что на каждой вычислительной машине хранятся вседля некоторого подмножества, на одной итерации алгоритма мы можем параллельно вычислить все. На следующей итерации аналогичным образом вычисляем все.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "IALS (Implicit ALS)",
    "text": "Оригинальная статья Раньше мы работали с матрицейкак с матрицей рейтингов, явно проставленных пользователем. Как мы говорили выше, такого фидбека обычно довольно мало, а куда больше неявного фидбека. При этом количество данных может быть критичным при работе с такими разреженными структурами, как матрицы рейтингов, поэтому хочется научиться работать и с неявным фидбеком тоже. Неявным фидбеком является в том числе и факт взаимодействия, поэтому мы можем заполнить всю матрицу user-item целиком: на тех позициях, где пользователь положительно взаимодействовал с объектом, поставим, а на тех, где взаимодействие было негативным или его вообще не произошло, поставим. Эта компонента фидбека называется предпочтением (preference): Тем самым мы избавились от пропусков в матрице, но использовали не всю информацию. Согласитесь, если один пользователь посмотрел часовое видео польностью, а другой выключил после 5 минут, несправедливо считать, что это видео им понравилось в одинаковой степени. Введём ещё степень уверенности (confidence), отражающую уверенность в оценке пользователя: где– некоторая константа. На местах пропусков мы явно проставляем. На остальных позициях мы можем сами регулировать степень уверенности в зависимости от фидбека пользователя. Рассмотрим следующую функцию потерь: Она позволяет: Учитывать неявный фидбек, которого обычно на порядок больше, чем явного, Регулировать степень уверенности в действиях пользователей. Распишем нашу функцию потерь по аналогии с ALS и приведем к форме: Разобьём сумму на 2 части. В первой будет сумма по тем элементам, с которыми у пользователя не было положительного взаимодействия. Во второй – сумма по всем остальным элементам. Также заметим, что во втором множителе суммирование имеет смысл только по ненулевым элементам: Заметим, что в первой сумме всебудут равны 1 (так как везде). Прибавим и вычтем единицу кво второй сумме и разобьем её на две компоненты. Вторый из них будет сумма по всем, где. Объединив её с первой суммой, получимпросто: Заметим, что произведениеникак не зависит от. Мы можем посчитать его один раз для всехперед очередной итерацией. В остальном же мы точно так же, как и в случае с обычным ALS, можем распределить данные так, чтобы на одной машине содержались все, необходимые для обновления, хранящихся на этой машине, и сделать следующий шаг оптимизации нашей функции потерь.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Оригинальная статья",
        "url": "http://yifanhu.net/PUB/cf.pdf"
      }
    ]
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "Обобщения ALS и IALS",
    "text": "Обе модели: и ALS, и Imlicit ALS – можно несколько усложнить, вместорассмотрев. В таком случаеииграют роль некоторых априорных усреднённых оценок пользователя и объекта соответственно, аявляется глобальной априорной константой. В модели IALS мы обычно полагаем элементыравнымиво всех случаях, когда имело место взаимодействие, но можем использовать и другие значения, в том числе зависящие от того, что ещё нам известно о пользователях и объектах. Для уверенностидля IALS необязательно использоватьв качестве значения по умолчанию. Например, события «пользователь не посмотрел популярный фильм» и «пользователь не посмотрел редкий фильм» могут иметь для нас разный вес.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "FunkSVD",
    "text": "Этот подход получил широкую известность после конкурса Netflix Prize в 2006 году.Пост Саймона Фанка про участие в Netflize Prize Фанк предложил моделировать рейтинг как. Однако, в отличие от ALS, оптимизация производилась с помощью стохастического градиентного спуска. Правила обновления весов выглядели следующим образом: Этот подход не получил большой популярности, так как градиентный спуск, в отличие от ALS, намного сложнее распараллелить.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Пост Саймона Фанка про участие в Netflize Prize",
        "url": "https://sifter.org/simon/journal/20061211.html"
      }
    ]
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "Singular Value Decomposition with implicit feedback (SVD++)",
    "text": "Оригинальная статья Ранее мы отдельно рассматривали факторизации для явного и неявного фидбека. Но, ограничиваясь только одним типом фидбека, мы теряем много информации. Если мы работаем над стриминговым сервисом, то в качестве неявного фидбека мы можем взять, например, историю фильмов, взятых в прокат. Такие данные не предоставляют нам явных оценок пользователей, но позволяют выявить неявные предпочтения. Учесть неявный фидбек в модели можно следующим образом: В данной модели пользователь представлен скрытым представлением, а также слагаемым, отражающим историю неявных взаимодей с айтемами:. Важно отметить, что векторане совпадают с векторами. Это своего рода «неявные» вектора айтемов.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Оригинальная статья",
        "url": "https://people.engr.tamu.edu/huangrh/Spring16/papers_course/matrix_factorization.pdf"
      }
    ]
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "Collaborative Filtering with Temporal Dynamics (timeSVD++)",
    "text": "Оригинальная статья Особенностью всех рассмотренных на данный момент разложений является отсутствие учёта порядка просмотра объектов. Однако, как показывает практика, со временем пользователь может менять своё мнение о тех или иных айтемах. Тогда, отсортировав взаимодействия по времени, мы можем разбить события на бакеты и модифицировать приведённую выше функцию потерь, в которой таргет выражается следующим образом:",
    "source_type": null,
    "useful_links": [
      {
        "text": "Оригинальная статья",
        "url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.379.1951&rep=rep1&type=pdf"
      }
    ]
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "SLIM (Sparse Linear Methods)",
    "text": "Оригинальная статья Описанные выше методы демонстрируют хорошее качество, однако требуют больших усилий для эффективной работы в онлайн сервисах. Возникает потребность в лёгких моделях, эффективность которых значительно выше, но качество которых не сильно хуже. Для этого была предложена линейная разреженная модель. Итак, пусть– бинарная матрицаuser-item взаимодействий, например, матрица кликов/показов. Будем определять ответ алгоритмакак взвешивание событий из истории пользователя: При этом наложим ограничение. В такой постановке мы будем учить модель находить «похожие» объекты. Добавим ещё условие, которое позволит нам избежать элементарного решения – единичной матрицы.В результате весвыступает в качестве некоторой меры схожести-го и-го объектов. Осталось определиться с методом оптимизации данных параметров. Для оптимизации используется функция потерь MSE с- и-регуляризаторами: Можно заметить, что задачу можно разбить нанезависимых по строкам матрицы: Данную задачу можно решать покоординатным спуском: Фиксируем все строки, кроме одной координаты; переходим в оптимум по; переходим к следующей координате; повторять до сходимости. Применение данной модели выглядит следующим образом: Рассчитываем вектор взаимодействий пользователя; Считаемдля всех непросмотренных объектов; Отбираем топнепросмотренных объектов по. Так как в задаче оптимизации мы пользуемся-регуляризацией, матрицаполучается разреженной. Матрица просмотровтоже разреженная (по определению). Эти обстоятельства позволяют заметно улучшить эффективность применения модели.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Оригинальная статья",
        "url": "http://glaros.dtc.umn.edu/gkhome/node/774"
      }
    ]
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "Итоги",
    "text": "В этом параграфе мы рассмотрели некоторые рекомендательные модели на основе матричных факторизаций. Такие модели редко используется в чистом виде для формирования рекомендательной выдачи. Обычно результаты матричной факторизации используются для генерации кандидатов в рекомендации, когда из сотен тысяч и миллионов объектов необходимо отобрать небольшое количество (например, сотни) самых релевантных. Для генерации кандидатов требуется перемножить вектор пользователя с вектором каждого из сотен тысяч объектов и отобрать топ самых релевантных. В онлайн-сервисах, когда время формирования рекомендаций составляет несколько сотен миллисекунд, нет возможности при каждом запросе рассчитывать релевантность каждого объекта для данного пользователя. Оптимизировать поиск можно с помощью инструментов для поиска ближайших соседей. Для любой функции близости, в том числе и для скалярного произведения, можно построить индекс – структуру данных, с помощью которой для любого пользователя мы сможем быстро приближённо, но зато быстро искать «ближайшие» объекты. В результате, принцип работы выглядит следующим образом: обучаются эмбеддинги объектов и пользователей; для представлений эмбеддингов строится индекс; в рантайме по вектору пользователя происходит приближённый поисксамых релевантных объектов; таким образом генерируется список кандидатов в рекомендации; дальше список кандидатов обрабатывается с помощью более хитрых методов машинного обучения. Подробнее о том, как быстро искать ближайших соседей, вы можете узнать в параграфе посвященномметрическим методам Помимо генерации кандидатов, полученные представления можно использовать в качестве признаков в более сложных моделях. Основной недостаток методов, основанных на матричной факторизации, состоит в том, что они используют лишь информацию о взаимодействии пользователей и объектов, но не о них самих. В следующем параграфе мы рассмотримконтентные методы, которые используют атрибуты объектов и пользователей.",
    "source_type": null,
    "useful_links": [
      {
        "text": "метрическим методам",
        "url": "https://education.yandex.ru/handbook/ml/article/metricheskiye-metody"
      },
      {
        "text": "контентные методы",
        "url": "https://education.yandex.ru/handbook/ml/article/kontentnye-rekomendacii"
      }
    ]
  },
  {
    "document_title": "Рекомендации на основе матричных разложений",
    "url": "https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij",
    "section_title": "Список литературы",
    "text": "Статьяпро Implicit ALS Статьяпро SVD++ Статьяпро TimeSVD++ Статьяпро SLIM ПостСаймона Фанка про участие в конкурсе Netflix Prize",
    "source_type": null,
    "useful_links": [
      {
        "text": "Статья",
        "url": "http://yifanhu.net/PUB/cf.pdf"
      },
      {
        "text": "Статья",
        "url": "https://people.engr.tamu.edu/huangrh/Spring16/papers_course/matrix_factorization.pdf"
      },
      {
        "text": "Статья",
        "url": "https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.379.1951&rep=rep1&type=pdf"
      },
      {
        "text": "Статья",
        "url": "http://glaros.dtc.umn.edu/gkhome/node/774"
      },
      {
        "text": "Пост",
        "url": "https://sifter.org/simon/journal/20061211.html"
      }
    ]
  },
  {
    "document_title": "Свёрточные нейросети",
    "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
    "section_title": "Формат данных",
    "text": "Картинки в большинстве случаев представляют собой упорядоченный набор пикселей, где каждый пиксель — это вектор из трех «каналов»: интенсивность красного, интенсивность зелёного, интенсивность синего. Каждая интенсивность характеризуется числом от 0 до 1, но для привычных нам изображений этот интервал равномерно дискретизирован для экономии памяти, чтобы уместиться в 8 бит (от 0 до 255). При этом нулевая интенсивность (0, 0, 0), соответствует чёрному цвету, а максимальная интенсивность (255, 255, 255) — белому. Когда мы наблюдаем изображение на мониторе компьютера, мы видим эти пиксели «уложенными» в строки одинаковой длины (человек не сможет воспринять картинку, вытянутую в один вектор). Длину каждой такой строки называют ширинойWкартинки, а количество строк — высотойH. Резюмирую, мы можем рассматривать картинку, как тензорHxWx3, состоящий из чисел uint8. Существует множество разных форматов хранения картинок: вместо трех интенсивностей мы можем использовать триплет «оттенок, насыщенность, интенсивность», а сами картинки хранить, например, как тензорCxHxW.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Свёрточные нейросети",
    "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
    "section_title": "MLP",
    "text": "Наверное, самый простой способ построить нейронную сеть для решения задачи классификации на наших данных — это «развернуть» нашу картинку в вектор, а затем использовать обычную многослойную сеть с кросс-энтропией в качестве лосса. Однако, такой подход имеет несколько недостатков. В первом слое у нас получаетсяHxWxCxCoutпараметров, где Cout — это количество нейронов в первом слое. Если поставитьCoutслишком маленьким, мы рискуем потерять много важной информации, особенно, если рассматривать картинки размером, например, 1920x1080. Если же выставить Cout большим, рискуем получить слишком много параметров (а это только первый слой), а с этим и все вытекающие проблемы — переобучение, сложность оптимизации и так далее. Что здесь имеется в виду под «структурой»? Попробуем объяснить на примере. Для этого рассмотрим картинку щеночка: Если мы сдвинем картинку на несколько пикселей, то мы все еще будем уверены в том, что это щенок: Точно также мы останемся неизменны в своем мнении, если картинку отмасштабировать: или повернуть/развернуть: Получается, что нейронная сеть должна «сама» понять, что ее ответ должен быть инвариантен к описанным преобразованиям. Но, обычно, это достигается за счет увеличения количества нейронов в скрытых слоях (как мы можем помнить изuniversal approximation theorem), что и так для нас — головная боль из-за первого пункта. С частью этих проблем нам поможет новый «строительный блок» — свёртка. О ней в следующем разделе.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Свёрточные нейросети",
    "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
    "section_title": "Свёртки",
    "text": "Строгое определение свёртки мы дадим ниже, а вначале разберёмся в мотивации. Давайте попробуем решить хотя бы проблему инвариантности к сдвигу. Щенок может быть где угодно на картинке, и мы не можем наверняка сказать, в какой части изображения наша модель «лучше всего» научилась видеть щенков. Поэтому для надёжного предсказания будет логично посдвигать картинку на все возможные смещения (пустоты заполним нулями): Затем для каждого смещения мы предскажем вероятность наличия щенка на картинке. Получившиеся предсказания можно уже агрегировать как удобно: среднее, максимум и так далее. Давайте взглянем на эту операцию под другим углом. Рассмотрим картинку, размером в 3 раза превышающую оригинальную, в центре которой находится наше изображение щеночка: Возьмём окно размером с исходную картинку, и будем его сдвигать на все возможные смещения внутри нового изображения: Легко видеть, что получается то же самое, как если бы мы картинку сдвигали относительно окна. Представим себе самую простую модель, основанную на данном принципе — что-то вроде ансамбля линейных. Каждую из сдвинутых картинок вытянем в вектор и скалярно умножим на вектор весов (для простоты один и тот же для всех сдвигов) — получим линейный оператор, для которого есть специальное имя —свёртка. Это один из важнейших компонент всвёрточныхнейронных сетях. Веса свёртки, упорядоченные в тензор (в нашем случае размерностиHxWx3), составляют еёядро. Область картинки, которая обрабатывается в текущий момент, обычно называетсяокном свёртки. Обратите внимание, что обычно такие свёртки называются двумерными — так как окно свёртки пробегает по двум измерениям картинки (при этом все цветовые каналы участвуют в вычислениях). Следующая картинка поможет разобраться (внимание: на нейнетизображения весов оператора): Каждый «кубик» на картинке — это число. Большой черный тензор слева — это изображение щеночка. Фиолетовым на нем выделено окно, из которого мы достаем все пиксели и разворачиваем в вектор (аналогично операции flatten в numpy). Далее этот вектор умножается на вектор весов класса «щенок», и получается число— логит интересующего класса. Добавив остальные классы, получим матрицу весов— прямо как в мультиномиальной логистической регрессии. Эту операцию мы повторяем для каждого возможного сдвига окна свёртки. Результаты домножения удобно бывает скомпоновать в двумерную табличку, которую при желании можно трактовать, как некоторую новую картинку (в серых тонах, потому что канал уже только один). Воспользуемся этим, чтобы получше осознать, что происходит в ходе свёртки. Вопрос на подумать. Какой геометрический смысл имеет свёртка с ядром А с ядром Вопрос на подумать. На краях картинок из ответа к предыдущему вопросу заметны тёмные рамки. Что это такое? Откуда они берутся? Решив проблему обеспечения устойчивости к сдвигу картинки и имея на руках наш огромный свёрточный фильтр, давайте попробуем теперь справиться с первой проблемой — количество параметров. Самое простое, что можно придумать, — это уменьшить размер окна сHxWдо, допустим,kxk(обычно нечётное и). В этом случае получается радикальное снижение количества параметров и сложности вычислений. К сожалению, с таким подходом возникает новая проблема: предсказание для какого-то окна никак не учитывает контекст вокруг него. Получается, мы можем получить разумные предсказания только в случае, если распознаваемый объект обладает признаками, которые «помещаются» в окно свёртки (например, лого автомобиля при классификации марок машин), либо объекты заметно отличаются по своей текстуре (шерсть кошки vs кирпич, например). На картинке ниже сделана попытка изобразить проблему: Область картинки, на которую «смотрит» наша нейронная сеть, называетсяreceptive field— и про него приходится часто думать в задачах компьютерного зрения. Давайте и мы подумаем, как его можно было бы увеличить, не увеличивая размер ядра. Вспомним, что в нашей нейронке сейчас есть только один слой, сразу предсказывающий класс. Выглядит так, что мы можем применить уже знакомую технику стекинга слоев: пусть на первой стадии мы делаемразных свёрток с фильтрам размеромkxk. Результаты каждой свёртки можно упорядочить в виде новой «картинки», а из этих «картинок» сложить трёхмерный тензор. Получаем так называемую карту признаков размеромHxWxC_1. Применим к ней поэлементно нелинейность и воспользуемсяKновыми свёртками для получения предсказаний для каждого пикселя. На таком шаге получается, что наш receptive field для финальных нейронов вырос отkxkдо(2k-1)x(2k-1)(пояснение накартинке). Повторяя такую операцию, мы можем добиться, чтобы наши финальные нейроны уже могли «видеть» почти всю нужную информацию для хорошего предикта. Более того, у нас возникает меньшее количество параметров и падает сложность вычислений в сравнении с использованием одной большой полносвязной сети. Как это схематично выглядит: Промежуточный тензор, полученный при помощисвёрток, можно себе представить, как новую картинку, у которой ужеканалов. На следующей картинке можно отследить, как меняется receptive field в зависимости от глубины: На картинке схематично изображен «плоский» двумерный тензор (количество каналов = 1), к которому последовательно применили три свёртки 3x3. В каждом случае рассматривается пиксель в центре. Каждый соответствующий тензор помечен, как. Если рассматривать первую свёртку (), то размер receptive field равен размеру е окна = 3. Рассмотрим вторую свёртку. В ее вычислении участвуют пиксели из квадрата 3х3, причём каждый из них, в свою очередь, был получен при помощи предыдущей свёртки. Получается, что receptive field композиции свёрток— это объединение receptive fields свёрткипо всем пикселям из окна свёртки, образуя новый, размером 5x5. Аналогичные рассуждения можно повторить и для всех последующих свёрток. Ещё один способ увеличить receptive field — это использовать dilated convolution, в которых окно свёртки (то есть те пиксели картинки, на которые умножается ядро) не обязано быть цельным, а может идти с некоторым шагом (вообще говоря, даже разным по осямHиW). Проиллюстрируем, как будет выглядеть окно для обычной свёртки и для свёртки с шагомdilation=2: Если установить параметрdilation=(1,1), получится обычная свёртка. Итак, свёртки помогли нам решить сразу две проблемы: устойчивости к сдвигу и минимизации числа параметров. Теперь давайте попробуем определить оператор более формально. Вопрос на подумать. Пусть у нас есть тензор размеромHxWxC_{in}, к которому одновременно применяетсясвёрток, размер окна каждой равенkxk. Посчитайте количество обучаемых параметров. Как изменится формула, если к свёртке добавить смещение (bias)? Во сколько раз изменится количество параметров, если увеличить размер окна в 2 раза? А если увеличить количество каналовив два раза? А если увеличить размер входного тензора в 2 раза по высоте и ширине? Вопрос на подумать. Оцените количество операций сложений-умножений для предыдущего упражнения. Как оно поменяется, если увеличить в два раза размер окна? Количество каналов? Размер входного тензора? Вопрос на подумать. Пусть последовательно применяетсясвёрток. Посчитайте размер receptive field для последнего оператора. Нетрудно видеть, что аналоги двумерной свёртки можно определить и для тензоров другой размерности, в любой ситуации, когда для нас актуально поддерживать устойчивость модели к сдвигам данных. Например, это актуально для работы с текстами. Обычно текст разбивается на последовательные токены (например, на слова или какие-то subword units), и каждому из этих токенов ставится в соответствие вектор (более подробно об этом вы можете почитать в параграфе про работу с текстами или вразделепро вложения слов учебника по NLP Лены Войта). Представим теперь, что мы хотим определить, позитивно или негативно окрашен этот текст. Мы можем предположить, что эмоциональная окраска локальна и может проявляться на любом участке текста, и тогда нам нужна модель, которая может «посмотреть» отдельно на каждый последовательный фрагмент текста некоторой длины. И здесь тоже может сработать свёртка: Существуют свёртки и для тензоров более высокой размерности, например, для видео (где прибавляется ещё координата «время»). А что делать с остальными проблемами: поворотом, отражением, масштабированием? К сожалению, на момент написания параграфа (вторая половина 2021 года), автору не было известно об успешном опыте решения этих проблем в архитектуре сети. При этом оказывается, что приведенного оператора уже достаточно, чтобы нейронная сеть могла хорошо обобщать на невиданные ранее картинки (лишь бы свёрток было больше и сеть глубже). В качестве потенциально интересного (но пока не проявившего себя на практике) направления исследований можно упомянуть капсульные нейросети. Кроме того, вам может быть интересно познакомиться сгеометрическим глубинным обучением. В качестве короткого введения рекомендуем посмотреть вот этотkeynote с ICLR 2021, которое ставит своей целью исследование общих принципов, связывающих устойчивость к различным преобразованием и современные нейросетевые архитектуры (авторы сравнивают свои идеи с эрлангенской программой Феликса Кляйна — отсюда название).",
    "source_type": null,
    "useful_links": [
      {
        "text": "картинке",
        "url": "#fig:receptive_field"
      },
      {
        "text": "разделе",
        "url": "https://lena-voita.github.io/nlp_course/word_embeddings.html"
      },
      {
        "text": "геометрическим глубинным обучением",
        "url": "https://geometricdeeplearning.com/lectures/"
      },
      {
        "text": "keynote с ICLR 2021",
        "url": "https://www.youtube.com/watch?v=w6Pw4MOzMuo"
      }
    ]
  },
  {
    "document_title": "Свёрточные нейросети",
    "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
    "section_title": "Свёрточный слой и обратное распространение ошибки",
    "text": "Поговорим о том, как через свёрточный слой протекают градиенты. Нам нужно будет научиться градиент по выходу превращать в градиент по входу и в градиент по весам из ядра. Начнём с иллюстрации для одномерной свёртки с одним входным каналом, ядром длиныс дополнением по бокам нулями. Заметим, что её можно представить в виде матричного умножения: Обозначим последнюю матрицу через, а ядро свёртки через. Что происходит с градиентом при переходе через матричное умножение, мы уже отлично знаем. Градиент по весам равен Разберёмся, что из себя представляет умножение насправа. Эта матрица имеет вид Она тоже соответствует свёртке, только: с симметричным исходному ядром; с дополнением векторанулями (это как раз соответствует неполным столбцам: можно считать, что «выходящие» за границы матрицы и отсутствующие в ней элементы умножаются на нули). Вопрос на подумать. Поменяется ли что-нибудь, если исходный вектор не дополнять нулями? Рассмотрим теперь двумерную свёртку, для простоты нечётного размера и без свободного члена Продифференцируем по: Разберёмся с производной. Во всей большой сумме из определения свёртки дляэлементможет встретиться в позицияхпри,и всевозможных, причём это возможно лишь если,(для всех остальныхпроизводная понулевая). Соответствующий коэффициент прибудет равен. Таким образом, производная будет иметь вид: Легко заметить, что это тоже свёртка, но поскольку индексыви встоят с разными знаками, получаем, что Продифференцируем по: В формуле дляэлементможет встретиться в позициях, для,, с коэффициентами(для любых). Значит, производная будет иметь вид: В этой формуле тоже нетрудно узнать свёртку: Вопрос на подумать. Если всё-таки есть свободные члены, как будет выглядить градиент по?",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Свёрточные нейросети",
    "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
    "section_title": "Остальные важные блоки свёрточных нейронных сетей",
    "text": "Наигравшись с нашими мысленными экспериментами, давайте обратимся к опыту инженеров и исследователей, который копился с 2012 года –alexnet. Он поможет нам разобраться с тем, как эффективней всего строить картиночные нейронки. Здесь будут перечислены самые важные (на момент написания и по мнению автора) блоки. Каждая изсвёрток очередного свёрточного слоя — это новая карта признаков для нашего изображения, и нам, конечно, хотелось бы, чтобы таких карт было побольше: ведь это позволит нам выучивать больше новых закономерностей. Но для картинок в высоком разрешении это может быть затруднительно: слишком уж много будет параметров. Выходом оказалось использование следующей эвристики: сначала сделаем несколько свёрток сканалами, а затем как-нибудь уменьшим нашу карту признаков в 2 раза и одновременно увеличим количество свёрток во столько же. Посчитаем, как в таком случае изменится число параметров: было, стало, то есть, ничего не изменилось, а количество фильтров удвоилось, что приводит к выучиванию более сложных зависимостей. Осталось разобраться, как именно можно понижать разрешение картинки. Тривиальный способ — взять все пиксели с нечетными индексами. Такой подход будет работать, но, как может подсказать здравый смысл, выкидывать пиксели — значит терять информацию, а этого не хотелось бы делать. Здесь есть много вариантов: например, брать среднее/максимум по обучаемым весам в окне2x2, которое идет по карте признаков с шагом 2. Экспериментально выяснилось, что максимум — хороший выбор, и, в большинстве архитектур, используют именно его. Обратите внимание, что максимум берется для каждого канала независимо. Еще одно преимущество — увеличение receptive field. Получается, что он увеличивается в 2 раза: Операция понижения разрешения со взятием максимума в окне называетсяmax pooling, а со взятием среднего —average pooling. Вопрос на подумать. Как будет преобразовываться градиент во время error backpropagation для maxpool с окном и шагом 2x2? А для average pool? Кстати, ещё один способ уменьшать размер карт признаков по ходу применения свёрточной сети — использованиеstrided convolution, в которых ядро свёртки сдвигается на каждом шаге на некоторое большее единицы число пикселей (возможно, разное для осейHиW; обычная свёртка получается, если установить параметрstride=(1,1)). Как свёрточные слои, так и пулинг превращают картинку в «стопку» карт признаков. Но если мы решаем задачу классификации или регрессии, то в итоге нам надо получить число (или вектор логитов, если речь про многоклассовую классификацию). Один из способов добиться этого — воспользоваться тем, что свёртка без дополнения нулями и пулинг уменьшают размер карты признаков, и в итоге при должном терпении и верном расчёте мы можем получить тензор1x1xC(финальные, общие признаки изображения), к которому уже можно применить один или несколько полносвязных слоёв. Или же можно, не дождавшись, пока пространственные измерения схлопнутся, «растянуть» всё в один вектор и после этого применить полносвязные слои (именно так, как мы не хотели делать, не правда ли?). Примерно так и происходило в старых архитектурах (alexnet, vgg). Вопрос на подумать. Попробуйте соорудить конструкцию из свёточных слоёв и слоёв пулинга, превращающую изображение размера128x128x3в тензор размера1x1xC. Но у такого подхода есть как минимум один существенный недостаток: для каждого размера входящего изображения нам придётся делать новую сетку. Позднее было предложено следующее: после скольких-то свёрточных слоёв мы будем брать среднее вдоль пространственных осей нашего последнего тензора и усреднять их активации, а уже после этого строить MLP. Это и есть Global Average Pooling. У такого подхода есть несколько преимуществ: радикально меньше параметров; теперь мы можем применять нейронку к картинку любого размера; мы сохраняем «магию» инвариантности предсказаний к сдвигам. Оказывается, что, если мы будем бесконтрольно стекать наши свёртки, то, несмотря на использование relu и batch normalization, градиенты все равно будут затухать, и на первых слоях будут почти нулевыми. Интересное решение предлагают авторы архитектуры resnet: давайте будем «прокидывать» признаки на предыдущем слое мимо свёрток на следующем: Таким образом получается, что градиент доплывет даже до самых первых слоев, что существенно ускоряет сходимость и качество полученной модели. Вопрос: почему именно сумма? Может, лучше конкатенировать? Авторы densenet именно такой подход и предлагают (с оговорками), получая результаты лучше, чем у resnet. Однако, такой подход получается вычислительно сложным и редко используется на практике.",
    "source_type": null,
    "useful_links": [
      {
        "text": "alexnet",
        "url": "https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf"
      }
    ]
  },
  {
    "document_title": "Свёрточные нейросети",
    "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
    "section_title": "Регуляризация",
    "text": "Несмотря на наши ухищрения со свёртками, в современных нейронных сетях параметров все равно оказывается больше, чем количество картинок. Поэтому часто оказывается важным использовать различные комбинации регуляризаторов, которых уже стало слишком много, чтобы все описывать в этом параграфе, так что мы рассмотрим лишь несколько наиболее важных. Почти все регуляризаторы, которые использовались в классической машинке и полносвязных сетях, применимы и здесь: l1/l2, dropout и так далее. Вопрос на подумать. Насколько разумно использовать dropout в свёрточных слоях? Как можно модифицировать метод, чтобы он стал «более подходящим»? Это один из самых мощных инструментов при работе с картинками. Помогает, даже если картинок несколько тысяч, а нейронная сеть с миллионами параметров. Мы уже выяснили, что смещение\\поворот\\прочее не меняют (при разумных параметрах) факта наличия на картинке того или иного объекта. На самом деле, есть огромное множество операций, сохраняющих это свойство: сдвиги, повороты и отражения; добавление случайного гауссового шума; вырезание случайной части картинки (cutout); перспективные преобразования; случайное изменение оттенка\\насыщенности\\яркости для всей картинки; и многое другое. Пример хорошой библиотеки с аугментациями:Albumentations. Часто оказывается, что нейронная сеть делает «слишком уверенные предсказания»: 0.9999 или 0.00001. Это становится головной болью, если в нашей разметке есть шум — тогда градиенты на таких объектах могут сильно портить сходимость. Исследователи пришли к интересной идее: давайте предсказывать не one-hot метку, а ее сглаженный вариант. Итак, пусть у нас естьклассов: Обычно берут. Тем самым модель штрафуется за слишком уверенные предсказания, а шумные лейблы уже не вносят такого большого вклада в градиент. Самый интересный вариант. А что будет, если мы сделаем выпуклую комбинацию двух картинок и их лейблов: гдеобычно семплируется из какого-нибудь Бета распределения. Оказывается, что такой подход заставляет модель выучивать в каком-то смысле более устойчивые предсказания, так как мы форсируем некую линейность в отображении из пространства картинок в пространство лейблов. На практике часто оказывается, что это дает значимое улучшение в качестве модели.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Albumentations",
        "url": "https://github.com/albumentations-team/albumentations"
      }
    ]
  },
  {
    "document_title": "Свёрточные нейросети",
    "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
    "section_title": "Бонус №1: знаковые архитектуры в мире свёрточных нейронных сетей для задачи классификации изображений",
    "text": "Дисклеймер: это мнениеодногоавтора. Приведённые в этом разделе вехи связаны преимущественно с архитектурами моделей, а не способом их оптимизации. Здесь перечислены знаковые архитектуры, заметно повлиявшие на мир свёрточных нейронных сетей в задаче классификации картинок (и не только). К каждой архитектуре указана ссылка на оригинальную статью, а также комментарий автора параграфа с указаниемключевыхнововведений. Значение метрики error rate на одном из влиятельных датасетовimagenetуказано для финального ансамбля из нейросетей, если не указано иное. Зачем это полезно изучить (вместе с чтением статей)? Основных причин две: Общее развитие. Полезно понимать, откуда взялись и чем мотивированы те или иные компоненты. Этот вопрос задают на собеседовании, когда не знают, что еще спросить 😃 Ссылка на статью 7 слоев Первая свёрточная нейронная сеть, показавшая SOTA (State Of The Art) результаты на задаче классификации изображений цифр MNIST. В архитектуре впервые успешно использовались свёрточные слои с ядром5x5. В качестве активации использовался tanh, а вместо max pool в тот момент использовался average. Ссылка на статью 11 слоев Первая CNN (Convolutional Neural Network), взявшая победу на конкурсе imagenet. Автор предложил использовать ReLU вместо сигмоид (чтобы градиенты не затухали) и популяризовал max-pool вместо average. Что самое важное, обучение модели было перенесено на несколько GPU, что позволило обучать достаточно большую модель за относительное небольшое время (6 дней на двух видеокартах того времени). Также автор обратил внимание, что глубина нейросети важна, так как выключение хотя бы одного слоя стабильно ухудшало качество на несколько процентов. Ссылка на статью В статье не привели интересных SOTA результатов, но зато ввели два очень популярных впоследствии модуля. Первый — это GAP (Global Average Pooling), который стоит после последнего свёрточного слоя и усредняет все активации вдоль пространственных осей. Второй — стекинг1x1свёрток поверх3x3, что эквивалентно тому, что вместо линейной свёртки используется полносвязный слой. Ссылка на статью 19 слоев Авторы предложили декомпозировать большие свёртки (5x5,7x7и выше) на последовательное выполнение свёрток3x3с нелинейностями между ними. Впоследствии, за нечастым исключением, свёртки3x3стали стандартом в индустрии (вместе со свёртками1x1). Ссылка на статью 22 слоя Ввели inception слой, просуществовавший довольно продолжительное время. Сейчас сам слой уже не используется, но идея лежащая в его основе, эксплуатируется. Идея следующая: будем параллельно применять свёртки с разным пространственными размерами ядер, чтобы можно было одновременно обрабатывать как low-, так и high-level признаки. Еще полезной для сообщества оказалась идея с dimensionality reduction: перед тяжелой операцией поставим свёртку 1x1, чтобы уменьшить количество каналов и кратно ускорить вычисление. Ссылка на статью Авторы внедрили вездесущую batch normalization, которая стабилизирует сходимость, позволяя увеличить шаг оптимизатора и скорость сходимости. Применив идею к архитектуре inception, они превзошли человека на imagenet. Ссылка на статью В статье предложили использовать инициализацию весов, берущую во внимание особенность активации ReLU (в предыдущих работах предполагалось, что, что, очевидно, нарушается для). Применение этой и других «свистелок» на VGG19 позволило существенно уменьшить ошибку на imagenet. Ссылка на статью 152 слоя Архитектура, которая на момент написания этого параграфа до сих пор бейзлайн и отправная точка во многих задачах. Основная идея — использование skip connections, что позволило градиенту протекать вплоть до первых слоев. Благодаря этому эффекту получилось успешно обучать очень глубокие нейронные сети, например, с 1202 слоями (впрочем, результаты на таких моделях менее впечатляющие, чем на 152-слойной). После этой статьи также стали повсеместно использоваться GAP и уменьшение размерности свёртками1x1. Ссылка на статью Очень популярная модель для быстрого инференса (на мобильных устройствах или gpu). По качеству хоть и немного проигрывает «монстрам», но в индустрии, оказывается, зачастую этого достаточно (особенно если брать последние варианты модели). Основная деталь — это использование depthwise convolutions: параллельный стекинг свёрток3x3x1x1— то есть таких, в которых вычисление для каждогоканала просходит только на основе признаков одногоканала. Чтобы скомбинировать фичи между каналами, используется классическая1x1свёртка. Ссылка на статью Одна из первых моделей, полученных при помощи NAS (Neural Architecture Search), которая взяла SOTA на imagenet. После этого, модели, где компоненты подбирались вручную, уже почти не показывали лучших результатов на классических задачах.",
    "source_type": null,
    "useful_links": [
      {
        "text": "imagenet",
        "url": "https://image-net.org/"
      },
      {
        "text": "Ссылка на статью",
        "url": "http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://arxiv.org/pdf/1312.4400.pdf"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://www.robots.ox.ac.uk/~vgg/publications/2015/Simonyan15/simonyan15.pdf"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://arxiv.org/pdf/1409.4842.pdf"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://arxiv.org/pdf/1502.03167.pdf"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://arxiv.org/pdf/1502.01852.pdf"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://arxiv.org/pdf/1512.03385.pdf"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://arxiv.org/pdf/1704.04861.pdf"
      },
      {
        "text": "Ссылка на статью",
        "url": "https://arxiv.org/pdf/1905.11946.pdf"
      }
    ]
  },
  {
    "document_title": "Свёрточные нейросети",
    "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
    "section_title": "Бонус №2: не классификацией единой",
    "text": "Свёрточными нейронными сетями можно решать большой спектр задач, например: Сегментация. Если убрать в конце слои GlobalAveragePool или flatten, то можно делать предсказания для каждого пикселя в отдельности (подумайте, что делать, если в сети есть maxpool) — получаем сегментацию картинки. Проблема — долгая и дорогая разметка. Детекция. Часто намного дешевле получить разметку объектов обрамляющими прямоугольниками. Здесь уже можно для каждого пикселя предсказывать размеры прямоугольника, который обрамляет объект, к которому принадлежит пиксель. Проблемы — нужен этап агрегации прямоугольников + много неоднозначностей во время разметки + много эверистик на всех этапах + данных нужно больше. Понимание видео. Добавляем в тензор новый канал — временной, считаем четырехмерные свёртки — и получаем распознавание сцен на видео. Metric learning. Часто мы не можем собрать все интересующие нас классы, например, в задаче идентификации человека по лицу (или товара на полке). В этом случае используют такой трюк: научим модель в некотором смысле (обычно по косиносному расстоянию) разделять эмбеддинги существующих классов (уникальных людей). Если на руках была репрезентативная выборка, то модель, скорее всего (а обычно — всегда), выучит генерировать дискриминативные эмбеддинги, которые уже позволят различать между собой ранее невиданные лица. и многое другое",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Свёрточные нейросети",
    "url": "https://education.yandex.ru/handbook/ml/article/svyortochnye-nejroseti",
    "section_title": "Итого",
    "text": "Мы разобрались, что для картинок эффективно использовать свёрточные фильтры в качестве основных операторов. Выяснили, какие основные блоки есть почти в каждой картиночной нейронной сети и зачем они там нужны. Разобрались, какие методы регуляризаторы сейчас самые популярные и какая за ними идея. И наконец — рассмотрели знаковые архитектуры в мире свёрточных нейронных сетей.",
    "source_type": null,
    "useful_links": []
  },
  {
    "document_title": "Обобщающая способность – классическая теория",
    "url": "https://education.yandex.ru/handbook/ml/article/obobshayushaya-sposobnost-klassicheskaya-teoriya",
    "section_title": "Оценка супремума",
    "text": "Попробуем оценить супремум разницы рисков. Будем считать, что выборкавыбирается случайным (и равновероятным) образом из распределения данных. Некоторые из выборок могут быть катастрофически плохими, поэтому мы будем рассматривать оценки, которые верны не обязательно всегда, а просто с достаточно большой вероятностью. Предположим сначала, что класс моделейконечен. Тогда Заметим, что. Поэтому при фиксированномразницу рисковможно оценить с помощью неравенства Хёффдинга. Неравенство Хёффдинга (Hoeffding's inequality). Пусть– независимые одинаково распределённые случайные величины со значениями в. Тогда для всехимеют место неравенства Как следствие неравенства Хёффдинга, получаем, что для любогои для любой. Заметим, что тогда для любой, Несмотря на то, что эта оценка является оценкой на обобщающую способность, она не имеет смысла, так как модельв ней задана априори и не зависит от. Другими словами, она верна для необученных моделей. Возвращаясь к нашей оценке, получаем: где– мощность класса. Следовательно, В случае бесконечногоиспользуем следующее обобщение неравенства Хёффдинга: Неравенство МакДайармида (McDiarmid's inequality). Пусть– независимые одинаково распределённые случайные величины,– скалярная функция саргументами, такая что для некоторых. Тогда для любогоимеет место неравенство Применяя теорему к, получаем: из чего следует: где– эмпирический риск на выборке. В следующем подразделе мы постараемся оценить жёлтое слагаемое. Оценим сверху матожидание супремума: Этот шаг называется «симметризация»: теперь выражение выше зависит от двух равнозначных обучающих выбороки. Ниже для краткости будем обозначатьи. Как оценить сверху супремум разности рисков? Наивная оценка, супремум суммы, слишком слаба: в самом деле, при фиксированном наборе данных вполне вероятно может существовать модель, имеющая большой риск на нём (достаточно взять модель, обученную на тех же данных, но с «неправильными» метками), поэтому матожидание супремума эмпирического риска может быть велико. Для обхода этой сложности заметим, что выражение выше симметрично относительно перестановки местами двух выборок: Более того, так как элементы обеих выборок выбираются независимо, значение выражения не меняется и при перестановке местами отдельно-ых элементов двух выборок. А именно, для любого набора Будем выбиратьнезависимо и равновероятно из. Такие случайные величины называютсяпеременными Радемахера. Поскольку оценки выше были верны для любых сигм, они верны и в среднем по переменным Радемахера, выбранным независимо от выборки: После введения переменных Радемахера оценка супремума разницы рисков через сумму супремумов становится не такой плохой. В самом деле, рассмотрим бинарную классификацию с помощью линейной модели. Если данные хорошо разделяются плоскостью, тобудет большим, так как в качествеможно взять линейную модель с противоположно ориентированной разделяющей плоскостью для. В то же время для того, чтобыбыло большим, необходимо, чтобы существовала модель, отвечающая правильно на тех примерах, где, и неправильно, где; для линейной модели это невозможно при большинстве конфигураций сигм. Величина называетсясложностью Радемахеракласса функций(для распределениянаи длины выборок). Она велика, если в классесодержатся функции, принимающие большие значения с заданными знаками на любом наборе данных фиксированного размера. Другими словами, сложность Радемахера измеряет, насколько выходы функций из классамогут коррелировать со случайным шумом. Для нас актуальна сложность Радемахера классов вида, то есть композиций моделей из классаи функции риска. Если– класс линейных моделей в пространстве размерности меньшей, чем, то сложность Радемахера невелика. В то же время если– множество всех возможных решающих деревьев, то, если только наборы данных непротиворечивы, она равна единице. В самом деле, решающее дерево способно запомнить всю обучающую выборку, то есть добиться единичной корреляции с любым случайным шумом. Вернёмся к оценке разницы рисков: Сложность Радемахера зависит от функции риска. Рассмотрим задачу бинарной классификации с классамии. Возьмём в качестве функции риска индикатор ошибки бинарной классификации, или «0/1-риск»: Название «0/1-риск» обусловлено тем, что риск принимает значенияи. Заметим следующее: где– класс эквивалентности функций из, в котором две функции считаются эквивалентными тогда и только тогда, когда их образы на выборкеимеют одинаковые знаки. Другими словами, среди всех функций, принимающих одни и те же знаки на, мы выберем по одной и сформируем из них множество. Заметим, что это множество конечно:. Нам понадобится следующая Лемма. Пусть– случайная величина со значениями ви нулевым средним. Тогда для любыхимеет место неравенство С её помощью получаем: Эта оценка верна для любого. Минимизируем её по. Легко видеть, что оптимальноеравняется; подставляя его, получаем: Определимфункцию ростаклассакак Эта функция показывает, сколько различных разметок класс функцийможет породить на наборе данных, в зависимости от размера этого набора. Очевидно, чтои монотонно не убывает. Например, для линейной модели на-мерном пространстве признаковпри(любое подмножествоточек в общем положении в-мерном пространстве всегда можно отделить гиперплоскостью), но строго меньше этого числа при(например, если точки – углы квадрата на плоскости, его диагонали нельзя разделить прямой). Когда, будем говорить, что «разделяет». Определимразмерность Вапника-Червоненкиса(илиVC-размерность) как максимальное, при котором семействоразделяет любой датасет: Таким образом, VC-размерность линейной модели равна. Следующая лемма даёт связь между размерностью Вапника-Червоненкиса и функцией роста: Лемма(Sauer–Shelah, см. подробнеездесь) Изучим асимптотическое поведение сложности Радемахера при. Обозначим. Дляимеем, а для: Подставляя это выражение в (1), получаем окончательную оценку на сложность Радемахера: Соответствующая оценка на истинный риск тогда примёт вид: Для того, чтобы эта оценка была осмыслена, необходимо гарантировать. Для линейных моделей, при условии(данных намного больше, чем признаков), оценки действительно получаются осмысленными. К сожалению, для нейронных сетей это подчас неверно. В работеNearly-tight VC-dimension and Pseudodimension Bounds for Piecewise Linear Neural Networksпоказано, что еслиобозначает класс моделей, реализуемых полносвязной сетью шириныспараметрами, то. Таким образом, наша оценка на сложность Радемахера становится бесполезной в реалистичных сценариях, когда число весов сетимного больше числа примеров в обучающей выборке. Если априори известно, что результат обучения лежит в некотором классе, то в оценке сложности Радемахера можно использовать именно этот класс, а не полный класс моделей. Очевидно, что сложность, лежащего в, не больше сложности. Так, в работеSpectrally-normalized margin bounds for neural networksполучены оценки для сложности полносвязной сети с липшицевыми функциями активации при условии, что нормы весов ограничены; см. такжеполный конспект лекций. В этом случае подбудем понимать класс сетей с весами нормы не больше. Обозначим соответствующую оценку через: К сожалению, нет гарантий, что градиентный спуск всегда сходится в решение с нормой меньше какого-то числа. Чтобы обойти это ограничение, используют следующую технику. Возьмём последовательность ограничений, такую что Также возьмём последовательность, монотонно убывающую к нулю и суммирующуюся в. Тогда для любого А значит, Из этого следует, что где– минимальное, при котором. Такая техника используется, например, в работахSpectrally-normalized margin bounds for neural networksиA PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks.",
    "source_type": null,
    "useful_links": [
      {
        "text": "здесь",
        "url": "https://en.wikipedia.org/wiki/Sauer%E2%80%93Shelah_lemma"
      },
      {
        "text": "Nearly-tight VC-dimension and Pseudodimension Bounds for Piecewise Linear Neural Networks",
        "url": "https://arxiv.org/pdf/1703.02930.pdf"
      },
      {
        "text": "Spectrally-normalized margin bounds for neural networks",
        "url": "https://arxiv.org/pdf/1706.08498.pdf"
      },
      {
        "text": "полный конспект лекций",
        "url": "https://arxiv.org/pdf/2012.05760.pdf"
      },
      {
        "text": "Spectrally-normalized margin bounds for neural networks",
        "url": "https://arxiv.org/pdf/1706.08498.pdf"
      },
      {
        "text": "A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks",
        "url": "https://arxiv.org/pdf/1707.09564.pdf"
      }
    ]
  },
  {
    "document_title": "Обобщающая способность – классическая теория",
    "url": "https://education.yandex.ru/handbook/ml/article/obobshayushaya-sposobnost-klassicheskaya-teoriya",
    "section_title": "Фундаментальная проблема равномерных оценок",
    "text": "Напомним, что построение равномерных оценок проходило в несколько шагов: Оценка супремумом Применение неравенства макДайармида: Оценка матожидания супремума (жёлтое слагаемое выше) с помощью симметризации с дальнейшим выходом на сложность Радемахера: На каждом шаге предыдущая величина оценивается сверху, и потенциально каждое из этих неравенств может оказаться слишком слабым и привести к бессмысленной оценке. Давайте это проиллюстрируем. Выше мы уже отмечали, что если класссодержит модель, для котороймал, авелик, то равномерная оценка становится бессмысленной. По этой причине, имеет смысл выбирать класскак можно более маленьким. Самым лучшим из возможных классов мог бы быть класс моделей, к которым сходится наш алгоритм обучения с высокой вероятностью. Рассмотрим случай, близкий к идеальному: тот, в котором существует, для которого при любыхимеем. Иными словами, предположим, что все модели классахорошо обобщают. В этом случае оценка выше близка к идеальной: Но что будет, если мы начнём честно воспроизводить процесс построения равномерных оценок? После второго шага мы получаем оценку вида которая не сильно хуже предыдущей, но в которой всё равно появилось лишнее слагаемое. Но допустим, что мы хотим честно проделать третий шаг процедуры получения равномерных оценок. Для этого нам необходимо было оценить матожидание супремума, которое после симметризации получает вот такую верхнюю оценку: Таким образом, малость истинного риска не гарантирует малость эмпирического риска на любом наборе данных. Так, авторы статьиUniform convergence may be unable to explain generalization in deep learningпредъявили пример, в котором для любогосуществует модель, такая что, но при этомималы. Иллюстрация такой ситуации приведена в начале параграфа. Тогдавелик, и оценки теряют смысл. К счастью, даже эта фундаментальная проблема не ставит крест на равномерных оценках. Так, работыUniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign OverfittingиStability and Deviation Optimal Risk Bounds with Convergence Rateрассматривают равномерную оценку в классе интерполирующих моделей, то есть, имеющих нулевой эмпирический риск: Для таких моделей контрпример выше не работает.",
    "source_type": null,
    "useful_links": [
      {
        "text": "Uniform convergence may be unable to explain generalization in deep learning",
        "url": "https://arxiv.org/pdf/1902.04742.pdf"
      },
      {
        "text": "Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign Overfitting",
        "url": "https://arxiv.org/pdf/2106.09276.pdf"
      },
      {
        "text": "Stability and Deviation Optimal Risk Bounds with Convergence Rate",
        "url": "https://arxiv.org/pdf/2103.12024.pdf"
      }
    ]
  }
]