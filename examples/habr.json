[
    {
        "source_type": "habr",
        "document_title": "Правила разработки документации ML-проекта",
        "url": "https://habr.com/ru/articles/676716/",
        "chunk": {
            "text": "Полезная, актуальная и при этом полная документация - миф или реальность? В первой части статьи обсудим зачем вообще нужна документация (а когда она и не нужна вовсе), поговорим о распространённых проблемах и ошибках, а во второй - посмотрим на примеры специфичной документации, связанной с ML-моделями и данными. Статья представляет собой текстовую версию доклада Lean DS. При обсуждении какого-то явления, полезно сначала посмотреть на его определение. Тут нам поможет старая добрая Википедия: “Письменный текст или иллюстрация, которая сопровождает программное обеспечение или интегрирована прямо в исходный код. Документация объясняет, как работает ПО или как его использовать. Может иметь разное значение для людей с разными ролями в команде” Определение действительно неплохое, в нём содержится несколько важных свойств документации: может существовать отдельно или “зашита” в код (documentation-as-code) может существовать отдельно или “зашита” в код (documentation-as-code) может иметь разные формы - текст, картинка, видео может иметь разные формы - текст, картинка, видео один и тот же документ может по-разному использоваться разными людьми один и тот же документ может по-разному использоваться разными людьми Давайте посмотрим на документацию с точки зрения ML-команды. Кто ей может пользоваться? Сама команда DS-разработчиков Сама команда DS-разработчиков Тимлид этой команды Тимлид этой команды Внешние пользователи (менеджмент компании, заказчики, конечные пользователи DS-продукта) Внешние пользователи (менеджмент компании, заказчики, конечные пользователи DS-продукта) Мы разрабатываем ИИ-решение для радиологов и вопрос документации для нас всегда был очень острым. Без качественной документации невозможно “выкатывать” новые релизы и четко планировать развитие продукта, очень сложно “онбордить” новых сотрудников, да и вообще плохое качество документации чревато разными проблемами, особенно это начинает чувствоваться при масштабировании продуктов и команды. Самим ML-командам документация служит для: Снижения сложности вникания в новые проекты. Снижения сложности вникания в новые проекты. Возможности получения актуального референса (например, при актуализации старой гипотезы, отложенной в “долгий ящик”) Возможности получения актуального референса (например, при актуализации старой гипотезы, отложенной в “долгий ящик”) Создания культуры открытости и обмена знаний внутри команды Создания культуры открытости и обмена знаний внутри команды Повышения количества новых идей и структуризации знаний о проектах Повышения количества новых идей и структуризации знаний о проектах Лидам документация помогает всегда оставаться в курсе актуального состояния проекта, позволяет быстро делиться информацией со стейкхолдерами проекта, формировать и обновлять вектор развития, а также облегчать процесс онбординга новых сотрудников. Документация помогает и внешним пользователям (здесь под внешними пользователями я понимаю и другие команды на проекте): с ее помощью они могут всегда получить актуальную информацию по продукту и не дергать лишний раз членов команды. Например, прочитать readme и самостоятельно подключиться к API. Также документация ускоряет процесс принятия управленческих решений, делая их более точными и основанными на актуальной информации. Прежде чем создавать любой документ или внедрять какую-то практику, связанную с документацией, рекомендую обязательно пройтись по такому чек-листу: Сколько будет стоить (в деньгах, времени, раздражении) написание и поддержка документа или практики? Сколько будет стоить (в деньгах, времени, раздражении) написание и поддержка документа или практики? Кто будет читать документ, как часто и в каких ситуациях? Кто будет читать документ, как часто и в каких ситуациях? Кто, как и когда будет актуализировать документ? Будут ли члены команды это делать добровольно? Кто, как и когда будет актуализировать документ? Будут ли члены команды это делать добровольно?",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Правила разработки документации ML-проекта",
        "url": "https://habr.com/ru/articles/676716/",
        "chunk": {
            "text": "или практики? Кто будет читать документ, как часто и в каких ситуациях? Кто будет читать документ, как часто и в каких ситуациях? Кто, как и когда будет актуализировать документ? Будут ли члены команды это делать добровольно? Кто, как и когда будет актуализировать документ? Будут ли члены команды это делать добровольно? Можно ли полностью или частично автоматизировать процесс актуализации документа? Можно ли полностью или частично автоматизировать процесс актуализации документа? В документации содержится слишком мало информации . Приходится часто дергать членов команды для получения нужных данных В документации содержится слишком мало информации . Приходится часто дергать членов команды для получения нужных данных Информации слишком много, и она разбросана по разным источникам - wiki, Slack, гугл-документы и презентации, бумажные носители Информации слишком много, и она разбросана по разным источникам - wiki, Slack, гугл-документы и презентации, бумажные носители Информация неактуальна Информация неактуальна Информация дублируется в разных источниках Информация дублируется в разных источниках Итак, мы разобрались с основными целями создания и ведения документации и знаем, с какими проблемами нам предстоит столкнуться. Теперь поговорим о “правилах хорошего тона”, использование которых сильно уменьшит вероятность появления этих самых проблем. Правила структуры и оформления: Единая точка входа ко всей документации проекта. Это может быть страница в Notion, фрейм в Miro или Markdown-документ, форма не так важна. Главное, чтобы с этой страницы любой человек мог получить доступ к нужной ему информации. Единая точка входа ко всей документации проекта. Это может быть страница в Notion, фрейм в Miro или Markdown-документ, форма не так важна. Главное, чтобы с этой страницы любой человек мог получить доступ к нужной ему информации. Единые правила оформления и стиля, наличие шаблонов . Немаловажным фактором для восприятия пользователем документации является наличие и консистентность общего стиля оформления документации. Единые правила оформления и стиля, наличие шаблонов . Немаловажным фактором для восприятия пользователем документации является наличие и консистентность общего стиля оформления документации. Стиль описания и подачи информации в документации соответствует культуре команды . Нет смысла придерживаться ненужного формализма во внутренних документах команды. Стиль описания и подачи информации в документации соответствует культуре команды . Нет смысла придерживаться ненужного формализма во внутренних документах команды. В документах есть ссылки на другие релевантные документы . В документах есть ссылки на другие релевантные документы . Важные места выделены Важные места выделены Используются оптимальные методы передачи информации. В зависимости от задачи документа может использоваться не только текст, но и картинки, графики, диаграммы, видео Используются оптимальные методы передачи информации. В зависимости от задачи документа может использоваться не только текст, но и картинки, графики, диаграммы, видео Правила использования и актуализации: Определена целевая аудитория каждого документа - кто, как и зачем будет его использовать Определена целевая аудитория каждого документа - кто, как и зачем будет его использовать Если документация не используется самой командой, то её актуализацию стоит встраивать в процессы в формате “ definition of done ”. Например, нельзя зарелизить новую модель, не обновив документацию Если документация не используется самой командой, то её актуализацию стоит встраивать в процессы в формате “ definition of done ”. Например, нельзя зарелизить новую модель, не обновив документацию Использование методологии (“docs as code”) там, где это актуально. В данном случае документация является частью кодовой базы, лежит в",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Правила разработки документации ML-проекта",
        "url": "https://habr.com/ru/articles/676716/",
        "chunk": {
            "text": "не обновив документацию Если документация не используется самой командой, то её актуализацию стоит встраивать в процессы в формате “ definition of done ”. Например, нельзя зарелизить новую модель, не обновив документацию Использование методологии (“docs as code”) там, где это актуально. В данном случае документация является частью кодовой базы, лежит в репозитории и пишется в IDE. Данный подход “из коробки” даёт возможность версионирования, тестирования, ревью изменений документации. Использование методологии (“docs as code”) там, где это актуально. В данном случае документация является частью кодовой базы, лежит в репозитории и пишется в IDE. Данный подход “из коробки” даёт возможность версионирования, тестирования, ревью изменений документации. Производится регулярная ревизия документации . Включает себя в том числе отказ от устаревших или лишних документов. Производится регулярная ревизия документации . Включает себя в том числе отказ от устаревших или лишних документов. Встречи команды должны порождать новые “артефакты” (документы по итогам встречи). Например, дорожная карта реализации или лист договоренностей. Встречи команды должны порождать новые “артефакты” (документы по итогам встречи). Например, дорожная карта реализации или лист договоренностей. Инвентаризация технического долга по документации. Да-да, техдолг по документации тоже является техдолгом. Инвентаризация технического долга по документации. Да-да, техдолг по документации тоже является техдолгом. Если у нас уже есть какая-то документация и процедуры её актуализации, можно ли попробовать померить её качество? Такие показатели действительно есть: Покрытие - какая часть кода проекта или DS-пайплайна покрыта документацией Покрытие - какая часть кода проекта или DS-пайплайна покрыта документацией Доступность - сколько времени или кликов в среднем занимает поиск нужного документа Доступность - сколько времени или кликов в среднем занимает поиск нужного документа Читаемость - насколько легко читать этот документ Читаемость - насколько легко читать этот документ Количество посещений/обновлений документа за период Количество посещений/обновлений документа за период Мы пока не дошли до того, чтобы регулярно замерять динамику этих показателей, пока это кажется лишним. Но в качестве точки среза - почему нет? В первой части статьи я рассказал про документацию процесса разработки. Однако ML-разработка довольно сильно отличается от классической разработки. Есть ли различия в документации? Если максимально упростить пайплайн ML-разработки, то он будет выглядеть следующим образом: Оценивается осуществимость и значимость проекта Оценивается осуществимость и значимость проекта Производится сбор, очистка и разметка данных Производится сбор, очистка и разметка данных Генерируем гипотезы, тренируем модели Генерируем гипотезы, тренируем модели Оцениваем качество и устойчивость лучшей модели Оцениваем качество и устойчивость лучшей модели Деплоим модель Деплоим модель Осуществляем мониторинг Осуществляем мониторинг Понятно, что этот пайплайн весьма условен, каких-то этапов может не быть, какие-то могут добавиться. Да и носит он, конечно, циклический характер, например на этапе оценки качества мы можем вернуться на этап генерации новых гипотез и построения моделей. Тем не менее, такое разделение позволит нам посмотреть на разные виды документации, характерные для разных этапов. Что же может быть входной точкой в документацию? В нашем случае это карточка проекта, оформленная в Notion. В таком случае в рамках проекта по маммографии документы распределены по группам: описание работы системы, код и model cards, эксперименты и идеи, данные и так далее. Если мы углубимся в какую либо подгруппу, например, описание работы системы, то мы увидим внутри список документов и ссылок, связанных с данной предметной областью. Как мы видим внутри",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Правила разработки документации ML-проекта",
        "url": "https://habr.com/ru/articles/676716/",
        "chunk": {
            "text": "рамках проекта по маммографии документы распределены по группам: описание работы системы, код и model cards, эксперименты и идеи, данные и так далее. Если мы углубимся в какую либо подгруппу, например, описание работы системы, то мы увидим внутри список документов и ссылок, связанных с данной предметной областью. Как мы видим внутри могут содержаться абсолютно разные документы, такие как Miro, Google-таблицы, PDF-файлы. На этапе оценки осуществимости и значимости проекта мы хотим собрать и агрегировать информацию, которой владеют разные группы пользователей - бизнес, аналитики, ML-специалисты, доменные эксперты, заказчики. Это позволяет нам создать общее понимание нюансов проекта, структурировать нужную информацию, которая позволит принять решение о старте проекта. Примеров, как может выглядеть такой документ, очень много - AI Canvas , Mission Canvas , карточка проекта ( design doc , чек-лист требований ). В эту же группу можно включить технические задания от заказчиков. Такие документы могут включать: Описание проблемы и предположения о достижимой ценности продукта Описание проблемы и предположения о достижимой ценности продукта Варианты решения с ML и без него Варианты решения с ML и без него Требования к качеству (метрики) Требования к качеству (метрики) Описание источников возможных данных Описание источников возможных данных Другие требования (например, к железу и программному обеспечению) Другие требования (например, к железу и программному обеспечению) Последствия ошибок системы и так далее Последствия ошибок системы и так далее Этапы проекта Этапы проекта Технические риски и заключение по проекту Технические риски и заключение по проекту Конкуретная среда Конкуретная среда Литература, научные статьи, видео по теме Литература, научные статьи, видео по теме Исходя из всей собранной информации мы готовим заключение о целесообразности или же её отсутствии для реализации проекта. После сбора и анализа такой информации, проведения встречи с бизнес-подразделением принимается решение о реализации или же отмене проекта. Допустим было принято положительное решение и теперь мы переходим к шагу №2 - “сбор, очистка и разметка данных”. Поскольку в нашем случае мы работаем с медицинскими данными, то разметка данных - это отдельный важный процесс. В нашем случаи, разметчики - доменные эксперты, врачи, что ведёт к отдельным трудностям. Сам процесс разметки, разумеется, также описан в документации - процесс отбора разметчиков, инструкции врачам, принципы разрешения конфликтов в разметке. Любой источник данных также требуется документировать. Это позволяет быстро получать информацию об источнике и объёме данных, их ограничений и свойств, генерировать новые гипотезы, связанные с данными - например, какие данные нужно доразметить или наоборот выбросить из датасета. Документацию датасетов мы называем dataset cards. В зависимости от специфики данных, частоты их пополнения, типа разметки это может быть как просто статический документ, так и интерактивный дашборд. В идеале датасет-карды обладать следующими свойствами: версионирование - мы хотим понимать, какая документ соответствует той или иной версии датасета версионирование - мы хотим понимать, какая документ соответствует той или иной версии датасета автообновление - если датасет-карт или дашборд подключен к БД с разметкой, то он всегда будет содержать актуальную информацию о датасетах автообновление - если датасет-карт или дашборд подключен к БД с разметкой, то он всегда будет содержать актуальную информацию о датасетах интерактивность - должна быть возможность подробно глазами изучить тот или иной слайс данных или конкретный кейс интерактивность - должна быть возможность подробно глазами изучить тот или иной",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Правила разработки документации ML-проекта",
        "url": "https://habr.com/ru/articles/676716/",
        "chunk": {
            "text": "информацию о датасетах автообновление - если датасет-карт или дашборд подключен к БД с разметкой, то он всегда будет содержать актуальную информацию о датасетах интерактивность - должна быть возможность подробно глазами изучить тот или иной слайс данных или конкретный кейс интерактивность - должна быть возможность подробно глазами изучить тот или иной слайс данных или конкретный кейс В зависимости от задачи датасет-кард может содержать различную информацию - примеры данных и разметки, описательные статистики, источник данных и описание процесса сбора данных, информация о разметчиках, известные проблемы и ограничения. Итак, мы определились с источниками данных, собрали их и разметили, создали документацию. Теперь пора начинать выдвигать гипотезы и тренировать модели для решения нашей бизнес-задачи. Среди целей, которые мы ставим перед собой на данном этапе: Быстрая генерация, приоритезация и проверка гипотез Быстрая генерация, приоритезация и проверка гипотез Удобный анализ результатов экспериментов Удобный анализ результатов экспериментов Возможность возврата к результатам предыдущих экспериментов Возможность возврата к результатам предыдущих экспериментов Удобство разработки Удобство разработки Безусловно, ни одна из этих целей не решается только документацией, но документация должна поддерживать наше стремление к реализации каждой цели. Примеры документации на этом этапе - база гипотез, карточки экспериментов, документация кода, презентации по итогам серии экспериментов. База гипотез - список приоритизированных идей на отработку. Он может содержать различную информацию и описание самой идеи, теги для удобной фильтрации контента внутри базы идей, оценки реализуемости и трудоемкости идеи (например, по ICE ), дизайн-ревью и отчет по эксперименту, ссылка на эксперимент в трекере экспериментов. В данном случае база идей реализована в Notion. Благодаря этому ее можно упорядочивать в необходимом нам формате. Например, по статусам, оценке “легкости реализации” и так далее. Отсюда мы можем попасть в саму карточку нужного нам эксперимента и посмотреть его детали. Когда гипотеза попадает в базу она как правило описана очень верхнеуровнево, без деталей. Этой информации обычно недостаточно, чтобы точно оценить трудоёмкость гипотезы, конкретные шаги, нужные для её проверки, зависимости. Большая часть этой информации приходит уже в процессе анализа задачи. Когда конкретный человек из команды берет ее на себя, собирает инфорацию, гуглит статьи, смотрит репозитории, наличие и доступность данных, он описывает детали эксперимента (experiment design), чтобы обозначить план итоговой реализации. Этот план затем оценивают другие члены команды в рамках процедуры design review. Это помогает избавиться от проблем неправильного понимания задачи, расходования времени на переписывание после код-ревью, нерационального расходования времени во время проверки гипотезы. Результаты реализации гипотез могут быть описаны в различном формате в зависимости от “ожиданий” и их важности. В некоторых случаях достаточно односложного комментария, а в некоторых необходимо готовить презентацию и обсуждать результаты и дальнейшие идеи с коллегами. Использование трекера (в нашем случае это ClearML) позволяет обеспечить репродуцируемость эксперимента и в любой момент получить информацию о его метриках, версии кода, гиперпараметрах. В трекере можно сравнить результаты разных экспериментов, изучить метрики, сформулировать выводы. Всё это по сути тоже является частью документации ML-проекта. На этом этапе мы хотим оценить качество модели, сравнить её с предыдущей версией, понять ограничения и особенности модели. Например, новая модель может работать с конкретным типом данных (снимки с определённого типа оборудования) хуже. И это также важно знать и учиывать. В качестве артефактов документации на этом этапе у нас появляются model card, дашборды с",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Правила разработки документации ML-проекта",
        "url": "https://habr.com/ru/articles/676716/",
        "chunk": {
            "text": "хотим оценить качество модели, сравнить её с предыдущей версией, понять ограничения и особенности модели. Например, новая модель может работать с конкретным типом данных (снимки с определённого типа оборудования) хуже. И это также важно знать и учиывать. В качестве артефактов документации на этом этапе у нас появляются model card, дашборды с таблицами и метриками, отчёты по анализу ошибок. Model Card - описание ML-системы, которая включает в себя следующую информацию: Изменения в последней версии Изменения в последней версии Описание обучающих и тестовых данных Описание обучающих и тестовых данных Описание архитектуры сети, препроцессинга и других компонентов Описание архитектуры сети, препроцессинга и других компонентов Описание требований к входным данным Описание требований к входным данным Описание аутпутов системы Описание аутпутов системы Метрики Метрики Описание известных ограничений и проблем Описание известных ограничений и проблем Модел-кард для разных групп пользователей может иметь разный итоговый вид. Например, для бизнес или конечных пользователей можно включить рекомендуемые сценарии использования системы, но убрать лишнюю информацию об архитектуре сети. Мы храним такую документацию в формате docs-as-code - в нашем случае, это Markdown-док, который версионируется и прилинкован к конкретным коммитам. По важным же релизам могут быть экспортированы и PDF. Деплой как и любой другой ML-процесс порождает свой класс специфичных документов. Среди которых : Отчеты по тестам (test reports) Автоматизированные тесты Результаты a/b тестов Отчеты по опросы пользователей Отчеты по тестам (test reports) Автоматизированные тесты Автоматизированные тесты Результаты a/b тестов Результаты a/b тестов Отчеты по опросы пользователей Отчеты по опросы пользователей Дашборды и регулярные автоматические отчёты Дашборды и регулярные автоматические отчёты Post-mortem по итогам инцидентов на проде (документация события, несущего негативные последствия с целью анализа и устранения его причин) Post-mortem по итогам инцидентов на проде (документация события, несущего негативные последствия с целью анализа и устранения его причин) Документация API Документация API Change Notes Change Notes Прочая документация, связанная с релизами Прочая документация, связанная с релизами Конечно, на ML-проекте появляется и всякая общая и процессная документация. Примеры из нашей практики: Team Canvas Team Canvas Очень полезный элемент для онбординга новых сотрудников. Документ описывает состав команды, ценности команды, зоны ответственности внутри команды и между сотрудниками, процессы, встречи и их формат, командные ритуалы и правила Доски и скоринговые карты собеседований сотрудников Доски и скоринговые карты собеседований сотрудников Таблица с описанием встреч Таблица с описанием встреч Таблица встреч - очень полезная вещь, которая обеспечивает понимание цели, участников и артефактов встреч для всех сотрудников. Для планирования стреч и напоминаний мы также используем гугл-календари. Гайдлайны по написанию кода Гайдлайны по написанию кода База знаний - по коду, инфраструктуре, ML, заметки со встреч с доменными экспертами (врачами) База знаний - по коду, инфраструктуре, ML, заметки со встреч с доменными экспертами (врачами) Доска онбординга Доска онбординга Общее Миро со всей информацией Стратегия и цели компании/проекта Роадмапы Общее Миро со всей информацией Стратегия и цели компании/проекта Стратегия и цели компании/проекта Роадмапы Роадмапы В зависимости от вида документа и его целевой аудитории варьируется и лицо, поддерживающее документ. Кроме того, важно в целом создавать культуру ведения документации в компании, формировать понимание каждого члена компании, что документация и её актуализация приносит конкретную ценность, экономит время и устраняет дублирование работы. Отдельно хочу остановиться на таком моменте как автоматизация документации.",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Правила разработки документации ML-проекта",
        "url": "https://habr.com/ru/articles/676716/",
        "chunk": {
            "text": "вида документа и его целевой аудитории варьируется и лицо, поддерживающее документ. Кроме того, важно в целом создавать культуру ведения документации в компании, формировать понимание каждого члена компании, что документация и её актуализация приносит конкретную ценность, экономит время и устраняет дублирование работы. Отдельно хочу остановиться на таком моменте как автоматизация документации. Во-первых, чем меньше мы в целом делаем руками - тем меньше нужды в ручном написании документации. Например, если мы ставим эксперименты в джупитере или меняем данные руками в эксель-табличках, то и документацию нужно будет написать руками. А работа с эксперимент-трекером или БД с разметкой автоматически создаёт нужные артефакты. Помимо этого, есть разные инструменты, которые позволяют автоматизировать процесс создания и актуализация документации - Swagger, плагины для IDE, интерактивные датасет-карды (о них можно прочесть выше), DVC-пайплайны, методология docs-as-code. Качественная документация - залог возможности успешного масштабирования как разработки, так и бизнеса в целом. Что бы я предложил вам сделать уже сейчас? Провести аудит документации и по каждому документу ответить на вопросы из списка (можно найти в первой части статьи), сформировать бэклог техдолга по документации Провести аудит документации и по каждому документу ответить на вопросы из списка (можно найти в первой части статьи), сформировать бэклог техдолга по документации Создать единую точку входа в документации (если её еще нет) Создать единую точку входа в документации (если её еще нет) Оценить, для каких документов подходит методология docs-as-code, актуализацию каких документов можно автоматизировать Оценить, для каких документов подходит методология docs-as-code, актуализацию каких документов можно автоматизировать Собрать обратную связь от разных групп (ML-инженеры, пользователи, разметчики, бизнес и другие команды) Собрать обратную связь от разных групп (ML-инженеры, пользователи, разметчики, бизнес и другие команды) Тренироваться писать хорошие технические (и не только) тексты Тренироваться писать хорошие технические (и не только) тексты Если вы хотите узнать ещё больше об организации процессов ML-разработки, подписывайтесь на наш Телеграм-канал Варим ML .",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
        "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
        "chunk": {
            "text": "Всем привет! Меня зовут Герман Кравец, я больше десяти лет в IT. В МойОфис работаю руководителем группы Календаря в отделе разработки Mailion — это наша отказоустойчивая корпоративная почта для крупного бизнеса. В этой статье расскажу, как мы с командой искали новое решение для нашего API Gateway: зачем вообще понадобилось его менять, с какими проблемами столкнулись и как проходили все этапы — от первых «что-то идёт не так» до финального рефакторинга и запуска нового Gateway в прод. Будет немного боли, немного архитектуры и чуть-чуть магии. Если вам интересно, как решать нетривиальные задачи в продуктовой разработке, где стоит использовать готовые решения, а где всё писать вручную, или просто хочется узнать, как мы сократили простои на регрессе с 4–6 часов до пары минут, — добро пожаловать под кат! API Gateway — это единая точка входа для всех запросов, особенно когда в системе много микросервисов. Публиковать наружу порты каждого из них неудобно, да и с точки зрения безопасности и мониторинга это быстро превращается в хаос. Gateway решает эту проблему: он берёт на себя маршрутизацию, защиту и контроль трафика. Помимо этого, он помогает обрабатывать и модифицировать запросы на лету. В реальных системах это происходит постоянно: запросы нужно обогащать дополнительными метаданными, информацией о пользователе или клиенте, добавлять данные для статистики и аналитики. Gateway становится универсальным фильтром, через который проходит всё взаимодействие между клиентом и микросервисами. С его помощью также значительно упрощается аутентификация и авторизация: достаточно один раз проверить, имеет ли конкретный клиент доступ к нужному ресурсу, и дальше распространять эти права централизованно. Встроенные механизмы безопасности позволяют защитить систему от DDoS-атак, ограничить частоту запросов (Rate Limiting) и контролировать подозрительную активность. API Gateway отвечает и за наблюдаемость: через него проходят логи, метрики и трейсы, что делает анализ работы всей системы прозрачным. Главный плюс подхода в том, что внешний мир не зависит от внутренней архитектуры. Gateway предоставляет единый публичный контракт — по нему с нами интегрируются клиенты и смежные системы. При этом внутренняя структура может меняться сколько угодно: можно оптимизировать алгоритмы, переписывать сервисы или перестраивать связи между ними без риска что-то «сломать» для пользователя. Это основные фишки, которые будут важны для нашей истории, а дальше расскажу, как мы использовали API Gateway. Так у нас выглядела архитектура до того, как мы занялись поиском нового решения. С внешним миром API Gateway взаимодействует через HTTP и WebSockets, а внутри это набор плагинов, сгенерированных на основе прото-файлов, написанных вручную, и всей структуры системы. Когда мы начали искать новое решение, стало очевидно: плагинов накопилось прилично: раздача клиентской статики, работа с картинками, файлами, их было около восьми, не считая десятков вспомогательных. Всё общение между сервисами шло по gRPC, и таких сервисов в системе насчитывалось больше семидесяти. Их все нужно было как-то безопасно и стабильно опубликовать наружу. Как мы пришли к жизни такой? Проект Gateway мы начали разрабатывать примерно в 2017 году. Основным веб-сервисом выбрали Caddy — тогда это был довольно мощный инструмент с гибкой системой плагинов и возможностью писать свои. Мы вручную написали шестнадцать активных плагинов, по сути, шестнадцать отдельных репозиториев с разным уровнем вложенности и зависимостей. А вдобавок создали мощный инструмент, который генерировал эти плагины из proto. Можно сказать, что это был отдельный продукт, заточенный именно",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
        "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
        "chunk": {
            "text": "это был довольно мощный инструмент с гибкой системой плагинов и возможностью писать свои. Мы вручную написали шестнадцать активных плагинов, по сути, шестнадцать отдельных репозиториев с разным уровнем вложенности и зависимостей. А вдобавок создали мощный инструмент, который генерировал эти плагины из proto. Можно сказать, что это был отдельный продукт, заточенный именно под генерацию плагинов для Caddy. Почему в своё время сделали именно такой выбор, сейчас можно только предполагать — исходный владелец сервиса уже не работает в компании, а значит, остаётся только анализировать решения по следам кода. Вероятно, решающими факторами стали несколько моментов. Во-первых, поддержка HTTP/2 : мы активно используем gRPC и gRPC-стримы, в том числе на клиентской стороне, и наличие полноценной поддержки протокола тогда было критично. Во-вторых, модульность и возможность генерации плагинов . Инструмент действительно мощный, и такая гибкость на этапе активной разработки казалась идеальным решением. Третий аргумент — Go-ориентированность . Наши бэкендеры все пишут на Go, поэтому порог входа был минимальным. Нужно добавить кастомный функционал — просто написал плагин или форкнул нужный модуль. Ну и, наконец, раздача статики из коробки . Caddy справлялся с этим не хуже NginX, поэтому выбор выглядел вполне оправданным. Звучит классно… Так в чём же проблема? На практике начали всплывать проблемы — и их оказалось немало. Главная — bus-фактор : ключевые знания о сервисе ушли вместе с людьми, а владельца у компонента не осталось. Поверх этого наложились сильная связанность со статикой , самописные генераторы плагинов и аж шестнадцать дочерних репозиториев . Сборки занимали от тридцати до шестидесяти минут: каждый из репозиториев тянул за собой зависимые сборки и деплой. Конфигурация тоже доставляла боль. Caddy первой версии использует Caddyfile, нечто вроде псевдо-YAML, и работать с ним было сложно даже для опытных инженеров. Ситуацию усугубляли C++-зависимости, которые повышали порог вхождения в проект, замедляли скорость сборки как локально,так и в CI/CD. Когда мы собрали всё это воедино, стало ясно, что система достигла точки, где поддерживать её дальше уже дороже, чем переписать. Мы были слегка в шоке от масштабов накопившихся проблем и поняли, что пора что-то менять. На старте у нас были жёсткие ограничения по ресурсам: фичи горят, баги горят, а сверху ещё навалился огромный ком техдолга. Выделить под это отдельную команду не получилось, поэтому техдолгом занимался один backend-разработчик в низком приоритете, между коммитами в основной релиз и правками продовых багов. В помощь ему подключили DevOps-инженера — тоже не на full time, а по мере возможности. В такой конфигурации мы решили идти двумя параллельными путями. Первый — сложный: поискать альтернативы текущему решению и оценить, во что выльется миграция. Второй — попроще и побыстрее: разделить статику и API Gateway , чтобы хоть немного разгрузить систему и перестать таскать лишнее между сборками. По классике всё разворачивалось в Docker: внутри и Caddy, и наши статики. Вроде все логично и красиво, но смотришь глубже и взрыв мозга: статики запускаются постепенно, а потом вольюмами запихиваются в веб-сервис. Этот пайплайн ещё и в Jenkins, в общем, очень больно. Кроме того, любое изменение или push в одну из статик заставлял пересобираться их все и передеплоиваться полностью вместе с Gateway. То есть на регрессе, когда мы активно стабилизировали продукт, выкатывали фичи, догоняли код фриз и фича фриз, порядка 120 разработчиков фиксили",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
        "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
        "chunk": {
            "text": "пайплайн ещё и в Jenkins, в общем, очень больно. Кроме того, любое изменение или push в одну из статик заставлял пересобираться их все и передеплоиваться полностью вместе с Gateway. То есть на регрессе, когда мы активно стабилизировали продукт, выкатывали фичи, догоняли код фриз и фича фриз, порядка 120 разработчиков фиксили баги, пайплайн на всё это триггерился и API Gateway мог лежать 4-6 часов. От этого люто страдали команды FE, BE и QA. Мы решили отделить статику от Gateway и пошли по самому очевидному пути — взяли nginx в качестве базового образа для статики и заодно использовали его как балансировщик. Решение оказалось не только простым, но и прагматичным: nginx уже был согласован с ИБ и юристами, использовался в других командах, а значит — не требовал бюрократии. Инструмент популярный, сообщество большое, документация понятная, и самое главное, у нас уже были все нужные компетенции. Любой разработчик мог что-то поправить, а команда поддержки кастомизировать конфигурацию прямо на площадке заказчика. В итоге получилась архитектура, в которой впереди стоит nginx-балансировщик , за ним — API Gateway , а статики живут отдельно и разворачиваются независимо . Никаких вольюмов, никаких общих сборок — каждый компонент выкатывается сам по себе. Результат почувствовали сразу: мы начали работать по новым пайплайнам, по новой архитектуре, и снизили время deploy с 30 до 2 минут. И боли на регрессе прекратились, потому что пайплайны выкатки стали незаметными, а время простоя API Gateway снизилось до считанных минут. Мы — продуктовая компания, и у нас есть собственный отдел ИБ, который проверяет все продукты на уязвимости. У коллег есть свои инструменты для анализа, но они не всегда успевают за обновлениями языков и библиотек. Поэтому разрешение на использование новой версии Go мы получаем только тогда, когда их стек готов это переварить. В этот раз, наконец, дали добро на Go 1.21 . Отлично — побежали обновлять сервисы. Всё шло по плану: обновили зависимости, подтянули библиотеки, ничего критичного не меняли, код не трогали. Локальная сборка прошла, запускаем... и сразу ловим панику. Окей, так быть точно не должно, надо искать, где собака зарыта. Gateway у нас построен на Caddy v1 , а тот, в свою очередь, зависит от ряда библиотек. Проблема в том, что актуальная open-source версия qTLS поддерживает максимум Go 1.15 , и именно на этом уровне начинает рушиться ядро Caddy. Самое неприятное, что паника срабатывает не при компиляции, а только при запуске. Мы пошли в отладку и довольно быстро докопались до корня: знакомьтесь, функция init() в одной из библиотек. Внутри — проверки вроде structsEqual для нескольких структур. Если сравнить TLS из стандартной библиотеки с тем, что лежит внутри qTLS, то они совпадают буквально один в один. И сразу возникает закономерный вопрос: зачем вообще делать такое сравнение на этапе инициализации? Дальше ещё интереснее. Ошибка, которая валится в лог, указывает на несовпадение структур. Первое, на что мы наткнулись, — различие в количестве полей. На этом моменте стало ясно: заплатками это не вытащить. Нужно всё выносить, перепроверять зависимости и фактически перекапывать Gateway заново, чтобы перейти на новую версию Go и при этом не сломать прод. На момент начала работы у нас было 16 репозиториев, и уровень вложенности у некоторых доходил до шести. Каждый отвечал",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
        "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
        "chunk": {
            "text": "На этом моменте стало ясно: заплатками это не вытащить. Нужно всё выносить, перепроверять зависимости и фактически перекапывать Gateway заново, чтобы перейти на новую версию Go и при этом не сломать прод. На момент начала работы у нас было 16 репозиториев, и уровень вложенности у некоторых доходил до шести. Каждый отвечал за свой кусок плагинов и зависимостей. Казалось удобно — микросервисный подход, всё по науке. Но на практике это вылилось в настоящий CI/CD-кошмар. Пайплайн для одного репозитория занимал около пяти минут: сборка, тесты, сканеры безопасности — полный набор. А из-за вложенности одно изменение на самом нижнем уровне тянуло за собой цепочку пересборок. В итоге простая правка одной строчки кода могла превращаться в полчаса ожидания, пока вся цепочка отрабатывает. Cкорость вывода изменений в прод страдала, а разработчики страдали вместе с ней. Даже не говоря уже о случаях, когда на инфраструктуре что-то падало и весь CI/CD превращался в домино. В какой-то момент стало очевидно, что нужно выбираться из этого болота. Мы объединили всё в один репозиторий, убрав ненужную вложенность. Теперь каждый пайплайн стабильно выполняется за те же пять минут, но без накопительного эффекта. Всё стало проще, прозрачнее и быстрее. Радуемся, архитектуру поправили, идём дальше. Пора было искать альтернативы Caddy v1. Первым делом решили проверить очевидное — может, сам Caddy уже эволюционировал. Вбиваем в Google, открываем официальную документацию и сразу видим: есть вторая версия! Да ещё и с поддержкой Go 1.21. Отлично, наконец-то шанс обновиться без костылей. Начали разбираться. Архитектурно Caddy v2 похож на своего предшественника: тот же модульный подход, тот же Go под капотом, активная разработка. Появилась и приятная новинка — JSON-конфигурация. После их псевдо-YAML в первой версии это просто глоток свежего воздуха. Главный плюс JSON-конфига — возможность hot-reload: можно обновлять настройки плагинов на лету, без полного перезапуска сервиса. Захотел — подхватил новый конфиг, перезагрузил нужный модуль и продолжаешь работать. Красота. Казалось бы, решение найдено. Но, как обычно, без подводных камней не обошлось. Во-первых, bus-фактор никуда не делся. Один человек из всей команды (а нас больше сотни) изучит новый стек, разберётся в конфигурации, соберёт систему и станет единственной точкой знаний. Дальше классика: отпуск? нельзя. больничный? не вовремя. Горячая пора релиза, и этот человек буквально живёт в деплое. Такой сценарий недопустим, если мы хотим держать стабильный продукт. Во-вторых, документация у v2 — это боль . Два соседних плагина: у одного есть описание, у другого тишина. Конфигурации половины плагинов задокументированы только в формате JSON, другой половины только в Caddyfile, и между ними нет совместимости. Даже ключи параметров могут отличаться. Это сразу оборачивается проблемой поддержки: DevOps-ы и сопровождение не смогут быстро разобраться, а значит, продукт станет заложником своей сложности. Дальше, неприятное открытие. В Caddy v1 можно было сделать небольшой костыль: считать исходный config-файл и построчно проверить каждый параметр, вытащить сквозные ссылки между плагинами. В v2, с переходом на JSON, эту возможность убрали, вероятно, из соображений безопасности. В результате стало невозможно реализовать привычный контекст между модулями. И наконец — порядок инициализации . Если итоговый JSON-файл формируется генератором не в той последовательности, в какой планировалась загрузка модулей, сервис может повести себя непредсказуемо. Иногда просто меняешь два блока местами и всё, поведение при запуске другое. При нашей сложной связности между плагинами",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
        "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
        "chunk": {
            "text": "стало невозможно реализовать привычный контекст между модулями. И наконец — порядок инициализации . Если итоговый JSON-файл формируется генератором не в той последовательности, в какой планировалась загрузка модулей, сервис может повести себя непредсказуемо. Иногда просто меняешь два блока местами и всё, поведение при запуске другое. При нашей сложной связности между плагинами это недопустимо: сервис может стартовать «не так», а часть модулей просто отвалится. В Caddy v1 у нас была обёртка, которая обеспечивала единый контекст загрузки — в v2 такого механизма нет вообще. После всех экспериментов стало ясно: зачем страдать с коробочными решениями, которые вроде бы предлагают модульность, но по факту не вписываются в архитектуру нашего сервиса и плагинов? Мы пришли к очевидному выводу — проще и надёжнее написать своё решение с нуля, полностью подконтрольное команде. Тогда можно будет кастомизировать всё, что угодно, и не зависеть от чьей-то документации, обновлений или внезапных несовместимостей. Но тут важно не впасть в другую крайность — не делать «всё своё» руками. В начале статьи я уже упоминал, что раньше мы писали собственные генераторы, которые создавали плагины для Caddy прямо из прото-файлов на лету. Эти генераторы со временем разрослись до состояния отдельных монстров — по объёму кода они превосходили большинство наших микросервисов. Повторять эту историю не хотелось. Писать третий генератор, если завтра опять изменится вектор — это бессмысленный оверхед. Нам нужно было решение, где архитектура остаётся под контролем, но при этом есть готовый, устойчивый фреймворк с предсказуемой производительностью и зрелым сообществом. Ключевые критерии были простые: стабильность, высокая скорость обработки запросов, нормальные бенчмарки и адекватное поведение под нагрузкой. Пусть сейчас Gateway не был узким местом по RPS — мы хотели предусмотреть запас на будущее. Выбор в итоге пал на Fiber. Почему он, а не FastHTTP? Когда мы выбирали фреймворк, времени было в обрез: фичи горели, инфраструктура стояла на паузе, и писать низкоуровневую обвязку с нуля было просто некогда. FastHTTP, конечно, быстрый и мощный, но требует ручной сборки экосистемы вокруг — middleware, логирования, ошибок, хэндлеров. На это нужны недели, которых у нас не было. Fiber, наоборот, подошёл идеально по балансу «готовое / контролируемое». Это, по сути, аналог Express.js в мире Go: простой, понятный, с нормальной документацией и логичной архитектурой. Порог вхождения низкий — любой разработчик может быстро разобраться, а коллеги с фронтенда даже получили возможность при необходимости зайти, поправить заголовки или плагин вручную, не залезая в дебри бэкенда. Fiber оказался лаконичным и предсказуемым, а документация — человеческой: всё описано, читается легко, без копания в исходниках. Построив архитектуру на нём, мы сразу выиграли в читаемости и поддерживаемости кода. Плюс, JSON-конфигурация у Fiber оказалась очень близка к тому, как устроены наши остальные gRPC-сервисы. В Caddy-файлах синтаксис был уникальный и никак не стыковался с инфраструктурой продукта, а тут всё единообразно: те же структуры, те же подходы. Это важно не только для разработчиков, но и для DevOps-ов и сопровождения — всё знакомо, всё на автомате. Мы не изобретаем велосипед, а просто берём то, что уже хорошо работает у соседей. Начали тестировать и сразу влетели в проблему. Мы активно используем стримы, и примерно половина клиентских запросов работает именно через них. Первые тесты шли нормально: запросы отрабатывали, ответы возвращались, всё красиво. Но потом — бах. На десятом,",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
        "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
        "chunk": {
            "text": "Мы не изобретаем велосипед, а просто берём то, что уже хорошо работает у соседей. Начали тестировать и сразу влетели в проблему. Мы активно используем стримы, и примерно половина клиентских запросов работает именно через них. Первые тесты шли нормально: запросы отрабатывали, ответы возвращались, всё красиво. Но потом — бах. На десятом, пятидесятом или сотом запросе (зависело от случая) страница переставала отвечать. Проверяем — сервис упал в панику. Проблема воспроизводилась хаотично: иногда с первого запроса, иногда только после сотого. Разбор показал: Fiber не поддерживает HTTP/2, а у нас стримы как раз шли поверх него, через обвязку gRPC Gateway. В результате — несовпадение дескрипшенов запросов на уровне ядра net/http, и сервер просто рушился. На этом этапе стало ясно: починить такое в лоб не получится. Мы снова оказались у развилки и пошли искать другой фреймворк, который умеет работать с HTTP/2 из коробки. Когда начали искать фреймворк с нормальной поддержкой HTTP/2, вариантов оказалось не так уж много. После серии тестов и чтения исходников остановились на Gin. Из всех кандидатов у него оказались лучшие документация и комьюнити, внятная архитектура и богатый набор middleware из коробки. Порог вхождения низкий даже для тех, кто раньше с ним не работал. Да, по RPS Gin немного проседает по сравнению с Fiber, но для нас это не критично: Gateway никогда не был узким местом по производительности, зато стабильность и поддерживаемость для нас приоритет. Интегрировав Gin, запустили всё прекрасно. Но наши приключения на этом не закончились. Разработчику всегда попадётся на глаза что-то, что нужно подрефачить. У нас было большое дублирование соединений. Каждый плагин по идеологии Caddy — это инкапсулированная, изолированная единица. Поэтому, чтобы прокинуть наши gRPC-соединения, их приходилось дублировать в каждом плагине и каждой конфигурации, хотя по факту все они стучались в один и тот же сервис. Мы сделали единую точку — фабрику соединений, которая по запросу «дай мне соединение к такому-то сервису» проверяет: если соединения нет — создаёт его, если есть — просто переиспользует и отдаёт плагину. Так мы сократили количество соединений по ключевым сервисам с восьми до одного, что в будущем заметно снизит нагрузку. C++-зависимость была нашей болью на протяжении всего существования Gateway. Это одна из причин, почему при виде задач по этому проекту разработчики думали: «О нет, только не он». Ни нормального readme, ни инструкций: запускаешь и получаешь сообщение «Отдай мне библиотеку». На Linux это ещё можно было пережить — где-то в Confluence можно найти, что именно нужно поставить. А вот на Mac библиотек просто нет, и приходилось проходить через эту боль вручную. Разобравшись, откуда растут ноги, я выяснил, что у нас есть плагин для работы с аватарками, который тянул зависимость соседнего модуля, тоже работающего с аватарками. А у соседа под капотом жила библиотека libmagic, используемая для изменения размеров, кропов и прочих операций с изображениями. В коде всё выглядело просто: интерфейс, конструктор и обработчик запроса. В конструктор подтягивался дочерний модуль соседа, и тот — libmagic. Обработчик же делал запрос к соседнему сервису, получал данные и отдавал их клиенту. Мы посмотрели внимательнее — действительно ли всё это нужно, ведь мы работаем по gRPC? Открыли прото соседа и обнаружили метод, который полностью закрывал нашу потребность. Мы удалили зависимость, переписали обработчик так, чтобы он",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
        "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
        "chunk": {
            "text": "и тот — libmagic. Обработчик же делал запрос к соседнему сервису, получал данные и отдавал их клиенту. Мы посмотрели внимательнее — действительно ли всё это нужно, ведь мы работаем по gRPC? Открыли прото соседа и обнаружили метод, который полностью закрывал нашу потребность. Мы удалили зависимость, переписали обработчик так, чтобы он просто вызывал этот метод через gRPC-стрим, и всё заработало. 40–50 строк кода заменились несколькими строками, ушла боль с C++, сборка стала заметно быстрее, а настройка проще. Теперь проект собирается чистым Go, без лишних зависимостей, а разработчики наконец могут просто запустить, скомпилировать и работать без шаманства. Первое, что мы почувствовали, — ушёл bus-фактор . Теперь любой бэкенд-разработчик в команде может спокойно запустить наш Gateway локально и разобраться, как он работает. Никаких «коробочных» ограничений, странных зависимостей и «магии». Код открыт, структурирован, модули логично разбиты по бизнес-областям. Если нужно что-то поправить — просто проваливаешься в нужный блок и сразу понимаешь, где внести изменения. Конфигурация стала лаконичной и унифицированной . Теперь она полностью соответствует подходам, принятым в других наших сервисах: понятна разработчикам, девопсам и поддержке. Раньше конфиг-файл старого Gateway был настоящей болью — около трёх тысяч строк ручного кода. В нём нужно было заполнять параметры для всех плагинов сразу: нельзя было отключить ненужные, даже если они не использовались при инициализации. Некоторые плагины требовали интеграции с NATS и другими инфраструктурными зависимостями, поэтому любое изменение превращалось в мучение. Генератора не было вовсе: сервис был «белой вороной», особенным и непонятным. Теперь всё иначе. Мы собрали локальный конфиг из примерно 200 строк — только базовые блоки: HTTP, аутентификация и авторизация. Всё остальное стало управляемым: если плагин нужен, то включаешь его в конфиг, не нужен — просто не указываешь. Плагины раньше не знали об общих блоках и дублировали кучу кода. Мы решили это с помощью механизма мёржа . Теперь достаточно указать дефолтное соединение с gRPC-балансировщиком, а Gateway сам подхватывает недостающие настройки. Если конфиг для конкретного сервиса пустой, он подставляет базовые параметры: ключи, таймауты, адреса — и спокойно ходит к балансировщику с готовыми данными. Это позволило заметно сократить размер конфигурации и сделать её человекочитаемой. Архитектура упростилась, а вместе с ней и процесс разработки. Всё стало прозрачнее, быстрее и предсказуемее. Мы также интегрировались с корпоративным PaaS-решением , которое коллеги из другой команды используют для централизованной работы с логами и трейсам. Раньше Gateway мешал полноценной интеграции: именно он был входной точкой для трейсов, а из-за ограничений старой версии Go мы не могли подключить нужные SDK. После обновления языка и переписывания Gateway мы наконец подтянули нужный пакет и успешно встали в общую систему мониторинга. И, наконец, мы избавились от CVE . История получилась показательной. Пока мы активно рефакторили Gateway, не спешили его выкатывать в релизы — и вовремя: через один релиз коллеги из ИБ сообщили, что найденные уязвимости в Go 1.19 получили критичный статус. Это означало риск блокировки релиза. К счастью, к тому моменту мы уже были готовы с новой версией Gateway и в следующий релиз ушли в прод именно с ним, полностью закрыв проблему. Такой вот получился тернистый, но очень полезный путь. Мы переписали Gateway почти с нуля, избавились от боли, старых зависимостей и хаоса в конфигах, а заодно укрепили связь между командами и",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Так у вас статика вольюмами маунтится! И другие весёлые приключения в поисках нового Gateway на Go",
        "url": "https://habr.com/ru/companies/ncloudtech/articles/965576/",
        "chunk": {
            "text": "уже были готовы с новой версией Gateway и в следующий релиз ушли в прод именно с ним, полностью закрыв проблему. Такой вот получился тернистый, но очень полезный путь. Мы переписали Gateway почти с нуля, избавились от боли, старых зависимостей и хаоса в конфигах, а заодно укрепили связь между командами и встроились в экосистему компании гораздо плотнее. Если интересно узнать больше — пишите в комментариях, с удовольствием расскажу детали и подводные камни. А если вам близка тематика масштабных инфраструктурных решений, распределённых систем и высоконагруженных сервисов — заходите в наши вакансии . Будем рады пообщаться с теми, кто хочет строить такие же сложные и красивые системы вместе с нами.",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Автоматизация рутинных задач на VPS с помощью cron и скриптов",
        "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
        "chunk": {
            "text": "Мы каждый день сталкиваемся со множеством однотипных задач. Постоянно возвращаясь к ним, мы расходуем самый ценный ресурс — время. В итоге застреваем в рутине, рискуем не уложиться в сроки и совершить ошибку. Но можно остановиться и передать повторяющуюся работу тому, кто не забудет и не промахнётся. Нас спасёт автоматизация! Сегодня расскажем о том, как автоматизировать рутинные задачи на Linux-сервере при помощи cron и немного с помощью скриптов. Cron — стандартный планировщик в Unix-подобных операционных системах. Он работает как фоновый демон: непрерывно следит за расписанием и в нужный момент запускает указанную команду или скрипт. Cron — от греческого «χρόνος» (chronos) — время. Он появился в Unix ещё в 1970-х и с тех пор не потерял своей значимости в администрировании систем. Cron запускает задачу с точностью до минуты. Его расписание может быть очень гибким: от «каждую минуту» до «один раз в год». Cron может иметь отдельные планы заданий для каждого пользователя системы, и после настройки он работает автономно и не требует вмешательства пользователя. По факту, любую повторяющуюся задачу, которую вы делаете вручную по расписанию, можно автоматизировать через cron. Любую на Linux. Почти любую. Для работы с cron используется утилита crontab, которая управляет таблицей заданий для текущего пользователя. В основных Linux-системах каждый пользователь может иметь собственный crontab, независимый от других. А может и не иметь, ведь crontab создаётся только тогда, когда пользователь впервые запускает команду: Данная команда открывает файл задач в текстовом редакторе, обычно это — vi или nano, и после сохранения cron сразу же подхватывает изменения без перезапуска сервиса. Задание в cron задаётся в следующем формате: Звёздочку (*) система воспринимает как любое значение, то есть задание будет выполняться при каждом значении соответствующего поля. Кроме звёздочки, поля в задании могут содержать: одно какое-либо число, например, 29 или 6; одно какое-либо число, например, 29 или 6; диапазон чисел, например, 1-4, то есть все значения от 1 до 4 включительно из диапазона, допустимого для данного поля; диапазон чисел, например, 1-4, то есть все значения от 1 до 4 включительно из диапазона, допустимого для данного поля; список чисел, например, 2,5,6; список чисел, например, 2,5,6; шаг, например, */5 означает каждые 5 единиц, начиная с минимального значения. шаг, например, */5 означает каждые 5 единиц, начиная с минимального значения. Здесь есть некоторые неочевидные для новичков тонкости. Например, дни недели могут принимать значения от 0 до 7. Не от одного, а от нуля. В итоге получается целых 8 значений, а дней недели — всего 7. Почему так? Потому что в cron два воскресенья — 0 и 7. Дело в том, что в старых его реализациях для воскресенья использовался 0, но чтобы упростить совместимость с ISO-стандартом, позже разрешили ещё и 7 для обозначения воскресного дня. Или, вот шаг. В нём число после знака / определяет, через сколько единиц значений будет выполняться задание, начиная с минимально допустимого в этом поле значения. Например, /10 для минут будет означать, что задание будет выполняться в минимально возможное количество минут, а затем каждые +10 пока не закончится нумерация минут в пределах часа. То есть, данная запись означает выполнение задания в 0, 10, 20, 30, 40 и 50 минут означенного часа. В отношении часов такая запись означает запуск задачи",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Автоматизация рутинных задач на VPS с помощью cron и скриптов",
        "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
        "chunk": {
            "text": "минут будет означать, что задание будет выполняться в минимально возможное количество минут, а затем каждые +10 пока не закончится нумерация минут в пределах часа. То есть, данная запись означает выполнение задания в 0, 10, 20, 30, 40 и 50 минут означенного часа. В отношении часов такая запись означает запуск задачи в 0 (полночь), 10 и 20 часов означенных суток. Для дней месяца минимальным значением является 1 — первый день месяца. Это означает. что запись /10 в третьей слева позиции инициирует выполнение задачи в первый день месяца, а затем в каждый +10-й день, пока не закончится месяц — 11, 21 и 31-е число, при условии, что последнее значение присутствует в нумерации текущего месяца. Аналогично для месяцев: /10 означает 1-й и 11-й месяцы, то есть январь и ноябрь. Применительно к дням недели запись /10 не имеет практического смысла, так как диапазон значений здесь ограничен числами от 0 до 7, то есть всего восемь возможных значений. Таким образом, шаг 10 превышает длину диапазона, и задание будет выполняться только для минимального значения, то есть для 0 — воскресенья. Здесь важно понимать, что указанное в шаге число не означает каждые x единиц времени от последнего запуска или от текущего момента, а определяет выполнение задачи каждые x значений поля от его минимального значения. Это мы рассмотрели запись */10. А ведь можно вместо звёздочки использовать число, например, 3/10. Такая запись означает, что планировщик будет прибавлять 10, но уже не к минимальному значению, а к значению 3. То есть, для минут задание будет выполняться в 3, 13, 23, 33, 43, 53 минуты; для часов и чисел месяца — в 3, 13, 23; для месяцев и дней недели — только в 3 (март или среда). Для некоторых значений времени в cron существуют специальные директивы: @yearly или @annually означает один раз в год и заменяет собой комбинацию 0 0 1 1 * , то есть в 00:00 1 января каждого года; @yearly или @annually означает один раз в год и заменяет собой комбинацию 0 0 1 1 * , то есть в 00:00 1 января каждого года; @monthly — раз в месяц, заменяет комбинацию 0 0 1 * * , то есть в 00:00 первого числа каждого месяца; @monthly — раз в месяц, заменяет комбинацию 0 0 1 * * , то есть в 00:00 первого числа каждого месяца; @weekly — раз в неделю, заменяет комбинацию 0 0 * * 0 и означает каждое воскресенье в 00:00; @weekly — раз в неделю, заменяет комбинацию 0 0 * * 0 и означает каждое воскресенье в 00:00; @daily или @midnight — раз в день, заменяет комбинацию 0 0 * * * и означает в полночь каждый день; @daily или @midnight — раз в день, заменяет комбинацию 0 0 * * * и означает в полночь каждый день; @hourly — догадайтесь сами :-) (ответ — ноль и четыре звёздочки). @hourly — догадайтесь сами :-) (ответ — ноль и четыре звёздочки). Есть ещё одна полезная директива — @reboot . Она позволяет выполнять указанную команду один раз при запуске системы. Полезность данной директивы заключается в том, что она не зависит от времени или дня и запускается только",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Автоматизация рутинных задач на VPS с помощью cron и скриптов",
        "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
        "chunk": {
            "text": "ноль и четыре звёздочки). @hourly — догадайтесь сами :-) (ответ — ноль и четыре звёздочки). Есть ещё одна полезная директива — @reboot . Она позволяет выполнять указанную команду один раз при запуске системы. Полезность данной директивы заключается в том, что она не зависит от времени или дня и запускается только при перезагрузке или старте сервера. Ну если разобрались с форматом записи месяцев, дней, часов и минут, то в шестом поле указываем команду, которая должна выполняться в указанное время. Что можно использовать в качестве команды? Во-первых, любые shell-команды: ls , cp , rm и т.д. Во-вторых, скрипты: bash, python, php и т.п. В-третьих, исполняемые файлы. А также, цепочки команд с операторами &&, ||, ; и перенаправление вывода типа > , >> , 2>&1 . Из важных моментов можно отметить следующее: всегда используйте полные абсолютные пути к скриптам и файлам, в противном случае cron не всегда сможет их отыскать. И ещё — старайтесь логировать вывод. Поверьте, это пригождается чаще, чем хотелось бы. Основное назначение cron — делегирование системе задач, для выполнения которых можно использовать расписание, чтобы разгрузить администратора данной системы, оградив его от определённого количества рутинной работы. Давайте рассмотрим некоторые типы и примеры задач, решить которые может помочь cron. Обсуждение важности создания резервных копий чего бы то ни было, наверное, уже набило оскомину. И хотя cron и не является полноценным инструментом бэкапирования, но всё же с его помощью можно кое-что реализовать, поскольку расписание плюс копирование это и есть несложное решение для подобной задачи. Например: Такая строка в cron представляет собой пример ежедневного создания дампа базы данных MySQL или MariaDB с сохранением его в директории /backup/ под именем, частью которого будет текущая дата. Это, чтобы можно было понять, когда этот бэкап сделан. Ещё один пример — еженедельное создание tar-архива каталога /var/www/html/ , в котором, вероятно, находятся файлы веб-сайта. 0 в пятой позиции означает запуск команды каждое воскресенье, а имя архива, как и в предыдущем примере, будет содержать дату архивирования данных: Подобным же образом при помощи rsync — утилиты для быстрой и надёжной синхронизации файлов и каталогов, можно с определённой периодичностью копировать данные из одной Linux-системы в другую: Прелесть данной утилиты в том, что она копирует только изменённые данные, что позволяет экономить трафик и время. Конкретно в этой команде: /important/data/ — каталог, содержимое которого подлежит синхронизации с удалённым ресурсом. Обратите внимание на слэш в конце: он означает, что копировать нужно только содержимое каталога, а не сам каталог. /important/data/ — каталог, содержимое которого подлежит синхронизации с удалённым ресурсом. Обратите внимание на слэш в конце: он означает, что копировать нужно только содержимое каталога, а не сам каталог. remote-user@192.168.0.11:/backup/ — место назначения, где: remote-user — это имя пользователя на удалённой системе; 192.168.0.11 — IP-адрес удалённой системы; /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. remote-user@192.168.0.11:/backup/ — место назначения, где: remote-user — это имя пользователя на удалённой системе; remote-user — это имя пользователя на удалённой системе; 192.168.0.11 — IP-адрес удалённой системы; 192.168.0.11 — IP-адрес удалённой системы; /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. На VPS всё",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Автоматизация рутинных задач на VPS с помощью cron и скриптов",
        "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
        "chunk": {
            "text": "на удалённой системе; remote-user — это имя пользователя на удалённой системе; 192.168.0.11 — IP-адрес удалённой системы; 192.168.0.11 — IP-адрес удалённой системы; /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. /backup/ — директория на удалённом узле, в который будет помещено содержимое исходного каталога. На VPS всё это особенно актуально: регулярные дампы, архивация и перенос данных между серверами — типичная практика. На виртуальных серверах UltraVDS , например, можно настроить такие задачи буквально за несколько минут. Это — ещё одно направление в администрировании Linux-систем, где использование планировщика является частью повседневности. При работе операционной системы, служб и приложений появляются и накапливаются временные файлы, которые создаются при установке, обновлении или обработке данных, и после выполнения своей задачи зачастую становятся бесполезными. Ниже — пример простенького скрипта, который удаляет из каталога /tmp файлы, не изменявшиеся больше семи дней: Такая запись в cron позволит запускать этот скрипт раз в сутки: Можно обойтись и без скрипта, записав команду удаления файлов сразу в cron: То же относится к логам — записям о событиях, ошибках и действиях системы. Логи полезны для диагностики, но со временем становятся слишком объёмными и могут занимать полезное пространство. Так может выглядеть задача по еженедельному удалению старых лог-файлов в директории /var/log. Здесь опция -mtime +30 говорит нам, что необходимо найти и удалить файлы старше тридцати дней: Или вот кэш — временное хранилище данных, которое призвано ускорить загрузку приложения, но по прошествии времени в нём накапливается много устаревших и ненужных данных. Пример ниже — ежедневное принудительное удаление содержимого кэш-директории условного приложения app: Планировщик cron в том числе можно использовать как простейший инструмент мониторинга системы. Например, так можно настроить периодическую отправку отчёта об использовании дискового пространства на электронную почту администратора: Правда, чтобы отправка писем действительно работала, сервер нужно заранее настроить — почтовая система должна понимать, куда и каким способом доставлять сообщения. Мониторинг используется не только как внимательный наблюдатель за состоянием сервисов и процессов. При помощи планировщика и несложного скрипта можно попытаться своевременно, или почти своевременно, поднять упавшую службу. Например, следующим образом каждые 10 минут cron проверяет, запущена ли служба Nginx, и если не запущена — перезапускает её: Классическая задача для cron — обновление бесплатного SSL-сертификата от Let's Encrypt с использованием Certbot. Как правило, такой сертификат выдаётся на 90 дней и перед истечением данного срока его нужно обновить, чтобы сайт продолжал быть доступным через HTTPS. Certbot — это утилита, которая позволяет автоматизировать процесс получения и продления SSL-сертификата от Let's Encrypt. Для проверки срока действия сертификата и его обновления в Certbot используется cron. Официальная документация Let's Encrypt рекомендует запускать проверку дважды в день, что должно гарантировать обновление сертификата даже при временном отсутствии интернета. Здесь: certbot renew — команда, которая пытается обновить SSL-сертификаты Let’s Encrypt, срок которых подходит к концу; certbot renew — команда, которая пытается обновить SSL-сертификаты Let’s Encrypt, срок которых подходит к концу; --quiet — опция, определяющая запуск команд в «тихом» режиме, то есть без вывода сообщений; --quiet — опция, определяющая запуск команд в «тихом» режиме, то есть без вывода сообщений; --deploy-hook — команда, которая выполнится только при успешном обновлении сертификата — перезапустит конфигурацию веб-сервера, в данном случае Nginx, чтобы он применил новый сертификат. --deploy-hook — команда,",
            "metadata": {}
        }
    },
    {
        "source_type": "habr",
        "document_title": "Автоматизация рутинных задач на VPS с помощью cron и скриптов",
        "url": "https://habr.com/ru/companies/ultravds/articles/972942/",
        "chunk": {
            "text": "запуск команд в «тихом» режиме, то есть без вывода сообщений; --quiet — опция, определяющая запуск команд в «тихом» режиме, то есть без вывода сообщений; --deploy-hook — команда, которая выполнится только при успешном обновлении сертификата — перезапустит конфигурацию веб-сервера, в данном случае Nginx, чтобы он применил новый сертификат. --deploy-hook — команда, которая выполнится только при успешном обновлении сертификата — перезапустит конфигурацию веб-сервера, в данном случае Nginx, чтобы он применил новый сертификат. Ещё один популярный сценарий для cron — автоматическая обработка данных. Например, регулярная генерация разных отчётов без вашего участия. Вместо ежедневной или еженедельной ручной сборки данных можно создать скрипт, который будет выполнять такую задачу, и автоматизировать процесс при помощи расписания. Примером могут послужить ежедневные отчёты, которые необходимо собирать в нерабочее время — до начала или, наоборот, после окончания рабочего дня. Сюда же можно отнести различную периодическую аналитику или статистику за определённый регулярно повторяющийся период. Такой отчёт, как правило, сохраняется в файл для последующей отправки на email, загрузки на файлообменник или ещё куда-либо. Python-скрипт, допустим, собирает данные из SQLite: Потом формирует текстовый отчёт и отправляет его на электронную почту: Запуск задачи поручаем cron — в 8 утра каждый понедельник: Кроме команды crontab -e , упомянутой в самом начале, при работе с планировщиком будут полезны инструменты командной строки, как, например, просмотр текущих задач: Команда выводит список всех запланированных заданий для текущего пользователя. Удобно, например, для того, чтобы убедиться в корректном добавлении задачи. Для удаления всех заданий запускаем: Команда полностью очищает crontab текущего пользователя. Поэтому используйте её осторожно, при выполнении команды не выводится никаких подтверждений. Команда для просмотра логов cron выглядит как: Вывод показывает записи о событиях при запуске задач cron. Потратив немного времени на настройку и проверку заданий для планировщика, мы получаем отличный бонус — больше не нужно вручную выполнять однообразные задачи и переживать, что что-то пойдёт не так. Теперь всё происходит по расписанию и без лишних нервов. Так мы постепенно переключаемся с вечного «тушения пожаров» на спокойное, продуманное управление. А своё время наконец можно потратить на то, что действительно требует человеческих мозгов или творчества.",
            "metadata": {}
        }
    }
]