# README

Проект — система подготовки к IT-собеседованиям. Пользователь задаёт вопрос по теме, система извлекает релевантные фрагменты из базы знаний (RAG) и генерирует ответ с опорой на источники (ссылки). Поверх RAG запускается агент (потенциально мультиагентный), который умеет планировать шаги: уточнить запрос, расширить поиск, собрать ответ и проверить качество.

## Быстрый старт

1. **Создание файла .env**
    
    ```
    DEEPSEEK_API_KEY=sk-ваш-проплаченный-api-ключ
    ```
    Файл должен лежать в корне проекта.

---

2. **Сборка Docker-образа**
    
    ```
    docker compose up -d --build
    ```
    Собирает локальный образ baseline_rag на основе Dockerfile.

3. **Запуск контейнера**
    
    ```
    docker compose exec rag bash
    ```
    - Использует переменные окружения из файла .env (обязателен рабочий DEEPSEEK_API_KEY).
    - Монтирует текущую директорию в контейнер (/app).
    - Запускает интерактивный bash.


**Контейнер открывает bash**, готовый для запуска inference, обработки файлов или работы с вашим RAG-пайплайном по материалам дела Эпштейна. Для минимального Dockerfile или шаблона .env обращайтесь — будет предоставлен самый короткий пример.

---

**Вопросы по настройке и дополнительной автоматизации приветствуются!**

## Архитектура


### Компоненты

- **Ingestion / Indexing**
  - Чанкование документов
  - Векторизация чанков
  - Сохранение:
    - FAISS индекс
    - метаданные чанка (source, url, title, другая полезная информация)

- **Retrieval**
  - Векторизация запроса
  - `top-k` поиск в FAISS
  - (опционально) rerank / diversity / фильтры по метаданным

- **Generation (DeepSeek)**
  - Промпт: вопрос + контекст (чанки) + инструкции по цитированию
  - Вывод: структурированный ответ + список источников

- **Agent layer**
  - Планировщик решает, нужно ли:
    - переформулировать запрос
    - сделать повторный retrieval с другим `k`
    - запросить “подтемы”
    - собрать финальный ответ
  - Инструменты агента: `retrieve()`, `generate()`, `judge()`, `log()`

### Взаимодействие компонентов

1) Пользователь задаёт вопрос  
2) Агент строит план → вызывает retrieval  
3) Retriever возвращает чанки + метаданные  
4) Context Builder собирает контекст (с ограничением токенов)  
5) Generator формирует ответ и привязывает утверждения к источникам  
6) Judge оценивает ответ, агент при необходимости делает ещё один цикл  

### Зависимости

См. `requirements.txt` (Python зависимости) + `Dockerfile` (среда запуска).  
Ключевые библиотеки: FAISS (векторный поиск), библиотека эмбеддингов, клиент LLM (DeepSeek API), утилиты для чанкинга/парсинга, eval (LLM-as-Judge).

